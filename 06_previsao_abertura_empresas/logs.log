2023-06-12 14:52:45,142:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 14:52:45,143:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 14:52:45,143:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 14:52:45,143:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 14:52:46,728:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-12 15:02:50,945:INFO:PyCaret RegressionExperiment
2023-06-12 15:02:50,945:INFO:Logging name: reg-default-name
2023-06-12 15:02:50,945:INFO:ML Usecase: MLUsecase.REGRESSION
2023-06-12 15:02:50,945:INFO:version 3.0.2
2023-06-12 15:02:50,945:INFO:Initializing setup()
2023-06-12 15:02:50,945:INFO:self.USI: 564b
2023-06-12 15:02:50,945:INFO:self._variable_keys: {'_ml_usecase', 'fold_groups_param', 'target_param', 'y', 'gpu_n_jobs_param', 'fold_shuffle_param', 'exp_name_log', 'gpu_param', 'logging_param', 'log_plots_param', 'html_param', 'seed', 'X_test', 'data', 'idx', '_available_plots', 'exp_id', 'memory', 'fold_generator', 'pipeline', 'X_train', 'y_train', 'y_test', 'n_jobs_param', 'transform_target_param', 'USI', 'X'}
2023-06-12 15:02:50,945:INFO:Checking environment
2023-06-12 15:02:50,945:INFO:python_version: 3.10.9
2023-06-12 15:02:50,946:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-06-12 15:02:50,946:INFO:machine: AMD64
2023-06-12 15:02:50,946:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-12 15:02:50,946:INFO:Memory: svmem(total=16901767168, available=5871259648, percent=65.3, used=11030507520, free=5871259648)
2023-06-12 15:02:50,946:INFO:Physical Core: 4
2023-06-12 15:02:50,946:INFO:Logical Core: 8
2023-06-12 15:02:50,946:INFO:Checking libraries
2023-06-12 15:02:50,946:INFO:System:
2023-06-12 15:02:50,946:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-06-12 15:02:50,946:INFO:executable: C:\Users\lapei\anaconda3\python.exe
2023-06-12 15:02:50,946:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-12 15:02:50,946:INFO:PyCaret required dependencies:
2023-06-12 15:02:50,947:INFO:                 pip: 22.3.1
2023-06-12 15:02:50,947:INFO:          setuptools: 65.6.3
2023-06-12 15:02:50,947:INFO:             pycaret: 3.0.2
2023-06-12 15:02:50,947:INFO:             IPython: 8.10.0
2023-06-12 15:02:50,947:INFO:          ipywidgets: 7.6.5
2023-06-12 15:02:50,947:INFO:                tqdm: 4.64.1
2023-06-12 15:02:50,947:INFO:               numpy: 1.23.5
2023-06-12 15:02:50,947:INFO:              pandas: 1.5.3
2023-06-12 15:02:50,947:INFO:              jinja2: 3.1.2
2023-06-12 15:02:50,947:INFO:               scipy: 1.10.0
2023-06-12 15:02:50,947:INFO:              joblib: 1.2.0
2023-06-12 15:02:50,947:INFO:             sklearn: 1.2.1
2023-06-12 15:02:50,947:INFO:                pyod: 1.0.9
2023-06-12 15:02:50,947:INFO:            imblearn: 0.10.1
2023-06-12 15:02:50,947:INFO:   category_encoders: 2.6.1
2023-06-12 15:02:50,947:INFO:            lightgbm: 3.3.5
2023-06-12 15:02:50,948:INFO:               numba: 0.56.4
2023-06-12 15:02:50,948:INFO:            requests: 2.28.1
2023-06-12 15:02:50,948:INFO:          matplotlib: 3.7.0
2023-06-12 15:02:50,948:INFO:          scikitplot: 0.3.7
2023-06-12 15:02:50,948:INFO:         yellowbrick: 1.5
2023-06-12 15:02:50,948:INFO:              plotly: 5.9.0
2023-06-12 15:02:50,948:INFO:             kaleido: 0.2.1
2023-06-12 15:02:50,948:INFO:         statsmodels: 0.13.5
2023-06-12 15:02:50,948:INFO:              sktime: 0.17.0
2023-06-12 15:02:50,948:INFO:               tbats: 1.1.3
2023-06-12 15:02:50,948:INFO:            pmdarima: 2.0.3
2023-06-12 15:02:50,948:INFO:              psutil: 5.9.0
2023-06-12 15:02:50,948:INFO:PyCaret optional dependencies:
2023-06-12 15:02:50,987:INFO:                shap: 0.41.0
2023-06-12 15:02:50,987:INFO:           interpret: Not installed
2023-06-12 15:02:50,987:INFO:                umap: Not installed
2023-06-12 15:02:50,988:INFO:    pandas_profiling: Not installed
2023-06-12 15:02:50,988:INFO:  explainerdashboard: Not installed
2023-06-12 15:02:50,988:INFO:             autoviz: Not installed
2023-06-12 15:02:50,988:INFO:           fairlearn: Not installed
2023-06-12 15:02:50,988:INFO:             xgboost: 1.7.3
2023-06-12 15:02:50,988:INFO:            catboost: Not installed
2023-06-12 15:02:50,988:INFO:              kmodes: Not installed
2023-06-12 15:02:50,988:INFO:             mlxtend: Not installed
2023-06-12 15:02:50,988:INFO:       statsforecast: Not installed
2023-06-12 15:02:50,988:INFO:        tune_sklearn: Not installed
2023-06-12 15:02:50,988:INFO:                 ray: Not installed
2023-06-12 15:02:50,988:INFO:            hyperopt: Not installed
2023-06-12 15:02:50,988:INFO:              optuna: Not installed
2023-06-12 15:02:50,988:INFO:               skopt: 0.9.0
2023-06-12 15:02:50,988:INFO:              mlflow: Not installed
2023-06-12 15:02:50,988:INFO:              gradio: Not installed
2023-06-12 15:02:50,988:INFO:             fastapi: Not installed
2023-06-12 15:02:50,988:INFO:             uvicorn: Not installed
2023-06-12 15:02:50,988:INFO:              m2cgen: Not installed
2023-06-12 15:02:50,988:INFO:           evidently: Not installed
2023-06-12 15:02:50,988:INFO:               fugue: Not installed
2023-06-12 15:02:50,988:INFO:           streamlit: Not installed
2023-06-12 15:02:50,988:INFO:             prophet: Not installed
2023-06-12 15:02:50,988:INFO:None
2023-06-12 15:02:50,988:INFO:Set up data.
2023-06-12 15:02:51,098:INFO:Set up train/test split.
2023-06-12 15:02:51,104:INFO:Set up index.
2023-06-12 15:02:51,104:INFO:Set up folding strategy.
2023-06-12 15:02:51,104:INFO:Assigning column types.
2023-06-12 15:02:51,107:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-12 15:02:51,107:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-12 15:02:51,110:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-12 15:02:51,114:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-12 15:02:51,158:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-12 15:02:51,195:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 15:02:51,196:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-12 15:02:51,530:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:02:51,530:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-12 15:02:51,533:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-12 15:02:51,537:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-12 15:02:51,580:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-12 15:02:51,615:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 15:02:51,615:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-12 15:02:51,617:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:02:51,617:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-06-12 15:02:51,621:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-12 15:02:51,624:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-12 15:02:51,668:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-12 15:02:51,703:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 15:02:51,703:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-12 15:02:51,705:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:02:51,709:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-12 15:02:51,713:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-12 15:02:51,758:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-12 15:02:51,792:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 15:02:51,792:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-12 15:02:51,794:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:02:51,795:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-06-12 15:02:51,801:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-12 15:02:51,846:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-12 15:02:51,881:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 15:02:51,882:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-12 15:02:51,884:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:02:51,891:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-12 15:02:51,936:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-12 15:02:51,971:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 15:02:51,972:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-12 15:02:51,974:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:02:51,974:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-06-12 15:02:52,028:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-12 15:02:52,063:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 15:02:52,063:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-12 15:02:52,065:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:02:52,119:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-12 15:02:52,152:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 15:02:52,152:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-12 15:02:52,154:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:02:52,157:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-12 15:02:52,212:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-12 15:02:52,248:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-12 15:02:52,250:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:02:52,303:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-12 15:02:52,338:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-12 15:02:52,340:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:02:52,340:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-06-12 15:02:52,428:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-12 15:02:52,430:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:02:52,517:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-12 15:02:52,519:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:02:52,523:INFO:Preparing preprocessing pipeline...
2023-06-12 15:02:52,523:INFO:Set up simple imputation.
2023-06-12 15:02:52,524:INFO:Set up column name cleaning.
2023-06-12 15:02:52,554:INFO:Finished creating preprocessing pipeline.
2023-06-12 15:02:52,559:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\lapei\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['taxa_homicidio', 'RH_adm_dir',
                                             'densidade_banda_larga',
                                             'densidade_telefonia_movel',
                                             'qtd_cursos_engenharias',
                                             'qtd_cursos_negocios_direito',
                                             'media_notas_CN', 'media_notas_CH',
                                             'media_NU_NOTA_LC',
                                             'media_NU_NOTA_MT',
                                             'media_...
                                             'Isencao_ISSQN_Sim',
                                             'Isencao_Tx_Sim',
                                             'Cessao_terrenos_Sim',
                                             'Doacao_terrenos_Sim',
                                             'Outros_mecanismos_Sim',
                                             'ISH_Baixa', 'ISH_Máxima',
                                             'ISH_Média', 'ISH_Mínima'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-06-12 15:02:52,559:INFO:Creating final display dataframe.
2023-06-12 15:02:52,630:INFO:Setup _display_container:                     Description                              Value
0                    Session id                               7606
1                        Target  qtd_abertas_Empresario_Individual
2                   Target type                         Regression
3           Original data shape                         (5570, 31)
4        Transformed data shape                         (5570, 31)
5   Transformed train set shape                         (3898, 31)
6    Transformed test set shape                         (1672, 31)
7              Numeric features                                 30
8                    Preprocess                               True
9               Imputation type                             simple
10           Numeric imputation                               mean
11       Categorical imputation                               mode
12               Fold Generator                              KFold
13                  Fold Number                                 10
14                     CPU Jobs                                 -1
15                      Use GPU                              False
16               Log Experiment                              False
17              Experiment Name                   reg-default-name
18                          USI                               564b
2023-06-12 15:02:52,725:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-12 15:02:52,727:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:02:52,815:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-12 15:02:52,817:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:02:52,818:INFO:setup() successfully completed in 1.87s...............
2023-06-12 15:09:18,835:INFO:PyCaret RegressionExperiment
2023-06-12 15:09:18,835:INFO:Logging name: reg-default-name
2023-06-12 15:09:18,835:INFO:ML Usecase: MLUsecase.REGRESSION
2023-06-12 15:09:18,836:INFO:version 3.0.2
2023-06-12 15:09:18,836:INFO:Initializing setup()
2023-06-12 15:09:18,836:INFO:self.USI: 6a8f
2023-06-12 15:09:18,836:INFO:self._variable_keys: {'_ml_usecase', 'fold_groups_param', 'target_param', 'y', 'gpu_n_jobs_param', 'fold_shuffle_param', 'exp_name_log', 'gpu_param', 'logging_param', 'log_plots_param', 'html_param', 'seed', 'X_test', 'data', 'idx', '_available_plots', 'exp_id', 'memory', 'fold_generator', 'pipeline', 'X_train', 'y_train', 'y_test', 'n_jobs_param', 'transform_target_param', 'USI', 'X'}
2023-06-12 15:09:18,836:INFO:Checking environment
2023-06-12 15:09:18,836:INFO:python_version: 3.10.9
2023-06-12 15:09:18,836:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-06-12 15:09:18,836:INFO:machine: AMD64
2023-06-12 15:09:18,836:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-12 15:09:18,836:INFO:Memory: svmem(total=16901767168, available=5659205632, percent=66.5, used=11242561536, free=5659205632)
2023-06-12 15:09:18,836:INFO:Physical Core: 4
2023-06-12 15:09:18,836:INFO:Logical Core: 8
2023-06-12 15:09:18,836:INFO:Checking libraries
2023-06-12 15:09:18,836:INFO:System:
2023-06-12 15:09:18,836:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-06-12 15:09:18,836:INFO:executable: C:\Users\lapei\anaconda3\python.exe
2023-06-12 15:09:18,837:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-12 15:09:18,837:INFO:PyCaret required dependencies:
2023-06-12 15:09:18,837:INFO:                 pip: 22.3.1
2023-06-12 15:09:18,837:INFO:          setuptools: 65.6.3
2023-06-12 15:09:18,837:INFO:             pycaret: 3.0.2
2023-06-12 15:09:18,837:INFO:             IPython: 8.10.0
2023-06-12 15:09:18,837:INFO:          ipywidgets: 7.6.5
2023-06-12 15:09:18,837:INFO:                tqdm: 4.64.1
2023-06-12 15:09:18,837:INFO:               numpy: 1.23.5
2023-06-12 15:09:18,837:INFO:              pandas: 1.5.3
2023-06-12 15:09:18,837:INFO:              jinja2: 3.1.2
2023-06-12 15:09:18,837:INFO:               scipy: 1.10.0
2023-06-12 15:09:18,837:INFO:              joblib: 1.2.0
2023-06-12 15:09:18,837:INFO:             sklearn: 1.2.1
2023-06-12 15:09:18,837:INFO:                pyod: 1.0.9
2023-06-12 15:09:18,837:INFO:            imblearn: 0.10.1
2023-06-12 15:09:18,838:INFO:   category_encoders: 2.6.1
2023-06-12 15:09:18,838:INFO:            lightgbm: 3.3.5
2023-06-12 15:09:18,838:INFO:               numba: 0.56.4
2023-06-12 15:09:18,838:INFO:            requests: 2.28.1
2023-06-12 15:09:18,838:INFO:          matplotlib: 3.7.0
2023-06-12 15:09:18,838:INFO:          scikitplot: 0.3.7
2023-06-12 15:09:18,838:INFO:         yellowbrick: 1.5
2023-06-12 15:09:18,838:INFO:              plotly: 5.9.0
2023-06-12 15:09:18,838:INFO:             kaleido: 0.2.1
2023-06-12 15:09:18,838:INFO:         statsmodels: 0.13.5
2023-06-12 15:09:18,838:INFO:              sktime: 0.17.0
2023-06-12 15:09:18,838:INFO:               tbats: 1.1.3
2023-06-12 15:09:18,838:INFO:            pmdarima: 2.0.3
2023-06-12 15:09:18,838:INFO:              psutil: 5.9.0
2023-06-12 15:09:18,838:INFO:PyCaret optional dependencies:
2023-06-12 15:09:18,838:INFO:                shap: 0.41.0
2023-06-12 15:09:18,838:INFO:           interpret: Not installed
2023-06-12 15:09:18,838:INFO:                umap: Not installed
2023-06-12 15:09:18,838:INFO:    pandas_profiling: Not installed
2023-06-12 15:09:18,838:INFO:  explainerdashboard: Not installed
2023-06-12 15:09:18,838:INFO:             autoviz: Not installed
2023-06-12 15:09:18,838:INFO:           fairlearn: Not installed
2023-06-12 15:09:18,838:INFO:             xgboost: 1.7.3
2023-06-12 15:09:18,838:INFO:            catboost: Not installed
2023-06-12 15:09:18,838:INFO:              kmodes: Not installed
2023-06-12 15:09:18,838:INFO:             mlxtend: Not installed
2023-06-12 15:09:18,839:INFO:       statsforecast: Not installed
2023-06-12 15:09:18,839:INFO:        tune_sklearn: Not installed
2023-06-12 15:09:18,839:INFO:                 ray: Not installed
2023-06-12 15:09:18,839:INFO:            hyperopt: Not installed
2023-06-12 15:09:18,839:INFO:              optuna: Not installed
2023-06-12 15:09:18,839:INFO:               skopt: 0.9.0
2023-06-12 15:09:18,839:INFO:              mlflow: Not installed
2023-06-12 15:09:18,839:INFO:              gradio: Not installed
2023-06-12 15:09:18,839:INFO:             fastapi: Not installed
2023-06-12 15:09:18,839:INFO:             uvicorn: Not installed
2023-06-12 15:09:18,839:INFO:              m2cgen: Not installed
2023-06-12 15:09:18,839:INFO:           evidently: Not installed
2023-06-12 15:09:18,839:INFO:               fugue: Not installed
2023-06-12 15:09:18,839:INFO:           streamlit: Not installed
2023-06-12 15:09:18,839:INFO:             prophet: Not installed
2023-06-12 15:09:18,839:INFO:None
2023-06-12 15:09:18,840:INFO:Set up data.
2023-06-12 15:09:18,853:INFO:Set up train/test split.
2023-06-12 15:09:18,857:INFO:Set up index.
2023-06-12 15:09:18,857:INFO:Set up folding strategy.
2023-06-12 15:09:18,857:INFO:Assigning column types.
2023-06-12 15:09:18,860:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-12 15:09:18,860:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-12 15:09:18,865:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-12 15:09:18,868:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-12 15:09:18,916:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-12 15:09:18,950:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 15:09:18,951:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-12 15:09:18,953:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:09:18,953:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-12 15:09:18,957:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-12 15:09:18,961:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-12 15:09:19,007:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-12 15:09:19,042:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 15:09:19,043:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-12 15:09:19,045:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:09:19,045:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-06-12 15:09:19,049:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-12 15:09:19,052:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-12 15:09:19,099:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-12 15:09:19,134:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 15:09:19,134:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-12 15:09:19,136:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:09:19,140:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-12 15:09:19,144:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-12 15:09:19,190:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-12 15:09:19,226:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 15:09:19,226:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-12 15:09:19,227:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:09:19,227:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-06-12 15:09:19,235:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-12 15:09:19,282:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-12 15:09:19,317:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 15:09:19,317:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-12 15:09:19,319:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:09:19,327:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-12 15:09:19,373:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-12 15:09:19,408:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 15:09:19,409:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-12 15:09:19,411:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:09:19,411:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-06-12 15:09:19,464:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-12 15:09:19,500:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 15:09:19,501:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-12 15:09:19,503:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:09:19,556:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-12 15:09:19,592:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 15:09:19,593:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-12 15:09:19,595:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:09:19,595:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-12 15:09:19,651:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-12 15:09:19,688:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-12 15:09:19,690:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:09:19,747:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-12 15:09:19,785:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-12 15:09:19,788:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:09:19,792:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-06-12 15:09:19,885:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-12 15:09:19,887:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:09:19,982:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-12 15:09:19,985:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:09:19,986:INFO:Preparing preprocessing pipeline...
2023-06-12 15:09:19,986:INFO:Set up simple imputation.
2023-06-12 15:09:19,986:INFO:Set up column name cleaning.
2023-06-12 15:09:20,009:INFO:Finished creating preprocessing pipeline.
2023-06-12 15:09:20,013:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\lapei\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['taxa_homicidio', 'RH_adm_dir',
                                             'densidade_banda_larga',
                                             'densidade_telefonia_movel',
                                             'qtd_cursos_engenharias',
                                             'qtd_cursos_negocios_direito',
                                             'media_notas_CN', 'media_notas_CH',
                                             'media_NU_NOTA_LC',
                                             'media_NU_NOTA_MT',
                                             'media_...
                                             'Isencao_ISSQN_Sim',
                                             'Isencao_Tx_Sim',
                                             'Cessao_terrenos_Sim',
                                             'Doacao_terrenos_Sim',
                                             'Outros_mecanismos_Sim',
                                             'ISH_Baixa', 'ISH_Máxima',
                                             'ISH_Média', 'ISH_Mínima'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-06-12 15:09:20,013:INFO:Creating final display dataframe.
2023-06-12 15:09:20,100:INFO:Setup _display_container:                     Description                              Value
0                    Session id                               7320
1                        Target  qtd_abertas_Empresario_Individual
2                   Target type                         Regression
3           Original data shape                         (5570, 31)
4        Transformed data shape                         (5570, 31)
5   Transformed train set shape                         (3898, 31)
6    Transformed test set shape                         (1672, 31)
7              Numeric features                                 30
8                    Preprocess                               True
9               Imputation type                             simple
10           Numeric imputation                               mean
11       Categorical imputation                               mode
12               Fold Generator                              KFold
13                  Fold Number                                 10
14                     CPU Jobs                                 -1
15                      Use GPU                              False
16               Log Experiment                              False
17              Experiment Name                   reg-default-name
18                          USI                               6a8f
2023-06-12 15:09:20,207:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-12 15:09:20,209:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:09:20,307:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-12 15:09:20,309:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:09:20,309:INFO:setup() successfully completed in 1.48s...............
2023-06-12 15:12:16,481:INFO:PyCaret RegressionExperiment
2023-06-12 15:12:16,481:INFO:Logging name: reg-default-name
2023-06-12 15:12:16,481:INFO:ML Usecase: MLUsecase.REGRESSION
2023-06-12 15:12:16,481:INFO:version 3.0.2
2023-06-12 15:12:16,482:INFO:Initializing setup()
2023-06-12 15:12:16,482:INFO:self.USI: a80d
2023-06-12 15:12:16,482:INFO:self._variable_keys: {'_ml_usecase', 'fold_groups_param', 'target_param', 'y', 'gpu_n_jobs_param', 'fold_shuffle_param', 'exp_name_log', 'gpu_param', 'logging_param', 'log_plots_param', 'html_param', 'seed', 'X_test', 'data', 'idx', '_available_plots', 'exp_id', 'memory', 'fold_generator', 'pipeline', 'X_train', 'y_train', 'y_test', 'n_jobs_param', 'transform_target_param', 'USI', 'X'}
2023-06-12 15:12:16,482:INFO:Checking environment
2023-06-12 15:12:16,482:INFO:python_version: 3.10.9
2023-06-12 15:12:16,482:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-06-12 15:12:16,482:INFO:machine: AMD64
2023-06-12 15:12:16,482:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-12 15:12:16,482:INFO:Memory: svmem(total=16901767168, available=5647040512, percent=66.6, used=11254726656, free=5647040512)
2023-06-12 15:12:16,482:INFO:Physical Core: 4
2023-06-12 15:12:16,482:INFO:Logical Core: 8
2023-06-12 15:12:16,482:INFO:Checking libraries
2023-06-12 15:12:16,482:INFO:System:
2023-06-12 15:12:16,482:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-06-12 15:12:16,482:INFO:executable: C:\Users\lapei\anaconda3\python.exe
2023-06-12 15:12:16,482:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-12 15:12:16,482:INFO:PyCaret required dependencies:
2023-06-12 15:12:16,482:INFO:                 pip: 22.3.1
2023-06-12 15:12:16,483:INFO:          setuptools: 65.6.3
2023-06-12 15:12:16,483:INFO:             pycaret: 3.0.2
2023-06-12 15:12:16,483:INFO:             IPython: 8.10.0
2023-06-12 15:12:16,483:INFO:          ipywidgets: 7.6.5
2023-06-12 15:12:16,483:INFO:                tqdm: 4.64.1
2023-06-12 15:12:16,483:INFO:               numpy: 1.23.5
2023-06-12 15:12:16,483:INFO:              pandas: 1.5.3
2023-06-12 15:12:16,483:INFO:              jinja2: 3.1.2
2023-06-12 15:12:16,483:INFO:               scipy: 1.10.0
2023-06-12 15:12:16,483:INFO:              joblib: 1.2.0
2023-06-12 15:12:16,483:INFO:             sklearn: 1.2.1
2023-06-12 15:12:16,483:INFO:                pyod: 1.0.9
2023-06-12 15:12:16,483:INFO:            imblearn: 0.10.1
2023-06-12 15:12:16,483:INFO:   category_encoders: 2.6.1
2023-06-12 15:12:16,483:INFO:            lightgbm: 3.3.5
2023-06-12 15:12:16,483:INFO:               numba: 0.56.4
2023-06-12 15:12:16,483:INFO:            requests: 2.28.1
2023-06-12 15:12:16,483:INFO:          matplotlib: 3.7.0
2023-06-12 15:12:16,483:INFO:          scikitplot: 0.3.7
2023-06-12 15:12:16,483:INFO:         yellowbrick: 1.5
2023-06-12 15:12:16,483:INFO:              plotly: 5.9.0
2023-06-12 15:12:16,484:INFO:             kaleido: 0.2.1
2023-06-12 15:12:16,484:INFO:         statsmodels: 0.13.5
2023-06-12 15:12:16,484:INFO:              sktime: 0.17.0
2023-06-12 15:12:16,484:INFO:               tbats: 1.1.3
2023-06-12 15:12:16,484:INFO:            pmdarima: 2.0.3
2023-06-12 15:12:16,484:INFO:              psutil: 5.9.0
2023-06-12 15:12:16,484:INFO:PyCaret optional dependencies:
2023-06-12 15:12:16,484:INFO:                shap: 0.41.0
2023-06-12 15:12:16,484:INFO:           interpret: Not installed
2023-06-12 15:12:16,484:INFO:                umap: Not installed
2023-06-12 15:12:16,484:INFO:    pandas_profiling: Not installed
2023-06-12 15:12:16,484:INFO:  explainerdashboard: Not installed
2023-06-12 15:12:16,484:INFO:             autoviz: Not installed
2023-06-12 15:12:16,484:INFO:           fairlearn: Not installed
2023-06-12 15:12:16,484:INFO:             xgboost: 1.7.3
2023-06-12 15:12:16,484:INFO:            catboost: Not installed
2023-06-12 15:12:16,484:INFO:              kmodes: Not installed
2023-06-12 15:12:16,486:INFO:             mlxtend: Not installed
2023-06-12 15:12:16,486:INFO:       statsforecast: Not installed
2023-06-12 15:12:16,486:INFO:        tune_sklearn: Not installed
2023-06-12 15:12:16,486:INFO:                 ray: Not installed
2023-06-12 15:12:16,486:INFO:            hyperopt: Not installed
2023-06-12 15:12:16,486:INFO:              optuna: Not installed
2023-06-12 15:12:16,486:INFO:               skopt: 0.9.0
2023-06-12 15:12:16,486:INFO:              mlflow: Not installed
2023-06-12 15:12:16,486:INFO:              gradio: Not installed
2023-06-12 15:12:16,486:INFO:             fastapi: Not installed
2023-06-12 15:12:16,486:INFO:             uvicorn: Not installed
2023-06-12 15:12:16,486:INFO:              m2cgen: Not installed
2023-06-12 15:12:16,486:INFO:           evidently: Not installed
2023-06-12 15:12:16,486:INFO:               fugue: Not installed
2023-06-12 15:12:16,486:INFO:           streamlit: Not installed
2023-06-12 15:12:16,486:INFO:             prophet: Not installed
2023-06-12 15:12:16,486:INFO:None
2023-06-12 15:12:16,486:INFO:Set up data.
2023-06-12 15:12:16,501:INFO:Set up train/test split.
2023-06-12 15:12:16,505:INFO:Set up index.
2023-06-12 15:12:16,505:INFO:Set up folding strategy.
2023-06-12 15:12:16,505:INFO:Assigning column types.
2023-06-12 15:12:16,508:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-12 15:12:16,508:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-12 15:12:16,512:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-12 15:12:16,515:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-12 15:12:16,564:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-12 15:12:16,600:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 15:12:16,601:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-12 15:12:16,603:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:12:16,603:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-12 15:12:16,607:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-12 15:12:16,610:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-12 15:12:16,661:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-12 15:12:16,700:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 15:12:16,701:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-12 15:12:16,703:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:12:16,703:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-06-12 15:12:16,707:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-12 15:12:16,711:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-12 15:12:16,766:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-12 15:12:16,806:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 15:12:16,807:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-12 15:12:16,809:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:12:16,813:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-12 15:12:16,817:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-12 15:12:16,870:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-12 15:12:16,911:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 15:12:16,911:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-12 15:12:16,913:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:12:16,914:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-06-12 15:12:16,922:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-12 15:12:16,973:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-12 15:12:17,014:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 15:12:17,015:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-12 15:12:17,018:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:12:17,026:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-12 15:12:17,079:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-12 15:12:17,119:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 15:12:17,120:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-12 15:12:17,122:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:12:17,123:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-06-12 15:12:17,181:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-12 15:12:17,220:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 15:12:17,222:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-12 15:12:17,225:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:12:17,276:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-12 15:12:17,309:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 15:12:17,309:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-12 15:12:17,311:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:12:17,311:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-12 15:12:17,365:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-12 15:12:17,403:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-12 15:12:17,405:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:12:17,461:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-12 15:12:17,497:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-12 15:12:17,499:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:12:17,499:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-06-12 15:12:17,588:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-12 15:12:17,590:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:12:17,677:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-12 15:12:17,679:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:12:17,680:INFO:Preparing preprocessing pipeline...
2023-06-12 15:12:17,680:INFO:Set up simple imputation.
2023-06-12 15:12:17,680:INFO:Set up column name cleaning.
2023-06-12 15:12:17,699:INFO:Finished creating preprocessing pipeline.
2023-06-12 15:12:17,704:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\lapei\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['taxa_homicidio', 'RH_adm_dir',
                                             'densidade_banda_larga',
                                             'densidade_telefonia_movel',
                                             'qtd_cursos_engenharias',
                                             'qtd_cursos_negocios_direito',
                                             'media_notas_CN', 'media_notas_CH',
                                             'media_NU_NOTA_LC',
                                             'media_NU_NOTA_MT',
                                             'media_...
                                             'Isencao_ISSQN_Sim',
                                             'Isencao_Tx_Sim',
                                             'Cessao_terrenos_Sim',
                                             'Doacao_terrenos_Sim',
                                             'Outros_mecanismos_Sim',
                                             'ISH_Baixa', 'ISH_Máxima',
                                             'ISH_Média', 'ISH_Mínima'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-06-12 15:12:17,705:INFO:Creating final display dataframe.
2023-06-12 15:12:17,781:INFO:Setup _display_container:                     Description                              Value
0                    Session id                               6027
1                        Target  qtd_abertas_Empresario_Individual
2                   Target type                         Regression
3           Original data shape                         (4456, 31)
4        Transformed data shape                         (4456, 31)
5   Transformed train set shape                         (3119, 31)
6    Transformed test set shape                         (1337, 31)
7              Numeric features                                 30
8                    Preprocess                               True
9               Imputation type                             simple
10           Numeric imputation                               mean
11       Categorical imputation                               mode
12               Fold Generator                              KFold
13                  Fold Number                                 10
14                     CPU Jobs                                 -1
15                      Use GPU                              False
16               Log Experiment                              False
17              Experiment Name                   reg-default-name
18                          USI                               a80d
2023-06-12 15:12:17,878:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-12 15:12:17,880:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:12:17,972:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-12 15:12:17,974:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:12:17,975:INFO:setup() successfully completed in 1.5s...............
2023-06-12 15:13:02,329:INFO:Initializing compare_models()
2023-06-12 15:13:02,329:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AE182016F0>, include=None, fold=5, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002AE182016F0>, 'include': None, 'exclude': None, 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-06-12 15:13:02,330:INFO:Checking exceptions
2023-06-12 15:13:02,334:INFO:Preparing display monitor
2023-06-12 15:13:02,364:INFO:Initializing Linear Regression
2023-06-12 15:13:02,365:INFO:Total runtime is 1.6729036966959637e-05 minutes
2023-06-12 15:13:02,368:INFO:SubProcess create_model() called ==================================
2023-06-12 15:13:02,368:INFO:Initializing create_model()
2023-06-12 15:13:02,368:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AE182016F0>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AE1840D2D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-12 15:13:02,368:INFO:Checking exceptions
2023-06-12 15:13:02,368:INFO:Importing libraries
2023-06-12 15:13:02,368:INFO:Copying training dataset
2023-06-12 15:13:02,387:INFO:Defining folds
2023-06-12 15:13:02,387:INFO:Declaring metric variables
2023-06-12 15:13:02,391:INFO:Importing untrained model
2023-06-12 15:13:02,394:INFO:Linear Regression Imported successfully
2023-06-12 15:13:02,401:INFO:Starting cross validation
2023-06-12 15:13:02,411:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 15:13:07,165:INFO:Calculating mean and std
2023-06-12 15:13:07,167:INFO:Creating metrics dataframe
2023-06-12 15:13:07,175:INFO:Uploading results into container
2023-06-12 15:13:07,177:INFO:Uploading model into container now
2023-06-12 15:13:07,178:INFO:_master_model_container: 1
2023-06-12 15:13:07,178:INFO:_display_container: 2
2023-06-12 15:13:07,179:INFO:LinearRegression(n_jobs=-1)
2023-06-12 15:13:07,179:INFO:create_model() successfully completed......................................
2023-06-12 15:13:07,336:INFO:SubProcess create_model() end ==================================
2023-06-12 15:13:07,336:INFO:Creating metrics dataframe
2023-06-12 15:13:07,343:INFO:Initializing Lasso Regression
2023-06-12 15:13:07,343:INFO:Total runtime is 0.08299773534138997 minutes
2023-06-12 15:13:07,347:INFO:SubProcess create_model() called ==================================
2023-06-12 15:13:07,347:INFO:Initializing create_model()
2023-06-12 15:13:07,348:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AE182016F0>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AE1840D2D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-12 15:13:07,348:INFO:Checking exceptions
2023-06-12 15:13:07,348:INFO:Importing libraries
2023-06-12 15:13:07,348:INFO:Copying training dataset
2023-06-12 15:13:07,354:INFO:Defining folds
2023-06-12 15:13:07,354:INFO:Declaring metric variables
2023-06-12 15:13:07,360:INFO:Importing untrained model
2023-06-12 15:13:07,365:INFO:Lasso Regression Imported successfully
2023-06-12 15:13:07,374:INFO:Starting cross validation
2023-06-12 15:13:07,376:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 15:13:09,615:INFO:Calculating mean and std
2023-06-12 15:13:09,617:INFO:Creating metrics dataframe
2023-06-12 15:13:09,626:INFO:Uploading results into container
2023-06-12 15:13:09,627:INFO:Uploading model into container now
2023-06-12 15:13:09,628:INFO:_master_model_container: 2
2023-06-12 15:13:09,628:INFO:_display_container: 2
2023-06-12 15:13:09,628:INFO:Lasso(random_state=6027)
2023-06-12 15:13:09,629:INFO:create_model() successfully completed......................................
2023-06-12 15:13:09,764:INFO:SubProcess create_model() end ==================================
2023-06-12 15:13:09,764:INFO:Creating metrics dataframe
2023-06-12 15:13:09,772:INFO:Initializing Ridge Regression
2023-06-12 15:13:09,772:INFO:Total runtime is 0.1234711488087972 minutes
2023-06-12 15:13:09,776:INFO:SubProcess create_model() called ==================================
2023-06-12 15:13:09,776:INFO:Initializing create_model()
2023-06-12 15:13:09,776:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AE182016F0>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AE1840D2D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-12 15:13:09,776:INFO:Checking exceptions
2023-06-12 15:13:09,776:INFO:Importing libraries
2023-06-12 15:13:09,777:INFO:Copying training dataset
2023-06-12 15:13:09,785:INFO:Defining folds
2023-06-12 15:13:09,787:INFO:Declaring metric variables
2023-06-12 15:13:09,793:INFO:Importing untrained model
2023-06-12 15:13:09,798:INFO:Ridge Regression Imported successfully
2023-06-12 15:13:09,806:INFO:Starting cross validation
2023-06-12 15:13:09,807:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 15:13:09,921:INFO:Calculating mean and std
2023-06-12 15:13:09,922:INFO:Creating metrics dataframe
2023-06-12 15:13:09,927:INFO:Uploading results into container
2023-06-12 15:13:09,927:INFO:Uploading model into container now
2023-06-12 15:13:09,929:INFO:_master_model_container: 3
2023-06-12 15:13:09,929:INFO:_display_container: 2
2023-06-12 15:13:09,929:INFO:Ridge(random_state=6027)
2023-06-12 15:13:09,929:INFO:create_model() successfully completed......................................
2023-06-12 15:13:10,056:INFO:SubProcess create_model() end ==================================
2023-06-12 15:13:10,056:INFO:Creating metrics dataframe
2023-06-12 15:13:10,065:INFO:Initializing Elastic Net
2023-06-12 15:13:10,065:INFO:Total runtime is 0.1283619006474813 minutes
2023-06-12 15:13:10,069:INFO:SubProcess create_model() called ==================================
2023-06-12 15:13:10,070:INFO:Initializing create_model()
2023-06-12 15:13:10,070:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AE182016F0>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AE1840D2D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-12 15:13:10,070:INFO:Checking exceptions
2023-06-12 15:13:10,070:INFO:Importing libraries
2023-06-12 15:13:10,070:INFO:Copying training dataset
2023-06-12 15:13:10,079:INFO:Defining folds
2023-06-12 15:13:10,079:INFO:Declaring metric variables
2023-06-12 15:13:10,083:INFO:Importing untrained model
2023-06-12 15:13:10,087:INFO:Elastic Net Imported successfully
2023-06-12 15:13:10,096:INFO:Starting cross validation
2023-06-12 15:13:10,097:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 15:13:10,238:INFO:Calculating mean and std
2023-06-12 15:13:10,239:INFO:Creating metrics dataframe
2023-06-12 15:13:10,244:INFO:Uploading results into container
2023-06-12 15:13:10,245:INFO:Uploading model into container now
2023-06-12 15:13:10,245:INFO:_master_model_container: 4
2023-06-12 15:13:10,245:INFO:_display_container: 2
2023-06-12 15:13:10,245:INFO:ElasticNet(random_state=6027)
2023-06-12 15:13:10,245:INFO:create_model() successfully completed......................................
2023-06-12 15:13:10,361:INFO:SubProcess create_model() end ==================================
2023-06-12 15:13:10,361:INFO:Creating metrics dataframe
2023-06-12 15:13:10,369:INFO:Initializing Least Angle Regression
2023-06-12 15:13:10,369:INFO:Total runtime is 0.13342989285786946 minutes
2023-06-12 15:13:10,372:INFO:SubProcess create_model() called ==================================
2023-06-12 15:13:10,372:INFO:Initializing create_model()
2023-06-12 15:13:10,373:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AE182016F0>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AE1840D2D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-12 15:13:10,373:INFO:Checking exceptions
2023-06-12 15:13:10,373:INFO:Importing libraries
2023-06-12 15:13:10,373:INFO:Copying training dataset
2023-06-12 15:13:10,380:INFO:Defining folds
2023-06-12 15:13:10,380:INFO:Declaring metric variables
2023-06-12 15:13:10,384:INFO:Importing untrained model
2023-06-12 15:13:10,390:INFO:Least Angle Regression Imported successfully
2023-06-12 15:13:10,398:INFO:Starting cross validation
2023-06-12 15:13:10,399:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 15:13:10,522:INFO:Calculating mean and std
2023-06-12 15:13:10,523:INFO:Creating metrics dataframe
2023-06-12 15:13:10,527:INFO:Uploading results into container
2023-06-12 15:13:10,528:INFO:Uploading model into container now
2023-06-12 15:13:10,529:INFO:_master_model_container: 5
2023-06-12 15:13:10,529:INFO:_display_container: 2
2023-06-12 15:13:10,529:INFO:Lars(random_state=6027)
2023-06-12 15:13:10,529:INFO:create_model() successfully completed......................................
2023-06-12 15:13:10,654:INFO:SubProcess create_model() end ==================================
2023-06-12 15:13:10,655:INFO:Creating metrics dataframe
2023-06-12 15:13:10,666:INFO:Initializing Lasso Least Angle Regression
2023-06-12 15:13:10,666:INFO:Total runtime is 0.13837153911590577 minutes
2023-06-12 15:13:10,669:INFO:SubProcess create_model() called ==================================
2023-06-12 15:13:10,670:INFO:Initializing create_model()
2023-06-12 15:13:10,670:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AE182016F0>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AE1840D2D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-12 15:13:10,670:INFO:Checking exceptions
2023-06-12 15:13:10,670:INFO:Importing libraries
2023-06-12 15:13:10,670:INFO:Copying training dataset
2023-06-12 15:13:10,677:INFO:Defining folds
2023-06-12 15:13:10,677:INFO:Declaring metric variables
2023-06-12 15:13:10,681:INFO:Importing untrained model
2023-06-12 15:13:10,684:INFO:Lasso Least Angle Regression Imported successfully
2023-06-12 15:13:10,692:INFO:Starting cross validation
2023-06-12 15:13:10,693:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 15:13:10,812:INFO:Calculating mean and std
2023-06-12 15:13:10,813:INFO:Creating metrics dataframe
2023-06-12 15:13:10,817:INFO:Uploading results into container
2023-06-12 15:13:10,818:INFO:Uploading model into container now
2023-06-12 15:13:10,818:INFO:_master_model_container: 6
2023-06-12 15:13:10,818:INFO:_display_container: 2
2023-06-12 15:13:10,818:INFO:LassoLars(random_state=6027)
2023-06-12 15:13:10,818:INFO:create_model() successfully completed......................................
2023-06-12 15:13:10,941:INFO:SubProcess create_model() end ==================================
2023-06-12 15:13:10,941:INFO:Creating metrics dataframe
2023-06-12 15:13:10,952:INFO:Initializing Orthogonal Matching Pursuit
2023-06-12 15:13:10,952:INFO:Total runtime is 0.14314780632654828 minutes
2023-06-12 15:13:10,956:INFO:SubProcess create_model() called ==================================
2023-06-12 15:13:10,956:INFO:Initializing create_model()
2023-06-12 15:13:10,956:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AE182016F0>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AE1840D2D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-12 15:13:10,956:INFO:Checking exceptions
2023-06-12 15:13:10,956:INFO:Importing libraries
2023-06-12 15:13:10,956:INFO:Copying training dataset
2023-06-12 15:13:10,963:INFO:Defining folds
2023-06-12 15:13:10,964:INFO:Declaring metric variables
2023-06-12 15:13:10,967:INFO:Importing untrained model
2023-06-12 15:13:10,973:INFO:Orthogonal Matching Pursuit Imported successfully
2023-06-12 15:13:10,980:INFO:Starting cross validation
2023-06-12 15:13:10,982:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 15:13:11,090:INFO:Calculating mean and std
2023-06-12 15:13:11,091:INFO:Creating metrics dataframe
2023-06-12 15:13:11,095:INFO:Uploading results into container
2023-06-12 15:13:11,097:INFO:Uploading model into container now
2023-06-12 15:13:11,097:INFO:_master_model_container: 7
2023-06-12 15:13:11,097:INFO:_display_container: 2
2023-06-12 15:13:11,098:INFO:OrthogonalMatchingPursuit()
2023-06-12 15:13:11,098:INFO:create_model() successfully completed......................................
2023-06-12 15:13:11,211:INFO:SubProcess create_model() end ==================================
2023-06-12 15:13:11,211:INFO:Creating metrics dataframe
2023-06-12 15:13:11,218:INFO:Initializing Bayesian Ridge
2023-06-12 15:13:11,219:INFO:Total runtime is 0.14759935537974042 minutes
2023-06-12 15:13:11,222:INFO:SubProcess create_model() called ==================================
2023-06-12 15:13:11,223:INFO:Initializing create_model()
2023-06-12 15:13:11,223:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AE182016F0>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AE1840D2D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-12 15:13:11,223:INFO:Checking exceptions
2023-06-12 15:13:11,223:INFO:Importing libraries
2023-06-12 15:13:11,223:INFO:Copying training dataset
2023-06-12 15:13:11,229:INFO:Defining folds
2023-06-12 15:13:11,229:INFO:Declaring metric variables
2023-06-12 15:13:11,235:INFO:Importing untrained model
2023-06-12 15:13:11,239:INFO:Bayesian Ridge Imported successfully
2023-06-12 15:13:11,248:INFO:Starting cross validation
2023-06-12 15:13:11,248:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 15:13:11,361:INFO:Calculating mean and std
2023-06-12 15:13:11,361:INFO:Creating metrics dataframe
2023-06-12 15:13:11,367:INFO:Uploading results into container
2023-06-12 15:13:11,368:INFO:Uploading model into container now
2023-06-12 15:13:11,368:INFO:_master_model_container: 8
2023-06-12 15:13:11,368:INFO:_display_container: 2
2023-06-12 15:13:11,368:INFO:BayesianRidge()
2023-06-12 15:13:11,368:INFO:create_model() successfully completed......................................
2023-06-12 15:13:11,494:INFO:SubProcess create_model() end ==================================
2023-06-12 15:13:11,494:INFO:Creating metrics dataframe
2023-06-12 15:13:11,503:INFO:Initializing Passive Aggressive Regressor
2023-06-12 15:13:11,503:INFO:Total runtime is 0.15231792529424035 minutes
2023-06-12 15:13:11,508:INFO:SubProcess create_model() called ==================================
2023-06-12 15:13:11,509:INFO:Initializing create_model()
2023-06-12 15:13:11,509:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AE182016F0>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AE1840D2D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-12 15:13:11,509:INFO:Checking exceptions
2023-06-12 15:13:11,509:INFO:Importing libraries
2023-06-12 15:13:11,509:INFO:Copying training dataset
2023-06-12 15:13:11,516:INFO:Defining folds
2023-06-12 15:13:11,516:INFO:Declaring metric variables
2023-06-12 15:13:11,520:INFO:Importing untrained model
2023-06-12 15:13:11,524:INFO:Passive Aggressive Regressor Imported successfully
2023-06-12 15:13:11,530:INFO:Starting cross validation
2023-06-12 15:13:11,532:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 15:13:11,662:INFO:Calculating mean and std
2023-06-12 15:13:11,664:INFO:Creating metrics dataframe
2023-06-12 15:13:11,669:INFO:Uploading results into container
2023-06-12 15:13:11,669:INFO:Uploading model into container now
2023-06-12 15:13:11,670:INFO:_master_model_container: 9
2023-06-12 15:13:11,670:INFO:_display_container: 2
2023-06-12 15:13:11,670:INFO:PassiveAggressiveRegressor(random_state=6027)
2023-06-12 15:13:11,670:INFO:create_model() successfully completed......................................
2023-06-12 15:13:11,784:INFO:SubProcess create_model() end ==================================
2023-06-12 15:13:11,784:INFO:Creating metrics dataframe
2023-06-12 15:13:11,792:INFO:Initializing Huber Regressor
2023-06-12 15:13:11,792:INFO:Total runtime is 0.1571379661560059 minutes
2023-06-12 15:13:11,796:INFO:SubProcess create_model() called ==================================
2023-06-12 15:13:11,796:INFO:Initializing create_model()
2023-06-12 15:13:11,796:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AE182016F0>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AE1840D2D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-12 15:13:11,796:INFO:Checking exceptions
2023-06-12 15:13:11,796:INFO:Importing libraries
2023-06-12 15:13:11,796:INFO:Copying training dataset
2023-06-12 15:13:11,802:INFO:Defining folds
2023-06-12 15:13:11,802:INFO:Declaring metric variables
2023-06-12 15:13:11,807:INFO:Importing untrained model
2023-06-12 15:13:11,811:INFO:Huber Regressor Imported successfully
2023-06-12 15:13:11,820:INFO:Starting cross validation
2023-06-12 15:13:11,821:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 15:13:11,936:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:13:11,940:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:13:11,948:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:13:11,991:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:13:11,991:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:13:12,010:INFO:Calculating mean and std
2023-06-12 15:13:12,012:INFO:Creating metrics dataframe
2023-06-12 15:13:12,016:INFO:Uploading results into container
2023-06-12 15:13:12,017:INFO:Uploading model into container now
2023-06-12 15:13:12,017:INFO:_master_model_container: 10
2023-06-12 15:13:12,017:INFO:_display_container: 2
2023-06-12 15:13:12,017:INFO:HuberRegressor()
2023-06-12 15:13:12,017:INFO:create_model() successfully completed......................................
2023-06-12 15:13:12,130:INFO:SubProcess create_model() end ==================================
2023-06-12 15:13:12,130:INFO:Creating metrics dataframe
2023-06-12 15:13:12,140:INFO:Initializing K Neighbors Regressor
2023-06-12 15:13:12,140:INFO:Total runtime is 0.16293636163075767 minutes
2023-06-12 15:13:12,145:INFO:SubProcess create_model() called ==================================
2023-06-12 15:13:12,146:INFO:Initializing create_model()
2023-06-12 15:13:12,146:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AE182016F0>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AE1840D2D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-12 15:13:12,146:INFO:Checking exceptions
2023-06-12 15:13:12,146:INFO:Importing libraries
2023-06-12 15:13:12,146:INFO:Copying training dataset
2023-06-12 15:13:12,153:INFO:Defining folds
2023-06-12 15:13:12,153:INFO:Declaring metric variables
2023-06-12 15:13:12,158:INFO:Importing untrained model
2023-06-12 15:13:12,162:INFO:K Neighbors Regressor Imported successfully
2023-06-12 15:13:12,169:INFO:Starting cross validation
2023-06-12 15:13:12,170:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 15:13:12,353:INFO:Calculating mean and std
2023-06-12 15:13:12,354:INFO:Creating metrics dataframe
2023-06-12 15:13:12,359:INFO:Uploading results into container
2023-06-12 15:13:12,360:INFO:Uploading model into container now
2023-06-12 15:13:12,360:INFO:_master_model_container: 11
2023-06-12 15:13:12,360:INFO:_display_container: 2
2023-06-12 15:13:12,360:INFO:KNeighborsRegressor(n_jobs=-1)
2023-06-12 15:13:12,360:INFO:create_model() successfully completed......................................
2023-06-12 15:13:12,476:INFO:SubProcess create_model() end ==================================
2023-06-12 15:13:12,477:INFO:Creating metrics dataframe
2023-06-12 15:13:12,485:INFO:Initializing Decision Tree Regressor
2023-06-12 15:13:12,486:INFO:Total runtime is 0.1687153458595276 minutes
2023-06-12 15:13:12,489:INFO:SubProcess create_model() called ==================================
2023-06-12 15:13:12,489:INFO:Initializing create_model()
2023-06-12 15:13:12,489:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AE182016F0>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AE1840D2D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-12 15:13:12,489:INFO:Checking exceptions
2023-06-12 15:13:12,489:INFO:Importing libraries
2023-06-12 15:13:12,489:INFO:Copying training dataset
2023-06-12 15:13:12,495:INFO:Defining folds
2023-06-12 15:13:12,495:INFO:Declaring metric variables
2023-06-12 15:13:12,499:INFO:Importing untrained model
2023-06-12 15:13:12,503:INFO:Decision Tree Regressor Imported successfully
2023-06-12 15:13:12,513:INFO:Starting cross validation
2023-06-12 15:13:12,514:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 15:13:12,681:INFO:Calculating mean and std
2023-06-12 15:13:12,682:INFO:Creating metrics dataframe
2023-06-12 15:13:12,687:INFO:Uploading results into container
2023-06-12 15:13:12,688:INFO:Uploading model into container now
2023-06-12 15:13:12,688:INFO:_master_model_container: 12
2023-06-12 15:13:12,688:INFO:_display_container: 2
2023-06-12 15:13:12,688:INFO:DecisionTreeRegressor(random_state=6027)
2023-06-12 15:13:12,688:INFO:create_model() successfully completed......................................
2023-06-12 15:13:12,815:INFO:SubProcess create_model() end ==================================
2023-06-12 15:13:12,815:INFO:Creating metrics dataframe
2023-06-12 15:13:12,826:INFO:Initializing Random Forest Regressor
2023-06-12 15:13:12,826:INFO:Total runtime is 0.17437066634496054 minutes
2023-06-12 15:13:12,830:INFO:SubProcess create_model() called ==================================
2023-06-12 15:13:12,830:INFO:Initializing create_model()
2023-06-12 15:13:12,830:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AE182016F0>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AE1840D2D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-12 15:13:12,831:INFO:Checking exceptions
2023-06-12 15:13:12,831:INFO:Importing libraries
2023-06-12 15:13:12,831:INFO:Copying training dataset
2023-06-12 15:13:12,836:INFO:Defining folds
2023-06-12 15:13:12,836:INFO:Declaring metric variables
2023-06-12 15:13:12,840:INFO:Importing untrained model
2023-06-12 15:13:12,845:INFO:Random Forest Regressor Imported successfully
2023-06-12 15:13:12,853:INFO:Starting cross validation
2023-06-12 15:13:12,855:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 15:13:17,820:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 15:13:18,087:INFO:Calculating mean and std
2023-06-12 15:13:18,088:INFO:Creating metrics dataframe
2023-06-12 15:13:18,093:INFO:Uploading results into container
2023-06-12 15:13:18,094:INFO:Uploading model into container now
2023-06-12 15:13:18,094:INFO:_master_model_container: 13
2023-06-12 15:13:18,094:INFO:_display_container: 2
2023-06-12 15:13:18,095:INFO:RandomForestRegressor(n_jobs=-1, random_state=6027)
2023-06-12 15:13:18,095:INFO:create_model() successfully completed......................................
2023-06-12 15:13:18,233:INFO:SubProcess create_model() end ==================================
2023-06-12 15:13:18,233:INFO:Creating metrics dataframe
2023-06-12 15:13:18,244:INFO:Initializing Extra Trees Regressor
2023-06-12 15:13:18,244:INFO:Total runtime is 0.264682944615682 minutes
2023-06-12 15:13:18,247:INFO:SubProcess create_model() called ==================================
2023-06-12 15:13:18,247:INFO:Initializing create_model()
2023-06-12 15:13:18,248:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AE182016F0>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AE1840D2D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-12 15:13:18,248:INFO:Checking exceptions
2023-06-12 15:13:18,248:INFO:Importing libraries
2023-06-12 15:13:18,248:INFO:Copying training dataset
2023-06-12 15:13:18,257:INFO:Defining folds
2023-06-12 15:13:18,257:INFO:Declaring metric variables
2023-06-12 15:13:18,261:INFO:Importing untrained model
2023-06-12 15:13:18,266:INFO:Extra Trees Regressor Imported successfully
2023-06-12 15:13:18,274:INFO:Starting cross validation
2023-06-12 15:13:18,274:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 15:13:20,007:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 15:13:20,063:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 15:13:20,253:INFO:Calculating mean and std
2023-06-12 15:13:20,254:INFO:Creating metrics dataframe
2023-06-12 15:13:20,263:INFO:Uploading results into container
2023-06-12 15:13:20,264:INFO:Uploading model into container now
2023-06-12 15:13:20,264:INFO:_master_model_container: 14
2023-06-12 15:13:20,264:INFO:_display_container: 2
2023-06-12 15:13:20,264:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=6027)
2023-06-12 15:13:20,264:INFO:create_model() successfully completed......................................
2023-06-12 15:13:20,405:INFO:SubProcess create_model() end ==================================
2023-06-12 15:13:20,405:INFO:Creating metrics dataframe
2023-06-12 15:13:20,418:INFO:Initializing AdaBoost Regressor
2023-06-12 15:13:20,418:INFO:Total runtime is 0.3009135484695435 minutes
2023-06-12 15:13:20,422:INFO:SubProcess create_model() called ==================================
2023-06-12 15:13:20,422:INFO:Initializing create_model()
2023-06-12 15:13:20,422:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AE182016F0>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AE1840D2D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-12 15:13:20,423:INFO:Checking exceptions
2023-06-12 15:13:20,423:INFO:Importing libraries
2023-06-12 15:13:20,423:INFO:Copying training dataset
2023-06-12 15:13:20,430:INFO:Defining folds
2023-06-12 15:13:20,430:INFO:Declaring metric variables
2023-06-12 15:13:20,433:INFO:Importing untrained model
2023-06-12 15:13:20,436:INFO:AdaBoost Regressor Imported successfully
2023-06-12 15:13:20,445:INFO:Starting cross validation
2023-06-12 15:13:20,446:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 15:13:21,028:INFO:Calculating mean and std
2023-06-12 15:13:21,029:INFO:Creating metrics dataframe
2023-06-12 15:13:21,044:INFO:Uploading results into container
2023-06-12 15:13:21,044:INFO:Uploading model into container now
2023-06-12 15:13:21,045:INFO:_master_model_container: 15
2023-06-12 15:13:21,045:INFO:_display_container: 2
2023-06-12 15:13:21,045:INFO:AdaBoostRegressor(random_state=6027)
2023-06-12 15:13:21,045:INFO:create_model() successfully completed......................................
2023-06-12 15:13:21,200:INFO:SubProcess create_model() end ==================================
2023-06-12 15:13:21,200:INFO:Creating metrics dataframe
2023-06-12 15:13:21,221:INFO:Initializing Gradient Boosting Regressor
2023-06-12 15:13:21,222:INFO:Total runtime is 0.3143144011497498 minutes
2023-06-12 15:13:21,230:INFO:SubProcess create_model() called ==================================
2023-06-12 15:13:21,231:INFO:Initializing create_model()
2023-06-12 15:13:21,231:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AE182016F0>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AE1840D2D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-12 15:13:21,231:INFO:Checking exceptions
2023-06-12 15:13:21,231:INFO:Importing libraries
2023-06-12 15:13:21,232:INFO:Copying training dataset
2023-06-12 15:13:21,243:INFO:Defining folds
2023-06-12 15:13:21,243:INFO:Declaring metric variables
2023-06-12 15:13:21,249:INFO:Importing untrained model
2023-06-12 15:13:21,254:INFO:Gradient Boosting Regressor Imported successfully
2023-06-12 15:13:21,265:INFO:Starting cross validation
2023-06-12 15:13:21,266:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 15:13:23,487:INFO:Calculating mean and std
2023-06-12 15:13:23,488:INFO:Creating metrics dataframe
2023-06-12 15:13:23,502:INFO:Uploading results into container
2023-06-12 15:13:23,503:INFO:Uploading model into container now
2023-06-12 15:13:23,503:INFO:_master_model_container: 16
2023-06-12 15:13:23,503:INFO:_display_container: 2
2023-06-12 15:13:23,504:INFO:GradientBoostingRegressor(random_state=6027)
2023-06-12 15:13:23,504:INFO:create_model() successfully completed......................................
2023-06-12 15:13:23,617:INFO:SubProcess create_model() end ==================================
2023-06-12 15:13:23,617:INFO:Creating metrics dataframe
2023-06-12 15:13:23,628:INFO:Initializing Extreme Gradient Boosting
2023-06-12 15:13:23,628:INFO:Total runtime is 0.3544101675351461 minutes
2023-06-12 15:13:23,631:INFO:SubProcess create_model() called ==================================
2023-06-12 15:13:23,631:INFO:Initializing create_model()
2023-06-12 15:13:23,632:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AE182016F0>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AE1840D2D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-12 15:13:23,632:INFO:Checking exceptions
2023-06-12 15:13:23,632:INFO:Importing libraries
2023-06-12 15:13:23,632:INFO:Copying training dataset
2023-06-12 15:13:23,637:INFO:Defining folds
2023-06-12 15:13:23,637:INFO:Declaring metric variables
2023-06-12 15:13:23,641:INFO:Importing untrained model
2023-06-12 15:13:23,646:INFO:Extreme Gradient Boosting Imported successfully
2023-06-12 15:13:23,652:INFO:Starting cross validation
2023-06-12 15:13:23,654:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 15:13:24,964:INFO:Calculating mean and std
2023-06-12 15:13:24,965:INFO:Creating metrics dataframe
2023-06-12 15:13:24,983:INFO:Uploading results into container
2023-06-12 15:13:24,983:INFO:Uploading model into container now
2023-06-12 15:13:24,984:INFO:_master_model_container: 17
2023-06-12 15:13:24,984:INFO:_display_container: 2
2023-06-12 15:13:24,984:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=6027, ...)
2023-06-12 15:13:24,984:INFO:create_model() successfully completed......................................
2023-06-12 15:13:25,100:INFO:SubProcess create_model() end ==================================
2023-06-12 15:13:25,100:INFO:Creating metrics dataframe
2023-06-12 15:13:25,111:INFO:Initializing Light Gradient Boosting Machine
2023-06-12 15:13:25,111:INFO:Total runtime is 0.3791168848673503 minutes
2023-06-12 15:13:25,114:INFO:SubProcess create_model() called ==================================
2023-06-12 15:13:25,114:INFO:Initializing create_model()
2023-06-12 15:13:25,114:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AE182016F0>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AE1840D2D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-12 15:13:25,114:INFO:Checking exceptions
2023-06-12 15:13:25,114:INFO:Importing libraries
2023-06-12 15:13:25,114:INFO:Copying training dataset
2023-06-12 15:13:25,122:INFO:Defining folds
2023-06-12 15:13:25,122:INFO:Declaring metric variables
2023-06-12 15:13:25,125:INFO:Importing untrained model
2023-06-12 15:13:25,128:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 15:13:25,134:INFO:Starting cross validation
2023-06-12 15:13:25,135:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 15:13:26,564:INFO:Calculating mean and std
2023-06-12 15:13:26,565:INFO:Creating metrics dataframe
2023-06-12 15:13:26,580:INFO:Uploading results into container
2023-06-12 15:13:26,581:INFO:Uploading model into container now
2023-06-12 15:13:26,581:INFO:_master_model_container: 18
2023-06-12 15:13:26,582:INFO:_display_container: 2
2023-06-12 15:13:26,582:INFO:LGBMRegressor(random_state=6027)
2023-06-12 15:13:26,582:INFO:create_model() successfully completed......................................
2023-06-12 15:13:26,694:INFO:SubProcess create_model() end ==================================
2023-06-12 15:13:26,694:INFO:Creating metrics dataframe
2023-06-12 15:13:26,704:INFO:Initializing Dummy Regressor
2023-06-12 15:13:26,704:INFO:Total runtime is 0.4056794206301372 minutes
2023-06-12 15:13:26,707:INFO:SubProcess create_model() called ==================================
2023-06-12 15:13:26,707:INFO:Initializing create_model()
2023-06-12 15:13:26,707:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AE182016F0>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AE1840D2D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-12 15:13:26,707:INFO:Checking exceptions
2023-06-12 15:13:26,707:INFO:Importing libraries
2023-06-12 15:13:26,708:INFO:Copying training dataset
2023-06-12 15:13:26,714:INFO:Defining folds
2023-06-12 15:13:26,714:INFO:Declaring metric variables
2023-06-12 15:13:26,718:INFO:Importing untrained model
2023-06-12 15:13:26,722:INFO:Dummy Regressor Imported successfully
2023-06-12 15:13:26,729:INFO:Starting cross validation
2023-06-12 15:13:26,730:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 15:13:26,857:INFO:Calculating mean and std
2023-06-12 15:13:26,858:INFO:Creating metrics dataframe
2023-06-12 15:13:26,873:INFO:Uploading results into container
2023-06-12 15:13:26,873:INFO:Uploading model into container now
2023-06-12 15:13:26,873:INFO:_master_model_container: 19
2023-06-12 15:13:26,874:INFO:_display_container: 2
2023-06-12 15:13:26,874:INFO:DummyRegressor()
2023-06-12 15:13:26,874:INFO:create_model() successfully completed......................................
2023-06-12 15:13:26,987:INFO:SubProcess create_model() end ==================================
2023-06-12 15:13:26,987:INFO:Creating metrics dataframe
2023-06-12 15:13:27,007:INFO:Initializing create_model()
2023-06-12 15:13:27,007:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AE182016F0>, estimator=HuberRegressor(), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-12 15:13:27,007:INFO:Checking exceptions
2023-06-12 15:13:27,008:INFO:Importing libraries
2023-06-12 15:13:27,008:INFO:Copying training dataset
2023-06-12 15:13:27,012:INFO:Defining folds
2023-06-12 15:13:27,012:INFO:Declaring metric variables
2023-06-12 15:13:27,012:INFO:Importing untrained model
2023-06-12 15:13:27,012:INFO:Declaring custom model
2023-06-12 15:13:27,013:INFO:Huber Regressor Imported successfully
2023-06-12 15:13:27,013:INFO:Cross validation set to False
2023-06-12 15:13:27,013:INFO:Fitting Model
2023-06-12 15:13:27,100:WARNING:lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html

2023-06-12 15:13:27,108:INFO:HuberRegressor()
2023-06-12 15:13:27,109:INFO:create_model() successfully completed......................................
2023-06-12 15:13:27,281:INFO:_master_model_container: 19
2023-06-12 15:13:27,281:INFO:_display_container: 2
2023-06-12 15:13:27,282:INFO:HuberRegressor()
2023-06-12 15:13:27,282:INFO:compare_models() successfully completed......................................
2023-06-12 15:16:21,800:INFO:Initializing plot_model()
2023-06-12 15:16:21,800:INFO:plot_model(plot=learning, fold=None, use_train_data=True, verbose=True, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AE182016F0>, system=True)
2023-06-12 15:16:21,801:INFO:Checking exceptions
2023-06-12 15:16:21,807:INFO:Preloading libraries
2023-06-12 15:16:21,808:INFO:Copying training dataset
2023-06-12 15:16:21,808:INFO:Plot type: learning
2023-06-12 15:16:21,907:INFO:Fitting Model
2023-06-12 15:16:22,012:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,023:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,025:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,027:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,031:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,034:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,048:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,053:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,084:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,103:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,107:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,113:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,115:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,130:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,147:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,154:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,183:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,195:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,206:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,210:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,212:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,232:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,234:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,256:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,285:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,287:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,312:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,314:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,334:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,348:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,362:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,372:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,386:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,406:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,407:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,421:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,426:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,454:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,472:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,473:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,504:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,522:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,525:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,532:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,536:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,586:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,587:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,611:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,619:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,624:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,644:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,658:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,694:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,695:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,703:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,709:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,717:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,731:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,747:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,772:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,782:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,786:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,795:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,806:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,828:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,835:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,843:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,874:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,874:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,903:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,905:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,911:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,932:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,960:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,990:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,993:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:22,996:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:23,007:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:23,013:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:23,035:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:23,056:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:23,084:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:23,092:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:23,100:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:23,109:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:23,119:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:23,129:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:23,147:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:23,147:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:23,169:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:23,172:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:23,178:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-12 15:16:23,356:INFO:Visual Rendered Successfully
2023-06-12 15:16:23,479:INFO:plot_model() successfully completed......................................
2023-06-12 15:17:00,725:INFO:Initializing plot_model()
2023-06-12 15:17:00,725:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AE182016F0>, system=True)
2023-06-12 15:17:00,725:INFO:Checking exceptions
2023-06-12 15:17:32,767:INFO:Initializing plot_model()
2023-06-12 15:17:32,767:INFO:plot_model(plot=class_report, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AE182016F0>, system=True)
2023-06-12 15:17:32,768:INFO:Checking exceptions
2023-06-12 15:18:28,799:INFO:Initializing plot_model()
2023-06-12 15:18:28,800:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AE182016F0>, system=True)
2023-06-12 15:18:28,800:INFO:Checking exceptions
2023-06-12 15:18:52,712:INFO:Initializing interpret_model()
2023-06-12 15:18:52,712:INFO:interpret_model(estimator=HuberRegressor(), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AE182016F0>)
2023-06-12 15:18:52,713:INFO:Checking exceptions
2023-06-12 15:18:52,713:INFO:Soft dependency imported: shap: 0.41.0
2023-06-12 15:31:02,106:INFO:Initializing interpret_model()
2023-06-12 15:31:02,106:INFO:interpret_model(estimator=HuberRegressor(), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=3, plot=reason, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AE182016F0>)
2023-06-12 15:31:02,107:INFO:Checking exceptions
2023-06-12 15:31:02,107:INFO:Soft dependency imported: shap: 0.41.0
2023-06-12 15:41:42,760:INFO:Initializing plot_model()
2023-06-12 15:41:42,760:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AE182016F0>, system=True)
2023-06-12 15:41:42,760:INFO:Checking exceptions
2023-06-12 15:41:42,768:INFO:Preloading libraries
2023-06-12 15:41:42,769:INFO:Copying training dataset
2023-06-12 15:41:42,769:INFO:Plot type: error
2023-06-12 15:41:42,869:INFO:Fitting Model
2023-06-12 15:41:42,869:WARNING:X does not have valid feature names, but HuberRegressor was fitted with feature names

2023-06-12 15:41:42,869:INFO:Scoring test/hold-out set
2023-06-12 15:41:43,222:INFO:Visual Rendered Successfully
2023-06-12 15:41:43,408:INFO:plot_model() successfully completed......................................
2023-06-12 15:42:38,894:INFO:Initializing plot_model()
2023-06-12 15:42:38,894:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AE182016F0>, system=True)
2023-06-12 15:42:38,894:INFO:Checking exceptions
2023-06-12 15:42:38,904:INFO:Preloading libraries
2023-06-12 15:42:38,905:INFO:Copying training dataset
2023-06-12 15:42:38,905:INFO:Plot type: feature
2023-06-12 15:42:39,103:INFO:Visual Rendered Successfully
2023-06-12 15:42:39,274:INFO:plot_model() successfully completed......................................
2023-06-12 15:44:30,071:INFO:Initializing interpret_model()
2023-06-12 15:44:30,072:INFO:interpret_model(estimator=HuberRegressor(), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=32, plot=reason, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AE182016F0>)
2023-06-12 15:44:30,072:INFO:Checking exceptions
2023-06-12 15:44:30,072:INFO:Soft dependency imported: shap: 0.41.0
2023-06-13 09:13:39,511:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-13 09:13:39,513:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-13 09:13:39,513:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-13 09:13:39,513:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-13 09:13:43,891:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-13 09:15:54,192:INFO:PyCaret RegressionExperiment
2023-06-13 09:15:54,192:INFO:Logging name: reg-default-name
2023-06-13 09:15:54,192:INFO:ML Usecase: MLUsecase.REGRESSION
2023-06-13 09:15:54,193:INFO:version 3.0.2
2023-06-13 09:15:54,193:INFO:Initializing setup()
2023-06-13 09:15:54,193:INFO:self.USI: 0a33
2023-06-13 09:15:54,193:INFO:self._variable_keys: {'fold_groups_param', 'data', 'y', 'transform_target_param', 'fold_shuffle_param', 'gpu_n_jobs_param', 'X_test', 'exp_id', 'logging_param', 'y_train', 'target_param', '_available_plots', 'html_param', 'X_train', 'USI', 'pipeline', 'y_test', 'fold_generator', 'exp_name_log', 'X', 'log_plots_param', 'gpu_param', 'memory', 'idx', '_ml_usecase', 'n_jobs_param', 'seed'}
2023-06-13 09:15:54,194:INFO:Checking environment
2023-06-13 09:15:54,194:INFO:python_version: 3.10.9
2023-06-13 09:15:54,194:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-06-13 09:15:54,194:INFO:machine: AMD64
2023-06-13 09:15:54,194:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-13 09:15:54,194:INFO:Memory: svmem(total=16901767168, available=6111145984, percent=63.8, used=10790621184, free=6111145984)
2023-06-13 09:15:54,194:INFO:Physical Core: 4
2023-06-13 09:15:54,195:INFO:Logical Core: 8
2023-06-13 09:15:54,195:INFO:Checking libraries
2023-06-13 09:15:54,195:INFO:System:
2023-06-13 09:15:54,195:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-06-13 09:15:54,195:INFO:executable: C:\Users\lapei\anaconda3\python.exe
2023-06-13 09:15:54,195:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-13 09:15:54,196:INFO:PyCaret required dependencies:
2023-06-13 09:15:54,196:INFO:                 pip: 22.3.1
2023-06-13 09:15:54,196:INFO:          setuptools: 65.6.3
2023-06-13 09:15:54,196:INFO:             pycaret: 3.0.2
2023-06-13 09:15:54,196:INFO:             IPython: 8.10.0
2023-06-13 09:15:54,196:INFO:          ipywidgets: 7.6.5
2023-06-13 09:15:54,196:INFO:                tqdm: 4.64.1
2023-06-13 09:15:54,197:INFO:               numpy: 1.23.5
2023-06-13 09:15:54,197:INFO:              pandas: 1.5.3
2023-06-13 09:15:54,197:INFO:              jinja2: 3.1.2
2023-06-13 09:15:54,197:INFO:               scipy: 1.10.0
2023-06-13 09:15:54,197:INFO:              joblib: 1.2.0
2023-06-13 09:15:54,197:INFO:             sklearn: 1.2.1
2023-06-13 09:15:54,197:INFO:                pyod: 1.0.9
2023-06-13 09:15:54,197:INFO:            imblearn: 0.10.1
2023-06-13 09:15:54,197:INFO:   category_encoders: 2.6.1
2023-06-13 09:15:54,197:INFO:            lightgbm: 3.3.5
2023-06-13 09:15:54,198:INFO:               numba: 0.56.4
2023-06-13 09:15:54,198:INFO:            requests: 2.28.1
2023-06-13 09:15:54,198:INFO:          matplotlib: 3.7.0
2023-06-13 09:15:54,198:INFO:          scikitplot: 0.3.7
2023-06-13 09:15:54,198:INFO:         yellowbrick: 1.5
2023-06-13 09:15:54,198:INFO:              plotly: 5.9.0
2023-06-13 09:15:54,198:INFO:             kaleido: 0.2.1
2023-06-13 09:15:54,198:INFO:         statsmodels: 0.13.5
2023-06-13 09:15:54,198:INFO:              sktime: 0.17.0
2023-06-13 09:15:54,199:INFO:               tbats: 1.1.3
2023-06-13 09:15:54,199:INFO:            pmdarima: 2.0.3
2023-06-13 09:15:54,199:INFO:              psutil: 5.9.0
2023-06-13 09:15:54,199:INFO:PyCaret optional dependencies:
2023-06-13 09:15:54,365:INFO:                shap: 0.41.0
2023-06-13 09:15:54,366:INFO:           interpret: Not installed
2023-06-13 09:15:54,366:INFO:                umap: Not installed
2023-06-13 09:15:54,366:INFO:    pandas_profiling: Not installed
2023-06-13 09:15:54,366:INFO:  explainerdashboard: Not installed
2023-06-13 09:15:54,366:INFO:             autoviz: Not installed
2023-06-13 09:15:54,366:INFO:           fairlearn: Not installed
2023-06-13 09:15:54,366:INFO:             xgboost: 1.7.3
2023-06-13 09:15:54,366:INFO:            catboost: Not installed
2023-06-13 09:15:54,367:INFO:              kmodes: Not installed
2023-06-13 09:15:54,367:INFO:             mlxtend: Not installed
2023-06-13 09:15:54,367:INFO:       statsforecast: Not installed
2023-06-13 09:15:54,367:INFO:        tune_sklearn: Not installed
2023-06-13 09:15:54,367:INFO:                 ray: Not installed
2023-06-13 09:15:54,367:INFO:            hyperopt: Not installed
2023-06-13 09:15:54,367:INFO:              optuna: Not installed
2023-06-13 09:15:54,367:INFO:               skopt: 0.9.0
2023-06-13 09:15:54,367:INFO:              mlflow: Not installed
2023-06-13 09:15:54,368:INFO:              gradio: Not installed
2023-06-13 09:15:54,368:INFO:             fastapi: Not installed
2023-06-13 09:15:54,368:INFO:             uvicorn: Not installed
2023-06-13 09:15:54,368:INFO:              m2cgen: Not installed
2023-06-13 09:15:54,368:INFO:           evidently: Not installed
2023-06-13 09:15:54,368:INFO:               fugue: Not installed
2023-06-13 09:15:54,368:INFO:           streamlit: Not installed
2023-06-13 09:15:54,368:INFO:             prophet: Not installed
2023-06-13 09:15:54,368:INFO:None
2023-06-13 09:15:54,369:INFO:Set up data.
2023-06-13 09:15:54,400:INFO:Set up train/test split.
2023-06-13 09:15:54,416:INFO:Set up index.
2023-06-13 09:15:54,417:INFO:Set up folding strategy.
2023-06-13 09:15:54,417:INFO:Assigning column types.
2023-06-13 09:15:54,427:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-13 09:15:54,427:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-13 09:15:54,440:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-13 09:15:54,455:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-13 09:15:54,633:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 09:15:54,764:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 09:15:54,767:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 09:15:55,639:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 09:15:55,640:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-13 09:15:55,653:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-13 09:15:55,666:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-13 09:15:55,827:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 09:15:55,951:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 09:15:55,952:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 09:15:55,959:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 09:15:55,960:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-06-13 09:15:55,974:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-13 09:15:55,990:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-13 09:15:56,163:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 09:15:56,291:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 09:15:56,292:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 09:15:56,300:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 09:15:56,314:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-13 09:15:56,327:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-13 09:15:56,495:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 09:15:56,631:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 09:15:56,632:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 09:15:56,639:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 09:15:56,640:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-06-13 09:15:56,665:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-13 09:15:56,827:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 09:15:56,959:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 09:15:56,960:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 09:15:56,968:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 09:15:56,994:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-13 09:15:57,164:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 09:15:57,287:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 09:15:57,289:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 09:15:57,296:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 09:15:57,297:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-06-13 09:15:57,487:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 09:15:57,611:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 09:15:57,613:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 09:15:57,620:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 09:15:57,807:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 09:15:57,932:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 09:15:57,933:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 09:15:57,940:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 09:15:57,941:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-13 09:15:58,127:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 09:15:58,261:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 09:15:58,269:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 09:15:58,452:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 09:15:58,577:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 09:15:58,585:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 09:15:58,586:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-06-13 09:15:58,896:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 09:15:58,903:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 09:15:59,215:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 09:15:59,222:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 09:15:59,232:INFO:Preparing preprocessing pipeline...
2023-06-13 09:15:59,232:INFO:Set up simple imputation.
2023-06-13 09:15:59,234:INFO:Set up column name cleaning.
2023-06-13 09:15:59,340:INFO:Finished creating preprocessing pipeline.
2023-06-13 09:15:59,360:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\lapei\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['taxa_homicidio', 'RH_adm_dir',
                                             'densidade_banda_larga',
                                             'densidade_telefonia_movel',
                                             'qtd_cursos_engenharias',
                                             'qtd_cursos_negocios_direito',
                                             'media_notas_CN', 'media_notas_CH',
                                             'media_NU_NOTA_LC',
                                             'media_NU_NOTA_MT',
                                             'media_...
                                             'Isencao_ISSQN_Sim',
                                             'Isencao_Tx_Sim',
                                             'Cessao_terrenos_Sim',
                                             'Doacao_terrenos_Sim',
                                             'Outros_mecanismos_Sim',
                                             'ISH_Baixa', 'ISH_Máxima',
                                             'ISH_Média', 'ISH_Mínima'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-06-13 09:15:59,360:INFO:Creating final display dataframe.
2023-06-13 09:15:59,629:INFO:Setup _display_container:                     Description                              Value
0                    Session id                               4116
1                        Target  qtd_abertas_Empresario_Individual
2                   Target type                         Regression
3           Original data shape                         (4456, 31)
4        Transformed data shape                         (4456, 31)
5   Transformed train set shape                         (3119, 31)
6    Transformed test set shape                         (1337, 31)
7              Numeric features                                 30
8                    Preprocess                               True
9               Imputation type                             simple
10           Numeric imputation                               mean
11       Categorical imputation                               mode
12               Fold Generator                              KFold
13                  Fold Number                                 10
14                     CPU Jobs                                 -1
15                      Use GPU                              False
16               Log Experiment                              False
17              Experiment Name                   reg-default-name
18                          USI                               0a33
2023-06-13 09:15:59,977:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 09:15:59,988:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 09:16:00,395:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 09:16:00,402:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 09:16:00,404:INFO:setup() successfully completed in 6.3s...............
2023-06-13 09:16:00,432:INFO:Initializing compare_models()
2023-06-13 09:16:00,432:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D33A2B90>, include=None, fold=5, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001E3D33A2B90>, 'include': None, 'exclude': None, 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-06-13 09:16:00,433:INFO:Checking exceptions
2023-06-13 09:16:00,440:INFO:Preparing display monitor
2023-06-13 09:16:00,518:INFO:Initializing Linear Regression
2023-06-13 09:16:00,518:INFO:Total runtime is 0.0 minutes
2023-06-13 09:16:00,532:INFO:SubProcess create_model() called ==================================
2023-06-13 09:16:00,534:INFO:Initializing create_model()
2023-06-13 09:16:00,534:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D33A2B90>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D3C7A5F0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 09:16:00,534:INFO:Checking exceptions
2023-06-13 09:16:00,534:INFO:Importing libraries
2023-06-13 09:16:00,535:INFO:Copying training dataset
2023-06-13 09:16:00,555:INFO:Defining folds
2023-06-13 09:16:00,555:INFO:Declaring metric variables
2023-06-13 09:16:00,565:INFO:Importing untrained model
2023-06-13 09:16:00,575:INFO:Linear Regression Imported successfully
2023-06-13 09:16:00,593:INFO:Starting cross validation
2023-06-13 09:16:00,620:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 09:16:06,250:INFO:Calculating mean and std
2023-06-13 09:16:06,253:INFO:Creating metrics dataframe
2023-06-13 09:16:06,296:INFO:Uploading results into container
2023-06-13 09:16:06,298:INFO:Uploading model into container now
2023-06-13 09:16:06,300:INFO:_master_model_container: 1
2023-06-13 09:16:06,300:INFO:_display_container: 2
2023-06-13 09:16:06,300:INFO:LinearRegression(n_jobs=-1)
2023-06-13 09:16:06,301:INFO:create_model() successfully completed......................................
2023-06-13 09:16:06,505:INFO:SubProcess create_model() end ==================================
2023-06-13 09:16:06,505:INFO:Creating metrics dataframe
2023-06-13 09:16:06,529:INFO:Initializing Lasso Regression
2023-06-13 09:16:06,530:INFO:Total runtime is 0.100198761622111 minutes
2023-06-13 09:16:06,540:INFO:SubProcess create_model() called ==================================
2023-06-13 09:16:06,541:INFO:Initializing create_model()
2023-06-13 09:16:06,542:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D33A2B90>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D3C7A5F0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 09:16:06,542:INFO:Checking exceptions
2023-06-13 09:16:06,542:INFO:Importing libraries
2023-06-13 09:16:06,543:INFO:Copying training dataset
2023-06-13 09:16:06,563:INFO:Defining folds
2023-06-13 09:16:06,564:INFO:Declaring metric variables
2023-06-13 09:16:06,575:INFO:Importing untrained model
2023-06-13 09:16:06,589:INFO:Lasso Regression Imported successfully
2023-06-13 09:16:06,611:INFO:Starting cross validation
2023-06-13 09:16:06,615:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 09:16:10,863:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.852e+08, tolerance: 7.593e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:16:11,163:INFO:Calculating mean and std
2023-06-13 09:16:11,166:INFO:Creating metrics dataframe
2023-06-13 09:16:11,229:INFO:Uploading results into container
2023-06-13 09:16:11,230:INFO:Uploading model into container now
2023-06-13 09:16:11,231:INFO:_master_model_container: 2
2023-06-13 09:16:11,232:INFO:_display_container: 2
2023-06-13 09:16:11,232:INFO:Lasso(random_state=4116)
2023-06-13 09:16:11,232:INFO:create_model() successfully completed......................................
2023-06-13 09:16:11,420:INFO:SubProcess create_model() end ==================================
2023-06-13 09:16:11,420:INFO:Creating metrics dataframe
2023-06-13 09:16:11,444:INFO:Initializing Ridge Regression
2023-06-13 09:16:11,445:INFO:Total runtime is 0.1821178118387858 minutes
2023-06-13 09:16:11,455:INFO:SubProcess create_model() called ==================================
2023-06-13 09:16:11,455:INFO:Initializing create_model()
2023-06-13 09:16:11,456:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D33A2B90>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D3C7A5F0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 09:16:11,456:INFO:Checking exceptions
2023-06-13 09:16:11,456:INFO:Importing libraries
2023-06-13 09:16:11,456:INFO:Copying training dataset
2023-06-13 09:16:11,481:INFO:Defining folds
2023-06-13 09:16:11,482:INFO:Declaring metric variables
2023-06-13 09:16:11,494:INFO:Importing untrained model
2023-06-13 09:16:11,505:INFO:Ridge Regression Imported successfully
2023-06-13 09:16:11,525:INFO:Starting cross validation
2023-06-13 09:16:11,532:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 09:16:11,922:INFO:Calculating mean and std
2023-06-13 09:16:11,925:INFO:Creating metrics dataframe
2023-06-13 09:16:11,989:INFO:Uploading results into container
2023-06-13 09:16:11,991:INFO:Uploading model into container now
2023-06-13 09:16:11,992:INFO:_master_model_container: 3
2023-06-13 09:16:11,992:INFO:_display_container: 2
2023-06-13 09:16:11,993:INFO:Ridge(random_state=4116)
2023-06-13 09:16:11,993:INFO:create_model() successfully completed......................................
2023-06-13 09:16:12,188:INFO:SubProcess create_model() end ==================================
2023-06-13 09:16:12,188:INFO:Creating metrics dataframe
2023-06-13 09:16:12,213:INFO:Initializing Elastic Net
2023-06-13 09:16:12,213:INFO:Total runtime is 0.1949262301127116 minutes
2023-06-13 09:16:12,223:INFO:SubProcess create_model() called ==================================
2023-06-13 09:16:12,224:INFO:Initializing create_model()
2023-06-13 09:16:12,224:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D33A2B90>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D3C7A5F0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 09:16:12,226:INFO:Checking exceptions
2023-06-13 09:16:12,226:INFO:Importing libraries
2023-06-13 09:16:12,226:INFO:Copying training dataset
2023-06-13 09:16:12,243:INFO:Defining folds
2023-06-13 09:16:12,243:INFO:Declaring metric variables
2023-06-13 09:16:12,253:INFO:Importing untrained model
2023-06-13 09:16:12,269:INFO:Elastic Net Imported successfully
2023-06-13 09:16:12,289:INFO:Starting cross validation
2023-06-13 09:16:12,293:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 09:16:12,580:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.851e+08, tolerance: 7.593e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:16:12,937:INFO:Calculating mean and std
2023-06-13 09:16:12,940:INFO:Creating metrics dataframe
2023-06-13 09:16:13,009:INFO:Uploading results into container
2023-06-13 09:16:13,010:INFO:Uploading model into container now
2023-06-13 09:16:13,011:INFO:_master_model_container: 4
2023-06-13 09:16:13,011:INFO:_display_container: 2
2023-06-13 09:16:13,012:INFO:ElasticNet(random_state=4116)
2023-06-13 09:16:13,013:INFO:create_model() successfully completed......................................
2023-06-13 09:16:13,201:INFO:SubProcess create_model() end ==================================
2023-06-13 09:16:13,202:INFO:Creating metrics dataframe
2023-06-13 09:16:13,229:INFO:Initializing Least Angle Regression
2023-06-13 09:16:13,230:INFO:Total runtime is 0.21187041600545248 minutes
2023-06-13 09:16:13,241:INFO:SubProcess create_model() called ==================================
2023-06-13 09:16:13,242:INFO:Initializing create_model()
2023-06-13 09:16:13,242:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D33A2B90>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D3C7A5F0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 09:16:13,242:INFO:Checking exceptions
2023-06-13 09:16:13,243:INFO:Importing libraries
2023-06-13 09:16:13,243:INFO:Copying training dataset
2023-06-13 09:16:13,262:INFO:Defining folds
2023-06-13 09:16:13,263:INFO:Declaring metric variables
2023-06-13 09:16:13,274:INFO:Importing untrained model
2023-06-13 09:16:13,287:INFO:Least Angle Regression Imported successfully
2023-06-13 09:16:13,308:INFO:Starting cross validation
2023-06-13 09:16:13,310:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 09:16:13,734:INFO:Calculating mean and std
2023-06-13 09:16:13,736:INFO:Creating metrics dataframe
2023-06-13 09:16:13,800:INFO:Uploading results into container
2023-06-13 09:16:13,803:INFO:Uploading model into container now
2023-06-13 09:16:13,804:INFO:_master_model_container: 5
2023-06-13 09:16:13,804:INFO:_display_container: 2
2023-06-13 09:16:13,805:INFO:Lars(random_state=4116)
2023-06-13 09:16:13,805:INFO:create_model() successfully completed......................................
2023-06-13 09:16:13,993:INFO:SubProcess create_model() end ==================================
2023-06-13 09:16:13,993:INFO:Creating metrics dataframe
2023-06-13 09:16:14,021:INFO:Initializing Lasso Least Angle Regression
2023-06-13 09:16:14,021:INFO:Total runtime is 0.22505269050598145 minutes
2023-06-13 09:16:14,029:INFO:SubProcess create_model() called ==================================
2023-06-13 09:16:14,030:INFO:Initializing create_model()
2023-06-13 09:16:14,030:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D33A2B90>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D3C7A5F0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 09:16:14,030:INFO:Checking exceptions
2023-06-13 09:16:14,030:INFO:Importing libraries
2023-06-13 09:16:14,031:INFO:Copying training dataset
2023-06-13 09:16:14,051:INFO:Defining folds
2023-06-13 09:16:14,051:INFO:Declaring metric variables
2023-06-13 09:16:14,062:INFO:Importing untrained model
2023-06-13 09:16:14,072:INFO:Lasso Least Angle Regression Imported successfully
2023-06-13 09:16:14,095:INFO:Starting cross validation
2023-06-13 09:16:14,098:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 09:16:14,554:INFO:Calculating mean and std
2023-06-13 09:16:14,557:INFO:Creating metrics dataframe
2023-06-13 09:16:14,629:INFO:Uploading results into container
2023-06-13 09:16:14,631:INFO:Uploading model into container now
2023-06-13 09:16:14,632:INFO:_master_model_container: 6
2023-06-13 09:16:14,632:INFO:_display_container: 2
2023-06-13 09:16:14,633:INFO:LassoLars(random_state=4116)
2023-06-13 09:16:14,633:INFO:create_model() successfully completed......................................
2023-06-13 09:16:14,837:INFO:SubProcess create_model() end ==================================
2023-06-13 09:16:14,837:INFO:Creating metrics dataframe
2023-06-13 09:16:14,866:INFO:Initializing Orthogonal Matching Pursuit
2023-06-13 09:16:14,867:INFO:Total runtime is 0.23914825518925986 minutes
2023-06-13 09:16:14,878:INFO:SubProcess create_model() called ==================================
2023-06-13 09:16:14,879:INFO:Initializing create_model()
2023-06-13 09:16:14,879:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D33A2B90>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D3C7A5F0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 09:16:14,880:INFO:Checking exceptions
2023-06-13 09:16:14,881:INFO:Importing libraries
2023-06-13 09:16:14,881:INFO:Copying training dataset
2023-06-13 09:16:14,900:INFO:Defining folds
2023-06-13 09:16:14,900:INFO:Declaring metric variables
2023-06-13 09:16:14,910:INFO:Importing untrained model
2023-06-13 09:16:14,921:INFO:Orthogonal Matching Pursuit Imported successfully
2023-06-13 09:16:14,938:INFO:Starting cross validation
2023-06-13 09:16:14,942:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 09:16:15,346:INFO:Calculating mean and std
2023-06-13 09:16:15,349:INFO:Creating metrics dataframe
2023-06-13 09:16:15,424:INFO:Uploading results into container
2023-06-13 09:16:15,427:INFO:Uploading model into container now
2023-06-13 09:16:15,428:INFO:_master_model_container: 7
2023-06-13 09:16:15,428:INFO:_display_container: 2
2023-06-13 09:16:15,428:INFO:OrthogonalMatchingPursuit()
2023-06-13 09:16:15,428:INFO:create_model() successfully completed......................................
2023-06-13 09:16:15,626:INFO:SubProcess create_model() end ==================================
2023-06-13 09:16:15,627:INFO:Creating metrics dataframe
2023-06-13 09:16:15,657:INFO:Initializing Bayesian Ridge
2023-06-13 09:16:15,658:INFO:Total runtime is 0.2523415962855021 minutes
2023-06-13 09:16:15,667:INFO:SubProcess create_model() called ==================================
2023-06-13 09:16:15,668:INFO:Initializing create_model()
2023-06-13 09:16:15,668:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D33A2B90>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D3C7A5F0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 09:16:15,669:INFO:Checking exceptions
2023-06-13 09:16:15,669:INFO:Importing libraries
2023-06-13 09:16:15,669:INFO:Copying training dataset
2023-06-13 09:16:15,686:INFO:Defining folds
2023-06-13 09:16:15,687:INFO:Declaring metric variables
2023-06-13 09:16:15,699:INFO:Importing untrained model
2023-06-13 09:16:15,715:INFO:Bayesian Ridge Imported successfully
2023-06-13 09:16:15,735:INFO:Starting cross validation
2023-06-13 09:16:15,738:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 09:16:16,152:INFO:Calculating mean and std
2023-06-13 09:16:16,154:INFO:Creating metrics dataframe
2023-06-13 09:16:16,222:INFO:Uploading results into container
2023-06-13 09:16:16,224:INFO:Uploading model into container now
2023-06-13 09:16:16,225:INFO:_master_model_container: 8
2023-06-13 09:16:16,226:INFO:_display_container: 2
2023-06-13 09:16:16,227:INFO:BayesianRidge()
2023-06-13 09:16:16,227:INFO:create_model() successfully completed......................................
2023-06-13 09:16:16,422:INFO:SubProcess create_model() end ==================================
2023-06-13 09:16:16,423:INFO:Creating metrics dataframe
2023-06-13 09:16:16,455:INFO:Initializing Passive Aggressive Regressor
2023-06-13 09:16:16,456:INFO:Total runtime is 0.26563677787780765 minutes
2023-06-13 09:16:16,465:INFO:SubProcess create_model() called ==================================
2023-06-13 09:16:16,466:INFO:Initializing create_model()
2023-06-13 09:16:16,466:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D33A2B90>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D3C7A5F0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 09:16:16,467:INFO:Checking exceptions
2023-06-13 09:16:16,467:INFO:Importing libraries
2023-06-13 09:16:16,467:INFO:Copying training dataset
2023-06-13 09:16:16,485:INFO:Defining folds
2023-06-13 09:16:16,486:INFO:Declaring metric variables
2023-06-13 09:16:16,499:INFO:Importing untrained model
2023-06-13 09:16:16,509:INFO:Passive Aggressive Regressor Imported successfully
2023-06-13 09:16:16,529:INFO:Starting cross validation
2023-06-13 09:16:16,531:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 09:16:16,949:INFO:Calculating mean and std
2023-06-13 09:16:16,951:INFO:Creating metrics dataframe
2023-06-13 09:16:17,012:INFO:Uploading results into container
2023-06-13 09:16:17,014:INFO:Uploading model into container now
2023-06-13 09:16:17,015:INFO:_master_model_container: 9
2023-06-13 09:16:17,015:INFO:_display_container: 2
2023-06-13 09:16:17,016:INFO:PassiveAggressiveRegressor(random_state=4116)
2023-06-13 09:16:17,016:INFO:create_model() successfully completed......................................
2023-06-13 09:16:17,206:INFO:SubProcess create_model() end ==================================
2023-06-13 09:16:17,207:INFO:Creating metrics dataframe
2023-06-13 09:16:17,239:INFO:Initializing Huber Regressor
2023-06-13 09:16:17,239:INFO:Total runtime is 0.2786819934844971 minutes
2023-06-13 09:16:17,252:INFO:SubProcess create_model() called ==================================
2023-06-13 09:16:17,254:INFO:Initializing create_model()
2023-06-13 09:16:17,254:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D33A2B90>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D3C7A5F0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 09:16:17,254:INFO:Checking exceptions
2023-06-13 09:16:17,255:INFO:Importing libraries
2023-06-13 09:16:17,255:INFO:Copying training dataset
2023-06-13 09:16:17,275:INFO:Defining folds
2023-06-13 09:16:17,276:INFO:Declaring metric variables
2023-06-13 09:16:17,286:INFO:Importing untrained model
2023-06-13 09:16:17,301:INFO:Huber Regressor Imported successfully
2023-06-13 09:16:17,323:INFO:Starting cross validation
2023-06-13 09:16:17,326:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 09:16:17,690:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-13 09:16:17,721:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-13 09:16:17,790:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-13 09:16:17,791:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-13 09:16:17,829:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-13 09:16:18,102:INFO:Calculating mean and std
2023-06-13 09:16:18,105:INFO:Creating metrics dataframe
2023-06-13 09:16:18,180:INFO:Uploading results into container
2023-06-13 09:16:18,182:INFO:Uploading model into container now
2023-06-13 09:16:18,183:INFO:_master_model_container: 10
2023-06-13 09:16:18,183:INFO:_display_container: 2
2023-06-13 09:16:18,183:INFO:HuberRegressor()
2023-06-13 09:16:18,184:INFO:create_model() successfully completed......................................
2023-06-13 09:16:18,384:INFO:SubProcess create_model() end ==================================
2023-06-13 09:16:18,384:INFO:Creating metrics dataframe
2023-06-13 09:16:18,417:INFO:Initializing K Neighbors Regressor
2023-06-13 09:16:18,417:INFO:Total runtime is 0.2983124812444052 minutes
2023-06-13 09:16:18,425:INFO:SubProcess create_model() called ==================================
2023-06-13 09:16:18,426:INFO:Initializing create_model()
2023-06-13 09:16:18,426:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D33A2B90>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D3C7A5F0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 09:16:18,427:INFO:Checking exceptions
2023-06-13 09:16:18,427:INFO:Importing libraries
2023-06-13 09:16:18,428:INFO:Copying training dataset
2023-06-13 09:16:18,450:INFO:Defining folds
2023-06-13 09:16:18,450:INFO:Declaring metric variables
2023-06-13 09:16:18,461:INFO:Importing untrained model
2023-06-13 09:16:18,473:INFO:K Neighbors Regressor Imported successfully
2023-06-13 09:16:18,494:INFO:Starting cross validation
2023-06-13 09:16:18,497:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 09:16:19,136:INFO:Calculating mean and std
2023-06-13 09:16:19,138:INFO:Creating metrics dataframe
2023-06-13 09:16:19,233:INFO:Uploading results into container
2023-06-13 09:16:19,235:INFO:Uploading model into container now
2023-06-13 09:16:19,236:INFO:_master_model_container: 11
2023-06-13 09:16:19,237:INFO:_display_container: 2
2023-06-13 09:16:19,237:INFO:KNeighborsRegressor(n_jobs=-1)
2023-06-13 09:16:19,237:INFO:create_model() successfully completed......................................
2023-06-13 09:16:19,437:INFO:SubProcess create_model() end ==================================
2023-06-13 09:16:19,437:INFO:Creating metrics dataframe
2023-06-13 09:16:19,470:INFO:Initializing Decision Tree Regressor
2023-06-13 09:16:19,470:INFO:Total runtime is 0.3158670822779338 minutes
2023-06-13 09:16:19,479:INFO:SubProcess create_model() called ==================================
2023-06-13 09:16:19,480:INFO:Initializing create_model()
2023-06-13 09:16:19,480:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D33A2B90>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D3C7A5F0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 09:16:19,481:INFO:Checking exceptions
2023-06-13 09:16:19,481:INFO:Importing libraries
2023-06-13 09:16:19,481:INFO:Copying training dataset
2023-06-13 09:16:19,497:INFO:Defining folds
2023-06-13 09:16:19,498:INFO:Declaring metric variables
2023-06-13 09:16:19,516:INFO:Importing untrained model
2023-06-13 09:16:19,525:INFO:Decision Tree Regressor Imported successfully
2023-06-13 09:16:19,547:INFO:Starting cross validation
2023-06-13 09:16:19,551:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 09:16:20,286:INFO:Calculating mean and std
2023-06-13 09:16:20,288:INFO:Creating metrics dataframe
2023-06-13 09:16:20,369:INFO:Uploading results into container
2023-06-13 09:16:20,371:INFO:Uploading model into container now
2023-06-13 09:16:20,372:INFO:_master_model_container: 12
2023-06-13 09:16:20,372:INFO:_display_container: 2
2023-06-13 09:16:20,373:INFO:DecisionTreeRegressor(random_state=4116)
2023-06-13 09:16:20,373:INFO:create_model() successfully completed......................................
2023-06-13 09:16:20,569:INFO:SubProcess create_model() end ==================================
2023-06-13 09:16:20,569:INFO:Creating metrics dataframe
2023-06-13 09:16:20,601:INFO:Initializing Random Forest Regressor
2023-06-13 09:16:20,602:INFO:Total runtime is 0.33473399082819627 minutes
2023-06-13 09:16:20,611:INFO:SubProcess create_model() called ==================================
2023-06-13 09:16:20,612:INFO:Initializing create_model()
2023-06-13 09:16:20,612:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D33A2B90>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D3C7A5F0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 09:16:20,613:INFO:Checking exceptions
2023-06-13 09:16:20,613:INFO:Importing libraries
2023-06-13 09:16:20,613:INFO:Copying training dataset
2023-06-13 09:16:20,633:INFO:Defining folds
2023-06-13 09:16:20,634:INFO:Declaring metric variables
2023-06-13 09:16:20,644:INFO:Importing untrained model
2023-06-13 09:16:20,658:INFO:Random Forest Regressor Imported successfully
2023-06-13 09:16:20,678:INFO:Starting cross validation
2023-06-13 09:16:20,680:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 09:16:33,342:INFO:Calculating mean and std
2023-06-13 09:16:33,345:INFO:Creating metrics dataframe
2023-06-13 09:16:33,441:INFO:Uploading results into container
2023-06-13 09:16:33,444:INFO:Uploading model into container now
2023-06-13 09:16:33,445:INFO:_master_model_container: 13
2023-06-13 09:16:33,445:INFO:_display_container: 2
2023-06-13 09:16:33,447:INFO:RandomForestRegressor(n_jobs=-1, random_state=4116)
2023-06-13 09:16:33,447:INFO:create_model() successfully completed......................................
2023-06-13 09:16:33,641:INFO:SubProcess create_model() end ==================================
2023-06-13 09:16:33,641:INFO:Creating metrics dataframe
2023-06-13 09:16:33,677:INFO:Initializing Extra Trees Regressor
2023-06-13 09:16:33,678:INFO:Total runtime is 0.5526634335517884 minutes
2023-06-13 09:16:33,686:INFO:SubProcess create_model() called ==================================
2023-06-13 09:16:33,686:INFO:Initializing create_model()
2023-06-13 09:16:33,686:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D33A2B90>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D3C7A5F0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 09:16:33,687:INFO:Checking exceptions
2023-06-13 09:16:33,687:INFO:Importing libraries
2023-06-13 09:16:33,687:INFO:Copying training dataset
2023-06-13 09:16:33,705:INFO:Defining folds
2023-06-13 09:16:33,705:INFO:Declaring metric variables
2023-06-13 09:16:33,715:INFO:Importing untrained model
2023-06-13 09:16:33,727:INFO:Extra Trees Regressor Imported successfully
2023-06-13 09:16:33,748:INFO:Starting cross validation
2023-06-13 09:16:33,751:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 09:16:37,818:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 09:16:37,825:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 09:16:37,917:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 09:16:37,934:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 09:16:38,652:INFO:Calculating mean and std
2023-06-13 09:16:38,656:INFO:Creating metrics dataframe
2023-06-13 09:16:38,750:INFO:Uploading results into container
2023-06-13 09:16:38,752:INFO:Uploading model into container now
2023-06-13 09:16:38,752:INFO:_master_model_container: 14
2023-06-13 09:16:38,753:INFO:_display_container: 2
2023-06-13 09:16:38,753:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=4116)
2023-06-13 09:16:38,753:INFO:create_model() successfully completed......................................
2023-06-13 09:16:38,960:INFO:SubProcess create_model() end ==================================
2023-06-13 09:16:38,962:INFO:Creating metrics dataframe
2023-06-13 09:16:39,008:INFO:Initializing AdaBoost Regressor
2023-06-13 09:16:39,009:INFO:Total runtime is 0.641525936126709 minutes
2023-06-13 09:16:39,019:INFO:SubProcess create_model() called ==================================
2023-06-13 09:16:39,021:INFO:Initializing create_model()
2023-06-13 09:16:39,021:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D33A2B90>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D3C7A5F0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 09:16:39,021:INFO:Checking exceptions
2023-06-13 09:16:39,021:INFO:Importing libraries
2023-06-13 09:16:39,022:INFO:Copying training dataset
2023-06-13 09:16:39,037:INFO:Defining folds
2023-06-13 09:16:39,038:INFO:Declaring metric variables
2023-06-13 09:16:39,048:INFO:Importing untrained model
2023-06-13 09:16:39,061:INFO:AdaBoost Regressor Imported successfully
2023-06-13 09:16:39,081:INFO:Starting cross validation
2023-06-13 09:16:39,084:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 09:16:40,435:INFO:Calculating mean and std
2023-06-13 09:16:40,437:INFO:Creating metrics dataframe
2023-06-13 09:16:40,542:INFO:Uploading results into container
2023-06-13 09:16:40,544:INFO:Uploading model into container now
2023-06-13 09:16:40,545:INFO:_master_model_container: 15
2023-06-13 09:16:40,546:INFO:_display_container: 2
2023-06-13 09:16:40,547:INFO:AdaBoostRegressor(random_state=4116)
2023-06-13 09:16:40,547:INFO:create_model() successfully completed......................................
2023-06-13 09:16:40,747:INFO:SubProcess create_model() end ==================================
2023-06-13 09:16:40,747:INFO:Creating metrics dataframe
2023-06-13 09:16:40,793:INFO:Initializing Gradient Boosting Regressor
2023-06-13 09:16:40,793:INFO:Total runtime is 0.6712546706199647 minutes
2023-06-13 09:16:40,802:INFO:SubProcess create_model() called ==================================
2023-06-13 09:16:40,803:INFO:Initializing create_model()
2023-06-13 09:16:40,804:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D33A2B90>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D3C7A5F0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 09:16:40,804:INFO:Checking exceptions
2023-06-13 09:16:40,805:INFO:Importing libraries
2023-06-13 09:16:40,805:INFO:Copying training dataset
2023-06-13 09:16:40,829:INFO:Defining folds
2023-06-13 09:16:40,830:INFO:Declaring metric variables
2023-06-13 09:16:40,843:INFO:Importing untrained model
2023-06-13 09:16:40,857:INFO:Gradient Boosting Regressor Imported successfully
2023-06-13 09:16:40,880:INFO:Starting cross validation
2023-06-13 09:16:40,883:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 09:16:46,500:INFO:Calculating mean and std
2023-06-13 09:16:46,503:INFO:Creating metrics dataframe
2023-06-13 09:16:46,647:INFO:Uploading results into container
2023-06-13 09:16:46,650:INFO:Uploading model into container now
2023-06-13 09:16:46,651:INFO:_master_model_container: 16
2023-06-13 09:16:46,651:INFO:_display_container: 2
2023-06-13 09:16:46,652:INFO:GradientBoostingRegressor(random_state=4116)
2023-06-13 09:16:46,653:INFO:create_model() successfully completed......................................
2023-06-13 09:16:46,848:INFO:SubProcess create_model() end ==================================
2023-06-13 09:16:46,849:INFO:Creating metrics dataframe
2023-06-13 09:16:46,887:INFO:Initializing Extreme Gradient Boosting
2023-06-13 09:16:46,887:INFO:Total runtime is 0.7728155533472698 minutes
2023-06-13 09:16:46,897:INFO:SubProcess create_model() called ==================================
2023-06-13 09:16:46,899:INFO:Initializing create_model()
2023-06-13 09:16:46,899:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D33A2B90>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D3C7A5F0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 09:16:46,900:INFO:Checking exceptions
2023-06-13 09:16:46,900:INFO:Importing libraries
2023-06-13 09:16:46,901:INFO:Copying training dataset
2023-06-13 09:16:46,920:INFO:Defining folds
2023-06-13 09:16:46,921:INFO:Declaring metric variables
2023-06-13 09:16:46,933:INFO:Importing untrained model
2023-06-13 09:16:46,947:INFO:Extreme Gradient Boosting Imported successfully
2023-06-13 09:16:46,966:INFO:Starting cross validation
2023-06-13 09:16:46,971:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 09:16:50,316:INFO:Calculating mean and std
2023-06-13 09:16:50,319:INFO:Creating metrics dataframe
2023-06-13 09:16:50,549:INFO:Uploading results into container
2023-06-13 09:16:50,551:INFO:Uploading model into container now
2023-06-13 09:16:50,552:INFO:_master_model_container: 17
2023-06-13 09:16:50,553:INFO:_display_container: 2
2023-06-13 09:16:50,556:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=4116, ...)
2023-06-13 09:16:50,557:INFO:create_model() successfully completed......................................
2023-06-13 09:16:50,749:INFO:SubProcess create_model() end ==================================
2023-06-13 09:16:50,750:INFO:Creating metrics dataframe
2023-06-13 09:16:50,790:INFO:Initializing Light Gradient Boosting Machine
2023-06-13 09:16:50,790:INFO:Total runtime is 0.8378770629564922 minutes
2023-06-13 09:16:50,802:INFO:SubProcess create_model() called ==================================
2023-06-13 09:16:50,803:INFO:Initializing create_model()
2023-06-13 09:16:50,803:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D33A2B90>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D3C7A5F0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 09:16:50,804:INFO:Checking exceptions
2023-06-13 09:16:50,804:INFO:Importing libraries
2023-06-13 09:16:50,804:INFO:Copying training dataset
2023-06-13 09:16:50,820:INFO:Defining folds
2023-06-13 09:16:50,820:INFO:Declaring metric variables
2023-06-13 09:16:50,830:INFO:Importing untrained model
2023-06-13 09:16:50,842:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-13 09:16:50,863:INFO:Starting cross validation
2023-06-13 09:16:50,867:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 09:16:54,389:INFO:Calculating mean and std
2023-06-13 09:16:54,392:INFO:Creating metrics dataframe
2023-06-13 09:16:54,544:INFO:Uploading results into container
2023-06-13 09:16:54,546:INFO:Uploading model into container now
2023-06-13 09:16:54,547:INFO:_master_model_container: 18
2023-06-13 09:16:54,548:INFO:_display_container: 2
2023-06-13 09:16:54,550:INFO:LGBMRegressor(random_state=4116)
2023-06-13 09:16:54,551:INFO:create_model() successfully completed......................................
2023-06-13 09:16:54,754:INFO:SubProcess create_model() end ==================================
2023-06-13 09:16:54,755:INFO:Creating metrics dataframe
2023-06-13 09:16:54,792:INFO:Initializing Dummy Regressor
2023-06-13 09:16:54,793:INFO:Total runtime is 0.9045851945877077 minutes
2023-06-13 09:16:54,802:INFO:SubProcess create_model() called ==================================
2023-06-13 09:16:54,803:INFO:Initializing create_model()
2023-06-13 09:16:54,803:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D33A2B90>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D3C7A5F0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 09:16:54,804:INFO:Checking exceptions
2023-06-13 09:16:54,804:INFO:Importing libraries
2023-06-13 09:16:54,804:INFO:Copying training dataset
2023-06-13 09:16:54,821:INFO:Defining folds
2023-06-13 09:16:54,822:INFO:Declaring metric variables
2023-06-13 09:16:54,831:INFO:Importing untrained model
2023-06-13 09:16:54,842:INFO:Dummy Regressor Imported successfully
2023-06-13 09:16:54,858:INFO:Starting cross validation
2023-06-13 09:16:54,860:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 09:16:55,371:INFO:Calculating mean and std
2023-06-13 09:16:55,374:INFO:Creating metrics dataframe
2023-06-13 09:16:55,520:INFO:Uploading results into container
2023-06-13 09:16:55,522:INFO:Uploading model into container now
2023-06-13 09:16:55,523:INFO:_master_model_container: 19
2023-06-13 09:16:55,523:INFO:_display_container: 2
2023-06-13 09:16:55,524:INFO:DummyRegressor()
2023-06-13 09:16:55,524:INFO:create_model() successfully completed......................................
2023-06-13 09:16:55,729:INFO:SubProcess create_model() end ==================================
2023-06-13 09:16:55,729:INFO:Creating metrics dataframe
2023-06-13 09:16:55,803:INFO:Initializing create_model()
2023-06-13 09:16:55,804:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D33A2B90>, estimator=ElasticNet(random_state=4116), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-13 09:16:55,804:INFO:Checking exceptions
2023-06-13 09:16:55,809:INFO:Importing libraries
2023-06-13 09:16:55,809:INFO:Copying training dataset
2023-06-13 09:16:55,826:INFO:Defining folds
2023-06-13 09:16:55,826:INFO:Declaring metric variables
2023-06-13 09:16:55,826:INFO:Importing untrained model
2023-06-13 09:16:55,827:INFO:Declaring custom model
2023-06-13 09:16:55,828:INFO:Elastic Net Imported successfully
2023-06-13 09:16:55,830:INFO:Cross validation set to False
2023-06-13 09:16:55,831:INFO:Fitting Model
2023-06-13 09:16:56,163:INFO:ElasticNet(random_state=4116)
2023-06-13 09:16:56,163:INFO:create_model() successfully completed......................................
2023-06-13 09:16:56,448:INFO:_master_model_container: 19
2023-06-13 09:16:56,449:INFO:_display_container: 2
2023-06-13 09:16:56,450:INFO:ElasticNet(random_state=4116)
2023-06-13 09:16:56,451:INFO:compare_models() successfully completed......................................
2023-06-13 09:18:08,777:INFO:Initializing plot_model()
2023-06-13 09:18:08,779:INFO:plot_model(plot=learning, fold=None, use_train_data=True, verbose=True, display=None, display_format=None, estimator=ElasticNet(random_state=4116), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D33A2B90>, system=True)
2023-06-13 09:18:08,779:INFO:Checking exceptions
2023-06-13 09:18:08,787:INFO:Preloading libraries
2023-06-13 09:18:08,787:INFO:Copying training dataset
2023-06-13 09:18:08,789:INFO:Plot type: learning
2023-06-13 09:18:09,077:INFO:Fitting Model
2023-06-13 09:18:09,270:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.365e+07, tolerance: 1.256e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:09,356:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.460e+08, tolerance: 8.198e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:09,378:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.452e+08, tolerance: 8.038e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:09,512:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.385e+08, tolerance: 6.995e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:09,520:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.527e+08, tolerance: 7.155e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:09,562:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.780e+07, tolerance: 1.345e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:09,583:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.765e+08, tolerance: 7.471e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:09,585:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.918e+08, tolerance: 7.611e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:09,638:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.045e+07, tolerance: 1.365e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:09,649:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.972e+08, tolerance: 7.673e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:09,695:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.314e+08, tolerance: 8.127e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:09,703:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.134e+08, tolerance: 7.721e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:09,749:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.451e+07, tolerance: 1.324e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:09,761:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.241e+08, tolerance: 8.287e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:09,800:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.527e+07, tolerance: 1.345e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:09,894:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.309e+08, tolerance: 8.108e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:09,926:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.451e+07, tolerance: 1.324e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:09,938:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.338e+08, tolerance: 8.268e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:09,963:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.099e+07, tolerance: 1.350e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:10,019:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.312e+06, tolerance: 1.395e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:10,097:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.216e+06, tolerance: 1.462e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:10,115:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.468e+08, tolerance: 7.904e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:10,137:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.451e+07, tolerance: 1.324e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:10,172:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.165e+07, tolerance: 8.380e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:10,197:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.099e+07, tolerance: 1.350e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:10,241:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.119e+06, tolerance: 1.393e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:10,309:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.231e+08, tolerance: 8.088e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:10,313:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.451e+07, tolerance: 1.324e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:10,334:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.099e+07, tolerance: 1.350e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:10,407:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.283e+08, tolerance: 8.248e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:10,424:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.119e+06, tolerance: 1.393e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:10,522:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.451e+07, tolerance: 1.324e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:10,537:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.099e+07, tolerance: 1.350e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:10,586:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.119e+06, tolerance: 1.393e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:10,659:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.451e+07, tolerance: 1.324e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:10,693:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.099e+07, tolerance: 1.350e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:10,723:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.119e+06, tolerance: 1.393e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:10,732:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.143e+07, tolerance: 8.377e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:10,745:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.234e+08, tolerance: 8.240e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:10,843:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.451e+07, tolerance: 1.324e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:10,871:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.234e+08, tolerance: 8.240e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:10,872:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.099e+07, tolerance: 1.350e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:10,937:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.119e+06, tolerance: 1.393e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:11,028:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.234e+08, tolerance: 8.240e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 09:18:11,975:INFO:Visual Rendered Successfully
2023-06-13 09:18:12,216:INFO:plot_model() successfully completed......................................
2023-06-13 09:18:20,714:INFO:Initializing plot_model()
2023-06-13 09:18:20,714:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ElasticNet(random_state=4116), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D33A2B90>, system=True)
2023-06-13 09:18:20,714:INFO:Checking exceptions
2023-06-13 09:18:20,729:INFO:Preloading libraries
2023-06-13 09:18:20,729:INFO:Copying training dataset
2023-06-13 09:18:20,730:INFO:Plot type: error
2023-06-13 09:18:21,054:INFO:Fitting Model
2023-06-13 09:18:21,055:WARNING:X does not have valid feature names, but ElasticNet was fitted with feature names

2023-06-13 09:18:21,057:INFO:Scoring test/hold-out set
2023-06-13 09:18:22,168:INFO:Visual Rendered Successfully
2023-06-13 09:18:22,367:INFO:plot_model() successfully completed......................................
2023-06-13 09:18:26,450:INFO:Initializing interpret_model()
2023-06-13 09:18:26,451:INFO:interpret_model(estimator=ElasticNet(random_state=4116), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D33A2B90>)
2023-06-13 09:18:26,451:INFO:Checking exceptions
2023-06-13 09:18:26,451:INFO:Soft dependency imported: shap: 0.41.0
2023-06-13 10:34:29,949:INFO:Initializing plot_model()
2023-06-13 10:34:29,950:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ElasticNet(random_state=4116), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D33A2B90>, system=True)
2023-06-13 10:34:29,950:INFO:Checking exceptions
2023-06-13 10:34:29,969:INFO:Preloading libraries
2023-06-13 10:34:29,969:INFO:Copying training dataset
2023-06-13 10:34:29,970:INFO:Plot type: residuals
2023-06-13 10:34:30,337:INFO:Fitting Model
2023-06-13 10:34:30,337:WARNING:X does not have valid feature names, but ElasticNet was fitted with feature names

2023-06-13 10:34:30,446:INFO:Scoring test/hold-out set
2023-06-13 10:34:31,555:INFO:Visual Rendered Successfully
2023-06-13 10:34:31,871:INFO:plot_model() successfully completed......................................
2023-06-13 10:55:58,239:INFO:PyCaret RegressionExperiment
2023-06-13 10:55:58,239:INFO:Logging name: reg-default-name
2023-06-13 10:55:58,239:INFO:ML Usecase: MLUsecase.REGRESSION
2023-06-13 10:55:58,239:INFO:version 3.0.2
2023-06-13 10:55:58,239:INFO:Initializing setup()
2023-06-13 10:55:58,240:INFO:self.USI: 5f49
2023-06-13 10:55:58,240:INFO:self._variable_keys: {'fold_groups_param', 'data', 'y', 'transform_target_param', 'fold_shuffle_param', 'gpu_n_jobs_param', 'X_test', 'exp_id', 'logging_param', 'y_train', 'target_param', '_available_plots', 'html_param', 'X_train', 'USI', 'pipeline', 'y_test', 'fold_generator', 'exp_name_log', 'X', 'log_plots_param', 'gpu_param', 'memory', 'idx', '_ml_usecase', 'n_jobs_param', 'seed'}
2023-06-13 10:55:58,240:INFO:Checking environment
2023-06-13 10:55:58,240:INFO:python_version: 3.10.9
2023-06-13 10:55:58,240:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-06-13 10:55:58,240:INFO:machine: AMD64
2023-06-13 10:55:58,240:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-13 10:55:58,241:INFO:Memory: svmem(total=16901767168, available=5527588864, percent=67.3, used=11374178304, free=5527588864)
2023-06-13 10:55:58,241:INFO:Physical Core: 4
2023-06-13 10:55:58,241:INFO:Logical Core: 8
2023-06-13 10:55:58,241:INFO:Checking libraries
2023-06-13 10:55:58,241:INFO:System:
2023-06-13 10:55:58,241:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-06-13 10:55:58,241:INFO:executable: C:\Users\lapei\anaconda3\python.exe
2023-06-13 10:55:58,242:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-13 10:55:58,242:INFO:PyCaret required dependencies:
2023-06-13 10:55:58,242:INFO:                 pip: 22.3.1
2023-06-13 10:55:58,242:INFO:          setuptools: 65.6.3
2023-06-13 10:55:58,242:INFO:             pycaret: 3.0.2
2023-06-13 10:55:58,242:INFO:             IPython: 8.10.0
2023-06-13 10:55:58,242:INFO:          ipywidgets: 7.6.5
2023-06-13 10:55:58,243:INFO:                tqdm: 4.64.1
2023-06-13 10:55:58,243:INFO:               numpy: 1.23.5
2023-06-13 10:55:58,243:INFO:              pandas: 1.5.3
2023-06-13 10:55:58,243:INFO:              jinja2: 3.1.2
2023-06-13 10:55:58,243:INFO:               scipy: 1.10.0
2023-06-13 10:55:58,243:INFO:              joblib: 1.2.0
2023-06-13 10:55:58,243:INFO:             sklearn: 1.2.1
2023-06-13 10:55:58,243:INFO:                pyod: 1.0.9
2023-06-13 10:55:58,243:INFO:            imblearn: 0.10.1
2023-06-13 10:55:58,243:INFO:   category_encoders: 2.6.1
2023-06-13 10:55:58,244:INFO:            lightgbm: 3.3.5
2023-06-13 10:55:58,244:INFO:               numba: 0.56.4
2023-06-13 10:55:58,244:INFO:            requests: 2.28.1
2023-06-13 10:55:58,244:INFO:          matplotlib: 3.7.0
2023-06-13 10:55:58,244:INFO:          scikitplot: 0.3.7
2023-06-13 10:55:58,244:INFO:         yellowbrick: 1.5
2023-06-13 10:55:58,244:INFO:              plotly: 5.9.0
2023-06-13 10:55:58,244:INFO:             kaleido: 0.2.1
2023-06-13 10:55:58,244:INFO:         statsmodels: 0.13.5
2023-06-13 10:55:58,245:INFO:              sktime: 0.17.0
2023-06-13 10:55:58,245:INFO:               tbats: 1.1.3
2023-06-13 10:55:58,245:INFO:            pmdarima: 2.0.3
2023-06-13 10:55:58,245:INFO:              psutil: 5.9.0
2023-06-13 10:55:58,245:INFO:PyCaret optional dependencies:
2023-06-13 10:55:58,245:INFO:                shap: 0.41.0
2023-06-13 10:55:58,245:INFO:           interpret: Not installed
2023-06-13 10:55:58,246:INFO:                umap: Not installed
2023-06-13 10:55:58,246:INFO:    pandas_profiling: Not installed
2023-06-13 10:55:58,246:INFO:  explainerdashboard: Not installed
2023-06-13 10:55:58,246:INFO:             autoviz: Not installed
2023-06-13 10:55:58,246:INFO:           fairlearn: Not installed
2023-06-13 10:55:58,246:INFO:             xgboost: 1.7.3
2023-06-13 10:55:58,246:INFO:            catboost: Not installed
2023-06-13 10:55:58,246:INFO:              kmodes: Not installed
2023-06-13 10:55:58,246:INFO:             mlxtend: Not installed
2023-06-13 10:55:58,247:INFO:       statsforecast: Not installed
2023-06-13 10:55:58,247:INFO:        tune_sklearn: Not installed
2023-06-13 10:55:58,247:INFO:                 ray: Not installed
2023-06-13 10:55:58,247:INFO:            hyperopt: Not installed
2023-06-13 10:55:58,247:INFO:              optuna: Not installed
2023-06-13 10:55:58,247:INFO:               skopt: 0.9.0
2023-06-13 10:55:58,247:INFO:              mlflow: Not installed
2023-06-13 10:55:58,247:INFO:              gradio: Not installed
2023-06-13 10:55:58,247:INFO:             fastapi: Not installed
2023-06-13 10:55:58,248:INFO:             uvicorn: Not installed
2023-06-13 10:55:58,248:INFO:              m2cgen: Not installed
2023-06-13 10:55:58,248:INFO:           evidently: Not installed
2023-06-13 10:55:58,248:INFO:               fugue: Not installed
2023-06-13 10:55:58,248:INFO:           streamlit: Not installed
2023-06-13 10:55:58,248:INFO:             prophet: Not installed
2023-06-13 10:55:58,248:INFO:None
2023-06-13 10:55:58,248:INFO:Set up data.
2023-06-13 10:55:58,279:INFO:Set up train/test split.
2023-06-13 10:55:58,292:INFO:Set up index.
2023-06-13 10:55:58,293:INFO:Set up folding strategy.
2023-06-13 10:55:58,293:INFO:Assigning column types.
2023-06-13 10:55:58,304:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-13 10:55:58,305:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-13 10:55:58,318:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-13 10:55:58,331:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-13 10:55:58,490:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 10:55:58,621:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 10:55:58,622:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 10:55:58,630:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 10:55:58,631:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-13 10:55:58,644:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-13 10:55:58,656:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-13 10:55:58,822:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 10:55:58,949:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 10:55:58,951:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 10:55:58,958:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 10:55:58,958:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-06-13 10:55:58,972:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-13 10:55:58,984:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-13 10:55:59,149:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 10:55:59,273:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 10:55:59,274:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 10:55:59,282:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 10:55:59,295:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-13 10:55:59,311:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-13 10:55:59,483:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 10:55:59,608:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 10:55:59,609:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 10:55:59,616:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 10:55:59,617:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-06-13 10:55:59,644:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-13 10:55:59,809:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 10:55:59,944:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 10:55:59,946:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 10:55:59,954:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 10:55:59,982:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-13 10:56:00,232:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 10:56:00,411:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 10:56:00,413:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 10:56:00,425:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 10:56:00,426:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-06-13 10:56:00,622:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 10:56:00,746:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 10:56:00,749:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 10:56:00,756:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 10:56:00,949:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 10:56:01,074:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 10:56:01,076:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 10:56:01,084:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 10:56:01,085:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-13 10:56:01,277:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 10:56:01,409:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 10:56:01,419:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 10:56:01,608:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 10:56:01,732:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 10:56:01,740:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 10:56:01,741:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-06-13 10:56:02,067:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 10:56:02,075:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 10:56:02,391:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 10:56:02,398:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 10:56:02,402:INFO:Preparing preprocessing pipeline...
2023-06-13 10:56:02,402:INFO:Set up simple imputation.
2023-06-13 10:56:02,404:INFO:Set up column name cleaning.
2023-06-13 10:56:02,483:INFO:Finished creating preprocessing pipeline.
2023-06-13 10:56:02,498:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\lapei\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['taxa_homicidio', 'RH_adm_dir',
                                             'densidade_banda_larga',
                                             'densidade_telefonia_movel',
                                             'qtd_cursos_engenharias',
                                             'qtd_cursos_negocios_direito',
                                             'media_notas_CN', 'media_notas_CH',
                                             'media_NU_NOTA_LC',
                                             'media_NU_NOTA_MT',
                                             'media_...
                                             'Isencao_ISSQN_Sim',
                                             'Isencao_Tx_Sim',
                                             'Cessao_terrenos_Sim',
                                             'Doacao_terrenos_Sim',
                                             'Outros_mecanismos_Sim',
                                             'ISH_Baixa', 'ISH_Máxima',
                                             'ISH_Média', 'ISH_Mínima'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-06-13 10:56:02,498:INFO:Creating final display dataframe.
2023-06-13 10:56:02,761:INFO:Setup _display_container:                     Description                              Value
0                    Session id                               2432
1                        Target  qtd_abertas_Empresario_Individual
2                   Target type                         Regression
3           Original data shape                         (4456, 31)
4        Transformed data shape                         (4456, 31)
5   Transformed train set shape                         (3119, 31)
6    Transformed test set shape                         (1337, 31)
7              Numeric features                                 30
8                    Preprocess                               True
9               Imputation type                             simple
10           Numeric imputation                               mean
11       Categorical imputation                               mode
12               Fold Generator                              KFold
13                  Fold Number                                 10
14                     CPU Jobs                                 -1
15                      Use GPU                              False
16               Log Experiment                              False
17              Experiment Name                   reg-default-name
18                          USI                               5f49
2023-06-13 10:56:03,124:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 10:56:03,132:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 10:56:03,461:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 10:56:03,469:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 10:56:03,471:INFO:setup() successfully completed in 5.31s...............
2023-06-13 10:59:28,080:INFO:PyCaret RegressionExperiment
2023-06-13 10:59:28,080:INFO:Logging name: reg-default-name
2023-06-13 10:59:28,080:INFO:ML Usecase: MLUsecase.REGRESSION
2023-06-13 10:59:28,080:INFO:version 3.0.2
2023-06-13 10:59:28,081:INFO:Initializing setup()
2023-06-13 10:59:28,081:INFO:self.USI: c0e3
2023-06-13 10:59:28,081:INFO:self._variable_keys: {'fold_groups_param', 'data', 'y', 'transform_target_param', 'fold_shuffle_param', 'gpu_n_jobs_param', 'X_test', 'exp_id', 'logging_param', 'y_train', 'target_param', '_available_plots', 'html_param', 'X_train', 'USI', 'pipeline', 'y_test', 'fold_generator', 'exp_name_log', 'X', 'log_plots_param', 'gpu_param', 'memory', 'idx', '_ml_usecase', 'n_jobs_param', 'seed'}
2023-06-13 10:59:28,081:INFO:Checking environment
2023-06-13 10:59:28,081:INFO:python_version: 3.10.9
2023-06-13 10:59:28,081:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-06-13 10:59:28,081:INFO:machine: AMD64
2023-06-13 10:59:28,081:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-13 10:59:28,082:INFO:Memory: svmem(total=16901767168, available=5349519360, percent=68.3, used=11552247808, free=5349519360)
2023-06-13 10:59:28,082:INFO:Physical Core: 4
2023-06-13 10:59:28,082:INFO:Logical Core: 8
2023-06-13 10:59:28,083:INFO:Checking libraries
2023-06-13 10:59:28,083:INFO:System:
2023-06-13 10:59:28,083:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-06-13 10:59:28,083:INFO:executable: C:\Users\lapei\anaconda3\python.exe
2023-06-13 10:59:28,083:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-13 10:59:28,083:INFO:PyCaret required dependencies:
2023-06-13 10:59:28,084:INFO:                 pip: 22.3.1
2023-06-13 10:59:28,084:INFO:          setuptools: 65.6.3
2023-06-13 10:59:28,084:INFO:             pycaret: 3.0.2
2023-06-13 10:59:28,084:INFO:             IPython: 8.10.0
2023-06-13 10:59:28,084:INFO:          ipywidgets: 7.6.5
2023-06-13 10:59:28,084:INFO:                tqdm: 4.64.1
2023-06-13 10:59:28,085:INFO:               numpy: 1.23.5
2023-06-13 10:59:28,085:INFO:              pandas: 1.5.3
2023-06-13 10:59:28,085:INFO:              jinja2: 3.1.2
2023-06-13 10:59:28,085:INFO:               scipy: 1.10.0
2023-06-13 10:59:28,085:INFO:              joblib: 1.2.0
2023-06-13 10:59:28,085:INFO:             sklearn: 1.2.1
2023-06-13 10:59:28,085:INFO:                pyod: 1.0.9
2023-06-13 10:59:28,085:INFO:            imblearn: 0.10.1
2023-06-13 10:59:28,085:INFO:   category_encoders: 2.6.1
2023-06-13 10:59:28,086:INFO:            lightgbm: 3.3.5
2023-06-13 10:59:28,086:INFO:               numba: 0.56.4
2023-06-13 10:59:28,086:INFO:            requests: 2.28.1
2023-06-13 10:59:28,086:INFO:          matplotlib: 3.7.0
2023-06-13 10:59:28,086:INFO:          scikitplot: 0.3.7
2023-06-13 10:59:28,086:INFO:         yellowbrick: 1.5
2023-06-13 10:59:28,086:INFO:              plotly: 5.9.0
2023-06-13 10:59:28,086:INFO:             kaleido: 0.2.1
2023-06-13 10:59:28,086:INFO:         statsmodels: 0.13.5
2023-06-13 10:59:28,087:INFO:              sktime: 0.17.0
2023-06-13 10:59:28,087:INFO:               tbats: 1.1.3
2023-06-13 10:59:28,087:INFO:            pmdarima: 2.0.3
2023-06-13 10:59:28,087:INFO:              psutil: 5.9.0
2023-06-13 10:59:28,087:INFO:PyCaret optional dependencies:
2023-06-13 10:59:28,087:INFO:                shap: 0.41.0
2023-06-13 10:59:28,087:INFO:           interpret: Not installed
2023-06-13 10:59:28,087:INFO:                umap: Not installed
2023-06-13 10:59:28,087:INFO:    pandas_profiling: Not installed
2023-06-13 10:59:28,088:INFO:  explainerdashboard: Not installed
2023-06-13 10:59:28,088:INFO:             autoviz: Not installed
2023-06-13 10:59:28,088:INFO:           fairlearn: Not installed
2023-06-13 10:59:28,088:INFO:             xgboost: 1.7.3
2023-06-13 10:59:28,088:INFO:            catboost: Not installed
2023-06-13 10:59:28,088:INFO:              kmodes: Not installed
2023-06-13 10:59:28,088:INFO:             mlxtend: Not installed
2023-06-13 10:59:28,088:INFO:       statsforecast: Not installed
2023-06-13 10:59:28,088:INFO:        tune_sklearn: Not installed
2023-06-13 10:59:28,089:INFO:                 ray: Not installed
2023-06-13 10:59:28,089:INFO:            hyperopt: Not installed
2023-06-13 10:59:28,089:INFO:              optuna: Not installed
2023-06-13 10:59:28,089:INFO:               skopt: 0.9.0
2023-06-13 10:59:28,089:INFO:              mlflow: Not installed
2023-06-13 10:59:28,089:INFO:              gradio: Not installed
2023-06-13 10:59:28,089:INFO:             fastapi: Not installed
2023-06-13 10:59:28,090:INFO:             uvicorn: Not installed
2023-06-13 10:59:28,090:INFO:              m2cgen: Not installed
2023-06-13 10:59:28,090:INFO:           evidently: Not installed
2023-06-13 10:59:28,090:INFO:               fugue: Not installed
2023-06-13 10:59:28,090:INFO:           streamlit: Not installed
2023-06-13 10:59:28,090:INFO:             prophet: Not installed
2023-06-13 10:59:28,090:INFO:None
2023-06-13 10:59:28,090:INFO:Set up data.
2023-06-13 10:59:28,122:INFO:Set up train/test split.
2023-06-13 10:59:28,136:INFO:Set up index.
2023-06-13 10:59:28,137:INFO:Set up folding strategy.
2023-06-13 10:59:28,137:INFO:Assigning column types.
2023-06-13 10:59:28,147:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-13 10:59:28,148:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-13 10:59:28,161:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-13 10:59:28,174:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-13 10:59:28,337:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 10:59:28,471:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 10:59:28,473:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 10:59:28,481:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 10:59:28,482:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-13 10:59:28,495:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-13 10:59:28,507:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-13 10:59:28,675:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 10:59:28,797:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 10:59:28,799:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 10:59:28,806:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 10:59:28,807:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-06-13 10:59:28,820:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-13 10:59:28,833:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-13 10:59:28,996:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 10:59:29,120:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 10:59:29,122:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 10:59:29,130:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 10:59:29,144:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-13 10:59:29,158:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-13 10:59:29,321:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 10:59:29,444:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 10:59:29,445:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 10:59:29,453:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 10:59:29,455:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-06-13 10:59:29,479:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-13 10:59:29,644:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 10:59:29,775:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 10:59:29,776:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 10:59:29,783:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 10:59:29,809:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-13 10:59:29,983:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 10:59:30,107:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 10:59:30,109:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 10:59:30,116:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 10:59:30,117:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-06-13 10:59:30,356:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 10:59:30,480:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 10:59:30,482:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 10:59:30,489:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 10:59:30,680:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 10:59:30,803:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 10:59:30,805:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 10:59:30,812:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 10:59:30,813:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-13 10:59:30,995:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 10:59:31,125:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 10:59:31,133:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 10:59:31,316:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 10:59:31,459:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 10:59:31,466:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 10:59:31,467:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-06-13 10:59:31,787:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 10:59:31,794:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 10:59:32,111:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 10:59:32,118:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 10:59:32,121:INFO:Preparing preprocessing pipeline...
2023-06-13 10:59:32,121:INFO:Set up simple imputation.
2023-06-13 10:59:32,124:INFO:Set up column name cleaning.
2023-06-13 10:59:32,201:INFO:Finished creating preprocessing pipeline.
2023-06-13 10:59:32,216:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\lapei\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['taxa_homicidio', 'RH_adm_dir',
                                             'densidade_banda_larga',
                                             'densidade_telefonia_movel',
                                             'qtd_cursos_engenharias',
                                             'qtd_cursos_negocios_direito',
                                             'media_notas_CN', 'media_notas_CH',
                                             'media_NU_NOTA_LC',
                                             'media_NU_NOTA_MT',
                                             'media_...
                                             'Isencao_ISSQN_Sim',
                                             'Isencao_Tx_Sim',
                                             'Cessao_terrenos_Sim',
                                             'Doacao_terrenos_Sim',
                                             'Outros_mecanismos_Sim',
                                             'ISH_Baixa', 'ISH_Máxima',
                                             'ISH_Média', 'ISH_Mínima'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-06-13 10:59:32,216:INFO:Creating final display dataframe.
2023-06-13 10:59:32,451:INFO:Setup _display_container:                     Description                              Value
0                    Session id                               6995
1                        Target  qtd_abertas_Empresario_Individual
2                   Target type                         Regression
3           Original data shape                         (4456, 30)
4        Transformed data shape                         (4456, 30)
5   Transformed train set shape                         (3119, 30)
6    Transformed test set shape                         (1337, 30)
7              Numeric features                                 29
8                    Preprocess                               True
9               Imputation type                             simple
10           Numeric imputation                               mean
11       Categorical imputation                               mode
12               Fold Generator                              KFold
13                  Fold Number                                 10
14                     CPU Jobs                                 -1
15                      Use GPU                              False
16               Log Experiment                              False
17              Experiment Name                   reg-default-name
18                          USI                               c0e3
2023-06-13 10:59:32,786:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 10:59:32,806:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 10:59:33,115:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 10:59:33,122:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 10:59:33,124:INFO:setup() successfully completed in 5.12s...............
2023-06-13 10:59:35,056:INFO:Initializing compare_models()
2023-06-13 10:59:35,057:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D66760E0>, include=None, fold=5, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001E3D66760E0>, 'include': None, 'exclude': None, 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-06-13 10:59:35,057:INFO:Checking exceptions
2023-06-13 10:59:35,063:INFO:Preparing display monitor
2023-06-13 10:59:35,141:INFO:Initializing Linear Regression
2023-06-13 10:59:35,142:INFO:Total runtime is 1.6498565673828126e-05 minutes
2023-06-13 10:59:35,154:INFO:SubProcess create_model() called ==================================
2023-06-13 10:59:35,155:INFO:Initializing create_model()
2023-06-13 10:59:35,156:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D66760E0>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D78D8460>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 10:59:35,156:INFO:Checking exceptions
2023-06-13 10:59:35,156:INFO:Importing libraries
2023-06-13 10:59:35,156:INFO:Copying training dataset
2023-06-13 10:59:35,177:INFO:Defining folds
2023-06-13 10:59:35,177:INFO:Declaring metric variables
2023-06-13 10:59:35,186:INFO:Importing untrained model
2023-06-13 10:59:35,197:INFO:Linear Regression Imported successfully
2023-06-13 10:59:35,216:INFO:Starting cross validation
2023-06-13 10:59:35,219:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 10:59:42,020:INFO:Calculating mean and std
2023-06-13 10:59:42,023:INFO:Creating metrics dataframe
2023-06-13 10:59:42,171:INFO:Uploading results into container
2023-06-13 10:59:42,173:INFO:Uploading model into container now
2023-06-13 10:59:42,174:INFO:_master_model_container: 1
2023-06-13 10:59:42,175:INFO:_display_container: 2
2023-06-13 10:59:42,176:INFO:LinearRegression(n_jobs=-1)
2023-06-13 10:59:42,176:INFO:create_model() successfully completed......................................
2023-06-13 10:59:42,443:INFO:SubProcess create_model() end ==================================
2023-06-13 10:59:42,443:INFO:Creating metrics dataframe
2023-06-13 10:59:42,468:INFO:Initializing Lasso Regression
2023-06-13 10:59:42,469:INFO:Total runtime is 0.12213632663091024 minutes
2023-06-13 10:59:42,478:INFO:SubProcess create_model() called ==================================
2023-06-13 10:59:42,479:INFO:Initializing create_model()
2023-06-13 10:59:42,479:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D66760E0>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D78D8460>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 10:59:42,480:INFO:Checking exceptions
2023-06-13 10:59:42,480:INFO:Importing libraries
2023-06-13 10:59:42,480:INFO:Copying training dataset
2023-06-13 10:59:42,498:INFO:Defining folds
2023-06-13 10:59:42,499:INFO:Declaring metric variables
2023-06-13 10:59:42,516:INFO:Importing untrained model
2023-06-13 10:59:42,527:INFO:Lasso Regression Imported successfully
2023-06-13 10:59:42,551:INFO:Starting cross validation
2023-06-13 10:59:42,556:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 10:59:49,187:INFO:Calculating mean and std
2023-06-13 10:59:49,190:INFO:Creating metrics dataframe
2023-06-13 10:59:49,334:INFO:Uploading results into container
2023-06-13 10:59:49,336:INFO:Uploading model into container now
2023-06-13 10:59:49,337:INFO:_master_model_container: 2
2023-06-13 10:59:49,337:INFO:_display_container: 2
2023-06-13 10:59:49,338:INFO:Lasso(random_state=6995)
2023-06-13 10:59:49,339:INFO:create_model() successfully completed......................................
2023-06-13 10:59:49,584:INFO:SubProcess create_model() end ==================================
2023-06-13 10:59:49,585:INFO:Creating metrics dataframe
2023-06-13 10:59:49,611:INFO:Initializing Ridge Regression
2023-06-13 10:59:49,612:INFO:Total runtime is 0.2411868174870809 minutes
2023-06-13 10:59:49,621:INFO:SubProcess create_model() called ==================================
2023-06-13 10:59:49,622:INFO:Initializing create_model()
2023-06-13 10:59:49,623:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D66760E0>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D78D8460>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 10:59:49,624:INFO:Checking exceptions
2023-06-13 10:59:49,624:INFO:Importing libraries
2023-06-13 10:59:49,624:INFO:Copying training dataset
2023-06-13 10:59:49,648:INFO:Defining folds
2023-06-13 10:59:49,648:INFO:Declaring metric variables
2023-06-13 10:59:49,660:INFO:Importing untrained model
2023-06-13 10:59:49,674:INFO:Ridge Regression Imported successfully
2023-06-13 10:59:49,694:INFO:Starting cross validation
2023-06-13 10:59:49,699:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 10:59:50,236:INFO:Calculating mean and std
2023-06-13 10:59:50,239:INFO:Creating metrics dataframe
2023-06-13 10:59:50,405:INFO:Uploading results into container
2023-06-13 10:59:50,407:INFO:Uploading model into container now
2023-06-13 10:59:50,408:INFO:_master_model_container: 3
2023-06-13 10:59:50,409:INFO:_display_container: 2
2023-06-13 10:59:50,410:INFO:Ridge(random_state=6995)
2023-06-13 10:59:50,411:INFO:create_model() successfully completed......................................
2023-06-13 10:59:50,665:INFO:SubProcess create_model() end ==================================
2023-06-13 10:59:50,666:INFO:Creating metrics dataframe
2023-06-13 10:59:50,697:INFO:Initializing Elastic Net
2023-06-13 10:59:50,697:INFO:Total runtime is 0.25927847226460776 minutes
2023-06-13 10:59:50,707:INFO:SubProcess create_model() called ==================================
2023-06-13 10:59:50,709:INFO:Initializing create_model()
2023-06-13 10:59:50,709:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D66760E0>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D78D8460>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 10:59:50,710:INFO:Checking exceptions
2023-06-13 10:59:50,711:INFO:Importing libraries
2023-06-13 10:59:50,711:INFO:Copying training dataset
2023-06-13 10:59:50,733:INFO:Defining folds
2023-06-13 10:59:50,734:INFO:Declaring metric variables
2023-06-13 10:59:50,744:INFO:Importing untrained model
2023-06-13 10:59:50,756:INFO:Elastic Net Imported successfully
2023-06-13 10:59:50,777:INFO:Starting cross validation
2023-06-13 10:59:50,779:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 10:59:51,046:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.781e+07, tolerance: 8.852e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 10:59:51,476:INFO:Calculating mean and std
2023-06-13 10:59:51,479:INFO:Creating metrics dataframe
2023-06-13 10:59:51,662:INFO:Uploading results into container
2023-06-13 10:59:51,663:INFO:Uploading model into container now
2023-06-13 10:59:51,664:INFO:_master_model_container: 4
2023-06-13 10:59:51,664:INFO:_display_container: 2
2023-06-13 10:59:51,665:INFO:ElasticNet(random_state=6995)
2023-06-13 10:59:51,665:INFO:create_model() successfully completed......................................
2023-06-13 10:59:51,922:INFO:SubProcess create_model() end ==================================
2023-06-13 10:59:51,923:INFO:Creating metrics dataframe
2023-06-13 10:59:51,966:INFO:Initializing Least Angle Regression
2023-06-13 10:59:51,968:INFO:Total runtime is 0.28043508529663086 minutes
2023-06-13 10:59:51,977:INFO:SubProcess create_model() called ==================================
2023-06-13 10:59:51,978:INFO:Initializing create_model()
2023-06-13 10:59:51,979:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D66760E0>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D78D8460>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 10:59:51,979:INFO:Checking exceptions
2023-06-13 10:59:51,979:INFO:Importing libraries
2023-06-13 10:59:51,980:INFO:Copying training dataset
2023-06-13 10:59:51,999:INFO:Defining folds
2023-06-13 10:59:52,000:INFO:Declaring metric variables
2023-06-13 10:59:52,010:INFO:Importing untrained model
2023-06-13 10:59:52,023:INFO:Least Angle Regression Imported successfully
2023-06-13 10:59:52,047:INFO:Starting cross validation
2023-06-13 10:59:52,050:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 10:59:52,656:INFO:Calculating mean and std
2023-06-13 10:59:52,660:INFO:Creating metrics dataframe
2023-06-13 10:59:52,826:INFO:Uploading results into container
2023-06-13 10:59:52,829:INFO:Uploading model into container now
2023-06-13 10:59:52,830:INFO:_master_model_container: 5
2023-06-13 10:59:52,831:INFO:_display_container: 2
2023-06-13 10:59:52,832:INFO:Lars(random_state=6995)
2023-06-13 10:59:52,834:INFO:create_model() successfully completed......................................
2023-06-13 10:59:53,091:INFO:SubProcess create_model() end ==================================
2023-06-13 10:59:53,091:INFO:Creating metrics dataframe
2023-06-13 10:59:53,121:INFO:Initializing Lasso Least Angle Regression
2023-06-13 10:59:53,122:INFO:Total runtime is 0.2996929446856181 minutes
2023-06-13 10:59:53,133:INFO:SubProcess create_model() called ==================================
2023-06-13 10:59:53,134:INFO:Initializing create_model()
2023-06-13 10:59:53,134:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D66760E0>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D78D8460>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 10:59:53,134:INFO:Checking exceptions
2023-06-13 10:59:53,135:INFO:Importing libraries
2023-06-13 10:59:53,135:INFO:Copying training dataset
2023-06-13 10:59:53,158:INFO:Defining folds
2023-06-13 10:59:53,159:INFO:Declaring metric variables
2023-06-13 10:59:53,168:INFO:Importing untrained model
2023-06-13 10:59:53,179:INFO:Lasso Least Angle Regression Imported successfully
2023-06-13 10:59:53,196:INFO:Starting cross validation
2023-06-13 10:59:53,201:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 10:59:53,786:INFO:Calculating mean and std
2023-06-13 10:59:53,790:INFO:Creating metrics dataframe
2023-06-13 10:59:53,939:INFO:Uploading results into container
2023-06-13 10:59:53,941:INFO:Uploading model into container now
2023-06-13 10:59:53,942:INFO:_master_model_container: 6
2023-06-13 10:59:53,942:INFO:_display_container: 2
2023-06-13 10:59:53,943:INFO:LassoLars(random_state=6995)
2023-06-13 10:59:53,944:INFO:create_model() successfully completed......................................
2023-06-13 10:59:54,207:INFO:SubProcess create_model() end ==================================
2023-06-13 10:59:54,207:INFO:Creating metrics dataframe
2023-06-13 10:59:54,242:INFO:Initializing Orthogonal Matching Pursuit
2023-06-13 10:59:54,242:INFO:Total runtime is 0.3183587153752645 minutes
2023-06-13 10:59:54,255:INFO:SubProcess create_model() called ==================================
2023-06-13 10:59:54,256:INFO:Initializing create_model()
2023-06-13 10:59:54,256:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D66760E0>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D78D8460>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 10:59:54,257:INFO:Checking exceptions
2023-06-13 10:59:54,257:INFO:Importing libraries
2023-06-13 10:59:54,257:INFO:Copying training dataset
2023-06-13 10:59:54,270:INFO:Defining folds
2023-06-13 10:59:54,271:INFO:Declaring metric variables
2023-06-13 10:59:54,283:INFO:Importing untrained model
2023-06-13 10:59:54,293:INFO:Orthogonal Matching Pursuit Imported successfully
2023-06-13 10:59:54,315:INFO:Starting cross validation
2023-06-13 10:59:54,318:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 10:59:54,907:INFO:Calculating mean and std
2023-06-13 10:59:54,910:INFO:Creating metrics dataframe
2023-06-13 10:59:55,059:INFO:Uploading results into container
2023-06-13 10:59:55,061:INFO:Uploading model into container now
2023-06-13 10:59:55,063:INFO:_master_model_container: 7
2023-06-13 10:59:55,063:INFO:_display_container: 2
2023-06-13 10:59:55,064:INFO:OrthogonalMatchingPursuit()
2023-06-13 10:59:55,064:INFO:create_model() successfully completed......................................
2023-06-13 10:59:55,306:INFO:SubProcess create_model() end ==================================
2023-06-13 10:59:55,306:INFO:Creating metrics dataframe
2023-06-13 10:59:55,342:INFO:Initializing Bayesian Ridge
2023-06-13 10:59:55,343:INFO:Total runtime is 0.3367083271344503 minutes
2023-06-13 10:59:55,353:INFO:SubProcess create_model() called ==================================
2023-06-13 10:59:55,354:INFO:Initializing create_model()
2023-06-13 10:59:55,354:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D66760E0>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D78D8460>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 10:59:55,355:INFO:Checking exceptions
2023-06-13 10:59:55,356:INFO:Importing libraries
2023-06-13 10:59:55,356:INFO:Copying training dataset
2023-06-13 10:59:55,370:INFO:Defining folds
2023-06-13 10:59:55,371:INFO:Declaring metric variables
2023-06-13 10:59:55,384:INFO:Importing untrained model
2023-06-13 10:59:55,393:INFO:Bayesian Ridge Imported successfully
2023-06-13 10:59:55,415:INFO:Starting cross validation
2023-06-13 10:59:55,419:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 10:59:56,009:INFO:Calculating mean and std
2023-06-13 10:59:56,012:INFO:Creating metrics dataframe
2023-06-13 10:59:56,199:INFO:Uploading results into container
2023-06-13 10:59:56,202:INFO:Uploading model into container now
2023-06-13 10:59:56,204:INFO:_master_model_container: 8
2023-06-13 10:59:56,204:INFO:_display_container: 2
2023-06-13 10:59:56,205:INFO:BayesianRidge()
2023-06-13 10:59:56,206:INFO:create_model() successfully completed......................................
2023-06-13 10:59:56,465:INFO:SubProcess create_model() end ==================================
2023-06-13 10:59:56,465:INFO:Creating metrics dataframe
2023-06-13 10:59:56,500:INFO:Initializing Passive Aggressive Regressor
2023-06-13 10:59:56,502:INFO:Total runtime is 0.35601065158844 minutes
2023-06-13 10:59:56,512:INFO:SubProcess create_model() called ==================================
2023-06-13 10:59:56,513:INFO:Initializing create_model()
2023-06-13 10:59:56,513:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D66760E0>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D78D8460>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 10:59:56,513:INFO:Checking exceptions
2023-06-13 10:59:56,514:INFO:Importing libraries
2023-06-13 10:59:56,514:INFO:Copying training dataset
2023-06-13 10:59:56,534:INFO:Defining folds
2023-06-13 10:59:56,536:INFO:Declaring metric variables
2023-06-13 10:59:56,550:INFO:Importing untrained model
2023-06-13 10:59:56,560:INFO:Passive Aggressive Regressor Imported successfully
2023-06-13 10:59:56,579:INFO:Starting cross validation
2023-06-13 10:59:56,583:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 10:59:57,190:INFO:Calculating mean and std
2023-06-13 10:59:57,194:INFO:Creating metrics dataframe
2023-06-13 10:59:57,389:INFO:Uploading results into container
2023-06-13 10:59:57,390:INFO:Uploading model into container now
2023-06-13 10:59:57,392:INFO:_master_model_container: 9
2023-06-13 10:59:57,393:INFO:_display_container: 2
2023-06-13 10:59:57,394:INFO:PassiveAggressiveRegressor(random_state=6995)
2023-06-13 10:59:57,394:INFO:create_model() successfully completed......................................
2023-06-13 10:59:57,653:INFO:SubProcess create_model() end ==================================
2023-06-13 10:59:57,653:INFO:Creating metrics dataframe
2023-06-13 10:59:57,687:INFO:Initializing Huber Regressor
2023-06-13 10:59:57,688:INFO:Total runtime is 0.37579058408737187 minutes
2023-06-13 10:59:57,697:INFO:SubProcess create_model() called ==================================
2023-06-13 10:59:57,699:INFO:Initializing create_model()
2023-06-13 10:59:57,699:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D66760E0>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D78D8460>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 10:59:57,699:INFO:Checking exceptions
2023-06-13 10:59:57,700:INFO:Importing libraries
2023-06-13 10:59:57,700:INFO:Copying training dataset
2023-06-13 10:59:57,720:INFO:Defining folds
2023-06-13 10:59:57,721:INFO:Declaring metric variables
2023-06-13 10:59:57,734:INFO:Importing untrained model
2023-06-13 10:59:57,745:INFO:Huber Regressor Imported successfully
2023-06-13 10:59:57,766:INFO:Starting cross validation
2023-06-13 10:59:57,770:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 10:59:58,201:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-13 10:59:58,236:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-13 10:59:58,642:WARNING:
1 fits failed out of a total of 5.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\lapei\anaconda3\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py", line 338, in fit
    raise ValueError(
ValueError: HuberRegressor convergence failed: l-BFGS-b solver terminated with ABNORMAL_TERMINATION_IN_LNSRCH


2023-06-13 10:59:58,643:INFO:Calculating mean and std
2023-06-13 10:59:58,645:INFO:Creating metrics dataframe
2023-06-13 10:59:58,832:INFO:Uploading results into container
2023-06-13 10:59:58,834:INFO:Uploading model into container now
2023-06-13 10:59:58,835:INFO:_master_model_container: 10
2023-06-13 10:59:58,836:INFO:_display_container: 2
2023-06-13 10:59:58,838:INFO:HuberRegressor()
2023-06-13 10:59:58,838:INFO:create_model() successfully completed......................................
2023-06-13 10:59:59,093:WARNING:create_model() for HuberRegressor() raised an exception or returned all 0.0, trying without fit_kwargs:
2023-06-13 10:59:59,094:WARNING:Traceback (most recent call last):
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

2023-06-13 10:59:59,096:INFO:Initializing create_model()
2023-06-13 10:59:59,097:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D66760E0>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D78D8460>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 10:59:59,097:INFO:Checking exceptions
2023-06-13 10:59:59,097:INFO:Importing libraries
2023-06-13 10:59:59,098:INFO:Copying training dataset
2023-06-13 10:59:59,117:INFO:Defining folds
2023-06-13 10:59:59,118:INFO:Declaring metric variables
2023-06-13 10:59:59,129:INFO:Importing untrained model
2023-06-13 10:59:59,141:INFO:Huber Regressor Imported successfully
2023-06-13 10:59:59,163:INFO:Starting cross validation
2023-06-13 10:59:59,168:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 10:59:59,815:WARNING:
1 fits failed out of a total of 5.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\lapei\anaconda3\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py", line 338, in fit
    raise ValueError(
ValueError: HuberRegressor convergence failed: l-BFGS-b solver terminated with ABNORMAL_TERMINATION_IN_LNSRCH


2023-06-13 10:59:59,816:INFO:Calculating mean and std
2023-06-13 10:59:59,819:INFO:Creating metrics dataframe
2023-06-13 11:00:00,058:INFO:Uploading results into container
2023-06-13 11:00:00,062:INFO:Uploading model into container now
2023-06-13 11:00:00,064:INFO:_master_model_container: 11
2023-06-13 11:00:00,065:INFO:_display_container: 2
2023-06-13 11:00:00,068:INFO:HuberRegressor()
2023-06-13 11:00:00,069:INFO:create_model() successfully completed......................................
2023-06-13 11:00:00,411:ERROR:create_model() for HuberRegressor() raised an exception or returned all 0.0:
2023-06-13 11:00:00,412:ERROR:Traceback (most recent call last):
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 811, in compare_models
    np.sum(
AssertionError

2023-06-13 11:00:00,412:INFO:Initializing K Neighbors Regressor
2023-06-13 11:00:00,413:INFO:Total runtime is 0.42120281855265307 minutes
2023-06-13 11:00:00,422:INFO:SubProcess create_model() called ==================================
2023-06-13 11:00:00,423:INFO:Initializing create_model()
2023-06-13 11:00:00,424:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D66760E0>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D78D8460>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 11:00:00,425:INFO:Checking exceptions
2023-06-13 11:00:00,425:INFO:Importing libraries
2023-06-13 11:00:00,425:INFO:Copying training dataset
2023-06-13 11:00:00,441:INFO:Defining folds
2023-06-13 11:00:00,442:INFO:Declaring metric variables
2023-06-13 11:00:00,452:INFO:Importing untrained model
2023-06-13 11:00:00,459:INFO:K Neighbors Regressor Imported successfully
2023-06-13 11:00:00,481:INFO:Starting cross validation
2023-06-13 11:00:00,483:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 11:00:01,302:INFO:Calculating mean and std
2023-06-13 11:00:01,305:INFO:Creating metrics dataframe
2023-06-13 11:00:01,506:INFO:Uploading results into container
2023-06-13 11:00:01,508:INFO:Uploading model into container now
2023-06-13 11:00:01,509:INFO:_master_model_container: 12
2023-06-13 11:00:01,509:INFO:_display_container: 2
2023-06-13 11:00:01,510:INFO:KNeighborsRegressor(n_jobs=-1)
2023-06-13 11:00:01,510:INFO:create_model() successfully completed......................................
2023-06-13 11:00:01,763:INFO:SubProcess create_model() end ==================================
2023-06-13 11:00:01,763:INFO:Creating metrics dataframe
2023-06-13 11:00:01,804:INFO:Initializing Decision Tree Regressor
2023-06-13 11:00:01,805:INFO:Total runtime is 0.444398311773936 minutes
2023-06-13 11:00:01,818:INFO:SubProcess create_model() called ==================================
2023-06-13 11:00:01,819:INFO:Initializing create_model()
2023-06-13 11:00:01,819:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D66760E0>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D78D8460>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 11:00:01,819:INFO:Checking exceptions
2023-06-13 11:00:01,819:INFO:Importing libraries
2023-06-13 11:00:01,820:INFO:Copying training dataset
2023-06-13 11:00:01,842:INFO:Defining folds
2023-06-13 11:00:01,842:INFO:Declaring metric variables
2023-06-13 11:00:01,860:INFO:Importing untrained model
2023-06-13 11:00:01,873:INFO:Decision Tree Regressor Imported successfully
2023-06-13 11:00:01,895:INFO:Starting cross validation
2023-06-13 11:00:01,901:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 11:00:02,807:INFO:Calculating mean and std
2023-06-13 11:00:02,810:INFO:Creating metrics dataframe
2023-06-13 11:00:03,006:INFO:Uploading results into container
2023-06-13 11:00:03,008:INFO:Uploading model into container now
2023-06-13 11:00:03,009:INFO:_master_model_container: 13
2023-06-13 11:00:03,010:INFO:_display_container: 2
2023-06-13 11:00:03,011:INFO:DecisionTreeRegressor(random_state=6995)
2023-06-13 11:00:03,012:INFO:create_model() successfully completed......................................
2023-06-13 11:00:03,266:INFO:SubProcess create_model() end ==================================
2023-06-13 11:00:03,266:INFO:Creating metrics dataframe
2023-06-13 11:00:03,311:INFO:Initializing Random Forest Regressor
2023-06-13 11:00:03,312:INFO:Total runtime is 0.46949879725774135 minutes
2023-06-13 11:00:03,328:INFO:SubProcess create_model() called ==================================
2023-06-13 11:00:03,329:INFO:Initializing create_model()
2023-06-13 11:00:03,329:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D66760E0>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D78D8460>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 11:00:03,329:INFO:Checking exceptions
2023-06-13 11:00:03,329:INFO:Importing libraries
2023-06-13 11:00:03,330:INFO:Copying training dataset
2023-06-13 11:00:03,349:INFO:Defining folds
2023-06-13 11:00:03,350:INFO:Declaring metric variables
2023-06-13 11:00:03,366:INFO:Importing untrained model
2023-06-13 11:00:03,377:INFO:Random Forest Regressor Imported successfully
2023-06-13 11:00:03,403:INFO:Starting cross validation
2023-06-13 11:00:03,406:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 11:00:14,867:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.31s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 11:00:15,113:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 11:00:15,296:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 11:00:16,416:INFO:Calculating mean and std
2023-06-13 11:00:16,419:INFO:Creating metrics dataframe
2023-06-13 11:00:16,636:INFO:Uploading results into container
2023-06-13 11:00:16,638:INFO:Uploading model into container now
2023-06-13 11:00:16,639:INFO:_master_model_container: 14
2023-06-13 11:00:16,639:INFO:_display_container: 2
2023-06-13 11:00:16,640:INFO:RandomForestRegressor(n_jobs=-1, random_state=6995)
2023-06-13 11:00:16,640:INFO:create_model() successfully completed......................................
2023-06-13 11:00:16,896:INFO:SubProcess create_model() end ==================================
2023-06-13 11:00:16,896:INFO:Creating metrics dataframe
2023-06-13 11:00:16,936:INFO:Initializing Extra Trees Regressor
2023-06-13 11:00:16,937:INFO:Total runtime is 0.6966043631235759 minutes
2023-06-13 11:00:16,947:INFO:SubProcess create_model() called ==================================
2023-06-13 11:00:16,948:INFO:Initializing create_model()
2023-06-13 11:00:16,949:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D66760E0>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D78D8460>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 11:00:16,949:INFO:Checking exceptions
2023-06-13 11:00:16,949:INFO:Importing libraries
2023-06-13 11:00:16,949:INFO:Copying training dataset
2023-06-13 11:00:16,969:INFO:Defining folds
2023-06-13 11:00:16,969:INFO:Declaring metric variables
2023-06-13 11:00:16,980:INFO:Importing untrained model
2023-06-13 11:00:16,996:INFO:Extra Trees Regressor Imported successfully
2023-06-13 11:00:17,018:INFO:Starting cross validation
2023-06-13 11:00:17,021:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 11:00:21,067:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 11:00:21,099:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 11:00:21,885:INFO:Calculating mean and std
2023-06-13 11:00:21,889:INFO:Creating metrics dataframe
2023-06-13 11:00:22,061:INFO:Uploading results into container
2023-06-13 11:00:22,064:INFO:Uploading model into container now
2023-06-13 11:00:22,064:INFO:_master_model_container: 15
2023-06-13 11:00:22,064:INFO:_display_container: 2
2023-06-13 11:00:22,067:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=6995)
2023-06-13 11:00:22,067:INFO:create_model() successfully completed......................................
2023-06-13 11:00:22,314:INFO:SubProcess create_model() end ==================================
2023-06-13 11:00:22,315:INFO:Creating metrics dataframe
2023-06-13 11:00:22,355:INFO:Initializing AdaBoost Regressor
2023-06-13 11:00:22,355:INFO:Total runtime is 0.7869008819262187 minutes
2023-06-13 11:00:22,365:INFO:SubProcess create_model() called ==================================
2023-06-13 11:00:22,365:INFO:Initializing create_model()
2023-06-13 11:00:22,366:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D66760E0>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D78D8460>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 11:00:22,366:INFO:Checking exceptions
2023-06-13 11:00:22,366:INFO:Importing libraries
2023-06-13 11:00:22,366:INFO:Copying training dataset
2023-06-13 11:00:22,385:INFO:Defining folds
2023-06-13 11:00:22,386:INFO:Declaring metric variables
2023-06-13 11:00:22,399:INFO:Importing untrained model
2023-06-13 11:00:22,412:INFO:AdaBoost Regressor Imported successfully
2023-06-13 11:00:22,434:INFO:Starting cross validation
2023-06-13 11:00:22,437:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 11:00:24,119:INFO:Calculating mean and std
2023-06-13 11:00:24,122:INFO:Creating metrics dataframe
2023-06-13 11:00:24,309:INFO:Uploading results into container
2023-06-13 11:00:24,312:INFO:Uploading model into container now
2023-06-13 11:00:24,314:INFO:_master_model_container: 16
2023-06-13 11:00:24,314:INFO:_display_container: 2
2023-06-13 11:00:24,315:INFO:AdaBoostRegressor(random_state=6995)
2023-06-13 11:00:24,315:INFO:create_model() successfully completed......................................
2023-06-13 11:00:24,573:INFO:SubProcess create_model() end ==================================
2023-06-13 11:00:24,573:INFO:Creating metrics dataframe
2023-06-13 11:00:24,611:INFO:Initializing Gradient Boosting Regressor
2023-06-13 11:00:24,611:INFO:Total runtime is 0.8245043635368347 minutes
2023-06-13 11:00:24,627:INFO:SubProcess create_model() called ==================================
2023-06-13 11:00:24,628:INFO:Initializing create_model()
2023-06-13 11:00:24,629:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D66760E0>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D78D8460>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 11:00:24,629:INFO:Checking exceptions
2023-06-13 11:00:24,630:INFO:Importing libraries
2023-06-13 11:00:24,630:INFO:Copying training dataset
2023-06-13 11:00:24,647:INFO:Defining folds
2023-06-13 11:00:24,647:INFO:Declaring metric variables
2023-06-13 11:00:24,659:INFO:Importing untrained model
2023-06-13 11:00:24,675:INFO:Gradient Boosting Regressor Imported successfully
2023-06-13 11:00:24,701:INFO:Starting cross validation
2023-06-13 11:00:24,705:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 11:00:30,912:INFO:Calculating mean and std
2023-06-13 11:00:30,915:INFO:Creating metrics dataframe
2023-06-13 11:00:31,170:INFO:Uploading results into container
2023-06-13 11:00:31,172:INFO:Uploading model into container now
2023-06-13 11:00:31,173:INFO:_master_model_container: 17
2023-06-13 11:00:31,174:INFO:_display_container: 2
2023-06-13 11:00:31,175:INFO:GradientBoostingRegressor(random_state=6995)
2023-06-13 11:00:31,175:INFO:create_model() successfully completed......................................
2023-06-13 11:00:31,442:INFO:SubProcess create_model() end ==================================
2023-06-13 11:00:31,443:INFO:Creating metrics dataframe
2023-06-13 11:00:31,493:INFO:Initializing Extreme Gradient Boosting
2023-06-13 11:00:31,493:INFO:Total runtime is 0.9392051339149474 minutes
2023-06-13 11:00:31,504:INFO:SubProcess create_model() called ==================================
2023-06-13 11:00:31,505:INFO:Initializing create_model()
2023-06-13 11:00:31,505:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D66760E0>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D78D8460>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 11:00:31,505:INFO:Checking exceptions
2023-06-13 11:00:31,506:INFO:Importing libraries
2023-06-13 11:00:31,506:INFO:Copying training dataset
2023-06-13 11:00:31,522:INFO:Defining folds
2023-06-13 11:00:31,523:INFO:Declaring metric variables
2023-06-13 11:00:31,532:INFO:Importing untrained model
2023-06-13 11:00:31,545:INFO:Extreme Gradient Boosting Imported successfully
2023-06-13 11:00:31,572:INFO:Starting cross validation
2023-06-13 11:00:31,575:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 11:00:35,269:INFO:Calculating mean and std
2023-06-13 11:00:35,272:INFO:Creating metrics dataframe
2023-06-13 11:00:35,520:INFO:Uploading results into container
2023-06-13 11:00:35,522:INFO:Uploading model into container now
2023-06-13 11:00:35,523:INFO:_master_model_container: 18
2023-06-13 11:00:35,523:INFO:_display_container: 2
2023-06-13 11:00:35,525:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=6995, ...)
2023-06-13 11:00:35,526:INFO:create_model() successfully completed......................................
2023-06-13 11:00:35,798:INFO:SubProcess create_model() end ==================================
2023-06-13 11:00:35,799:INFO:Creating metrics dataframe
2023-06-13 11:00:35,834:INFO:Initializing Light Gradient Boosting Machine
2023-06-13 11:00:35,835:INFO:Total runtime is 1.0115674217542012 minutes
2023-06-13 11:00:35,845:INFO:SubProcess create_model() called ==================================
2023-06-13 11:00:35,845:INFO:Initializing create_model()
2023-06-13 11:00:35,845:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D66760E0>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D78D8460>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 11:00:35,846:INFO:Checking exceptions
2023-06-13 11:00:35,846:INFO:Importing libraries
2023-06-13 11:00:35,846:INFO:Copying training dataset
2023-06-13 11:00:35,872:INFO:Defining folds
2023-06-13 11:00:35,872:INFO:Declaring metric variables
2023-06-13 11:00:35,884:INFO:Importing untrained model
2023-06-13 11:00:35,896:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-13 11:00:35,922:INFO:Starting cross validation
2023-06-13 11:00:35,925:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 11:00:39,984:INFO:Calculating mean and std
2023-06-13 11:00:39,987:INFO:Creating metrics dataframe
2023-06-13 11:00:40,256:INFO:Uploading results into container
2023-06-13 11:00:40,259:INFO:Uploading model into container now
2023-06-13 11:00:40,260:INFO:_master_model_container: 19
2023-06-13 11:00:40,260:INFO:_display_container: 2
2023-06-13 11:00:40,261:INFO:LGBMRegressor(random_state=6995)
2023-06-13 11:00:40,261:INFO:create_model() successfully completed......................................
2023-06-13 11:00:40,535:INFO:SubProcess create_model() end ==================================
2023-06-13 11:00:40,535:INFO:Creating metrics dataframe
2023-06-13 11:00:40,576:INFO:Initializing Dummy Regressor
2023-06-13 11:00:40,576:INFO:Total runtime is 1.0905840357144674 minutes
2023-06-13 11:00:40,587:INFO:SubProcess create_model() called ==================================
2023-06-13 11:00:40,588:INFO:Initializing create_model()
2023-06-13 11:00:40,589:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D66760E0>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D78D8460>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 11:00:40,590:INFO:Checking exceptions
2023-06-13 11:00:40,590:INFO:Importing libraries
2023-06-13 11:00:40,590:INFO:Copying training dataset
2023-06-13 11:00:40,609:INFO:Defining folds
2023-06-13 11:00:40,609:INFO:Declaring metric variables
2023-06-13 11:00:40,622:INFO:Importing untrained model
2023-06-13 11:00:40,633:INFO:Dummy Regressor Imported successfully
2023-06-13 11:00:40,656:INFO:Starting cross validation
2023-06-13 11:00:40,659:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 11:00:41,327:INFO:Calculating mean and std
2023-06-13 11:00:41,342:INFO:Creating metrics dataframe
2023-06-13 11:00:41,597:INFO:Uploading results into container
2023-06-13 11:00:41,600:INFO:Uploading model into container now
2023-06-13 11:00:41,601:INFO:_master_model_container: 20
2023-06-13 11:00:41,601:INFO:_display_container: 2
2023-06-13 11:00:41,602:INFO:DummyRegressor()
2023-06-13 11:00:41,602:INFO:create_model() successfully completed......................................
2023-06-13 11:00:41,860:INFO:SubProcess create_model() end ==================================
2023-06-13 11:00:41,860:INFO:Creating metrics dataframe
2023-06-13 11:00:41,931:INFO:Initializing create_model()
2023-06-13 11:00:41,931:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D66760E0>, estimator=OrthogonalMatchingPursuit(), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-13 11:00:41,932:INFO:Checking exceptions
2023-06-13 11:00:41,939:INFO:Importing libraries
2023-06-13 11:00:41,940:INFO:Copying training dataset
2023-06-13 11:00:41,961:INFO:Defining folds
2023-06-13 11:00:41,961:INFO:Declaring metric variables
2023-06-13 11:00:41,962:INFO:Importing untrained model
2023-06-13 11:00:41,962:INFO:Declaring custom model
2023-06-13 11:00:41,964:INFO:Orthogonal Matching Pursuit Imported successfully
2023-06-13 11:00:41,967:INFO:Cross validation set to False
2023-06-13 11:00:41,967:INFO:Fitting Model
2023-06-13 11:00:42,164:INFO:OrthogonalMatchingPursuit()
2023-06-13 11:00:42,164:INFO:create_model() successfully completed......................................
2023-06-13 11:00:42,506:INFO:_master_model_container: 20
2023-06-13 11:00:42,507:INFO:_display_container: 2
2023-06-13 11:00:42,508:INFO:OrthogonalMatchingPursuit()
2023-06-13 11:00:42,509:INFO:compare_models() successfully completed......................................
2023-06-13 11:01:23,121:INFO:Initializing plot_model()
2023-06-13 11:01:23,121:INFO:plot_model(plot=learning, fold=None, use_train_data=True, verbose=True, display=None, display_format=None, estimator=OrthogonalMatchingPursuit(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D66760E0>, system=True)
2023-06-13 11:01:23,122:INFO:Checking exceptions
2023-06-13 11:01:23,135:INFO:Preloading libraries
2023-06-13 11:01:23,137:INFO:Copying training dataset
2023-06-13 11:01:23,137:INFO:Plot type: learning
2023-06-13 11:01:23,386:INFO:Fitting Model
2023-06-13 11:01:24,786:INFO:Visual Rendered Successfully
2023-06-13 11:01:25,037:INFO:plot_model() successfully completed......................................
2023-06-13 11:01:32,473:INFO:Initializing plot_model()
2023-06-13 11:01:32,473:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=OrthogonalMatchingPursuit(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D66760E0>, system=True)
2023-06-13 11:01:32,473:INFO:Checking exceptions
2023-06-13 11:01:32,487:INFO:Preloading libraries
2023-06-13 11:01:32,488:INFO:Copying training dataset
2023-06-13 11:01:32,488:INFO:Plot type: error
2023-06-13 11:01:32,741:INFO:Fitting Model
2023-06-13 11:01:32,742:WARNING:X does not have valid feature names, but OrthogonalMatchingPursuit was fitted with feature names

2023-06-13 11:01:32,742:INFO:Scoring test/hold-out set
2023-06-13 11:01:33,458:INFO:Visual Rendered Successfully
2023-06-13 11:01:33,721:INFO:plot_model() successfully completed......................................
2023-06-13 11:01:41,216:INFO:Initializing plot_model()
2023-06-13 11:01:41,216:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=OrthogonalMatchingPursuit(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D66760E0>, system=True)
2023-06-13 11:01:41,216:INFO:Checking exceptions
2023-06-13 11:01:41,232:INFO:Preloading libraries
2023-06-13 11:01:41,234:INFO:Copying training dataset
2023-06-13 11:01:41,234:INFO:Plot type: feature
2023-06-13 11:01:41,850:INFO:Visual Rendered Successfully
2023-06-13 11:01:42,115:INFO:plot_model() successfully completed......................................
2023-06-13 11:02:31,502:INFO:Initializing plot_model()
2023-06-13 11:02:31,503:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=OrthogonalMatchingPursuit(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D66760E0>, system=True)
2023-06-13 11:02:31,504:INFO:Checking exceptions
2023-06-13 11:02:31,515:INFO:Preloading libraries
2023-06-13 11:02:31,516:INFO:Copying training dataset
2023-06-13 11:02:31,516:INFO:Plot type: residuals
2023-06-13 11:02:31,835:INFO:Fitting Model
2023-06-13 11:02:31,835:WARNING:X does not have valid feature names, but OrthogonalMatchingPursuit was fitted with feature names

2023-06-13 11:02:31,951:INFO:Scoring test/hold-out set
2023-06-13 11:02:33,088:INFO:Visual Rendered Successfully
2023-06-13 11:02:33,357:INFO:plot_model() successfully completed......................................
2023-06-13 11:03:52,286:INFO:PyCaret RegressionExperiment
2023-06-13 11:03:52,286:INFO:Logging name: reg-default-name
2023-06-13 11:03:52,286:INFO:ML Usecase: MLUsecase.REGRESSION
2023-06-13 11:03:52,286:INFO:version 3.0.2
2023-06-13 11:03:52,286:INFO:Initializing setup()
2023-06-13 11:03:52,286:INFO:self.USI: 91cb
2023-06-13 11:03:52,287:INFO:self._variable_keys: {'fold_groups_param', 'data', 'y', 'transform_target_param', 'fold_shuffle_param', 'gpu_n_jobs_param', 'X_test', 'exp_id', 'logging_param', 'y_train', 'target_param', '_available_plots', 'html_param', 'X_train', 'USI', 'pipeline', 'y_test', 'fold_generator', 'exp_name_log', 'X', 'log_plots_param', 'gpu_param', 'memory', 'idx', '_ml_usecase', 'n_jobs_param', 'seed'}
2023-06-13 11:03:52,287:INFO:Checking environment
2023-06-13 11:03:52,287:INFO:python_version: 3.10.9
2023-06-13 11:03:52,287:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-06-13 11:03:52,287:INFO:machine: AMD64
2023-06-13 11:03:52,288:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-13 11:03:52,288:INFO:Memory: svmem(total=16901767168, available=4387590144, percent=74.0, used=12514177024, free=4387590144)
2023-06-13 11:03:52,288:INFO:Physical Core: 4
2023-06-13 11:03:52,288:INFO:Logical Core: 8
2023-06-13 11:03:52,288:INFO:Checking libraries
2023-06-13 11:03:52,288:INFO:System:
2023-06-13 11:03:52,288:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-06-13 11:03:52,288:INFO:executable: C:\Users\lapei\anaconda3\python.exe
2023-06-13 11:03:52,289:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-13 11:03:52,289:INFO:PyCaret required dependencies:
2023-06-13 11:03:52,289:INFO:                 pip: 22.3.1
2023-06-13 11:03:52,289:INFO:          setuptools: 65.6.3
2023-06-13 11:03:52,289:INFO:             pycaret: 3.0.2
2023-06-13 11:03:52,289:INFO:             IPython: 8.10.0
2023-06-13 11:03:52,289:INFO:          ipywidgets: 7.6.5
2023-06-13 11:03:52,289:INFO:                tqdm: 4.64.1
2023-06-13 11:03:52,290:INFO:               numpy: 1.23.5
2023-06-13 11:03:52,290:INFO:              pandas: 1.5.3
2023-06-13 11:03:52,290:INFO:              jinja2: 3.1.2
2023-06-13 11:03:52,290:INFO:               scipy: 1.10.0
2023-06-13 11:03:52,290:INFO:              joblib: 1.2.0
2023-06-13 11:03:52,290:INFO:             sklearn: 1.2.1
2023-06-13 11:03:52,290:INFO:                pyod: 1.0.9
2023-06-13 11:03:52,290:INFO:            imblearn: 0.10.1
2023-06-13 11:03:52,290:INFO:   category_encoders: 2.6.1
2023-06-13 11:03:52,290:INFO:            lightgbm: 3.3.5
2023-06-13 11:03:52,291:INFO:               numba: 0.56.4
2023-06-13 11:03:52,291:INFO:            requests: 2.28.1
2023-06-13 11:03:52,291:INFO:          matplotlib: 3.7.0
2023-06-13 11:03:52,291:INFO:          scikitplot: 0.3.7
2023-06-13 11:03:52,291:INFO:         yellowbrick: 1.5
2023-06-13 11:03:52,291:INFO:              plotly: 5.9.0
2023-06-13 11:03:52,291:INFO:             kaleido: 0.2.1
2023-06-13 11:03:52,291:INFO:         statsmodels: 0.13.5
2023-06-13 11:03:52,292:INFO:              sktime: 0.17.0
2023-06-13 11:03:52,292:INFO:               tbats: 1.1.3
2023-06-13 11:03:52,292:INFO:            pmdarima: 2.0.3
2023-06-13 11:03:52,292:INFO:              psutil: 5.9.0
2023-06-13 11:03:52,292:INFO:PyCaret optional dependencies:
2023-06-13 11:03:52,292:INFO:                shap: 0.41.0
2023-06-13 11:03:52,292:INFO:           interpret: Not installed
2023-06-13 11:03:52,292:INFO:                umap: Not installed
2023-06-13 11:03:52,293:INFO:    pandas_profiling: Not installed
2023-06-13 11:03:52,293:INFO:  explainerdashboard: Not installed
2023-06-13 11:03:52,293:INFO:             autoviz: Not installed
2023-06-13 11:03:52,293:INFO:           fairlearn: Not installed
2023-06-13 11:03:52,293:INFO:             xgboost: 1.7.3
2023-06-13 11:03:52,293:INFO:            catboost: Not installed
2023-06-13 11:03:52,293:INFO:              kmodes: Not installed
2023-06-13 11:03:52,293:INFO:             mlxtend: Not installed
2023-06-13 11:03:52,293:INFO:       statsforecast: Not installed
2023-06-13 11:03:52,294:INFO:        tune_sklearn: Not installed
2023-06-13 11:03:52,294:INFO:                 ray: Not installed
2023-06-13 11:03:52,294:INFO:            hyperopt: Not installed
2023-06-13 11:03:52,294:INFO:              optuna: Not installed
2023-06-13 11:03:52,294:INFO:               skopt: 0.9.0
2023-06-13 11:03:52,294:INFO:              mlflow: Not installed
2023-06-13 11:03:52,294:INFO:              gradio: Not installed
2023-06-13 11:03:52,294:INFO:             fastapi: Not installed
2023-06-13 11:03:52,294:INFO:             uvicorn: Not installed
2023-06-13 11:03:52,294:INFO:              m2cgen: Not installed
2023-06-13 11:03:52,295:INFO:           evidently: Not installed
2023-06-13 11:03:52,295:INFO:               fugue: Not installed
2023-06-13 11:03:52,295:INFO:           streamlit: Not installed
2023-06-13 11:03:52,295:INFO:             prophet: Not installed
2023-06-13 11:03:52,295:INFO:None
2023-06-13 11:03:52,295:INFO:Set up data.
2023-06-13 11:03:52,323:INFO:Set up train/test split.
2023-06-13 11:03:52,338:INFO:Set up index.
2023-06-13 11:03:52,338:INFO:Set up folding strategy.
2023-06-13 11:03:52,339:INFO:Assigning column types.
2023-06-13 11:03:52,350:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-13 11:03:52,351:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-13 11:03:52,364:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-13 11:03:52,376:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-13 11:03:52,536:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 11:03:52,660:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 11:03:52,662:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 11:03:52,669:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 11:03:52,670:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-13 11:03:52,682:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-13 11:03:52,699:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-13 11:03:52,867:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 11:03:52,990:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 11:03:52,992:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 11:03:52,999:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 11:03:53,000:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-06-13 11:03:53,014:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-13 11:03:53,033:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-13 11:03:53,202:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 11:03:53,325:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 11:03:53,326:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 11:03:53,333:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 11:03:53,346:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-13 11:03:53,359:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-13 11:03:53,522:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 11:03:53,646:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 11:03:53,647:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 11:03:53,655:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 11:03:53,656:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-06-13 11:03:53,681:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-13 11:03:53,843:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 11:03:53,967:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 11:03:53,968:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 11:03:53,976:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 11:03:54,003:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-13 11:03:54,165:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 11:03:54,298:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 11:03:54,299:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 11:03:54,308:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 11:03:54,308:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-06-13 11:03:54,492:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 11:03:54,613:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 11:03:54,621:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 11:03:54,628:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 11:03:54,836:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 11:03:54,959:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 11:03:54,961:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 11:03:54,969:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 11:03:54,969:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-13 11:03:55,169:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 11:03:55,298:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 11:03:55,306:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 11:03:55,493:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 11:03:55,618:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 11:03:55,627:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 11:03:55,627:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-06-13 11:03:55,974:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 11:03:55,981:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 11:03:56,296:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 11:03:56,303:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 11:03:56,306:INFO:Preparing preprocessing pipeline...
2023-06-13 11:03:56,306:INFO:Set up simple imputation.
2023-06-13 11:03:56,308:INFO:Set up column name cleaning.
2023-06-13 11:03:56,383:INFO:Finished creating preprocessing pipeline.
2023-06-13 11:03:56,398:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\lapei\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['taxa_homicidio', 'RH_adm_dir',
                                             'densidade_banda_larga',
                                             'densidade_telefonia_movel',
                                             'qtd_cursos_engenharias',
                                             'qtd_cursos_negocios_direito',
                                             'media_notas_CN', 'media_notas_CH',
                                             'media_NU_NOTA_LC',
                                             'media_NU_NOTA_MT',
                                             'media_...
                                             'Isencao_ISSQN_Sim',
                                             'Isencao_Tx_Sim',
                                             'Cessao_terrenos_Sim',
                                             'Doacao_terrenos_Sim',
                                             'Outros_mecanismos_Sim',
                                             'ISH_Baixa', 'ISH_Máxima',
                                             'ISH_Média', 'ISH_Mínima'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-06-13 11:03:56,398:INFO:Creating final display dataframe.
2023-06-13 11:03:56,640:INFO:Setup _display_container:                     Description                              Value
0                    Session id                               5909
1                        Target  qtd_abertas_Empresario_Individual
2                   Target type                         Regression
3           Original data shape                         (4456, 30)
4        Transformed data shape                         (4456, 30)
5   Transformed train set shape                         (3119, 30)
6    Transformed test set shape                         (1337, 30)
7              Numeric features                                 29
8                    Preprocess                               True
9               Imputation type                             simple
10           Numeric imputation                               mean
11       Categorical imputation                               mode
12               Fold Generator                              KFold
13                  Fold Number                                 10
14                     CPU Jobs                                 -1
15                      Use GPU                              False
16               Log Experiment                              False
17              Experiment Name                   reg-default-name
18                          USI                               91cb
2023-06-13 11:03:57,001:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 11:03:57,011:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 11:03:57,334:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 11:03:57,341:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 11:03:57,343:INFO:setup() successfully completed in 5.17s...............
2023-06-13 11:04:02,878:INFO:Initializing compare_models()
2023-06-13 11:04:02,879:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D770C670>, include=None, fold=5, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001E3D770C670>, 'include': None, 'exclude': None, 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-06-13 11:04:02,879:INFO:Checking exceptions
2023-06-13 11:04:02,886:INFO:Preparing display monitor
2023-06-13 11:04:02,970:INFO:Initializing Linear Regression
2023-06-13 11:04:02,972:INFO:Total runtime is 3.242890040079753e-05 minutes
2023-06-13 11:04:02,982:INFO:SubProcess create_model() called ==================================
2023-06-13 11:04:02,983:INFO:Initializing create_model()
2023-06-13 11:04:02,984:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D770C670>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D66E00D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 11:04:02,984:INFO:Checking exceptions
2023-06-13 11:04:02,984:INFO:Importing libraries
2023-06-13 11:04:02,985:INFO:Copying training dataset
2023-06-13 11:04:03,000:INFO:Defining folds
2023-06-13 11:04:03,000:INFO:Declaring metric variables
2023-06-13 11:04:03,009:INFO:Importing untrained model
2023-06-13 11:04:03,019:INFO:Linear Regression Imported successfully
2023-06-13 11:04:03,039:INFO:Starting cross validation
2023-06-13 11:04:03,043:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 11:04:03,809:INFO:Calculating mean and std
2023-06-13 11:04:03,811:INFO:Creating metrics dataframe
2023-06-13 11:04:04,039:INFO:Uploading results into container
2023-06-13 11:04:04,041:INFO:Uploading model into container now
2023-06-13 11:04:04,042:INFO:_master_model_container: 1
2023-06-13 11:04:04,042:INFO:_display_container: 2
2023-06-13 11:04:04,043:INFO:LinearRegression(n_jobs=-1)
2023-06-13 11:04:04,043:INFO:create_model() successfully completed......................................
2023-06-13 11:04:04,319:INFO:SubProcess create_model() end ==================================
2023-06-13 11:04:04,319:INFO:Creating metrics dataframe
2023-06-13 11:04:04,352:INFO:Initializing Lasso Regression
2023-06-13 11:04:04,352:INFO:Total runtime is 0.02302682399749756 minutes
2023-06-13 11:04:04,364:INFO:SubProcess create_model() called ==================================
2023-06-13 11:04:04,366:INFO:Initializing create_model()
2023-06-13 11:04:04,366:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D770C670>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D66E00D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 11:04:04,366:INFO:Checking exceptions
2023-06-13 11:04:04,366:INFO:Importing libraries
2023-06-13 11:04:04,367:INFO:Copying training dataset
2023-06-13 11:04:04,391:INFO:Defining folds
2023-06-13 11:04:04,392:INFO:Declaring metric variables
2023-06-13 11:04:04,403:INFO:Importing untrained model
2023-06-13 11:04:04,417:INFO:Lasso Regression Imported successfully
2023-06-13 11:04:04,442:INFO:Starting cross validation
2023-06-13 11:04:04,446:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 11:04:04,723:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.111e+07, tolerance: 8.292e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 11:04:04,725:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.531e+08, tolerance: 7.182e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 11:04:04,781:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.928e+07, tolerance: 8.466e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 11:04:05,282:INFO:Calculating mean and std
2023-06-13 11:04:05,285:INFO:Creating metrics dataframe
2023-06-13 11:04:05,532:INFO:Uploading results into container
2023-06-13 11:04:05,534:INFO:Uploading model into container now
2023-06-13 11:04:05,536:INFO:_master_model_container: 2
2023-06-13 11:04:05,536:INFO:_display_container: 2
2023-06-13 11:04:05,538:INFO:Lasso(random_state=5909)
2023-06-13 11:04:05,538:INFO:create_model() successfully completed......................................
2023-06-13 11:04:05,800:INFO:SubProcess create_model() end ==================================
2023-06-13 11:04:05,800:INFO:Creating metrics dataframe
2023-06-13 11:04:05,827:INFO:Initializing Ridge Regression
2023-06-13 11:04:05,827:INFO:Total runtime is 0.047614550590515135 minutes
2023-06-13 11:04:05,839:INFO:SubProcess create_model() called ==================================
2023-06-13 11:04:05,840:INFO:Initializing create_model()
2023-06-13 11:04:05,841:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D770C670>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D66E00D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 11:04:05,841:INFO:Checking exceptions
2023-06-13 11:04:05,841:INFO:Importing libraries
2023-06-13 11:04:05,842:INFO:Copying training dataset
2023-06-13 11:04:05,861:INFO:Defining folds
2023-06-13 11:04:05,862:INFO:Declaring metric variables
2023-06-13 11:04:05,876:INFO:Importing untrained model
2023-06-13 11:04:05,886:INFO:Ridge Regression Imported successfully
2023-06-13 11:04:05,906:INFO:Starting cross validation
2023-06-13 11:04:05,911:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 11:04:06,648:INFO:Calculating mean and std
2023-06-13 11:04:06,651:INFO:Creating metrics dataframe
2023-06-13 11:04:06,892:INFO:Uploading results into container
2023-06-13 11:04:06,896:INFO:Uploading model into container now
2023-06-13 11:04:06,897:INFO:_master_model_container: 3
2023-06-13 11:04:06,898:INFO:_display_container: 2
2023-06-13 11:04:06,899:INFO:Ridge(random_state=5909)
2023-06-13 11:04:06,899:INFO:create_model() successfully completed......................................
2023-06-13 11:04:07,161:INFO:SubProcess create_model() end ==================================
2023-06-13 11:04:07,161:INFO:Creating metrics dataframe
2023-06-13 11:04:07,188:INFO:Initializing Elastic Net
2023-06-13 11:04:07,189:INFO:Total runtime is 0.07032268842061361 minutes
2023-06-13 11:04:07,199:INFO:SubProcess create_model() called ==================================
2023-06-13 11:04:07,201:INFO:Initializing create_model()
2023-06-13 11:04:07,202:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D770C670>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D66E00D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 11:04:07,202:INFO:Checking exceptions
2023-06-13 11:04:07,202:INFO:Importing libraries
2023-06-13 11:04:07,203:INFO:Copying training dataset
2023-06-13 11:04:07,222:INFO:Defining folds
2023-06-13 11:04:07,224:INFO:Declaring metric variables
2023-06-13 11:04:07,234:INFO:Importing untrained model
2023-06-13 11:04:07,244:INFO:Elastic Net Imported successfully
2023-06-13 11:04:07,264:INFO:Starting cross validation
2023-06-13 11:04:07,267:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 11:04:07,531:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.555e+08, tolerance: 7.182e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 11:04:07,544:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.487e+07, tolerance: 8.292e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 11:04:07,569:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.181e+08, tolerance: 8.466e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 11:04:07,668:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.982e+07, tolerance: 8.494e+06
  model = cd_fast.enet_coordinate_descent(

2023-06-13 11:04:08,225:INFO:Calculating mean and std
2023-06-13 11:04:08,227:INFO:Creating metrics dataframe
2023-06-13 11:04:08,508:INFO:Uploading results into container
2023-06-13 11:04:08,509:INFO:Uploading model into container now
2023-06-13 11:04:08,510:INFO:_master_model_container: 4
2023-06-13 11:04:08,511:INFO:_display_container: 2
2023-06-13 11:04:08,512:INFO:ElasticNet(random_state=5909)
2023-06-13 11:04:08,512:INFO:create_model() successfully completed......................................
2023-06-13 11:04:08,794:INFO:SubProcess create_model() end ==================================
2023-06-13 11:04:08,794:INFO:Creating metrics dataframe
2023-06-13 11:04:08,834:INFO:Initializing Least Angle Regression
2023-06-13 11:04:08,834:INFO:Total runtime is 0.0977328101793925 minutes
2023-06-13 11:04:08,846:INFO:SubProcess create_model() called ==================================
2023-06-13 11:04:08,847:INFO:Initializing create_model()
2023-06-13 11:04:08,847:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D770C670>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D66E00D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 11:04:08,848:INFO:Checking exceptions
2023-06-13 11:04:08,848:INFO:Importing libraries
2023-06-13 11:04:08,848:INFO:Copying training dataset
2023-06-13 11:04:08,864:INFO:Defining folds
2023-06-13 11:04:08,864:INFO:Declaring metric variables
2023-06-13 11:04:08,876:INFO:Importing untrained model
2023-06-13 11:04:08,887:INFO:Least Angle Regression Imported successfully
2023-06-13 11:04:08,910:INFO:Starting cross validation
2023-06-13 11:04:08,912:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 11:04:09,678:INFO:Calculating mean and std
2023-06-13 11:04:09,681:INFO:Creating metrics dataframe
2023-06-13 11:04:09,974:INFO:Uploading results into container
2023-06-13 11:04:09,976:INFO:Uploading model into container now
2023-06-13 11:04:09,977:INFO:_master_model_container: 5
2023-06-13 11:04:09,977:INFO:_display_container: 2
2023-06-13 11:04:09,978:INFO:Lars(random_state=5909)
2023-06-13 11:04:09,979:INFO:create_model() successfully completed......................................
2023-06-13 11:04:10,231:INFO:SubProcess create_model() end ==================================
2023-06-13 11:04:10,233:INFO:Creating metrics dataframe
2023-06-13 11:04:10,262:INFO:Initializing Lasso Least Angle Regression
2023-06-13 11:04:10,262:INFO:Total runtime is 0.12154008150100709 minutes
2023-06-13 11:04:10,272:INFO:SubProcess create_model() called ==================================
2023-06-13 11:04:10,273:INFO:Initializing create_model()
2023-06-13 11:04:10,273:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D770C670>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D66E00D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 11:04:10,274:INFO:Checking exceptions
2023-06-13 11:04:10,274:INFO:Importing libraries
2023-06-13 11:04:10,274:INFO:Copying training dataset
2023-06-13 11:04:10,290:INFO:Defining folds
2023-06-13 11:04:10,291:INFO:Declaring metric variables
2023-06-13 11:04:10,304:INFO:Importing untrained model
2023-06-13 11:04:10,315:INFO:Lasso Least Angle Regression Imported successfully
2023-06-13 11:04:10,336:INFO:Starting cross validation
2023-06-13 11:04:10,338:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 11:04:11,075:INFO:Calculating mean and std
2023-06-13 11:04:11,078:INFO:Creating metrics dataframe
2023-06-13 11:04:11,340:INFO:Uploading results into container
2023-06-13 11:04:11,342:INFO:Uploading model into container now
2023-06-13 11:04:11,343:INFO:_master_model_container: 6
2023-06-13 11:04:11,344:INFO:_display_container: 2
2023-06-13 11:04:11,344:INFO:LassoLars(random_state=5909)
2023-06-13 11:04:11,345:INFO:create_model() successfully completed......................................
2023-06-13 11:04:11,595:INFO:SubProcess create_model() end ==================================
2023-06-13 11:04:11,595:INFO:Creating metrics dataframe
2023-06-13 11:04:11,629:INFO:Initializing Orthogonal Matching Pursuit
2023-06-13 11:04:11,629:INFO:Total runtime is 0.1443242152531942 minutes
2023-06-13 11:04:11,642:INFO:SubProcess create_model() called ==================================
2023-06-13 11:04:11,643:INFO:Initializing create_model()
2023-06-13 11:04:11,643:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D770C670>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D66E00D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 11:04:11,645:INFO:Checking exceptions
2023-06-13 11:04:11,645:INFO:Importing libraries
2023-06-13 11:04:11,645:INFO:Copying training dataset
2023-06-13 11:04:11,665:INFO:Defining folds
2023-06-13 11:04:11,668:INFO:Declaring metric variables
2023-06-13 11:04:11,678:INFO:Importing untrained model
2023-06-13 11:04:11,689:INFO:Orthogonal Matching Pursuit Imported successfully
2023-06-13 11:04:11,711:INFO:Starting cross validation
2023-06-13 11:04:11,714:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 11:04:12,461:INFO:Calculating mean and std
2023-06-13 11:04:12,464:INFO:Creating metrics dataframe
2023-06-13 11:04:12,735:INFO:Uploading results into container
2023-06-13 11:04:12,737:INFO:Uploading model into container now
2023-06-13 11:04:12,739:INFO:_master_model_container: 7
2023-06-13 11:04:12,740:INFO:_display_container: 2
2023-06-13 11:04:12,740:INFO:OrthogonalMatchingPursuit()
2023-06-13 11:04:12,740:INFO:create_model() successfully completed......................................
2023-06-13 11:04:12,988:INFO:SubProcess create_model() end ==================================
2023-06-13 11:04:12,988:INFO:Creating metrics dataframe
2023-06-13 11:04:13,023:INFO:Initializing Bayesian Ridge
2023-06-13 11:04:13,024:INFO:Total runtime is 0.16755250692367557 minutes
2023-06-13 11:04:13,033:INFO:SubProcess create_model() called ==================================
2023-06-13 11:04:13,034:INFO:Initializing create_model()
2023-06-13 11:04:13,034:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D770C670>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D66E00D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 11:04:13,035:INFO:Checking exceptions
2023-06-13 11:04:13,035:INFO:Importing libraries
2023-06-13 11:04:13,035:INFO:Copying training dataset
2023-06-13 11:04:13,057:INFO:Defining folds
2023-06-13 11:04:13,058:INFO:Declaring metric variables
2023-06-13 11:04:13,072:INFO:Importing untrained model
2023-06-13 11:04:13,083:INFO:Bayesian Ridge Imported successfully
2023-06-13 11:04:13,103:INFO:Starting cross validation
2023-06-13 11:04:13,107:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 11:04:13,848:INFO:Calculating mean and std
2023-06-13 11:04:13,851:INFO:Creating metrics dataframe
2023-06-13 11:04:14,159:INFO:Uploading results into container
2023-06-13 11:04:14,163:INFO:Uploading model into container now
2023-06-13 11:04:14,164:INFO:_master_model_container: 8
2023-06-13 11:04:14,164:INFO:_display_container: 2
2023-06-13 11:04:14,166:INFO:BayesianRidge()
2023-06-13 11:04:14,166:INFO:create_model() successfully completed......................................
2023-06-13 11:04:14,424:INFO:SubProcess create_model() end ==================================
2023-06-13 11:04:14,424:INFO:Creating metrics dataframe
2023-06-13 11:04:14,472:INFO:Initializing Passive Aggressive Regressor
2023-06-13 11:04:14,472:INFO:Total runtime is 0.1916964689890544 minutes
2023-06-13 11:04:14,483:INFO:SubProcess create_model() called ==================================
2023-06-13 11:04:14,485:INFO:Initializing create_model()
2023-06-13 11:04:14,485:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D770C670>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D66E00D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 11:04:14,486:INFO:Checking exceptions
2023-06-13 11:04:14,486:INFO:Importing libraries
2023-06-13 11:04:14,486:INFO:Copying training dataset
2023-06-13 11:04:14,505:INFO:Defining folds
2023-06-13 11:04:14,506:INFO:Declaring metric variables
2023-06-13 11:04:14,516:INFO:Importing untrained model
2023-06-13 11:04:14,529:INFO:Passive Aggressive Regressor Imported successfully
2023-06-13 11:04:14,551:INFO:Starting cross validation
2023-06-13 11:04:14,555:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 11:04:15,274:INFO:Calculating mean and std
2023-06-13 11:04:15,277:INFO:Creating metrics dataframe
2023-06-13 11:04:15,578:INFO:Uploading results into container
2023-06-13 11:04:15,580:INFO:Uploading model into container now
2023-06-13 11:04:15,581:INFO:_master_model_container: 9
2023-06-13 11:04:15,581:INFO:_display_container: 2
2023-06-13 11:04:15,583:INFO:PassiveAggressiveRegressor(random_state=5909)
2023-06-13 11:04:15,584:INFO:create_model() successfully completed......................................
2023-06-13 11:04:15,856:INFO:SubProcess create_model() end ==================================
2023-06-13 11:04:15,857:INFO:Creating metrics dataframe
2023-06-13 11:04:15,896:INFO:Initializing Huber Regressor
2023-06-13 11:04:15,896:INFO:Total runtime is 0.21542625029881798 minutes
2023-06-13 11:04:15,908:INFO:SubProcess create_model() called ==================================
2023-06-13 11:04:15,911:INFO:Initializing create_model()
2023-06-13 11:04:15,911:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D770C670>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D66E00D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 11:04:15,911:INFO:Checking exceptions
2023-06-13 11:04:15,911:INFO:Importing libraries
2023-06-13 11:04:15,911:INFO:Copying training dataset
2023-06-13 11:04:15,928:INFO:Defining folds
2023-06-13 11:04:15,928:INFO:Declaring metric variables
2023-06-13 11:04:15,941:INFO:Importing untrained model
2023-06-13 11:04:15,951:INFO:Huber Regressor Imported successfully
2023-06-13 11:04:15,971:INFO:Starting cross validation
2023-06-13 11:04:15,974:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 11:04:16,354:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-13 11:04:16,414:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-13 11:04:16,422:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-13 11:04:17,087:INFO:Calculating mean and std
2023-06-13 11:04:17,091:INFO:Creating metrics dataframe
2023-06-13 11:04:17,396:INFO:Uploading results into container
2023-06-13 11:04:17,398:INFO:Uploading model into container now
2023-06-13 11:04:17,399:INFO:_master_model_container: 10
2023-06-13 11:04:17,399:INFO:_display_container: 2
2023-06-13 11:04:17,400:INFO:HuberRegressor()
2023-06-13 11:04:17,400:INFO:create_model() successfully completed......................................
2023-06-13 11:04:17,649:INFO:SubProcess create_model() end ==================================
2023-06-13 11:04:17,650:INFO:Creating metrics dataframe
2023-06-13 11:04:17,694:INFO:Initializing K Neighbors Regressor
2023-06-13 11:04:17,694:INFO:Total runtime is 0.24539740482966108 minutes
2023-06-13 11:04:17,704:INFO:SubProcess create_model() called ==================================
2023-06-13 11:04:17,705:INFO:Initializing create_model()
2023-06-13 11:04:17,706:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D770C670>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D66E00D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 11:04:17,707:INFO:Checking exceptions
2023-06-13 11:04:17,707:INFO:Importing libraries
2023-06-13 11:04:17,707:INFO:Copying training dataset
2023-06-13 11:04:17,727:INFO:Defining folds
2023-06-13 11:04:17,728:INFO:Declaring metric variables
2023-06-13 11:04:17,740:INFO:Importing untrained model
2023-06-13 11:04:17,753:INFO:K Neighbors Regressor Imported successfully
2023-06-13 11:04:17,780:INFO:Starting cross validation
2023-06-13 11:04:17,785:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 11:04:18,666:INFO:Calculating mean and std
2023-06-13 11:04:18,669:INFO:Creating metrics dataframe
2023-06-13 11:04:18,974:INFO:Uploading results into container
2023-06-13 11:04:18,976:INFO:Uploading model into container now
2023-06-13 11:04:18,977:INFO:_master_model_container: 11
2023-06-13 11:04:18,977:INFO:_display_container: 2
2023-06-13 11:04:18,979:INFO:KNeighborsRegressor(n_jobs=-1)
2023-06-13 11:04:18,979:INFO:create_model() successfully completed......................................
2023-06-13 11:04:19,238:INFO:SubProcess create_model() end ==================================
2023-06-13 11:04:19,238:INFO:Creating metrics dataframe
2023-06-13 11:04:19,275:INFO:Initializing Decision Tree Regressor
2023-06-13 11:04:19,276:INFO:Total runtime is 0.27177271842956546 minutes
2023-06-13 11:04:19,286:INFO:SubProcess create_model() called ==================================
2023-06-13 11:04:19,287:INFO:Initializing create_model()
2023-06-13 11:04:19,288:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D770C670>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D66E00D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 11:04:19,288:INFO:Checking exceptions
2023-06-13 11:04:19,288:INFO:Importing libraries
2023-06-13 11:04:19,288:INFO:Copying training dataset
2023-06-13 11:04:19,299:INFO:Defining folds
2023-06-13 11:04:19,299:INFO:Declaring metric variables
2023-06-13 11:04:19,306:INFO:Importing untrained model
2023-06-13 11:04:19,318:INFO:Decision Tree Regressor Imported successfully
2023-06-13 11:04:19,344:INFO:Starting cross validation
2023-06-13 11:04:19,351:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 11:04:20,423:INFO:Calculating mean and std
2023-06-13 11:04:20,426:INFO:Creating metrics dataframe
2023-06-13 11:04:20,757:INFO:Uploading results into container
2023-06-13 11:04:20,759:INFO:Uploading model into container now
2023-06-13 11:04:20,760:INFO:_master_model_container: 12
2023-06-13 11:04:20,761:INFO:_display_container: 2
2023-06-13 11:04:20,761:INFO:DecisionTreeRegressor(random_state=5909)
2023-06-13 11:04:20,762:INFO:create_model() successfully completed......................................
2023-06-13 11:04:21,009:INFO:SubProcess create_model() end ==================================
2023-06-13 11:04:21,010:INFO:Creating metrics dataframe
2023-06-13 11:04:21,046:INFO:Initializing Random Forest Regressor
2023-06-13 11:04:21,046:INFO:Total runtime is 0.30126920143763225 minutes
2023-06-13 11:04:21,058:INFO:SubProcess create_model() called ==================================
2023-06-13 11:04:21,060:INFO:Initializing create_model()
2023-06-13 11:04:21,060:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D770C670>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D66E00D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 11:04:21,060:INFO:Checking exceptions
2023-06-13 11:04:21,060:INFO:Importing libraries
2023-06-13 11:04:21,061:INFO:Copying training dataset
2023-06-13 11:04:21,090:INFO:Defining folds
2023-06-13 11:04:21,091:INFO:Declaring metric variables
2023-06-13 11:04:21,106:INFO:Importing untrained model
2023-06-13 11:04:21,124:INFO:Random Forest Regressor Imported successfully
2023-06-13 11:04:21,147:INFO:Starting cross validation
2023-06-13 11:04:21,152:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 11:04:32,764:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 11:04:32,924:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 11:04:33,796:INFO:Calculating mean and std
2023-06-13 11:04:33,798:INFO:Creating metrics dataframe
2023-06-13 11:04:34,124:INFO:Uploading results into container
2023-06-13 11:04:34,126:INFO:Uploading model into container now
2023-06-13 11:04:34,127:INFO:_master_model_container: 13
2023-06-13 11:04:34,128:INFO:_display_container: 2
2023-06-13 11:04:34,128:INFO:RandomForestRegressor(n_jobs=-1, random_state=5909)
2023-06-13 11:04:34,129:INFO:create_model() successfully completed......................................
2023-06-13 11:04:34,401:INFO:SubProcess create_model() end ==================================
2023-06-13 11:04:34,401:INFO:Creating metrics dataframe
2023-06-13 11:04:34,446:INFO:Initializing Extra Trees Regressor
2023-06-13 11:04:34,446:INFO:Total runtime is 0.5245972832043966 minutes
2023-06-13 11:04:34,457:INFO:SubProcess create_model() called ==================================
2023-06-13 11:04:34,458:INFO:Initializing create_model()
2023-06-13 11:04:34,458:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D770C670>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D66E00D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 11:04:34,459:INFO:Checking exceptions
2023-06-13 11:04:34,459:INFO:Importing libraries
2023-06-13 11:04:34,459:INFO:Copying training dataset
2023-06-13 11:04:34,482:INFO:Defining folds
2023-06-13 11:04:34,483:INFO:Declaring metric variables
2023-06-13 11:04:34,494:INFO:Importing untrained model
2023-06-13 11:04:34,508:INFO:Extra Trees Regressor Imported successfully
2023-06-13 11:04:34,533:INFO:Starting cross validation
2023-06-13 11:04:34,536:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 11:04:38,684:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.27s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 11:04:38,718:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.37s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 11:04:39,634:INFO:Calculating mean and std
2023-06-13 11:04:39,636:INFO:Creating metrics dataframe
2023-06-13 11:04:39,932:INFO:Uploading results into container
2023-06-13 11:04:39,934:INFO:Uploading model into container now
2023-06-13 11:04:39,935:INFO:_master_model_container: 14
2023-06-13 11:04:39,936:INFO:_display_container: 2
2023-06-13 11:04:39,937:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=5909)
2023-06-13 11:04:39,937:INFO:create_model() successfully completed......................................
2023-06-13 11:04:40,193:INFO:SubProcess create_model() end ==================================
2023-06-13 11:04:40,194:INFO:Creating metrics dataframe
2023-06-13 11:04:40,234:INFO:Initializing AdaBoost Regressor
2023-06-13 11:04:40,235:INFO:Total runtime is 0.6210768381754558 minutes
2023-06-13 11:04:40,247:INFO:SubProcess create_model() called ==================================
2023-06-13 11:04:40,248:INFO:Initializing create_model()
2023-06-13 11:04:40,248:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D770C670>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D66E00D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 11:04:40,249:INFO:Checking exceptions
2023-06-13 11:04:40,249:INFO:Importing libraries
2023-06-13 11:04:40,249:INFO:Copying training dataset
2023-06-13 11:04:40,271:INFO:Defining folds
2023-06-13 11:04:40,272:INFO:Declaring metric variables
2023-06-13 11:04:40,284:INFO:Importing untrained model
2023-06-13 11:04:40,296:INFO:AdaBoost Regressor Imported successfully
2023-06-13 11:04:40,325:INFO:Starting cross validation
2023-06-13 11:04:40,331:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 11:04:41,832:INFO:Calculating mean and std
2023-06-13 11:04:41,835:INFO:Creating metrics dataframe
2023-06-13 11:04:42,160:INFO:Uploading results into container
2023-06-13 11:04:42,162:INFO:Uploading model into container now
2023-06-13 11:04:42,163:INFO:_master_model_container: 15
2023-06-13 11:04:42,164:INFO:_display_container: 2
2023-06-13 11:04:42,165:INFO:AdaBoostRegressor(random_state=5909)
2023-06-13 11:04:42,165:INFO:create_model() successfully completed......................................
2023-06-13 11:04:42,423:INFO:SubProcess create_model() end ==================================
2023-06-13 11:04:42,424:INFO:Creating metrics dataframe
2023-06-13 11:04:42,458:INFO:Initializing Gradient Boosting Regressor
2023-06-13 11:04:42,459:INFO:Total runtime is 0.658150311311086 minutes
2023-06-13 11:04:42,469:INFO:SubProcess create_model() called ==================================
2023-06-13 11:04:42,470:INFO:Initializing create_model()
2023-06-13 11:04:42,470:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D770C670>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D66E00D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 11:04:42,470:INFO:Checking exceptions
2023-06-13 11:04:42,471:INFO:Importing libraries
2023-06-13 11:04:42,472:INFO:Copying training dataset
2023-06-13 11:04:42,482:INFO:Defining folds
2023-06-13 11:04:42,482:INFO:Declaring metric variables
2023-06-13 11:04:42,489:INFO:Importing untrained model
2023-06-13 11:04:42,509:INFO:Gradient Boosting Regressor Imported successfully
2023-06-13 11:04:42,535:INFO:Starting cross validation
2023-06-13 11:04:42,538:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 11:04:48,953:INFO:Calculating mean and std
2023-06-13 11:04:48,956:INFO:Creating metrics dataframe
2023-06-13 11:04:49,296:INFO:Uploading results into container
2023-06-13 11:04:49,299:INFO:Uploading model into container now
2023-06-13 11:04:49,301:INFO:_master_model_container: 16
2023-06-13 11:04:49,301:INFO:_display_container: 2
2023-06-13 11:04:49,302:INFO:GradientBoostingRegressor(random_state=5909)
2023-06-13 11:04:49,302:INFO:create_model() successfully completed......................................
2023-06-13 11:04:49,565:INFO:SubProcess create_model() end ==================================
2023-06-13 11:04:49,566:INFO:Creating metrics dataframe
2023-06-13 11:04:49,606:INFO:Initializing Extreme Gradient Boosting
2023-06-13 11:04:49,607:INFO:Total runtime is 0.7772851467132569 minutes
2023-06-13 11:04:49,617:INFO:SubProcess create_model() called ==================================
2023-06-13 11:04:49,619:INFO:Initializing create_model()
2023-06-13 11:04:49,619:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D770C670>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D66E00D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 11:04:49,620:INFO:Checking exceptions
2023-06-13 11:04:49,620:INFO:Importing libraries
2023-06-13 11:04:49,620:INFO:Copying training dataset
2023-06-13 11:04:49,643:INFO:Defining folds
2023-06-13 11:04:49,643:INFO:Declaring metric variables
2023-06-13 11:04:49,656:INFO:Importing untrained model
2023-06-13 11:04:49,676:INFO:Extreme Gradient Boosting Imported successfully
2023-06-13 11:04:49,696:INFO:Starting cross validation
2023-06-13 11:04:49,699:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 11:04:53,463:INFO:Calculating mean and std
2023-06-13 11:04:53,466:INFO:Creating metrics dataframe
2023-06-13 11:04:53,809:INFO:Uploading results into container
2023-06-13 11:04:53,811:INFO:Uploading model into container now
2023-06-13 11:04:53,812:INFO:_master_model_container: 17
2023-06-13 11:04:53,812:INFO:_display_container: 2
2023-06-13 11:04:53,815:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=5909, ...)
2023-06-13 11:04:53,815:INFO:create_model() successfully completed......................................
2023-06-13 11:04:54,070:INFO:SubProcess create_model() end ==================================
2023-06-13 11:04:54,070:INFO:Creating metrics dataframe
2023-06-13 11:04:54,112:INFO:Initializing Light Gradient Boosting Machine
2023-06-13 11:04:54,114:INFO:Total runtime is 0.8523928721745809 minutes
2023-06-13 11:04:54,128:INFO:SubProcess create_model() called ==================================
2023-06-13 11:04:54,129:INFO:Initializing create_model()
2023-06-13 11:04:54,130:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D770C670>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D66E00D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 11:04:54,130:INFO:Checking exceptions
2023-06-13 11:04:54,130:INFO:Importing libraries
2023-06-13 11:04:54,130:INFO:Copying training dataset
2023-06-13 11:04:54,154:INFO:Defining folds
2023-06-13 11:04:54,155:INFO:Declaring metric variables
2023-06-13 11:04:54,168:INFO:Importing untrained model
2023-06-13 11:04:54,180:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-13 11:04:54,208:INFO:Starting cross validation
2023-06-13 11:04:54,212:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 11:04:57,532:INFO:Calculating mean and std
2023-06-13 11:04:57,537:INFO:Creating metrics dataframe
2023-06-13 11:04:57,843:INFO:Uploading results into container
2023-06-13 11:04:57,844:INFO:Uploading model into container now
2023-06-13 11:04:57,846:INFO:_master_model_container: 18
2023-06-13 11:04:57,846:INFO:_display_container: 2
2023-06-13 11:04:57,847:INFO:LGBMRegressor(random_state=5909)
2023-06-13 11:04:57,847:INFO:create_model() successfully completed......................................
2023-06-13 11:04:58,113:INFO:SubProcess create_model() end ==================================
2023-06-13 11:04:58,113:INFO:Creating metrics dataframe
2023-06-13 11:04:58,155:INFO:Initializing Dummy Regressor
2023-06-13 11:04:58,155:INFO:Total runtime is 0.9197540243466695 minutes
2023-06-13 11:04:58,165:INFO:SubProcess create_model() called ==================================
2023-06-13 11:04:58,166:INFO:Initializing create_model()
2023-06-13 11:04:58,166:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D770C670>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D66E00D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 11:04:58,167:INFO:Checking exceptions
2023-06-13 11:04:58,167:INFO:Importing libraries
2023-06-13 11:04:58,168:INFO:Copying training dataset
2023-06-13 11:04:58,191:INFO:Defining folds
2023-06-13 11:04:58,192:INFO:Declaring metric variables
2023-06-13 11:04:58,211:INFO:Importing untrained model
2023-06-13 11:04:58,223:INFO:Dummy Regressor Imported successfully
2023-06-13 11:04:58,245:INFO:Starting cross validation
2023-06-13 11:04:58,251:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 11:04:59,136:INFO:Calculating mean and std
2023-06-13 11:04:59,140:INFO:Creating metrics dataframe
2023-06-13 11:04:59,522:INFO:Uploading results into container
2023-06-13 11:04:59,524:INFO:Uploading model into container now
2023-06-13 11:04:59,525:INFO:_master_model_container: 19
2023-06-13 11:04:59,525:INFO:_display_container: 2
2023-06-13 11:04:59,525:INFO:DummyRegressor()
2023-06-13 11:04:59,526:INFO:create_model() successfully completed......................................
2023-06-13 11:04:59,780:INFO:SubProcess create_model() end ==================================
2023-06-13 11:04:59,780:INFO:Creating metrics dataframe
2023-06-13 11:04:59,846:INFO:Initializing create_model()
2023-06-13 11:04:59,846:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D770C670>, estimator=ElasticNet(random_state=5909), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-13 11:04:59,847:INFO:Checking exceptions
2023-06-13 11:04:59,849:INFO:Importing libraries
2023-06-13 11:04:59,850:INFO:Copying training dataset
2023-06-13 11:04:59,867:INFO:Defining folds
2023-06-13 11:04:59,868:INFO:Declaring metric variables
2023-06-13 11:04:59,868:INFO:Importing untrained model
2023-06-13 11:04:59,868:INFO:Declaring custom model
2023-06-13 11:04:59,870:INFO:Elastic Net Imported successfully
2023-06-13 11:04:59,873:INFO:Cross validation set to False
2023-06-13 11:04:59,873:INFO:Fitting Model
2023-06-13 11:05:00,146:WARNING:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.692e+07, tolerance: 8.583e+06

2023-06-13 11:05:00,366:INFO:ElasticNet(random_state=5909)
2023-06-13 11:05:00,367:INFO:create_model() successfully completed......................................
2023-06-13 11:05:00,717:INFO:_master_model_container: 19
2023-06-13 11:05:00,718:INFO:_display_container: 2
2023-06-13 11:05:00,719:INFO:ElasticNet(random_state=5909)
2023-06-13 11:05:00,719:INFO:compare_models() successfully completed......................................
2023-06-13 12:26:21,979:INFO:PyCaret RegressionExperiment
2023-06-13 12:26:21,980:INFO:Logging name: reg-default-name
2023-06-13 12:26:21,980:INFO:ML Usecase: MLUsecase.REGRESSION
2023-06-13 12:26:21,980:INFO:version 3.0.2
2023-06-13 12:26:21,980:INFO:Initializing setup()
2023-06-13 12:26:21,980:INFO:self.USI: f76f
2023-06-13 12:26:21,980:INFO:self._variable_keys: {'fold_groups_param', 'data', 'y', 'transform_target_param', 'fold_shuffle_param', 'gpu_n_jobs_param', 'X_test', 'exp_id', 'logging_param', 'y_train', 'target_param', '_available_plots', 'html_param', 'X_train', 'USI', 'pipeline', 'y_test', 'fold_generator', 'exp_name_log', 'X', 'log_plots_param', 'gpu_param', 'memory', 'idx', '_ml_usecase', 'n_jobs_param', 'seed'}
2023-06-13 12:26:21,980:INFO:Checking environment
2023-06-13 12:26:21,980:INFO:python_version: 3.10.9
2023-06-13 12:26:21,980:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-06-13 12:26:21,980:INFO:machine: AMD64
2023-06-13 12:26:21,980:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-13 12:26:21,980:INFO:Memory: svmem(total=16901767168, available=5518675968, percent=67.3, used=11383091200, free=5518675968)
2023-06-13 12:26:21,980:INFO:Physical Core: 4
2023-06-13 12:26:21,980:INFO:Logical Core: 8
2023-06-13 12:26:21,981:INFO:Checking libraries
2023-06-13 12:26:21,981:INFO:System:
2023-06-13 12:26:21,981:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-06-13 12:26:21,981:INFO:executable: C:\Users\lapei\anaconda3\python.exe
2023-06-13 12:26:21,981:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-13 12:26:21,981:INFO:PyCaret required dependencies:
2023-06-13 12:26:21,981:INFO:                 pip: 22.3.1
2023-06-13 12:26:21,981:INFO:          setuptools: 65.6.3
2023-06-13 12:26:21,981:INFO:             pycaret: 3.0.2
2023-06-13 12:26:21,981:INFO:             IPython: 8.10.0
2023-06-13 12:26:21,981:INFO:          ipywidgets: 7.6.5
2023-06-13 12:26:21,981:INFO:                tqdm: 4.64.1
2023-06-13 12:26:21,981:INFO:               numpy: 1.23.5
2023-06-13 12:26:21,981:INFO:              pandas: 1.5.3
2023-06-13 12:26:21,981:INFO:              jinja2: 3.1.2
2023-06-13 12:26:21,981:INFO:               scipy: 1.10.0
2023-06-13 12:26:21,981:INFO:              joblib: 1.2.0
2023-06-13 12:26:21,981:INFO:             sklearn: 1.2.1
2023-06-13 12:26:21,981:INFO:                pyod: 1.0.9
2023-06-13 12:26:21,981:INFO:            imblearn: 0.10.1
2023-06-13 12:26:21,981:INFO:   category_encoders: 2.6.1
2023-06-13 12:26:21,981:INFO:            lightgbm: 3.3.5
2023-06-13 12:26:21,981:INFO:               numba: 0.56.4
2023-06-13 12:26:21,981:INFO:            requests: 2.28.1
2023-06-13 12:26:21,981:INFO:          matplotlib: 3.7.0
2023-06-13 12:26:21,981:INFO:          scikitplot: 0.3.7
2023-06-13 12:26:21,981:INFO:         yellowbrick: 1.5
2023-06-13 12:26:21,981:INFO:              plotly: 5.9.0
2023-06-13 12:26:21,981:INFO:             kaleido: 0.2.1
2023-06-13 12:26:21,982:INFO:         statsmodels: 0.13.5
2023-06-13 12:26:21,982:INFO:              sktime: 0.17.0
2023-06-13 12:26:21,982:INFO:               tbats: 1.1.3
2023-06-13 12:26:21,982:INFO:            pmdarima: 2.0.3
2023-06-13 12:26:21,982:INFO:              psutil: 5.9.0
2023-06-13 12:26:21,982:INFO:PyCaret optional dependencies:
2023-06-13 12:26:21,982:INFO:                shap: 0.41.0
2023-06-13 12:26:21,982:INFO:           interpret: Not installed
2023-06-13 12:26:21,982:INFO:                umap: Not installed
2023-06-13 12:26:21,982:INFO:    pandas_profiling: Not installed
2023-06-13 12:26:21,982:INFO:  explainerdashboard: Not installed
2023-06-13 12:26:21,982:INFO:             autoviz: Not installed
2023-06-13 12:26:21,982:INFO:           fairlearn: Not installed
2023-06-13 12:26:21,982:INFO:             xgboost: 1.7.3
2023-06-13 12:26:21,982:INFO:            catboost: Not installed
2023-06-13 12:26:21,982:INFO:              kmodes: Not installed
2023-06-13 12:26:21,982:INFO:             mlxtend: Not installed
2023-06-13 12:26:21,982:INFO:       statsforecast: Not installed
2023-06-13 12:26:21,982:INFO:        tune_sklearn: Not installed
2023-06-13 12:26:21,982:INFO:                 ray: Not installed
2023-06-13 12:26:21,982:INFO:            hyperopt: Not installed
2023-06-13 12:26:21,982:INFO:              optuna: Not installed
2023-06-13 12:26:21,982:INFO:               skopt: 0.9.0
2023-06-13 12:26:21,982:INFO:              mlflow: Not installed
2023-06-13 12:26:21,982:INFO:              gradio: Not installed
2023-06-13 12:26:21,982:INFO:             fastapi: Not installed
2023-06-13 12:26:21,982:INFO:             uvicorn: Not installed
2023-06-13 12:26:21,982:INFO:              m2cgen: Not installed
2023-06-13 12:26:21,982:INFO:           evidently: Not installed
2023-06-13 12:26:21,982:INFO:               fugue: Not installed
2023-06-13 12:26:21,983:INFO:           streamlit: Not installed
2023-06-13 12:26:21,983:INFO:             prophet: Not installed
2023-06-13 12:26:21,983:INFO:None
2023-06-13 12:26:21,983:INFO:Set up data.
2023-06-13 12:26:21,991:INFO:Set up train/test split.
2023-06-13 12:26:21,998:INFO:Set up index.
2023-06-13 12:26:21,998:INFO:Set up folding strategy.
2023-06-13 12:26:21,998:INFO:Assigning column types.
2023-06-13 12:26:22,005:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-13 12:26:22,005:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-13 12:26:22,013:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-13 12:26:22,023:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-13 12:26:22,103:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 12:26:22,145:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 12:26:22,146:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 12:26:22,148:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 12:26:22,149:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-13 12:26:22,153:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-13 12:26:22,157:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-13 12:26:22,249:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 12:26:22,292:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 12:26:22,292:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 12:26:22,295:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 12:26:22,295:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-06-13 12:26:22,298:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-13 12:26:22,307:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-13 12:26:22,419:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 12:26:22,471:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 12:26:22,472:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 12:26:22,477:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 12:26:22,488:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-13 12:26:22,499:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-13 12:26:22,594:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 12:26:22,666:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 12:26:22,666:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 12:26:22,669:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 12:26:22,670:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-06-13 12:26:22,684:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-13 12:26:22,771:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 12:26:22,829:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 12:26:22,830:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 12:26:22,833:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 12:26:22,846:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-13 12:26:22,907:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 12:26:22,951:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 12:26:22,952:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 12:26:22,955:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 12:26:22,955:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-06-13 12:26:23,049:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 12:26:23,110:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 12:26:23,112:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 12:26:23,117:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 12:26:23,201:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 12:26:23,264:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 12:26:23,268:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 12:26:23,270:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 12:26:23,271:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-13 12:26:23,360:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 12:26:23,446:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 12:26:23,449:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 12:26:23,516:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 12:26:23,588:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 12:26:23,591:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 12:26:23,591:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-06-13 12:26:23,703:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 12:26:23,705:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 12:26:23,822:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 12:26:23,825:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 12:26:23,826:INFO:Preparing preprocessing pipeline...
2023-06-13 12:26:23,826:INFO:Set up simple imputation.
2023-06-13 12:26:23,827:INFO:Set up column name cleaning.
2023-06-13 12:26:23,864:INFO:Finished creating preprocessing pipeline.
2023-06-13 12:26:23,869:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\lapei\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['taxa_homicidio', 'RH_adm_dir',
                                             'densidade_banda_larga',
                                             'densidade_telefonia_movel',
                                             'qtd_cursos_engenharias',
                                             'qtd_cursos_negocios_direito',
                                             'media_notas_CN', 'media_notas_CH',
                                             'media_NU_NOTA_LC',
                                             'media_NU_NOTA_MT',
                                             'media_...
                                             'Isencao_ISSQN_Sim',
                                             'Isencao_Tx_Sim',
                                             'Cessao_terrenos_Sim',
                                             'Doacao_terrenos_Sim',
                                             'Outros_mecanismos_Sim',
                                             'ISH_Baixa', 'ISH_Máxima',
                                             'ISH_Média', 'ISH_Mínima'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-06-13 12:26:23,869:INFO:Creating final display dataframe.
2023-06-13 12:26:23,986:INFO:Setup _display_container:                     Description                              Value
0                    Session id                               7520
1                        Target  qtd_abertas_Empresario_Individual
2                   Target type                         Regression
3           Original data shape                         (4456, 30)
4        Transformed data shape                         (4456, 30)
5   Transformed train set shape                         (3119, 30)
6    Transformed test set shape                         (1337, 30)
7              Numeric features                                 29
8                    Preprocess                               True
9               Imputation type                             simple
10           Numeric imputation                               mean
11       Categorical imputation                               mode
12               Fold Generator                              KFold
13                  Fold Number                                 10
14                     CPU Jobs                                 -1
15                      Use GPU                              False
16               Log Experiment                              False
17              Experiment Name                   reg-default-name
18                          USI                               f76f
2023-06-13 12:26:24,158:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 12:26:24,161:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 12:26:24,289:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 12:26:24,294:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 12:26:24,296:INFO:setup() successfully completed in 2.39s...............
2023-06-13 12:28:48,043:INFO:PyCaret RegressionExperiment
2023-06-13 12:28:48,043:INFO:Logging name: reg-default-name
2023-06-13 12:28:48,043:INFO:ML Usecase: MLUsecase.REGRESSION
2023-06-13 12:28:48,043:INFO:version 3.0.2
2023-06-13 12:28:48,044:INFO:Initializing setup()
2023-06-13 12:28:48,044:INFO:self.USI: 7d08
2023-06-13 12:28:48,044:INFO:self._variable_keys: {'fold_groups_param', 'data', 'y', 'transform_target_param', 'fold_shuffle_param', 'gpu_n_jobs_param', 'X_test', 'exp_id', 'logging_param', 'y_train', 'target_param', '_available_plots', 'html_param', 'X_train', 'USI', 'pipeline', 'y_test', 'fold_generator', 'exp_name_log', 'X', 'log_plots_param', 'gpu_param', 'memory', 'idx', '_ml_usecase', 'n_jobs_param', 'seed'}
2023-06-13 12:28:48,044:INFO:Checking environment
2023-06-13 12:28:48,044:INFO:python_version: 3.10.9
2023-06-13 12:28:48,044:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-06-13 12:28:48,044:INFO:machine: AMD64
2023-06-13 12:28:48,044:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-13 12:28:48,045:INFO:Memory: svmem(total=16901767168, available=5507215360, percent=67.4, used=11394551808, free=5507215360)
2023-06-13 12:28:48,045:INFO:Physical Core: 4
2023-06-13 12:28:48,045:INFO:Logical Core: 8
2023-06-13 12:28:48,045:INFO:Checking libraries
2023-06-13 12:28:48,045:INFO:System:
2023-06-13 12:28:48,045:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-06-13 12:28:48,045:INFO:executable: C:\Users\lapei\anaconda3\python.exe
2023-06-13 12:28:48,045:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-13 12:28:48,045:INFO:PyCaret required dependencies:
2023-06-13 12:28:48,046:INFO:                 pip: 22.3.1
2023-06-13 12:28:48,046:INFO:          setuptools: 65.6.3
2023-06-13 12:28:48,046:INFO:             pycaret: 3.0.2
2023-06-13 12:28:48,046:INFO:             IPython: 8.10.0
2023-06-13 12:28:48,046:INFO:          ipywidgets: 7.6.5
2023-06-13 12:28:48,046:INFO:                tqdm: 4.64.1
2023-06-13 12:28:48,046:INFO:               numpy: 1.23.5
2023-06-13 12:28:48,046:INFO:              pandas: 1.5.3
2023-06-13 12:28:48,046:INFO:              jinja2: 3.1.2
2023-06-13 12:28:48,046:INFO:               scipy: 1.10.0
2023-06-13 12:28:48,046:INFO:              joblib: 1.2.0
2023-06-13 12:28:48,047:INFO:             sklearn: 1.2.1
2023-06-13 12:28:48,047:INFO:                pyod: 1.0.9
2023-06-13 12:28:48,047:INFO:            imblearn: 0.10.1
2023-06-13 12:28:48,047:INFO:   category_encoders: 2.6.1
2023-06-13 12:28:48,047:INFO:            lightgbm: 3.3.5
2023-06-13 12:28:48,047:INFO:               numba: 0.56.4
2023-06-13 12:28:48,047:INFO:            requests: 2.28.1
2023-06-13 12:28:48,047:INFO:          matplotlib: 3.7.0
2023-06-13 12:28:48,047:INFO:          scikitplot: 0.3.7
2023-06-13 12:28:48,047:INFO:         yellowbrick: 1.5
2023-06-13 12:28:48,047:INFO:              plotly: 5.9.0
2023-06-13 12:28:48,047:INFO:             kaleido: 0.2.1
2023-06-13 12:28:48,047:INFO:         statsmodels: 0.13.5
2023-06-13 12:28:48,048:INFO:              sktime: 0.17.0
2023-06-13 12:28:48,048:INFO:               tbats: 1.1.3
2023-06-13 12:28:48,048:INFO:            pmdarima: 2.0.3
2023-06-13 12:28:48,048:INFO:              psutil: 5.9.0
2023-06-13 12:28:48,048:INFO:PyCaret optional dependencies:
2023-06-13 12:28:48,048:INFO:                shap: 0.41.0
2023-06-13 12:28:48,048:INFO:           interpret: Not installed
2023-06-13 12:28:48,048:INFO:                umap: Not installed
2023-06-13 12:28:48,048:INFO:    pandas_profiling: Not installed
2023-06-13 12:28:48,048:INFO:  explainerdashboard: Not installed
2023-06-13 12:28:48,048:INFO:             autoviz: Not installed
2023-06-13 12:28:48,049:INFO:           fairlearn: Not installed
2023-06-13 12:28:48,049:INFO:             xgboost: 1.7.3
2023-06-13 12:28:48,049:INFO:            catboost: Not installed
2023-06-13 12:28:48,049:INFO:              kmodes: Not installed
2023-06-13 12:28:48,049:INFO:             mlxtend: Not installed
2023-06-13 12:28:48,049:INFO:       statsforecast: Not installed
2023-06-13 12:28:48,049:INFO:        tune_sklearn: Not installed
2023-06-13 12:28:48,049:INFO:                 ray: Not installed
2023-06-13 12:28:48,049:INFO:            hyperopt: Not installed
2023-06-13 12:28:48,049:INFO:              optuna: Not installed
2023-06-13 12:28:48,050:INFO:               skopt: 0.9.0
2023-06-13 12:28:48,050:INFO:              mlflow: Not installed
2023-06-13 12:28:48,050:INFO:              gradio: Not installed
2023-06-13 12:28:48,050:INFO:             fastapi: Not installed
2023-06-13 12:28:48,050:INFO:             uvicorn: Not installed
2023-06-13 12:28:48,050:INFO:              m2cgen: Not installed
2023-06-13 12:28:48,050:INFO:           evidently: Not installed
2023-06-13 12:28:48,050:INFO:               fugue: Not installed
2023-06-13 12:28:48,050:INFO:           streamlit: Not installed
2023-06-13 12:28:48,050:INFO:             prophet: Not installed
2023-06-13 12:28:48,050:INFO:None
2023-06-13 12:28:48,050:INFO:Set up data.
2023-06-13 12:28:48,074:INFO:Set up train/test split.
2023-06-13 12:28:48,083:INFO:Set up index.
2023-06-13 12:28:48,083:INFO:Set up folding strategy.
2023-06-13 12:28:48,084:INFO:Assigning column types.
2023-06-13 12:28:48,090:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-13 12:28:48,090:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-13 12:28:48,096:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-13 12:28:48,100:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-13 12:28:48,183:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 12:28:48,256:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 12:28:48,257:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 12:28:48,264:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 12:28:48,265:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-13 12:28:48,275:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-13 12:28:48,285:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-13 12:28:48,366:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 12:28:48,411:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 12:28:48,412:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 12:28:48,414:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 12:28:48,414:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-06-13 12:28:48,419:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-13 12:28:48,424:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-13 12:28:48,482:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 12:28:48,526:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 12:28:48,526:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 12:28:48,529:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 12:28:48,535:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-13 12:28:48,539:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-13 12:28:48,641:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 12:28:48,705:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 12:28:48,706:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 12:28:48,711:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 12:28:48,711:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-06-13 12:28:48,727:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-13 12:28:48,786:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 12:28:48,830:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 12:28:48,831:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 12:28:48,833:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 12:28:48,842:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-13 12:28:48,906:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 12:28:48,949:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 12:28:48,949:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 12:28:48,952:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 12:28:48,952:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-06-13 12:28:49,018:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 12:28:49,061:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 12:28:49,062:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 12:28:49,065:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 12:28:49,131:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 12:28:49,175:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 12:28:49,175:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 12:28:49,178:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 12:28:49,178:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-13 12:28:49,244:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 12:28:49,298:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 12:28:49,301:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 12:28:49,368:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 12:28:49,425:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 12:28:49,430:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 12:28:49,431:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-06-13 12:28:49,582:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 12:28:49,585:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 12:28:49,693:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 12:28:49,695:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 12:28:49,696:INFO:Preparing preprocessing pipeline...
2023-06-13 12:28:49,696:INFO:Set up simple imputation.
2023-06-13 12:28:49,697:INFO:Set up column name cleaning.
2023-06-13 12:28:49,729:INFO:Finished creating preprocessing pipeline.
2023-06-13 12:28:49,734:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\lapei\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['taxa_homicidio', 'RH_adm_dir',
                                             'densidade_banda_larga',
                                             'densidade_telefonia_movel',
                                             'qtd_cursos_engenharias',
                                             'qtd_cursos_negocios_direito',
                                             'media_notas_CN', 'media_notas_CH',
                                             'media_NU_NOTA_LC',
                                             'media_NU_NOTA_MT',
                                             'media_...
                                             'Isencao_ISSQN_Sim',
                                             'Isencao_Tx_Sim',
                                             'Cessao_terrenos_Sim',
                                             'Doacao_terrenos_Sim',
                                             'Outros_mecanismos_Sim',
                                             'ISH_Baixa', 'ISH_Máxima',
                                             'ISH_Média', 'ISH_Mínima'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-06-13 12:28:49,734:INFO:Creating final display dataframe.
2023-06-13 12:28:49,821:INFO:Setup _display_container:                     Description                              Value
0                    Session id                                 42
1                        Target  qtd_abertas_Empresario_Individual
2                   Target type                         Regression
3           Original data shape                         (4456, 30)
4        Transformed data shape                         (4456, 30)
5   Transformed train set shape                         (3119, 30)
6    Transformed test set shape                         (1337, 30)
7              Numeric features                                 29
8                    Preprocess                               True
9               Imputation type                             simple
10           Numeric imputation                               mean
11       Categorical imputation                               mode
12               Fold Generator                              KFold
13                  Fold Number                                 10
14                     CPU Jobs                                 -1
15                      Use GPU                              False
16               Log Experiment                              False
17              Experiment Name                   reg-default-name
18                          USI                               7d08
2023-06-13 12:28:49,958:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 12:28:49,962:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 12:28:50,106:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 12:28:50,111:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 12:28:50,112:INFO:setup() successfully completed in 2.16s...............
2023-06-13 12:28:53,707:INFO:Initializing compare_models()
2023-06-13 12:28:53,707:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D3C79450>, include=None, fold=5, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001E3D3C79450>, 'include': None, 'exclude': None, 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-06-13 12:28:53,708:INFO:Checking exceptions
2023-06-13 12:28:53,712:INFO:Preparing display monitor
2023-06-13 12:28:53,749:INFO:Initializing Linear Regression
2023-06-13 12:28:53,750:INFO:Total runtime is 1.72575314839681e-05 minutes
2023-06-13 12:28:53,758:INFO:SubProcess create_model() called ==================================
2023-06-13 12:28:53,759:INFO:Initializing create_model()
2023-06-13 12:28:53,759:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D3C79450>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D3CAA020>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 12:28:53,759:INFO:Checking exceptions
2023-06-13 12:28:53,759:INFO:Importing libraries
2023-06-13 12:28:53,759:INFO:Copying training dataset
2023-06-13 12:28:53,772:INFO:Defining folds
2023-06-13 12:28:53,773:INFO:Declaring metric variables
2023-06-13 12:28:53,780:INFO:Importing untrained model
2023-06-13 12:28:53,784:INFO:Linear Regression Imported successfully
2023-06-13 12:28:53,800:INFO:Starting cross validation
2023-06-13 12:28:53,801:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 12:28:58,842:INFO:Calculating mean and std
2023-06-13 12:28:58,845:INFO:Creating metrics dataframe
2023-06-13 12:28:59,041:INFO:Uploading results into container
2023-06-13 12:28:59,042:INFO:Uploading model into container now
2023-06-13 12:28:59,043:INFO:_master_model_container: 1
2023-06-13 12:28:59,044:INFO:_display_container: 2
2023-06-13 12:28:59,044:INFO:LinearRegression(n_jobs=-1)
2023-06-13 12:28:59,044:INFO:create_model() successfully completed......................................
2023-06-13 12:28:59,237:INFO:SubProcess create_model() end ==================================
2023-06-13 12:28:59,238:INFO:Creating metrics dataframe
2023-06-13 12:28:59,252:INFO:Initializing Lasso Regression
2023-06-13 12:28:59,252:INFO:Total runtime is 0.09171834389368694 minutes
2023-06-13 12:28:59,258:INFO:SubProcess create_model() called ==================================
2023-06-13 12:28:59,258:INFO:Initializing create_model()
2023-06-13 12:28:59,259:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D3C79450>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D3CAA020>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 12:28:59,259:INFO:Checking exceptions
2023-06-13 12:28:59,259:INFO:Importing libraries
2023-06-13 12:28:59,260:INFO:Copying training dataset
2023-06-13 12:28:59,274:INFO:Defining folds
2023-06-13 12:28:59,274:INFO:Declaring metric variables
2023-06-13 12:28:59,282:INFO:Importing untrained model
2023-06-13 12:28:59,287:INFO:Lasso Regression Imported successfully
2023-06-13 12:28:59,301:INFO:Starting cross validation
2023-06-13 12:28:59,302:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 12:29:01,746:INFO:Calculating mean and std
2023-06-13 12:29:01,747:INFO:Creating metrics dataframe
2023-06-13 12:29:01,923:INFO:Uploading results into container
2023-06-13 12:29:01,925:INFO:Uploading model into container now
2023-06-13 12:29:01,926:INFO:_master_model_container: 2
2023-06-13 12:29:01,927:INFO:_display_container: 2
2023-06-13 12:29:01,928:INFO:Lasso(random_state=42)
2023-06-13 12:29:01,928:INFO:create_model() successfully completed......................................
2023-06-13 12:29:02,149:INFO:SubProcess create_model() end ==================================
2023-06-13 12:29:02,149:INFO:Creating metrics dataframe
2023-06-13 12:29:02,159:INFO:Initializing Ridge Regression
2023-06-13 12:29:02,159:INFO:Total runtime is 0.1401579777399699 minutes
2023-06-13 12:29:02,165:INFO:SubProcess create_model() called ==================================
2023-06-13 12:29:02,165:INFO:Initializing create_model()
2023-06-13 12:29:02,165:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D3C79450>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D3CAA020>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 12:29:02,165:INFO:Checking exceptions
2023-06-13 12:29:02,165:INFO:Importing libraries
2023-06-13 12:29:02,165:INFO:Copying training dataset
2023-06-13 12:29:02,177:INFO:Defining folds
2023-06-13 12:29:02,177:INFO:Declaring metric variables
2023-06-13 12:29:02,183:INFO:Importing untrained model
2023-06-13 12:29:02,188:INFO:Ridge Regression Imported successfully
2023-06-13 12:29:02,197:INFO:Starting cross validation
2023-06-13 12:29:02,200:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 12:29:02,575:INFO:Calculating mean and std
2023-06-13 12:29:02,578:INFO:Creating metrics dataframe
2023-06-13 12:29:02,770:INFO:Uploading results into container
2023-06-13 12:29:02,771:INFO:Uploading model into container now
2023-06-13 12:29:02,772:INFO:_master_model_container: 3
2023-06-13 12:29:02,772:INFO:_display_container: 2
2023-06-13 12:29:02,773:INFO:Ridge(random_state=42)
2023-06-13 12:29:02,773:INFO:create_model() successfully completed......................................
2023-06-13 12:29:02,942:INFO:SubProcess create_model() end ==================================
2023-06-13 12:29:02,942:INFO:Creating metrics dataframe
2023-06-13 12:29:02,967:INFO:Initializing Elastic Net
2023-06-13 12:29:02,967:INFO:Total runtime is 0.15363039573033652 minutes
2023-06-13 12:29:02,977:INFO:SubProcess create_model() called ==================================
2023-06-13 12:29:02,978:INFO:Initializing create_model()
2023-06-13 12:29:02,978:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D3C79450>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D3CAA020>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 12:29:02,979:INFO:Checking exceptions
2023-06-13 12:29:02,979:INFO:Importing libraries
2023-06-13 12:29:02,979:INFO:Copying training dataset
2023-06-13 12:29:02,992:INFO:Defining folds
2023-06-13 12:29:02,992:INFO:Declaring metric variables
2023-06-13 12:29:02,999:INFO:Importing untrained model
2023-06-13 12:29:03,009:INFO:Elastic Net Imported successfully
2023-06-13 12:29:03,025:INFO:Starting cross validation
2023-06-13 12:29:03,028:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 12:29:03,436:INFO:Calculating mean and std
2023-06-13 12:29:03,437:INFO:Creating metrics dataframe
2023-06-13 12:29:03,602:INFO:Uploading results into container
2023-06-13 12:29:03,603:INFO:Uploading model into container now
2023-06-13 12:29:03,604:INFO:_master_model_container: 4
2023-06-13 12:29:03,604:INFO:_display_container: 2
2023-06-13 12:29:03,605:INFO:ElasticNet(random_state=42)
2023-06-13 12:29:03,605:INFO:create_model() successfully completed......................................
2023-06-13 12:29:03,748:INFO:SubProcess create_model() end ==================================
2023-06-13 12:29:03,748:INFO:Creating metrics dataframe
2023-06-13 12:29:03,758:INFO:Initializing Least Angle Regression
2023-06-13 12:29:03,758:INFO:Total runtime is 0.16681790351867676 minutes
2023-06-13 12:29:03,769:INFO:SubProcess create_model() called ==================================
2023-06-13 12:29:03,770:INFO:Initializing create_model()
2023-06-13 12:29:03,771:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D3C79450>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D3CAA020>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 12:29:03,771:INFO:Checking exceptions
2023-06-13 12:29:03,771:INFO:Importing libraries
2023-06-13 12:29:03,771:INFO:Copying training dataset
2023-06-13 12:29:03,784:INFO:Defining folds
2023-06-13 12:29:03,785:INFO:Declaring metric variables
2023-06-13 12:29:03,793:INFO:Importing untrained model
2023-06-13 12:29:03,803:INFO:Least Angle Regression Imported successfully
2023-06-13 12:29:03,820:INFO:Starting cross validation
2023-06-13 12:29:03,823:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 12:29:04,225:INFO:Calculating mean and std
2023-06-13 12:29:04,227:INFO:Creating metrics dataframe
2023-06-13 12:29:04,419:INFO:Uploading results into container
2023-06-13 12:29:04,421:INFO:Uploading model into container now
2023-06-13 12:29:04,422:INFO:_master_model_container: 5
2023-06-13 12:29:04,423:INFO:_display_container: 2
2023-06-13 12:29:04,424:INFO:Lars(random_state=42)
2023-06-13 12:29:04,425:INFO:create_model() successfully completed......................................
2023-06-13 12:29:04,592:INFO:SubProcess create_model() end ==================================
2023-06-13 12:29:04,592:INFO:Creating metrics dataframe
2023-06-13 12:29:04,602:INFO:Initializing Lasso Least Angle Regression
2023-06-13 12:29:04,602:INFO:Total runtime is 0.18087875445683796 minutes
2023-06-13 12:29:04,606:INFO:SubProcess create_model() called ==================================
2023-06-13 12:29:04,607:INFO:Initializing create_model()
2023-06-13 12:29:04,607:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D3C79450>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D3CAA020>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 12:29:04,607:INFO:Checking exceptions
2023-06-13 12:29:04,607:INFO:Importing libraries
2023-06-13 12:29:04,607:INFO:Copying training dataset
2023-06-13 12:29:04,618:INFO:Defining folds
2023-06-13 12:29:04,618:INFO:Declaring metric variables
2023-06-13 12:29:04,627:INFO:Importing untrained model
2023-06-13 12:29:04,636:INFO:Lasso Least Angle Regression Imported successfully
2023-06-13 12:29:04,650:INFO:Starting cross validation
2023-06-13 12:29:04,651:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 12:29:05,028:INFO:Calculating mean and std
2023-06-13 12:29:05,030:INFO:Creating metrics dataframe
2023-06-13 12:29:05,241:INFO:Uploading results into container
2023-06-13 12:29:05,242:INFO:Uploading model into container now
2023-06-13 12:29:05,243:INFO:_master_model_container: 6
2023-06-13 12:29:05,243:INFO:_display_container: 2
2023-06-13 12:29:05,243:INFO:LassoLars(random_state=42)
2023-06-13 12:29:05,243:INFO:create_model() successfully completed......................................
2023-06-13 12:29:05,434:INFO:SubProcess create_model() end ==================================
2023-06-13 12:29:05,434:INFO:Creating metrics dataframe
2023-06-13 12:29:05,459:INFO:Initializing Orthogonal Matching Pursuit
2023-06-13 12:29:05,459:INFO:Total runtime is 0.1951559543609619 minutes
2023-06-13 12:29:05,465:INFO:SubProcess create_model() called ==================================
2023-06-13 12:29:05,466:INFO:Initializing create_model()
2023-06-13 12:29:05,466:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D3C79450>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D3CAA020>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 12:29:05,466:INFO:Checking exceptions
2023-06-13 12:29:05,466:INFO:Importing libraries
2023-06-13 12:29:05,467:INFO:Copying training dataset
2023-06-13 12:29:05,474:INFO:Defining folds
2023-06-13 12:29:05,474:INFO:Declaring metric variables
2023-06-13 12:29:05,481:INFO:Importing untrained model
2023-06-13 12:29:05,493:INFO:Orthogonal Matching Pursuit Imported successfully
2023-06-13 12:29:05,508:INFO:Starting cross validation
2023-06-13 12:29:05,511:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 12:29:05,935:INFO:Calculating mean and std
2023-06-13 12:29:05,937:INFO:Creating metrics dataframe
2023-06-13 12:29:06,095:INFO:Uploading results into container
2023-06-13 12:29:06,096:INFO:Uploading model into container now
2023-06-13 12:29:06,097:INFO:_master_model_container: 7
2023-06-13 12:29:06,097:INFO:_display_container: 2
2023-06-13 12:29:06,097:INFO:OrthogonalMatchingPursuit()
2023-06-13 12:29:06,098:INFO:create_model() successfully completed......................................
2023-06-13 12:29:06,266:INFO:SubProcess create_model() end ==================================
2023-06-13 12:29:06,266:INFO:Creating metrics dataframe
2023-06-13 12:29:06,278:INFO:Initializing Bayesian Ridge
2023-06-13 12:29:06,278:INFO:Total runtime is 0.2088104724884033 minutes
2023-06-13 12:29:06,283:INFO:SubProcess create_model() called ==================================
2023-06-13 12:29:06,285:INFO:Initializing create_model()
2023-06-13 12:29:06,285:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D3C79450>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D3CAA020>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 12:29:06,285:INFO:Checking exceptions
2023-06-13 12:29:06,285:INFO:Importing libraries
2023-06-13 12:29:06,285:INFO:Copying training dataset
2023-06-13 12:29:06,300:INFO:Defining folds
2023-06-13 12:29:06,301:INFO:Declaring metric variables
2023-06-13 12:29:06,310:INFO:Importing untrained model
2023-06-13 12:29:06,316:INFO:Bayesian Ridge Imported successfully
2023-06-13 12:29:06,332:INFO:Starting cross validation
2023-06-13 12:29:06,333:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 12:29:06,738:INFO:Calculating mean and std
2023-06-13 12:29:06,740:INFO:Creating metrics dataframe
2023-06-13 12:29:06,903:INFO:Uploading results into container
2023-06-13 12:29:06,905:INFO:Uploading model into container now
2023-06-13 12:29:06,906:INFO:_master_model_container: 8
2023-06-13 12:29:06,906:INFO:_display_container: 2
2023-06-13 12:29:06,906:INFO:BayesianRidge()
2023-06-13 12:29:06,906:INFO:create_model() successfully completed......................................
2023-06-13 12:29:07,049:INFO:SubProcess create_model() end ==================================
2023-06-13 12:29:07,049:INFO:Creating metrics dataframe
2023-06-13 12:29:07,061:INFO:Initializing Passive Aggressive Regressor
2023-06-13 12:29:07,062:INFO:Total runtime is 0.22186378637949622 minutes
2023-06-13 12:29:07,067:INFO:SubProcess create_model() called ==================================
2023-06-13 12:29:07,067:INFO:Initializing create_model()
2023-06-13 12:29:07,067:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D3C79450>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D3CAA020>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 12:29:07,067:INFO:Checking exceptions
2023-06-13 12:29:07,068:INFO:Importing libraries
2023-06-13 12:29:07,068:INFO:Copying training dataset
2023-06-13 12:29:07,079:INFO:Defining folds
2023-06-13 12:29:07,079:INFO:Declaring metric variables
2023-06-13 12:29:07,084:INFO:Importing untrained model
2023-06-13 12:29:07,090:INFO:Passive Aggressive Regressor Imported successfully
2023-06-13 12:29:07,104:INFO:Starting cross validation
2023-06-13 12:29:07,107:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 12:29:07,445:INFO:Calculating mean and std
2023-06-13 12:29:07,447:INFO:Creating metrics dataframe
2023-06-13 12:29:07,670:INFO:Uploading results into container
2023-06-13 12:29:07,672:INFO:Uploading model into container now
2023-06-13 12:29:07,672:INFO:_master_model_container: 9
2023-06-13 12:29:07,672:INFO:_display_container: 2
2023-06-13 12:29:07,673:INFO:PassiveAggressiveRegressor(random_state=42)
2023-06-13 12:29:07,673:INFO:create_model() successfully completed......................................
2023-06-13 12:29:07,823:INFO:SubProcess create_model() end ==================================
2023-06-13 12:29:07,824:INFO:Creating metrics dataframe
2023-06-13 12:29:07,853:INFO:Initializing Huber Regressor
2023-06-13 12:29:07,854:INFO:Total runtime is 0.23506851196289058 minutes
2023-06-13 12:29:07,862:INFO:SubProcess create_model() called ==================================
2023-06-13 12:29:07,863:INFO:Initializing create_model()
2023-06-13 12:29:07,864:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D3C79450>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D3CAA020>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 12:29:07,864:INFO:Checking exceptions
2023-06-13 12:29:07,864:INFO:Importing libraries
2023-06-13 12:29:07,865:INFO:Copying training dataset
2023-06-13 12:29:07,879:INFO:Defining folds
2023-06-13 12:29:07,880:INFO:Declaring metric variables
2023-06-13 12:29:07,887:INFO:Importing untrained model
2023-06-13 12:29:07,894:INFO:Huber Regressor Imported successfully
2023-06-13 12:29:07,908:INFO:Starting cross validation
2023-06-13 12:29:07,911:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 12:29:08,093:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-13 12:29:08,100:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-13 12:29:08,111:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-13 12:29:08,119:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-13 12:29:08,369:INFO:Calculating mean and std
2023-06-13 12:29:08,370:INFO:Creating metrics dataframe
2023-06-13 12:29:08,574:INFO:Uploading results into container
2023-06-13 12:29:08,575:INFO:Uploading model into container now
2023-06-13 12:29:08,576:INFO:_master_model_container: 10
2023-06-13 12:29:08,576:INFO:_display_container: 2
2023-06-13 12:29:08,577:INFO:HuberRegressor()
2023-06-13 12:29:08,577:INFO:create_model() successfully completed......................................
2023-06-13 12:29:08,786:INFO:SubProcess create_model() end ==================================
2023-06-13 12:29:08,786:INFO:Creating metrics dataframe
2023-06-13 12:29:08,799:INFO:Initializing K Neighbors Regressor
2023-06-13 12:29:08,799:INFO:Total runtime is 0.250821296374003 minutes
2023-06-13 12:29:08,806:INFO:SubProcess create_model() called ==================================
2023-06-13 12:29:08,806:INFO:Initializing create_model()
2023-06-13 12:29:08,806:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D3C79450>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D3CAA020>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 12:29:08,807:INFO:Checking exceptions
2023-06-13 12:29:08,807:INFO:Importing libraries
2023-06-13 12:29:08,807:INFO:Copying training dataset
2023-06-13 12:29:08,814:INFO:Defining folds
2023-06-13 12:29:08,814:INFO:Declaring metric variables
2023-06-13 12:29:08,823:INFO:Importing untrained model
2023-06-13 12:29:08,833:INFO:K Neighbors Regressor Imported successfully
2023-06-13 12:29:08,850:INFO:Starting cross validation
2023-06-13 12:29:08,854:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 12:29:09,334:INFO:Calculating mean and std
2023-06-13 12:29:09,336:INFO:Creating metrics dataframe
2023-06-13 12:29:09,525:INFO:Uploading results into container
2023-06-13 12:29:09,526:INFO:Uploading model into container now
2023-06-13 12:29:09,527:INFO:_master_model_container: 11
2023-06-13 12:29:09,528:INFO:_display_container: 2
2023-06-13 12:29:09,528:INFO:KNeighborsRegressor(n_jobs=-1)
2023-06-13 12:29:09,528:INFO:create_model() successfully completed......................................
2023-06-13 12:29:09,715:INFO:SubProcess create_model() end ==================================
2023-06-13 12:29:09,715:INFO:Creating metrics dataframe
2023-06-13 12:29:09,727:INFO:Initializing Decision Tree Regressor
2023-06-13 12:29:09,727:INFO:Total runtime is 0.2663000384966532 minutes
2023-06-13 12:29:09,734:INFO:SubProcess create_model() called ==================================
2023-06-13 12:29:09,735:INFO:Initializing create_model()
2023-06-13 12:29:09,735:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D3C79450>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D3CAA020>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 12:29:09,735:INFO:Checking exceptions
2023-06-13 12:29:09,735:INFO:Importing libraries
2023-06-13 12:29:09,735:INFO:Copying training dataset
2023-06-13 12:29:09,743:INFO:Defining folds
2023-06-13 12:29:09,743:INFO:Declaring metric variables
2023-06-13 12:29:09,749:INFO:Importing untrained model
2023-06-13 12:29:09,753:INFO:Decision Tree Regressor Imported successfully
2023-06-13 12:29:09,764:INFO:Starting cross validation
2023-06-13 12:29:09,768:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 12:29:10,233:INFO:Calculating mean and std
2023-06-13 12:29:10,234:INFO:Creating metrics dataframe
2023-06-13 12:29:10,390:INFO:Uploading results into container
2023-06-13 12:29:10,391:INFO:Uploading model into container now
2023-06-13 12:29:10,392:INFO:_master_model_container: 12
2023-06-13 12:29:10,392:INFO:_display_container: 2
2023-06-13 12:29:10,393:INFO:DecisionTreeRegressor(random_state=42)
2023-06-13 12:29:10,393:INFO:create_model() successfully completed......................................
2023-06-13 12:29:10,603:INFO:SubProcess create_model() end ==================================
2023-06-13 12:29:10,604:INFO:Creating metrics dataframe
2023-06-13 12:29:10,619:INFO:Initializing Random Forest Regressor
2023-06-13 12:29:10,619:INFO:Total runtime is 0.2811593135197957 minutes
2023-06-13 12:29:10,628:INFO:SubProcess create_model() called ==================================
2023-06-13 12:29:10,628:INFO:Initializing create_model()
2023-06-13 12:29:10,629:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D3C79450>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D3CAA020>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 12:29:10,629:INFO:Checking exceptions
2023-06-13 12:29:10,630:INFO:Importing libraries
2023-06-13 12:29:10,630:INFO:Copying training dataset
2023-06-13 12:29:10,650:INFO:Defining folds
2023-06-13 12:29:10,651:INFO:Declaring metric variables
2023-06-13 12:29:10,662:INFO:Importing untrained model
2023-06-13 12:29:10,670:INFO:Random Forest Regressor Imported successfully
2023-06-13 12:29:10,686:INFO:Starting cross validation
2023-06-13 12:29:10,689:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 12:29:15,494:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 12:29:15,552:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 12:29:15,998:INFO:Calculating mean and std
2023-06-13 12:29:15,999:INFO:Creating metrics dataframe
2023-06-13 12:29:16,128:INFO:Uploading results into container
2023-06-13 12:29:16,129:INFO:Uploading model into container now
2023-06-13 12:29:16,130:INFO:_master_model_container: 13
2023-06-13 12:29:16,130:INFO:_display_container: 2
2023-06-13 12:29:16,131:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-13 12:29:16,131:INFO:create_model() successfully completed......................................
2023-06-13 12:29:16,324:INFO:SubProcess create_model() end ==================================
2023-06-13 12:29:16,324:INFO:Creating metrics dataframe
2023-06-13 12:29:16,340:INFO:Initializing Extra Trees Regressor
2023-06-13 12:29:16,340:INFO:Total runtime is 0.3765075723330179 minutes
2023-06-13 12:29:16,352:INFO:SubProcess create_model() called ==================================
2023-06-13 12:29:16,353:INFO:Initializing create_model()
2023-06-13 12:29:16,354:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D3C79450>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D3CAA020>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 12:29:16,354:INFO:Checking exceptions
2023-06-13 12:29:16,354:INFO:Importing libraries
2023-06-13 12:29:16,355:INFO:Copying training dataset
2023-06-13 12:29:16,369:INFO:Defining folds
2023-06-13 12:29:16,370:INFO:Declaring metric variables
2023-06-13 12:29:16,381:INFO:Importing untrained model
2023-06-13 12:29:16,390:INFO:Extra Trees Regressor Imported successfully
2023-06-13 12:29:16,401:INFO:Starting cross validation
2023-06-13 12:29:16,403:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 12:29:18,221:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 12:29:18,250:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 12:29:18,252:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 12:29:18,591:INFO:Calculating mean and std
2023-06-13 12:29:18,593:INFO:Creating metrics dataframe
2023-06-13 12:29:18,755:INFO:Uploading results into container
2023-06-13 12:29:18,756:INFO:Uploading model into container now
2023-06-13 12:29:18,757:INFO:_master_model_container: 14
2023-06-13 12:29:18,757:INFO:_display_container: 2
2023-06-13 12:29:18,758:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2023-06-13 12:29:18,758:INFO:create_model() successfully completed......................................
2023-06-13 12:29:18,919:INFO:SubProcess create_model() end ==================================
2023-06-13 12:29:18,919:INFO:Creating metrics dataframe
2023-06-13 12:29:18,937:INFO:Initializing AdaBoost Regressor
2023-06-13 12:29:18,937:INFO:Total runtime is 0.4197961926460265 minutes
2023-06-13 12:29:18,942:INFO:SubProcess create_model() called ==================================
2023-06-13 12:29:18,942:INFO:Initializing create_model()
2023-06-13 12:29:18,942:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D3C79450>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D3CAA020>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 12:29:18,943:INFO:Checking exceptions
2023-06-13 12:29:18,943:INFO:Importing libraries
2023-06-13 12:29:18,943:INFO:Copying training dataset
2023-06-13 12:29:18,954:INFO:Defining folds
2023-06-13 12:29:18,955:INFO:Declaring metric variables
2023-06-13 12:29:18,964:INFO:Importing untrained model
2023-06-13 12:29:18,971:INFO:AdaBoost Regressor Imported successfully
2023-06-13 12:29:18,983:INFO:Starting cross validation
2023-06-13 12:29:18,984:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 12:29:19,701:INFO:Calculating mean and std
2023-06-13 12:29:19,703:INFO:Creating metrics dataframe
2023-06-13 12:29:19,857:INFO:Uploading results into container
2023-06-13 12:29:19,858:INFO:Uploading model into container now
2023-06-13 12:29:19,859:INFO:_master_model_container: 15
2023-06-13 12:29:19,859:INFO:_display_container: 2
2023-06-13 12:29:19,859:INFO:AdaBoostRegressor(random_state=42)
2023-06-13 12:29:19,859:INFO:create_model() successfully completed......................................
2023-06-13 12:29:20,023:INFO:SubProcess create_model() end ==================================
2023-06-13 12:29:20,023:INFO:Creating metrics dataframe
2023-06-13 12:29:20,036:INFO:Initializing Gradient Boosting Regressor
2023-06-13 12:29:20,037:INFO:Total runtime is 0.4381310065587361 minutes
2023-06-13 12:29:20,041:INFO:SubProcess create_model() called ==================================
2023-06-13 12:29:20,041:INFO:Initializing create_model()
2023-06-13 12:29:20,041:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D3C79450>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D3CAA020>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 12:29:20,041:INFO:Checking exceptions
2023-06-13 12:29:20,041:INFO:Importing libraries
2023-06-13 12:29:20,041:INFO:Copying training dataset
2023-06-13 12:29:20,051:INFO:Defining folds
2023-06-13 12:29:20,051:INFO:Declaring metric variables
2023-06-13 12:29:20,057:INFO:Importing untrained model
2023-06-13 12:29:20,064:INFO:Gradient Boosting Regressor Imported successfully
2023-06-13 12:29:20,075:INFO:Starting cross validation
2023-06-13 12:29:20,076:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 12:29:22,517:INFO:Calculating mean and std
2023-06-13 12:29:22,519:INFO:Creating metrics dataframe
2023-06-13 12:29:22,713:INFO:Uploading results into container
2023-06-13 12:29:22,714:INFO:Uploading model into container now
2023-06-13 12:29:22,715:INFO:_master_model_container: 16
2023-06-13 12:29:22,716:INFO:_display_container: 2
2023-06-13 12:29:22,716:INFO:GradientBoostingRegressor(random_state=42)
2023-06-13 12:29:22,716:INFO:create_model() successfully completed......................................
2023-06-13 12:29:22,910:INFO:SubProcess create_model() end ==================================
2023-06-13 12:29:22,910:INFO:Creating metrics dataframe
2023-06-13 12:29:22,926:INFO:Initializing Extreme Gradient Boosting
2023-06-13 12:29:22,926:INFO:Total runtime is 0.48627148866653436 minutes
2023-06-13 12:29:22,933:INFO:SubProcess create_model() called ==================================
2023-06-13 12:29:22,933:INFO:Initializing create_model()
2023-06-13 12:29:22,933:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D3C79450>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D3CAA020>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 12:29:22,933:INFO:Checking exceptions
2023-06-13 12:29:22,934:INFO:Importing libraries
2023-06-13 12:29:22,934:INFO:Copying training dataset
2023-06-13 12:29:22,947:INFO:Defining folds
2023-06-13 12:29:22,948:INFO:Declaring metric variables
2023-06-13 12:29:22,957:INFO:Importing untrained model
2023-06-13 12:29:22,965:INFO:Extreme Gradient Boosting Imported successfully
2023-06-13 12:29:22,980:INFO:Starting cross validation
2023-06-13 12:29:22,982:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 12:29:24,662:INFO:Calculating mean and std
2023-06-13 12:29:24,663:INFO:Creating metrics dataframe
2023-06-13 12:29:24,833:INFO:Uploading results into container
2023-06-13 12:29:24,834:INFO:Uploading model into container now
2023-06-13 12:29:24,834:INFO:_master_model_container: 17
2023-06-13 12:29:24,834:INFO:_display_container: 2
2023-06-13 12:29:24,836:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=42, ...)
2023-06-13 12:29:24,837:INFO:create_model() successfully completed......................................
2023-06-13 12:29:25,050:INFO:SubProcess create_model() end ==================================
2023-06-13 12:29:25,051:INFO:Creating metrics dataframe
2023-06-13 12:29:25,082:INFO:Initializing Light Gradient Boosting Machine
2023-06-13 12:29:25,082:INFO:Total runtime is 0.5222117185592651 minutes
2023-06-13 12:29:25,087:INFO:SubProcess create_model() called ==================================
2023-06-13 12:29:25,087:INFO:Initializing create_model()
2023-06-13 12:29:25,087:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D3C79450>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D3CAA020>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 12:29:25,087:INFO:Checking exceptions
2023-06-13 12:29:25,088:INFO:Importing libraries
2023-06-13 12:29:25,088:INFO:Copying training dataset
2023-06-13 12:29:25,102:INFO:Defining folds
2023-06-13 12:29:25,103:INFO:Declaring metric variables
2023-06-13 12:29:25,110:INFO:Importing untrained model
2023-06-13 12:29:25,116:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-13 12:29:25,127:INFO:Starting cross validation
2023-06-13 12:29:25,130:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 12:29:26,957:INFO:Calculating mean and std
2023-06-13 12:29:26,958:INFO:Creating metrics dataframe
2023-06-13 12:29:27,141:INFO:Uploading results into container
2023-06-13 12:29:27,142:INFO:Uploading model into container now
2023-06-13 12:29:27,143:INFO:_master_model_container: 18
2023-06-13 12:29:27,144:INFO:_display_container: 2
2023-06-13 12:29:27,144:INFO:LGBMRegressor(random_state=42)
2023-06-13 12:29:27,144:INFO:create_model() successfully completed......................................
2023-06-13 12:29:27,344:INFO:SubProcess create_model() end ==================================
2023-06-13 12:29:27,344:INFO:Creating metrics dataframe
2023-06-13 12:29:27,376:INFO:Initializing Dummy Regressor
2023-06-13 12:29:27,376:INFO:Total runtime is 0.5604384899139404 minutes
2023-06-13 12:29:27,380:INFO:SubProcess create_model() called ==================================
2023-06-13 12:29:27,381:INFO:Initializing create_model()
2023-06-13 12:29:27,381:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D3C79450>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D3CAA020>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 12:29:27,381:INFO:Checking exceptions
2023-06-13 12:29:27,381:INFO:Importing libraries
2023-06-13 12:29:27,381:INFO:Copying training dataset
2023-06-13 12:29:27,396:INFO:Defining folds
2023-06-13 12:29:27,396:INFO:Declaring metric variables
2023-06-13 12:29:27,403:INFO:Importing untrained model
2023-06-13 12:29:27,409:INFO:Dummy Regressor Imported successfully
2023-06-13 12:29:27,417:INFO:Starting cross validation
2023-06-13 12:29:27,418:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 12:29:27,829:INFO:Calculating mean and std
2023-06-13 12:29:27,831:INFO:Creating metrics dataframe
2023-06-13 12:29:27,989:INFO:Uploading results into container
2023-06-13 12:29:27,990:INFO:Uploading model into container now
2023-06-13 12:29:27,990:INFO:_master_model_container: 19
2023-06-13 12:29:27,990:INFO:_display_container: 2
2023-06-13 12:29:27,991:INFO:DummyRegressor()
2023-06-13 12:29:27,991:INFO:create_model() successfully completed......................................
2023-06-13 12:29:28,227:INFO:SubProcess create_model() end ==================================
2023-06-13 12:29:28,228:INFO:Creating metrics dataframe
2023-06-13 12:29:28,262:INFO:Initializing create_model()
2023-06-13 12:29:28,263:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D3C79450>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-13 12:29:28,263:INFO:Checking exceptions
2023-06-13 12:29:28,266:INFO:Importing libraries
2023-06-13 12:29:28,267:INFO:Copying training dataset
2023-06-13 12:29:28,272:INFO:Defining folds
2023-06-13 12:29:28,272:INFO:Declaring metric variables
2023-06-13 12:29:28,273:INFO:Importing untrained model
2023-06-13 12:29:28,273:INFO:Declaring custom model
2023-06-13 12:29:28,274:INFO:Random Forest Regressor Imported successfully
2023-06-13 12:29:28,274:INFO:Cross validation set to False
2023-06-13 12:29:28,275:INFO:Fitting Model
2023-06-13 12:29:29,888:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-13 12:29:29,889:INFO:create_model() successfully completed......................................
2023-06-13 12:29:30,081:INFO:_master_model_container: 19
2023-06-13 12:29:30,081:INFO:_display_container: 2
2023-06-13 12:29:30,083:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-13 12:29:30,083:INFO:compare_models() successfully completed......................................
2023-06-13 12:32:45,167:INFO:PyCaret RegressionExperiment
2023-06-13 12:32:45,167:INFO:Logging name: reg-default-name
2023-06-13 12:32:45,167:INFO:ML Usecase: MLUsecase.REGRESSION
2023-06-13 12:32:45,167:INFO:version 3.0.2
2023-06-13 12:32:45,167:INFO:Initializing setup()
2023-06-13 12:32:45,167:INFO:self.USI: 108d
2023-06-13 12:32:45,167:INFO:self._variable_keys: {'fold_groups_param', 'data', 'y', 'transform_target_param', 'fold_shuffle_param', 'gpu_n_jobs_param', 'X_test', 'exp_id', 'logging_param', 'y_train', 'target_param', '_available_plots', 'html_param', 'X_train', 'USI', 'pipeline', 'y_test', 'fold_generator', 'exp_name_log', 'X', 'log_plots_param', 'gpu_param', 'memory', 'idx', '_ml_usecase', 'n_jobs_param', 'seed'}
2023-06-13 12:32:45,168:INFO:Checking environment
2023-06-13 12:32:45,168:INFO:python_version: 3.10.9
2023-06-13 12:32:45,168:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-06-13 12:32:45,168:INFO:machine: AMD64
2023-06-13 12:32:45,168:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-13 12:32:45,168:INFO:Memory: svmem(total=16901767168, available=4566044672, percent=73.0, used=12335722496, free=4566044672)
2023-06-13 12:32:45,168:INFO:Physical Core: 4
2023-06-13 12:32:45,168:INFO:Logical Core: 8
2023-06-13 12:32:45,169:INFO:Checking libraries
2023-06-13 12:32:45,169:INFO:System:
2023-06-13 12:32:45,169:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-06-13 12:32:45,169:INFO:executable: C:\Users\lapei\anaconda3\python.exe
2023-06-13 12:32:45,169:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-13 12:32:45,170:INFO:PyCaret required dependencies:
2023-06-13 12:32:45,170:INFO:                 pip: 22.3.1
2023-06-13 12:32:45,170:INFO:          setuptools: 65.6.3
2023-06-13 12:32:45,170:INFO:             pycaret: 3.0.2
2023-06-13 12:32:45,171:INFO:             IPython: 8.10.0
2023-06-13 12:32:45,171:INFO:          ipywidgets: 7.6.5
2023-06-13 12:32:45,171:INFO:                tqdm: 4.64.1
2023-06-13 12:32:45,171:INFO:               numpy: 1.23.5
2023-06-13 12:32:45,171:INFO:              pandas: 1.5.3
2023-06-13 12:32:45,171:INFO:              jinja2: 3.1.2
2023-06-13 12:32:45,172:INFO:               scipy: 1.10.0
2023-06-13 12:32:45,172:INFO:              joblib: 1.2.0
2023-06-13 12:32:45,172:INFO:             sklearn: 1.2.1
2023-06-13 12:32:45,172:INFO:                pyod: 1.0.9
2023-06-13 12:32:45,172:INFO:            imblearn: 0.10.1
2023-06-13 12:32:45,172:INFO:   category_encoders: 2.6.1
2023-06-13 12:32:45,172:INFO:            lightgbm: 3.3.5
2023-06-13 12:32:45,172:INFO:               numba: 0.56.4
2023-06-13 12:32:45,172:INFO:            requests: 2.28.1
2023-06-13 12:32:45,173:INFO:          matplotlib: 3.7.0
2023-06-13 12:32:45,173:INFO:          scikitplot: 0.3.7
2023-06-13 12:32:45,173:INFO:         yellowbrick: 1.5
2023-06-13 12:32:45,173:INFO:              plotly: 5.9.0
2023-06-13 12:32:45,173:INFO:             kaleido: 0.2.1
2023-06-13 12:32:45,173:INFO:         statsmodels: 0.13.5
2023-06-13 12:32:45,173:INFO:              sktime: 0.17.0
2023-06-13 12:32:45,173:INFO:               tbats: 1.1.3
2023-06-13 12:32:45,173:INFO:            pmdarima: 2.0.3
2023-06-13 12:32:45,173:INFO:              psutil: 5.9.0
2023-06-13 12:32:45,173:INFO:PyCaret optional dependencies:
2023-06-13 12:32:45,174:INFO:                shap: 0.41.0
2023-06-13 12:32:45,174:INFO:           interpret: Not installed
2023-06-13 12:32:45,174:INFO:                umap: Not installed
2023-06-13 12:32:45,174:INFO:    pandas_profiling: Not installed
2023-06-13 12:32:45,174:INFO:  explainerdashboard: Not installed
2023-06-13 12:32:45,174:INFO:             autoviz: Not installed
2023-06-13 12:32:45,174:INFO:           fairlearn: Not installed
2023-06-13 12:32:45,174:INFO:             xgboost: 1.7.3
2023-06-13 12:32:45,174:INFO:            catboost: Not installed
2023-06-13 12:32:45,174:INFO:              kmodes: Not installed
2023-06-13 12:32:45,174:INFO:             mlxtend: Not installed
2023-06-13 12:32:45,175:INFO:       statsforecast: Not installed
2023-06-13 12:32:45,175:INFO:        tune_sklearn: Not installed
2023-06-13 12:32:45,175:INFO:                 ray: Not installed
2023-06-13 12:32:45,175:INFO:            hyperopt: Not installed
2023-06-13 12:32:45,175:INFO:              optuna: Not installed
2023-06-13 12:32:45,175:INFO:               skopt: 0.9.0
2023-06-13 12:32:45,175:INFO:              mlflow: Not installed
2023-06-13 12:32:45,175:INFO:              gradio: Not installed
2023-06-13 12:32:45,175:INFO:             fastapi: Not installed
2023-06-13 12:32:45,175:INFO:             uvicorn: Not installed
2023-06-13 12:32:45,175:INFO:              m2cgen: Not installed
2023-06-13 12:32:45,175:INFO:           evidently: Not installed
2023-06-13 12:32:45,175:INFO:               fugue: Not installed
2023-06-13 12:32:45,175:INFO:           streamlit: Not installed
2023-06-13 12:32:45,175:INFO:             prophet: Not installed
2023-06-13 12:32:45,175:INFO:None
2023-06-13 12:32:45,175:INFO:Set up data.
2023-06-13 12:32:45,199:INFO:Set up train/test split.
2023-06-13 12:32:45,209:INFO:Set up index.
2023-06-13 12:32:45,209:INFO:Set up folding strategy.
2023-06-13 12:32:45,209:INFO:Assigning column types.
2023-06-13 12:32:45,215:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-13 12:32:45,215:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-13 12:32:45,226:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-13 12:32:45,237:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-13 12:32:45,313:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 12:32:45,356:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 12:32:45,357:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 12:32:45,360:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 12:32:45,361:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-13 12:32:45,370:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-13 12:32:45,379:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-13 12:32:45,454:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 12:32:45,497:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 12:32:45,497:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 12:32:45,500:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 12:32:45,500:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-06-13 12:32:45,505:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-13 12:32:45,509:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-13 12:32:45,567:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 12:32:45,610:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 12:32:45,611:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 12:32:45,613:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 12:32:45,618:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-13 12:32:45,623:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-13 12:32:45,687:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 12:32:45,730:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 12:32:45,731:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 12:32:45,734:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 12:32:45,734:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-06-13 12:32:45,743:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-13 12:32:45,802:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 12:32:45,846:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 12:32:45,846:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 12:32:45,849:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 12:32:45,858:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-13 12:32:45,915:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 12:32:45,958:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 12:32:45,959:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 12:32:45,961:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 12:32:45,962:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-06-13 12:32:46,045:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 12:32:46,090:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 12:32:46,091:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 12:32:46,094:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 12:32:46,185:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 12:32:46,230:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 12:32:46,235:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 12:32:46,238:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 12:32:46,238:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-13 12:32:46,310:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 12:32:46,356:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 12:32:46,358:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 12:32:46,426:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-13 12:32:46,486:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 12:32:46,489:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 12:32:46,489:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-06-13 12:32:46,599:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 12:32:46,602:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 12:32:46,717:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 12:32:46,720:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 12:32:46,721:INFO:Preparing preprocessing pipeline...
2023-06-13 12:32:46,721:INFO:Set up simple imputation.
2023-06-13 12:32:46,723:INFO:Set up column name cleaning.
2023-06-13 12:32:46,752:INFO:Finished creating preprocessing pipeline.
2023-06-13 12:32:46,761:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\lapei\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['taxa_homicidio', 'RH_adm_dir',
                                             'densidade_banda_larga',
                                             'densidade_telefonia_movel',
                                             'qtd_cursos_engenharias',
                                             'qtd_cursos_negocios_direito',
                                             'media_notas_CN', 'media_notas_CH',
                                             'media_NU_NOTA_LC',
                                             'media_NU_NOTA_MT',
                                             'media_...
                                             'Isencao_ISSQN_Sim',
                                             'Isencao_Tx_Sim',
                                             'Cessao_terrenos_Sim',
                                             'Doacao_terrenos_Sim',
                                             'Outros_mecanismos_Sim',
                                             'ISH_Baixa', 'ISH_Máxima',
                                             'ISH_Média', 'ISH_Mínima'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-06-13 12:32:46,761:INFO:Creating final display dataframe.
2023-06-13 12:32:46,857:INFO:Setup _display_container:                     Description                              Value
0                    Session id                                 42
1                        Target  qtd_abertas_Empresario_Individual
2                   Target type                         Regression
3           Original data shape                         (4456, 30)
4        Transformed data shape                         (4456, 30)
5   Transformed train set shape                         (3119, 30)
6    Transformed test set shape                         (1337, 30)
7              Numeric features                                 29
8                    Preprocess                               True
9               Imputation type                             simple
10           Numeric imputation                               mean
11       Categorical imputation                               mode
12               Fold Generator                              KFold
13                  Fold Number                                 10
14                     CPU Jobs                                 -1
15                      Use GPU                              False
16               Log Experiment                              False
17              Experiment Name                   reg-default-name
18                          USI                               108d
2023-06-13 12:32:46,999:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 12:32:47,003:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 12:32:47,155:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-13 12:32:47,159:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 12:32:47,161:INFO:setup() successfully completed in 2.09s...............
2023-06-13 12:32:48,047:INFO:Initializing compare_models()
2023-06-13 12:32:48,048:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D76CBA30>, include=None, fold=5, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001E3D76CBA30>, 'include': None, 'exclude': None, 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-06-13 12:32:48,048:INFO:Checking exceptions
2023-06-13 12:32:48,053:INFO:Preparing display monitor
2023-06-13 12:32:48,095:INFO:Initializing Linear Regression
2023-06-13 12:32:48,095:INFO:Total runtime is 0.0 minutes
2023-06-13 12:32:48,104:INFO:SubProcess create_model() called ==================================
2023-06-13 12:32:48,104:INFO:Initializing create_model()
2023-06-13 12:32:48,105:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D76CBA30>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D53A2F80>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 12:32:48,105:INFO:Checking exceptions
2023-06-13 12:32:48,105:INFO:Importing libraries
2023-06-13 12:32:48,105:INFO:Copying training dataset
2023-06-13 12:32:48,111:INFO:Defining folds
2023-06-13 12:32:48,111:INFO:Declaring metric variables
2023-06-13 12:32:48,116:INFO:Importing untrained model
2023-06-13 12:32:48,122:INFO:Linear Regression Imported successfully
2023-06-13 12:32:48,136:INFO:Starting cross validation
2023-06-13 12:32:48,137:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 12:32:48,619:INFO:Calculating mean and std
2023-06-13 12:32:48,619:INFO:Creating metrics dataframe
2023-06-13 12:32:48,811:INFO:Uploading results into container
2023-06-13 12:32:48,811:INFO:Uploading model into container now
2023-06-13 12:32:48,812:INFO:_master_model_container: 1
2023-06-13 12:32:48,812:INFO:_display_container: 2
2023-06-13 12:32:48,812:INFO:LinearRegression(n_jobs=-1)
2023-06-13 12:32:48,812:INFO:create_model() successfully completed......................................
2023-06-13 12:32:48,995:INFO:SubProcess create_model() end ==================================
2023-06-13 12:32:48,995:INFO:Creating metrics dataframe
2023-06-13 12:32:49,017:INFO:Initializing Lasso Regression
2023-06-13 12:32:49,017:INFO:Total runtime is 0.015369017918904623 minutes
2023-06-13 12:32:49,022:INFO:SubProcess create_model() called ==================================
2023-06-13 12:32:49,023:INFO:Initializing create_model()
2023-06-13 12:32:49,023:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D76CBA30>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D53A2F80>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 12:32:49,024:INFO:Checking exceptions
2023-06-13 12:32:49,024:INFO:Importing libraries
2023-06-13 12:32:49,025:INFO:Copying training dataset
2023-06-13 12:32:49,038:INFO:Defining folds
2023-06-13 12:32:49,039:INFO:Declaring metric variables
2023-06-13 12:32:49,045:INFO:Importing untrained model
2023-06-13 12:32:49,053:INFO:Lasso Regression Imported successfully
2023-06-13 12:32:49,065:INFO:Starting cross validation
2023-06-13 12:32:49,067:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 12:32:49,500:INFO:Calculating mean and std
2023-06-13 12:32:49,501:INFO:Creating metrics dataframe
2023-06-13 12:32:49,691:INFO:Uploading results into container
2023-06-13 12:32:49,692:INFO:Uploading model into container now
2023-06-13 12:32:49,692:INFO:_master_model_container: 2
2023-06-13 12:32:49,692:INFO:_display_container: 2
2023-06-13 12:32:49,693:INFO:Lasso(random_state=42)
2023-06-13 12:32:49,693:INFO:create_model() successfully completed......................................
2023-06-13 12:32:49,867:INFO:SubProcess create_model() end ==================================
2023-06-13 12:32:49,867:INFO:Creating metrics dataframe
2023-06-13 12:32:49,880:INFO:Initializing Ridge Regression
2023-06-13 12:32:49,881:INFO:Total runtime is 0.029763305187225343 minutes
2023-06-13 12:32:49,890:INFO:SubProcess create_model() called ==================================
2023-06-13 12:32:49,891:INFO:Initializing create_model()
2023-06-13 12:32:49,891:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D76CBA30>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D53A2F80>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 12:32:49,892:INFO:Checking exceptions
2023-06-13 12:32:49,892:INFO:Importing libraries
2023-06-13 12:32:49,892:INFO:Copying training dataset
2023-06-13 12:32:49,903:INFO:Defining folds
2023-06-13 12:32:49,904:INFO:Declaring metric variables
2023-06-13 12:32:49,910:INFO:Importing untrained model
2023-06-13 12:32:49,916:INFO:Ridge Regression Imported successfully
2023-06-13 12:32:49,925:INFO:Starting cross validation
2023-06-13 12:32:49,926:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 12:32:50,320:INFO:Calculating mean and std
2023-06-13 12:32:50,321:INFO:Creating metrics dataframe
2023-06-13 12:32:50,497:INFO:Uploading results into container
2023-06-13 12:32:50,499:INFO:Uploading model into container now
2023-06-13 12:32:50,501:INFO:_master_model_container: 3
2023-06-13 12:32:50,501:INFO:_display_container: 2
2023-06-13 12:32:50,501:INFO:Ridge(random_state=42)
2023-06-13 12:32:50,502:INFO:create_model() successfully completed......................................
2023-06-13 12:32:50,675:INFO:SubProcess create_model() end ==================================
2023-06-13 12:32:50,676:INFO:Creating metrics dataframe
2023-06-13 12:32:50,689:INFO:Initializing Elastic Net
2023-06-13 12:32:50,689:INFO:Total runtime is 0.0432220180829366 minutes
2023-06-13 12:32:50,692:INFO:SubProcess create_model() called ==================================
2023-06-13 12:32:50,692:INFO:Initializing create_model()
2023-06-13 12:32:50,692:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D76CBA30>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D53A2F80>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 12:32:50,692:INFO:Checking exceptions
2023-06-13 12:32:50,692:INFO:Importing libraries
2023-06-13 12:32:50,693:INFO:Copying training dataset
2023-06-13 12:32:50,701:INFO:Defining folds
2023-06-13 12:32:50,702:INFO:Declaring metric variables
2023-06-13 12:32:50,708:INFO:Importing untrained model
2023-06-13 12:32:50,713:INFO:Elastic Net Imported successfully
2023-06-13 12:32:50,725:INFO:Starting cross validation
2023-06-13 12:32:50,728:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 12:32:51,121:INFO:Calculating mean and std
2023-06-13 12:32:51,122:INFO:Creating metrics dataframe
2023-06-13 12:32:51,323:INFO:Uploading results into container
2023-06-13 12:32:51,324:INFO:Uploading model into container now
2023-06-13 12:32:51,325:INFO:_master_model_container: 4
2023-06-13 12:32:51,325:INFO:_display_container: 2
2023-06-13 12:32:51,325:INFO:ElasticNet(random_state=42)
2023-06-13 12:32:51,325:INFO:create_model() successfully completed......................................
2023-06-13 12:32:51,476:INFO:SubProcess create_model() end ==================================
2023-06-13 12:32:51,477:INFO:Creating metrics dataframe
2023-06-13 12:32:51,490:INFO:Initializing Least Angle Regression
2023-06-13 12:32:51,491:INFO:Total runtime is 0.05660031636555989 minutes
2023-06-13 12:32:51,499:INFO:SubProcess create_model() called ==================================
2023-06-13 12:32:51,500:INFO:Initializing create_model()
2023-06-13 12:32:51,500:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D76CBA30>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D53A2F80>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 12:32:51,501:INFO:Checking exceptions
2023-06-13 12:32:51,501:INFO:Importing libraries
2023-06-13 12:32:51,501:INFO:Copying training dataset
2023-06-13 12:32:51,515:INFO:Defining folds
2023-06-13 12:32:51,515:INFO:Declaring metric variables
2023-06-13 12:32:51,525:INFO:Importing untrained model
2023-06-13 12:32:51,531:INFO:Least Angle Regression Imported successfully
2023-06-13 12:32:51,544:INFO:Starting cross validation
2023-06-13 12:32:51,546:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 12:32:52,008:INFO:Calculating mean and std
2023-06-13 12:32:52,009:INFO:Creating metrics dataframe
2023-06-13 12:32:52,112:INFO:Uploading results into container
2023-06-13 12:32:52,113:INFO:Uploading model into container now
2023-06-13 12:32:52,114:INFO:_master_model_container: 5
2023-06-13 12:32:52,115:INFO:_display_container: 2
2023-06-13 12:32:52,116:INFO:Lars(random_state=42)
2023-06-13 12:32:52,116:INFO:create_model() successfully completed......................................
2023-06-13 12:32:52,280:INFO:SubProcess create_model() end ==================================
2023-06-13 12:32:52,281:INFO:Creating metrics dataframe
2023-06-13 12:32:52,304:INFO:Initializing Lasso Least Angle Regression
2023-06-13 12:32:52,304:INFO:Total runtime is 0.07014726797739665 minutes
2023-06-13 12:32:52,311:INFO:SubProcess create_model() called ==================================
2023-06-13 12:32:52,312:INFO:Initializing create_model()
2023-06-13 12:32:52,312:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D76CBA30>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D53A2F80>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 12:32:52,312:INFO:Checking exceptions
2023-06-13 12:32:52,312:INFO:Importing libraries
2023-06-13 12:32:52,313:INFO:Copying training dataset
2023-06-13 12:32:52,325:INFO:Defining folds
2023-06-13 12:32:52,326:INFO:Declaring metric variables
2023-06-13 12:32:52,336:INFO:Importing untrained model
2023-06-13 12:32:52,343:INFO:Lasso Least Angle Regression Imported successfully
2023-06-13 12:32:52,352:INFO:Starting cross validation
2023-06-13 12:32:52,354:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 12:32:52,737:INFO:Calculating mean and std
2023-06-13 12:32:52,739:INFO:Creating metrics dataframe
2023-06-13 12:32:52,925:INFO:Uploading results into container
2023-06-13 12:32:52,926:INFO:Uploading model into container now
2023-06-13 12:32:52,926:INFO:_master_model_container: 6
2023-06-13 12:32:52,927:INFO:_display_container: 2
2023-06-13 12:32:52,927:INFO:LassoLars(random_state=42)
2023-06-13 12:32:52,927:INFO:create_model() successfully completed......................................
2023-06-13 12:32:53,079:INFO:SubProcess create_model() end ==================================
2023-06-13 12:32:53,080:INFO:Creating metrics dataframe
2023-06-13 12:32:53,105:INFO:Initializing Orthogonal Matching Pursuit
2023-06-13 12:32:53,106:INFO:Total runtime is 0.08350645701090495 minutes
2023-06-13 12:32:53,114:INFO:SubProcess create_model() called ==================================
2023-06-13 12:32:53,114:INFO:Initializing create_model()
2023-06-13 12:32:53,114:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D76CBA30>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D53A2F80>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 12:32:53,116:INFO:Checking exceptions
2023-06-13 12:32:53,116:INFO:Importing libraries
2023-06-13 12:32:53,116:INFO:Copying training dataset
2023-06-13 12:32:53,129:INFO:Defining folds
2023-06-13 12:32:53,129:INFO:Declaring metric variables
2023-06-13 12:32:53,134:INFO:Importing untrained model
2023-06-13 12:32:53,140:INFO:Orthogonal Matching Pursuit Imported successfully
2023-06-13 12:32:53,153:INFO:Starting cross validation
2023-06-13 12:32:53,155:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 12:32:53,540:INFO:Calculating mean and std
2023-06-13 12:32:53,543:INFO:Creating metrics dataframe
2023-06-13 12:32:53,690:INFO:Uploading results into container
2023-06-13 12:32:53,691:INFO:Uploading model into container now
2023-06-13 12:32:53,692:INFO:_master_model_container: 7
2023-06-13 12:32:53,692:INFO:_display_container: 2
2023-06-13 12:32:53,693:INFO:OrthogonalMatchingPursuit()
2023-06-13 12:32:53,693:INFO:create_model() successfully completed......................................
2023-06-13 12:32:53,848:INFO:SubProcess create_model() end ==================================
2023-06-13 12:32:53,849:INFO:Creating metrics dataframe
2023-06-13 12:32:53,862:INFO:Initializing Bayesian Ridge
2023-06-13 12:32:53,863:INFO:Total runtime is 0.09612472454706827 minutes
2023-06-13 12:32:53,874:INFO:SubProcess create_model() called ==================================
2023-06-13 12:32:53,876:INFO:Initializing create_model()
2023-06-13 12:32:53,876:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D76CBA30>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D53A2F80>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 12:32:53,876:INFO:Checking exceptions
2023-06-13 12:32:53,876:INFO:Importing libraries
2023-06-13 12:32:53,876:INFO:Copying training dataset
2023-06-13 12:32:53,885:INFO:Defining folds
2023-06-13 12:32:53,885:INFO:Declaring metric variables
2023-06-13 12:32:53,889:INFO:Importing untrained model
2023-06-13 12:32:53,895:INFO:Bayesian Ridge Imported successfully
2023-06-13 12:32:53,903:INFO:Starting cross validation
2023-06-13 12:32:53,904:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 12:32:54,289:INFO:Calculating mean and std
2023-06-13 12:32:54,290:INFO:Creating metrics dataframe
2023-06-13 12:32:54,443:INFO:Uploading results into container
2023-06-13 12:32:54,443:INFO:Uploading model into container now
2023-06-13 12:32:54,444:INFO:_master_model_container: 8
2023-06-13 12:32:54,444:INFO:_display_container: 2
2023-06-13 12:32:54,445:INFO:BayesianRidge()
2023-06-13 12:32:54,445:INFO:create_model() successfully completed......................................
2023-06-13 12:32:54,603:INFO:SubProcess create_model() end ==================================
2023-06-13 12:32:54,604:INFO:Creating metrics dataframe
2023-06-13 12:32:54,616:INFO:Initializing Passive Aggressive Regressor
2023-06-13 12:32:54,616:INFO:Total runtime is 0.10868018468221029 minutes
2023-06-13 12:32:54,621:INFO:SubProcess create_model() called ==================================
2023-06-13 12:32:54,622:INFO:Initializing create_model()
2023-06-13 12:32:54,622:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D76CBA30>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D53A2F80>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 12:32:54,623:INFO:Checking exceptions
2023-06-13 12:32:54,623:INFO:Importing libraries
2023-06-13 12:32:54,623:INFO:Copying training dataset
2023-06-13 12:32:54,630:INFO:Defining folds
2023-06-13 12:32:54,630:INFO:Declaring metric variables
2023-06-13 12:32:54,635:INFO:Importing untrained model
2023-06-13 12:32:54,640:INFO:Passive Aggressive Regressor Imported successfully
2023-06-13 12:32:54,649:INFO:Starting cross validation
2023-06-13 12:32:54,651:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 12:32:55,040:INFO:Calculating mean and std
2023-06-13 12:32:55,042:INFO:Creating metrics dataframe
2023-06-13 12:32:55,189:INFO:Uploading results into container
2023-06-13 12:32:55,190:INFO:Uploading model into container now
2023-06-13 12:32:55,191:INFO:_master_model_container: 9
2023-06-13 12:32:55,191:INFO:_display_container: 2
2023-06-13 12:32:55,192:INFO:PassiveAggressiveRegressor(random_state=42)
2023-06-13 12:32:55,192:INFO:create_model() successfully completed......................................
2023-06-13 12:32:55,339:INFO:SubProcess create_model() end ==================================
2023-06-13 12:32:55,339:INFO:Creating metrics dataframe
2023-06-13 12:32:55,351:INFO:Initializing Huber Regressor
2023-06-13 12:32:55,351:INFO:Total runtime is 0.12092356681823731 minutes
2023-06-13 12:32:55,357:INFO:SubProcess create_model() called ==================================
2023-06-13 12:32:55,358:INFO:Initializing create_model()
2023-06-13 12:32:55,358:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D76CBA30>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D53A2F80>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 12:32:55,358:INFO:Checking exceptions
2023-06-13 12:32:55,358:INFO:Importing libraries
2023-06-13 12:32:55,358:INFO:Copying training dataset
2023-06-13 12:32:55,367:INFO:Defining folds
2023-06-13 12:32:55,369:INFO:Declaring metric variables
2023-06-13 12:32:55,374:INFO:Importing untrained model
2023-06-13 12:32:55,387:INFO:Huber Regressor Imported successfully
2023-06-13 12:32:55,398:INFO:Starting cross validation
2023-06-13 12:32:55,399:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 12:32:55,538:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-13 12:32:55,540:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-13 12:32:55,565:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-13 12:32:55,570:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-13 12:32:55,575:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-13 12:32:55,912:INFO:Calculating mean and std
2023-06-13 12:32:55,913:INFO:Creating metrics dataframe
2023-06-13 12:32:56,125:INFO:Uploading results into container
2023-06-13 12:32:56,125:INFO:Uploading model into container now
2023-06-13 12:32:56,126:INFO:_master_model_container: 10
2023-06-13 12:32:56,126:INFO:_display_container: 2
2023-06-13 12:32:56,126:INFO:HuberRegressor()
2023-06-13 12:32:56,126:INFO:create_model() successfully completed......................................
2023-06-13 12:32:56,276:INFO:SubProcess create_model() end ==================================
2023-06-13 12:32:56,276:INFO:Creating metrics dataframe
2023-06-13 12:32:56,292:INFO:Initializing K Neighbors Regressor
2023-06-13 12:32:56,292:INFO:Total runtime is 0.13662037054697673 minutes
2023-06-13 12:32:56,301:INFO:SubProcess create_model() called ==================================
2023-06-13 12:32:56,301:INFO:Initializing create_model()
2023-06-13 12:32:56,301:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D76CBA30>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D53A2F80>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 12:32:56,302:INFO:Checking exceptions
2023-06-13 12:32:56,302:INFO:Importing libraries
2023-06-13 12:32:56,302:INFO:Copying training dataset
2023-06-13 12:32:56,313:INFO:Defining folds
2023-06-13 12:32:56,313:INFO:Declaring metric variables
2023-06-13 12:32:56,318:INFO:Importing untrained model
2023-06-13 12:32:56,324:INFO:K Neighbors Regressor Imported successfully
2023-06-13 12:32:56,335:INFO:Starting cross validation
2023-06-13 12:32:56,336:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 12:32:56,765:INFO:Calculating mean and std
2023-06-13 12:32:56,766:INFO:Creating metrics dataframe
2023-06-13 12:32:56,985:INFO:Uploading results into container
2023-06-13 12:32:56,986:INFO:Uploading model into container now
2023-06-13 12:32:56,987:INFO:_master_model_container: 11
2023-06-13 12:32:56,987:INFO:_display_container: 2
2023-06-13 12:32:56,988:INFO:KNeighborsRegressor(n_jobs=-1)
2023-06-13 12:32:56,988:INFO:create_model() successfully completed......................................
2023-06-13 12:32:57,225:INFO:SubProcess create_model() end ==================================
2023-06-13 12:32:57,225:INFO:Creating metrics dataframe
2023-06-13 12:32:57,248:INFO:Initializing Decision Tree Regressor
2023-06-13 12:32:57,249:INFO:Total runtime is 0.15255812406539918 minutes
2023-06-13 12:32:57,259:INFO:SubProcess create_model() called ==================================
2023-06-13 12:32:57,260:INFO:Initializing create_model()
2023-06-13 12:32:57,260:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D76CBA30>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D53A2F80>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 12:32:57,260:INFO:Checking exceptions
2023-06-13 12:32:57,261:INFO:Importing libraries
2023-06-13 12:32:57,261:INFO:Copying training dataset
2023-06-13 12:32:57,275:INFO:Defining folds
2023-06-13 12:32:57,276:INFO:Declaring metric variables
2023-06-13 12:32:57,285:INFO:Importing untrained model
2023-06-13 12:32:57,290:INFO:Decision Tree Regressor Imported successfully
2023-06-13 12:32:57,302:INFO:Starting cross validation
2023-06-13 12:32:57,303:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 12:32:57,741:INFO:Calculating mean and std
2023-06-13 12:32:57,742:INFO:Creating metrics dataframe
2023-06-13 12:32:57,960:INFO:Uploading results into container
2023-06-13 12:32:57,962:INFO:Uploading model into container now
2023-06-13 12:32:57,963:INFO:_master_model_container: 12
2023-06-13 12:32:57,963:INFO:_display_container: 2
2023-06-13 12:32:57,964:INFO:DecisionTreeRegressor(random_state=42)
2023-06-13 12:32:57,965:INFO:create_model() successfully completed......................................
2023-06-13 12:32:58,148:INFO:SubProcess create_model() end ==================================
2023-06-13 12:32:58,148:INFO:Creating metrics dataframe
2023-06-13 12:32:58,164:INFO:Initializing Random Forest Regressor
2023-06-13 12:32:58,164:INFO:Total runtime is 0.16780765056610109 minutes
2023-06-13 12:32:58,168:INFO:SubProcess create_model() called ==================================
2023-06-13 12:32:58,168:INFO:Initializing create_model()
2023-06-13 12:32:58,169:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D76CBA30>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D53A2F80>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 12:32:58,169:INFO:Checking exceptions
2023-06-13 12:32:58,169:INFO:Importing libraries
2023-06-13 12:32:58,170:INFO:Copying training dataset
2023-06-13 12:32:58,185:INFO:Defining folds
2023-06-13 12:32:58,186:INFO:Declaring metric variables
2023-06-13 12:32:58,192:INFO:Importing untrained model
2023-06-13 12:32:58,199:INFO:Random Forest Regressor Imported successfully
2023-06-13 12:32:58,210:INFO:Starting cross validation
2023-06-13 12:32:58,212:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 12:32:58,742:INFO:Calculating mean and std
2023-06-13 12:32:58,743:INFO:Creating metrics dataframe
2023-06-13 12:32:58,999:INFO:Uploading results into container
2023-06-13 12:32:59,000:INFO:Uploading model into container now
2023-06-13 12:32:59,001:INFO:_master_model_container: 13
2023-06-13 12:32:59,001:INFO:_display_container: 2
2023-06-13 12:32:59,002:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-13 12:32:59,002:INFO:create_model() successfully completed......................................
2023-06-13 12:32:59,172:INFO:SubProcess create_model() end ==================================
2023-06-13 12:32:59,172:INFO:Creating metrics dataframe
2023-06-13 12:32:59,189:INFO:Initializing Extra Trees Regressor
2023-06-13 12:32:59,189:INFO:Total runtime is 0.18489392598470053 minutes
2023-06-13 12:32:59,195:INFO:SubProcess create_model() called ==================================
2023-06-13 12:32:59,195:INFO:Initializing create_model()
2023-06-13 12:32:59,195:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D76CBA30>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D53A2F80>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 12:32:59,195:INFO:Checking exceptions
2023-06-13 12:32:59,195:INFO:Importing libraries
2023-06-13 12:32:59,196:INFO:Copying training dataset
2023-06-13 12:32:59,201:INFO:Defining folds
2023-06-13 12:32:59,201:INFO:Declaring metric variables
2023-06-13 12:32:59,207:INFO:Importing untrained model
2023-06-13 12:32:59,213:INFO:Extra Trees Regressor Imported successfully
2023-06-13 12:32:59,228:INFO:Starting cross validation
2023-06-13 12:32:59,228:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 12:32:59,797:INFO:Calculating mean and std
2023-06-13 12:32:59,798:INFO:Creating metrics dataframe
2023-06-13 12:33:00,001:INFO:Uploading results into container
2023-06-13 12:33:00,002:INFO:Uploading model into container now
2023-06-13 12:33:00,003:INFO:_master_model_container: 14
2023-06-13 12:33:00,003:INFO:_display_container: 2
2023-06-13 12:33:00,005:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2023-06-13 12:33:00,005:INFO:create_model() successfully completed......................................
2023-06-13 12:33:00,221:INFO:SubProcess create_model() end ==================================
2023-06-13 12:33:00,222:INFO:Creating metrics dataframe
2023-06-13 12:33:00,250:INFO:Initializing AdaBoost Regressor
2023-06-13 12:33:00,251:INFO:Total runtime is 0.20258893569310507 minutes
2023-06-13 12:33:00,257:INFO:SubProcess create_model() called ==================================
2023-06-13 12:33:00,258:INFO:Initializing create_model()
2023-06-13 12:33:00,258:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D76CBA30>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D53A2F80>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 12:33:00,258:INFO:Checking exceptions
2023-06-13 12:33:00,258:INFO:Importing libraries
2023-06-13 12:33:00,258:INFO:Copying training dataset
2023-06-13 12:33:00,270:INFO:Defining folds
2023-06-13 12:33:00,270:INFO:Declaring metric variables
2023-06-13 12:33:00,276:INFO:Importing untrained model
2023-06-13 12:33:00,280:INFO:AdaBoost Regressor Imported successfully
2023-06-13 12:33:00,288:INFO:Starting cross validation
2023-06-13 12:33:00,290:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 12:33:00,739:INFO:Calculating mean and std
2023-06-13 12:33:00,740:INFO:Creating metrics dataframe
2023-06-13 12:33:00,925:INFO:Uploading results into container
2023-06-13 12:33:00,926:INFO:Uploading model into container now
2023-06-13 12:33:00,926:INFO:_master_model_container: 15
2023-06-13 12:33:00,927:INFO:_display_container: 2
2023-06-13 12:33:00,927:INFO:AdaBoostRegressor(random_state=42)
2023-06-13 12:33:00,927:INFO:create_model() successfully completed......................................
2023-06-13 12:33:01,119:INFO:SubProcess create_model() end ==================================
2023-06-13 12:33:01,119:INFO:Creating metrics dataframe
2023-06-13 12:33:01,153:INFO:Initializing Gradient Boosting Regressor
2023-06-13 12:33:01,154:INFO:Total runtime is 0.21763571898142497 minutes
2023-06-13 12:33:01,161:INFO:SubProcess create_model() called ==================================
2023-06-13 12:33:01,161:INFO:Initializing create_model()
2023-06-13 12:33:01,161:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D76CBA30>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D53A2F80>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 12:33:01,161:INFO:Checking exceptions
2023-06-13 12:33:01,161:INFO:Importing libraries
2023-06-13 12:33:01,161:INFO:Copying training dataset
2023-06-13 12:33:01,176:INFO:Defining folds
2023-06-13 12:33:01,177:INFO:Declaring metric variables
2023-06-13 12:33:01,182:INFO:Importing untrained model
2023-06-13 12:33:01,186:INFO:Gradient Boosting Regressor Imported successfully
2023-06-13 12:33:01,196:INFO:Starting cross validation
2023-06-13 12:33:01,197:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 12:33:01,699:INFO:Calculating mean and std
2023-06-13 12:33:01,702:INFO:Creating metrics dataframe
2023-06-13 12:33:01,896:INFO:Uploading results into container
2023-06-13 12:33:01,897:INFO:Uploading model into container now
2023-06-13 12:33:01,898:INFO:_master_model_container: 16
2023-06-13 12:33:01,899:INFO:_display_container: 2
2023-06-13 12:33:01,900:INFO:GradientBoostingRegressor(random_state=42)
2023-06-13 12:33:01,900:INFO:create_model() successfully completed......................................
2023-06-13 12:33:02,052:INFO:SubProcess create_model() end ==================================
2023-06-13 12:33:02,052:INFO:Creating metrics dataframe
2023-06-13 12:33:02,066:INFO:Initializing Extreme Gradient Boosting
2023-06-13 12:33:02,067:INFO:Total runtime is 0.2328652580579122 minutes
2023-06-13 12:33:02,072:INFO:SubProcess create_model() called ==================================
2023-06-13 12:33:02,072:INFO:Initializing create_model()
2023-06-13 12:33:02,073:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D76CBA30>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D53A2F80>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 12:33:02,073:INFO:Checking exceptions
2023-06-13 12:33:02,073:INFO:Importing libraries
2023-06-13 12:33:02,073:INFO:Copying training dataset
2023-06-13 12:33:02,088:INFO:Defining folds
2023-06-13 12:33:02,088:INFO:Declaring metric variables
2023-06-13 12:33:02,093:INFO:Importing untrained model
2023-06-13 12:33:02,100:INFO:Extreme Gradient Boosting Imported successfully
2023-06-13 12:33:02,107:INFO:Starting cross validation
2023-06-13 12:33:02,108:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 12:33:02,494:INFO:Calculating mean and std
2023-06-13 12:33:02,495:INFO:Creating metrics dataframe
2023-06-13 12:33:02,668:INFO:Uploading results into container
2023-06-13 12:33:02,669:INFO:Uploading model into container now
2023-06-13 12:33:02,670:INFO:_master_model_container: 17
2023-06-13 12:33:02,670:INFO:_display_container: 2
2023-06-13 12:33:02,671:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=42, ...)
2023-06-13 12:33:02,671:INFO:create_model() successfully completed......................................
2023-06-13 12:33:02,839:INFO:SubProcess create_model() end ==================================
2023-06-13 12:33:02,839:INFO:Creating metrics dataframe
2023-06-13 12:33:02,855:INFO:Initializing Light Gradient Boosting Machine
2023-06-13 12:33:02,856:INFO:Total runtime is 0.24600528478622438 minutes
2023-06-13 12:33:02,860:INFO:SubProcess create_model() called ==================================
2023-06-13 12:33:02,861:INFO:Initializing create_model()
2023-06-13 12:33:02,861:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D76CBA30>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D53A2F80>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 12:33:02,861:INFO:Checking exceptions
2023-06-13 12:33:02,861:INFO:Importing libraries
2023-06-13 12:33:02,861:INFO:Copying training dataset
2023-06-13 12:33:02,875:INFO:Defining folds
2023-06-13 12:33:02,875:INFO:Declaring metric variables
2023-06-13 12:33:02,879:INFO:Importing untrained model
2023-06-13 12:33:02,886:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-13 12:33:02,895:INFO:Starting cross validation
2023-06-13 12:33:02,896:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 12:33:04,715:INFO:Calculating mean and std
2023-06-13 12:33:04,716:INFO:Creating metrics dataframe
2023-06-13 12:33:04,905:INFO:Uploading results into container
2023-06-13 12:33:04,907:INFO:Uploading model into container now
2023-06-13 12:33:04,908:INFO:_master_model_container: 18
2023-06-13 12:33:04,908:INFO:_display_container: 2
2023-06-13 12:33:04,909:INFO:LGBMRegressor(random_state=42)
2023-06-13 12:33:04,910:INFO:create_model() successfully completed......................................
2023-06-13 12:33:05,060:INFO:SubProcess create_model() end ==================================
2023-06-13 12:33:05,060:INFO:Creating metrics dataframe
2023-06-13 12:33:05,074:INFO:Initializing Dummy Regressor
2023-06-13 12:33:05,074:INFO:Total runtime is 0.28297877709070846 minutes
2023-06-13 12:33:05,079:INFO:SubProcess create_model() called ==================================
2023-06-13 12:33:05,080:INFO:Initializing create_model()
2023-06-13 12:33:05,080:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D76CBA30>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D53A2F80>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 12:33:05,080:INFO:Checking exceptions
2023-06-13 12:33:05,080:INFO:Importing libraries
2023-06-13 12:33:05,080:INFO:Copying training dataset
2023-06-13 12:33:05,095:INFO:Defining folds
2023-06-13 12:33:05,095:INFO:Declaring metric variables
2023-06-13 12:33:05,101:INFO:Importing untrained model
2023-06-13 12:33:05,106:INFO:Dummy Regressor Imported successfully
2023-06-13 12:33:05,117:INFO:Starting cross validation
2023-06-13 12:33:05,119:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 12:33:05,523:INFO:Calculating mean and std
2023-06-13 12:33:05,524:INFO:Creating metrics dataframe
2023-06-13 12:33:05,733:INFO:Uploading results into container
2023-06-13 12:33:05,734:INFO:Uploading model into container now
2023-06-13 12:33:05,735:INFO:_master_model_container: 19
2023-06-13 12:33:05,736:INFO:_display_container: 2
2023-06-13 12:33:05,736:INFO:DummyRegressor()
2023-06-13 12:33:05,737:INFO:create_model() successfully completed......................................
2023-06-13 12:33:05,929:INFO:SubProcess create_model() end ==================================
2023-06-13 12:33:05,929:INFO:Creating metrics dataframe
2023-06-13 12:33:05,969:INFO:Initializing create_model()
2023-06-13 12:33:05,969:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D76CBA30>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-13 12:33:05,969:INFO:Checking exceptions
2023-06-13 12:33:05,972:INFO:Importing libraries
2023-06-13 12:33:05,972:INFO:Copying training dataset
2023-06-13 12:33:05,982:INFO:Defining folds
2023-06-13 12:33:05,982:INFO:Declaring metric variables
2023-06-13 12:33:05,982:INFO:Importing untrained model
2023-06-13 12:33:05,982:INFO:Declaring custom model
2023-06-13 12:33:05,983:INFO:Random Forest Regressor Imported successfully
2023-06-13 12:33:05,983:INFO:Cross validation set to False
2023-06-13 12:33:05,984:INFO:Fitting Model
2023-06-13 12:33:06,161:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-13 12:33:06,161:INFO:create_model() successfully completed......................................
2023-06-13 12:33:06,398:INFO:_master_model_container: 19
2023-06-13 12:33:06,398:INFO:_display_container: 2
2023-06-13 12:33:06,399:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-13 12:33:06,399:INFO:compare_models() successfully completed......................................
2023-06-13 12:41:19,021:INFO:Initializing create_model()
2023-06-13 12:41:19,021:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D76CBA30>, estimator=rf, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-13 12:41:19,022:INFO:Checking exceptions
2023-06-13 12:41:19,058:INFO:Importing libraries
2023-06-13 12:41:19,059:INFO:Copying training dataset
2023-06-13 12:41:19,082:INFO:Defining folds
2023-06-13 12:41:19,083:INFO:Declaring metric variables
2023-06-13 12:41:19,093:INFO:Importing untrained model
2023-06-13 12:41:19,100:INFO:Random Forest Regressor Imported successfully
2023-06-13 12:41:19,115:INFO:Starting cross validation
2023-06-13 12:41:19,116:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 12:41:24,069:INFO:Calculating mean and std
2023-06-13 12:41:24,070:INFO:Creating metrics dataframe
2023-06-13 12:41:24,077:INFO:Finalizing model
2023-06-13 12:41:24,391:INFO:Uploading results into container
2023-06-13 12:41:24,393:INFO:Uploading model into container now
2023-06-13 12:41:24,409:INFO:_master_model_container: 20
2023-06-13 12:41:24,409:INFO:_display_container: 3
2023-06-13 12:41:24,410:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-13 12:41:24,410:INFO:create_model() successfully completed......................................
2023-06-13 12:45:12,538:INFO:Initializing tune_model()
2023-06-13 12:45:12,539:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=5, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D76CBA30>)
2023-06-13 12:45:12,539:INFO:Checking exceptions
2023-06-13 12:45:12,572:INFO:Copying training dataset
2023-06-13 12:45:12,580:INFO:Checking base model
2023-06-13 12:45:12,580:INFO:Base model : Random Forest Regressor
2023-06-13 12:45:12,588:INFO:Declaring metric variables
2023-06-13 12:45:12,593:INFO:Defining Hyperparameters
2023-06-13 12:45:12,780:INFO:Tuning with n_jobs=-1
2023-06-13 12:45:12,780:INFO:Initializing RandomizedSearchCV
2023-06-13 12:45:13,834:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 12:45:14,018:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 12:45:14,070:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 12:45:21,465:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 12:45:23,180:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 12:45:26,022:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 12:45:26,801:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 12:45:27,249:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 12:45:30,301:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 12:45:32,362:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 12:45:32,465:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-13 12:45:34,272:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 12:45:35,098:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-13 12:45:40,420:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-13 12:45:43,980:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-13 12:45:45,431:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 12:45:46,111:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 12:45:47,094:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-13 12:45:48,648:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-13 12:45:50,751:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 12:45:50,889:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 12:45:50,937:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 12:45:51,415:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 12:45:52,770:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-13 12:45:53,503:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 12:45:54,745:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 12:45:55,201:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-13 12:45:56,101:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 12:45:57,573:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.31s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-13 12:45:57,738:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 12:45:57,852:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 12:45:58,366:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 12:45:59,586:INFO:best_params: {'actual_estimator__n_estimators': 190, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 4, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': True}
2023-06-13 12:45:59,588:INFO:Hyperparameter search completed
2023-06-13 12:45:59,588:INFO:SubProcess create_model() called ==================================
2023-06-13 12:45:59,589:INFO:Initializing create_model()
2023-06-13 12:45:59,589:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D76CBA30>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3D3E6D0C0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 190, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.3, 'max_features': 1.0, 'max_depth': 4, 'criterion': 'squared_error', 'bootstrap': True})
2023-06-13 12:45:59,589:INFO:Checking exceptions
2023-06-13 12:45:59,589:INFO:Importing libraries
2023-06-13 12:45:59,589:INFO:Copying training dataset
2023-06-13 12:45:59,599:INFO:Defining folds
2023-06-13 12:45:59,600:INFO:Declaring metric variables
2023-06-13 12:45:59,606:INFO:Importing untrained model
2023-06-13 12:45:59,608:INFO:Declaring custom model
2023-06-13 12:45:59,618:INFO:Random Forest Regressor Imported successfully
2023-06-13 12:45:59,632:INFO:Starting cross validation
2023-06-13 12:45:59,635:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 12:46:00,487:INFO:Calculating mean and std
2023-06-13 12:46:00,488:INFO:Creating metrics dataframe
2023-06-13 12:46:00,497:INFO:Finalizing model
2023-06-13 12:46:01,682:INFO:Uploading results into container
2023-06-13 12:46:01,684:INFO:Uploading model into container now
2023-06-13 12:46:01,685:INFO:_master_model_container: 21
2023-06-13 12:46:01,685:INFO:_display_container: 4
2023-06-13 12:46:01,686:INFO:RandomForestRegressor(max_depth=4, min_impurity_decrease=0.3,
                      min_samples_leaf=2, n_estimators=190, n_jobs=-1,
                      random_state=42)
2023-06-13 12:46:01,686:INFO:create_model() successfully completed......................................
2023-06-13 12:46:01,858:INFO:SubProcess create_model() end ==================================
2023-06-13 12:46:01,858:INFO:choose_better activated
2023-06-13 12:46:01,864:INFO:SubProcess create_model() called ==================================
2023-06-13 12:46:01,865:INFO:Initializing create_model()
2023-06-13 12:46:01,865:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D76CBA30>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-13 12:46:01,866:INFO:Checking exceptions
2023-06-13 12:46:01,869:INFO:Importing libraries
2023-06-13 12:46:01,869:INFO:Copying training dataset
2023-06-13 12:46:01,875:INFO:Defining folds
2023-06-13 12:46:01,875:INFO:Declaring metric variables
2023-06-13 12:46:01,875:INFO:Importing untrained model
2023-06-13 12:46:01,875:INFO:Declaring custom model
2023-06-13 12:46:01,876:INFO:Random Forest Regressor Imported successfully
2023-06-13 12:46:01,876:INFO:Starting cross validation
2023-06-13 12:46:01,876:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 12:46:02,665:INFO:Calculating mean and std
2023-06-13 12:46:02,665:INFO:Creating metrics dataframe
2023-06-13 12:46:02,669:INFO:Finalizing model
2023-06-13 12:46:03,019:INFO:Uploading results into container
2023-06-13 12:46:03,020:INFO:Uploading model into container now
2023-06-13 12:46:03,021:INFO:_master_model_container: 22
2023-06-13 12:46:03,021:INFO:_display_container: 5
2023-06-13 12:46:03,022:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-13 12:46:03,022:INFO:create_model() successfully completed......................................
2023-06-13 12:46:03,172:INFO:SubProcess create_model() end ==================================
2023-06-13 12:46:03,172:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) result for R2 is 0.9102
2023-06-13 12:46:03,173:INFO:RandomForestRegressor(max_depth=4, min_impurity_decrease=0.3,
                      min_samples_leaf=2, n_estimators=190, n_jobs=-1,
                      random_state=42) result for R2 is 0.8871
2023-06-13 12:46:03,174:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) is best model
2023-06-13 12:46:03,174:INFO:choose_better completed
2023-06-13 12:46:03,174:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-06-13 12:46:03,192:INFO:_master_model_container: 22
2023-06-13 12:46:03,192:INFO:_display_container: 4
2023-06-13 12:46:03,193:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-13 12:46:03,193:INFO:tune_model() successfully completed......................................
2023-06-13 12:52:09,643:INFO:Initializing predict_model()
2023-06-13 12:52:09,643:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D76CBA30>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E3D360D5A0>)
2023-06-13 12:52:09,643:INFO:Checking exceptions
2023-06-13 12:52:09,643:INFO:Preloading libraries
2023-06-13 12:53:12,282:INFO:Initializing predict_model()
2023-06-13 12:53:12,283:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D76CBA30>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E3D3C98040>)
2023-06-13 12:53:12,283:INFO:Checking exceptions
2023-06-13 12:53:12,283:INFO:Preloading libraries
2023-06-13 12:53:12,287:INFO:Set up data.
2023-06-13 12:53:12,304:INFO:Set up index.
2023-06-13 12:58:53,326:INFO:Initializing plot_model()
2023-06-13 12:58:53,327:INFO:plot_model(plot=learning, fold=None, use_train_data=True, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D76CBA30>, system=True)
2023-06-13 12:58:53,327:INFO:Checking exceptions
2023-06-13 12:58:53,371:INFO:Preloading libraries
2023-06-13 12:58:53,407:INFO:Copying training dataset
2023-06-13 12:58:53,408:INFO:Plot type: learning
2023-06-13 12:58:53,510:INFO:Fitting Model
2023-06-13 13:00:16,469:INFO:Visual Rendered Successfully
2023-06-13 13:00:16,688:INFO:plot_model() successfully completed......................................
2023-06-13 13:00:44,275:INFO:Initializing plot_model()
2023-06-13 13:00:44,277:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D76CBA30>, system=True)
2023-06-13 13:00:44,277:INFO:Checking exceptions
2023-06-13 13:00:44,319:INFO:Preloading libraries
2023-06-13 13:00:44,356:INFO:Copying training dataset
2023-06-13 13:00:44,356:INFO:Plot type: error
2023-06-13 13:00:44,464:INFO:Fitting Model
2023-06-13 13:00:44,464:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2023-06-13 13:00:44,464:INFO:Scoring test/hold-out set
2023-06-13 13:00:44,869:INFO:Visual Rendered Successfully
2023-06-13 13:00:45,054:INFO:plot_model() successfully completed......................................
2023-06-13 13:00:55,140:INFO:Initializing plot_model()
2023-06-13 13:00:55,140:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D76CBA30>, system=True)
2023-06-13 13:00:55,140:INFO:Checking exceptions
2023-06-13 13:00:55,181:INFO:Preloading libraries
2023-06-13 13:00:55,240:INFO:Copying training dataset
2023-06-13 13:00:55,241:INFO:Plot type: feature
2023-06-13 13:00:55,241:WARNING:No coef_ found. Trying feature_importances_
2023-06-13 13:00:55,489:INFO:Visual Rendered Successfully
2023-06-13 13:00:55,727:INFO:plot_model() successfully completed......................................
2023-06-13 13:01:11,269:INFO:Initializing interpret_model()
2023-06-13 13:01:11,269:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D76CBA30>)
2023-06-13 13:01:11,269:INFO:Checking exceptions
2023-06-13 13:01:11,270:INFO:Soft dependency imported: shap: 0.41.0
2023-06-13 13:01:11,311:INFO:plot type: summary
2023-06-13 13:01:11,311:INFO:Creating TreeExplainer
2023-06-13 13:01:11,348:INFO:Compiling shap values
2023-06-13 13:03:18,126:WARNING:No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored

2023-06-13 13:03:18,956:INFO:Visual Rendered Successfully
2023-06-13 13:03:18,956:INFO:interpret_model() successfully completed......................................
2023-06-13 13:04:24,431:INFO:Initializing plot_model()
2023-06-13 13:04:24,431:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D76CBA30>, system=True)
2023-06-13 13:04:24,431:INFO:Checking exceptions
2023-06-13 13:04:24,472:INFO:Preloading libraries
2023-06-13 13:04:24,519:INFO:Copying training dataset
2023-06-13 13:04:24,520:INFO:Plot type: residuals
2023-06-13 13:04:24,720:INFO:Fitting Model
2023-06-13 13:04:24,721:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2023-06-13 13:04:24,864:INFO:Scoring test/hold-out set
2023-06-13 13:04:25,474:INFO:Visual Rendered Successfully
2023-06-13 13:04:25,649:INFO:plot_model() successfully completed......................................
2023-06-13 13:05:04,640:INFO:Initializing plot_model()
2023-06-13 13:05:04,641:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D76CBA30>, system=True)
2023-06-13 13:05:04,641:INFO:Checking exceptions
2023-06-13 13:05:47,260:INFO:Initializing plot_model()
2023-06-13 13:05:47,260:INFO:plot_model(plot=class_report, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D76CBA30>, system=True)
2023-06-13 13:05:47,260:INFO:Checking exceptions
2023-06-13 13:07:05,535:INFO:Initializing interpret_model()
2023-06-13 13:07:05,535:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=correlation, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D76CBA30>)
2023-06-13 13:07:05,535:INFO:Checking exceptions
2023-06-13 13:07:05,535:INFO:Soft dependency imported: shap: 0.41.0
2023-06-13 13:07:05,583:INFO:plot type: correlation
2023-06-13 13:07:05,583:WARNING:No feature passed. Default value of feature used for correlation plot: taxa_homicidio
2023-06-13 13:07:05,583:INFO:Creating TreeExplainer
2023-06-13 13:07:05,618:INFO:Compiling shap values
2023-06-13 13:09:12,670:INFO:model type detected: type 2
2023-06-13 13:09:13,060:INFO:Visual Rendered Successfully
2023-06-13 13:09:13,061:INFO:interpret_model() successfully completed......................................
2023-06-13 13:11:14,664:INFO:Initializing interpret_model()
2023-06-13 13:11:14,665:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=pop_total, kwargs={}, observation=None, plot=correlation, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D76CBA30>)
2023-06-13 13:11:14,665:INFO:Checking exceptions
2023-06-13 13:11:14,665:INFO:Soft dependency imported: shap: 0.41.0
2023-06-13 13:11:14,709:INFO:plot type: correlation
2023-06-13 13:11:14,709:WARNING:feature value passed. Feature used for correlation plot: pop_total
2023-06-13 13:11:14,709:INFO:Creating TreeExplainer
2023-06-13 13:11:14,733:INFO:Compiling shap values
2023-06-13 13:13:15,493:INFO:model type detected: type 2
2023-06-13 13:13:15,782:INFO:Visual Rendered Successfully
2023-06-13 13:13:15,782:INFO:interpret_model() successfully completed......................................
2023-06-13 13:13:52,562:INFO:Initializing interpret_model()
2023-06-13 13:13:52,563:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=1, plot=reason, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D76CBA30>)
2023-06-13 13:13:52,563:INFO:Checking exceptions
2023-06-13 13:13:52,563:INFO:Soft dependency imported: shap: 0.41.0
2023-06-13 13:13:52,592:INFO:plot type: reason
2023-06-13 13:13:52,592:INFO:model type detected: type 2
2023-06-13 13:13:52,592:INFO:Creating TreeExplainer
2023-06-13 13:13:52,625:INFO:Compiling shap values
2023-06-13 13:15:56,097:INFO:Visual Rendered Successfully
2023-06-13 13:15:56,098:INFO:interpret_model() successfully completed......................................
2023-06-13 13:16:05,820:INFO:Initializing interpret_model()
2023-06-13 13:16:05,820:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=3, plot=reason, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E3D76CBA30>)
2023-06-13 13:16:05,821:INFO:Checking exceptions
2023-06-13 13:16:05,821:INFO:Soft dependency imported: shap: 0.41.0
2023-06-13 13:16:05,856:INFO:plot type: reason
2023-06-13 13:16:05,857:INFO:model type detected: type 2
2023-06-13 13:16:05,857:INFO:Creating TreeExplainer
2023-06-13 13:16:05,890:INFO:Compiling shap values
2023-06-13 13:18:08,031:INFO:Visual Rendered Successfully
2023-06-13 13:18:08,031:INFO:interpret_model() successfully completed......................................
2023-06-14 08:40:00,182:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 08:40:00,184:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 08:40:00,184:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 08:40:00,184:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 08:40:01,357:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-14 08:45:16,777:INFO:PyCaret RegressionExperiment
2023-06-14 08:45:16,777:INFO:Logging name: reg-default-name
2023-06-14 08:45:16,777:INFO:ML Usecase: MLUsecase.REGRESSION
2023-06-14 08:45:16,778:INFO:version 3.0.2
2023-06-14 08:45:16,778:INFO:Initializing setup()
2023-06-14 08:45:16,778:INFO:self.USI: 4465
2023-06-14 08:45:16,778:INFO:self._variable_keys: {'fold_groups_param', 'idx', 'logging_param', 'fold_shuffle_param', 'X_train', 'y_test', 'transform_target_param', 'exp_name_log', 'n_jobs_param', 'X', 'gpu_param', '_available_plots', 'seed', 'gpu_n_jobs_param', 'y', 'y_train', 'X_test', 'log_plots_param', 'html_param', 'target_param', '_ml_usecase', 'data', 'pipeline', 'memory', 'fold_generator', 'exp_id', 'USI'}
2023-06-14 08:45:16,778:INFO:Checking environment
2023-06-14 08:45:16,778:INFO:python_version: 3.10.9
2023-06-14 08:45:16,779:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-06-14 08:45:16,779:INFO:machine: AMD64
2023-06-14 08:45:16,779:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-14 08:45:16,779:INFO:Memory: svmem(total=16901767168, available=6985625600, percent=58.7, used=9916141568, free=6985625600)
2023-06-14 08:45:16,779:INFO:Physical Core: 4
2023-06-14 08:45:16,779:INFO:Logical Core: 8
2023-06-14 08:45:16,779:INFO:Checking libraries
2023-06-14 08:45:16,779:INFO:System:
2023-06-14 08:45:16,779:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-06-14 08:45:16,779:INFO:executable: C:\Users\lapei\anaconda3\python.exe
2023-06-14 08:45:16,779:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-14 08:45:16,780:INFO:PyCaret required dependencies:
2023-06-14 08:45:16,780:INFO:                 pip: 22.3.1
2023-06-14 08:45:16,780:INFO:          setuptools: 65.6.3
2023-06-14 08:45:16,780:INFO:             pycaret: 3.0.2
2023-06-14 08:45:16,780:INFO:             IPython: 8.10.0
2023-06-14 08:45:16,780:INFO:          ipywidgets: 7.6.5
2023-06-14 08:45:16,780:INFO:                tqdm: 4.64.1
2023-06-14 08:45:16,780:INFO:               numpy: 1.23.5
2023-06-14 08:45:16,780:INFO:              pandas: 1.5.3
2023-06-14 08:45:16,780:INFO:              jinja2: 3.1.2
2023-06-14 08:45:16,780:INFO:               scipy: 1.10.0
2023-06-14 08:45:16,780:INFO:              joblib: 1.2.0
2023-06-14 08:45:16,780:INFO:             sklearn: 1.2.1
2023-06-14 08:45:16,780:INFO:                pyod: 1.0.9
2023-06-14 08:45:16,780:INFO:            imblearn: 0.10.1
2023-06-14 08:45:16,780:INFO:   category_encoders: 2.6.1
2023-06-14 08:45:16,780:INFO:            lightgbm: 3.3.5
2023-06-14 08:45:16,780:INFO:               numba: 0.56.4
2023-06-14 08:45:16,780:INFO:            requests: 2.28.1
2023-06-14 08:45:16,780:INFO:          matplotlib: 3.7.0
2023-06-14 08:45:16,780:INFO:          scikitplot: 0.3.7
2023-06-14 08:45:16,780:INFO:         yellowbrick: 1.5
2023-06-14 08:45:16,780:INFO:              plotly: 5.9.0
2023-06-14 08:45:16,780:INFO:             kaleido: 0.2.1
2023-06-14 08:45:16,780:INFO:         statsmodels: 0.13.5
2023-06-14 08:45:16,780:INFO:              sktime: 0.17.0
2023-06-14 08:45:16,780:INFO:               tbats: 1.1.3
2023-06-14 08:45:16,780:INFO:            pmdarima: 2.0.3
2023-06-14 08:45:16,780:INFO:              psutil: 5.9.0
2023-06-14 08:45:16,780:INFO:PyCaret optional dependencies:
2023-06-14 08:45:16,952:INFO:                shap: 0.41.0
2023-06-14 08:45:16,952:INFO:           interpret: Not installed
2023-06-14 08:45:16,952:INFO:                umap: Not installed
2023-06-14 08:45:16,952:INFO:    pandas_profiling: Not installed
2023-06-14 08:45:16,952:INFO:  explainerdashboard: Not installed
2023-06-14 08:45:16,952:INFO:             autoviz: Not installed
2023-06-14 08:45:16,952:INFO:           fairlearn: Not installed
2023-06-14 08:45:16,952:INFO:             xgboost: 1.7.3
2023-06-14 08:45:16,952:INFO:            catboost: Not installed
2023-06-14 08:45:16,952:INFO:              kmodes: Not installed
2023-06-14 08:45:16,952:INFO:             mlxtend: Not installed
2023-06-14 08:45:16,952:INFO:       statsforecast: Not installed
2023-06-14 08:45:16,952:INFO:        tune_sklearn: Not installed
2023-06-14 08:45:16,952:INFO:                 ray: Not installed
2023-06-14 08:45:16,952:INFO:            hyperopt: Not installed
2023-06-14 08:45:16,952:INFO:              optuna: Not installed
2023-06-14 08:45:16,952:INFO:               skopt: 0.9.0
2023-06-14 08:45:16,952:INFO:              mlflow: Not installed
2023-06-14 08:45:16,952:INFO:              gradio: Not installed
2023-06-14 08:45:16,952:INFO:             fastapi: Not installed
2023-06-14 08:45:16,952:INFO:             uvicorn: Not installed
2023-06-14 08:45:16,952:INFO:              m2cgen: Not installed
2023-06-14 08:45:16,952:INFO:           evidently: Not installed
2023-06-14 08:45:16,952:INFO:               fugue: Not installed
2023-06-14 08:45:16,952:INFO:           streamlit: Not installed
2023-06-14 08:45:16,952:INFO:             prophet: Not installed
2023-06-14 08:45:16,952:INFO:None
2023-06-14 08:45:16,952:INFO:Set up data.
2023-06-14 08:45:16,978:INFO:Set up train/test split.
2023-06-14 08:45:16,994:INFO:Set up index.
2023-06-14 08:45:16,994:INFO:Set up folding strategy.
2023-06-14 08:45:16,994:INFO:Assigning column types.
2023-06-14 08:45:16,994:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-14 08:45:16,994:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-14 08:45:17,027:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 08:45:17,027:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 08:45:17,196:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 08:45:17,326:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 08:45:17,326:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 08:45:18,256:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 08:45:18,263:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-14 08:45:18,273:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 08:45:18,281:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 08:45:18,349:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 08:45:18,391:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 08:45:18,391:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 08:45:18,391:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 08:45:18,391:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-06-14 08:45:18,391:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 08:45:18,391:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 08:45:18,454:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 08:45:18,501:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 08:45:18,501:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 08:45:18,505:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 08:45:18,505:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 08:45:18,517:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 08:45:18,580:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 08:45:18,619:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 08:45:18,619:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 08:45:18,624:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 08:45:18,624:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-06-14 08:45:18,629:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 08:45:18,692:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 08:45:18,738:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 08:45:18,739:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 08:45:18,739:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 08:45:18,739:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 08:45:18,789:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 08:45:18,836:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 08:45:18,836:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 08:45:18,850:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 08:45:18,850:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-06-14 08:45:18,909:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 08:45:18,952:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 08:45:18,952:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 08:45:18,952:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 08:45:19,031:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 08:45:19,066:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 08:45:19,080:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 08:45:19,082:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 08:45:19,083:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-14 08:45:19,147:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 08:45:19,193:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 08:45:19,195:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 08:45:19,259:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 08:45:19,296:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 08:45:19,296:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 08:45:19,296:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-06-14 08:45:19,417:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 08:45:19,422:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 08:45:19,536:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 08:45:19,541:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 08:45:19,544:INFO:Preparing preprocessing pipeline...
2023-06-14 08:45:19,544:INFO:Set up simple imputation.
2023-06-14 08:45:19,546:INFO:Set up column name cleaning.
2023-06-14 08:45:19,582:INFO:Finished creating preprocessing pipeline.
2023-06-14 08:45:19,597:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\lapei\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['taxa_homicidio', 'RH_adm_dir',
                                             'densidade_banda_larga',
                                             'densidade_telefonia_movel',
                                             'qtd_cursos_engenharias',
                                             'qtd_cursos_negocios_direito',
                                             'media_notas_CN', 'media_notas_CH',
                                             'media_NU_NOTA_LC',
                                             'media_NU_NOTA_MT',
                                             'media_...
                                             'Isencao_ISSQN_Sim',
                                             'Isencao_Tx_Sim',
                                             'Cessao_terrenos_Sim',
                                             'Doacao_terrenos_Sim',
                                             'Outros_mecanismos_Sim',
                                             'ISH_Baixa', 'ISH_Máxima',
                                             'ISH_Média', 'ISH_Mínima'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-06-14 08:45:19,597:INFO:Creating final display dataframe.
2023-06-14 08:45:19,706:INFO:Setup _display_container:                     Description                              Value
0                    Session id                                 42
1                        Target  qtd_abertas_Empresario_Individual
2                   Target type                         Regression
3           Original data shape                         (4456, 30)
4        Transformed data shape                         (4456, 30)
5   Transformed train set shape                         (3119, 30)
6    Transformed test set shape                         (1337, 30)
7              Numeric features                                 29
8                    Preprocess                               True
9               Imputation type                             simple
10           Numeric imputation                               mean
11       Categorical imputation                               mode
12               Fold Generator                              KFold
13                  Fold Number                                 10
14                     CPU Jobs                                 -1
15                      Use GPU                              False
16               Log Experiment                              False
17              Experiment Name                   reg-default-name
18                          USI                               4465
2023-06-14 08:45:19,831:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 08:45:19,831:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 08:45:19,970:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 08:45:19,970:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 08:45:19,980:INFO:setup() successfully completed in 3.44s...............
2023-06-14 08:45:22,434:INFO:Initializing compare_models()
2023-06-14 08:45:22,434:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8C1582D10>, include=None, fold=5, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001F8C1582D10>, 'include': None, 'exclude': None, 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-06-14 08:45:22,435:INFO:Checking exceptions
2023-06-14 08:45:22,437:INFO:Preparing display monitor
2023-06-14 08:45:22,470:INFO:Initializing Linear Regression
2023-06-14 08:45:22,472:INFO:Total runtime is 3.6211808522542316e-05 minutes
2023-06-14 08:45:22,477:INFO:SubProcess create_model() called ==================================
2023-06-14 08:45:22,477:INFO:Initializing create_model()
2023-06-14 08:45:22,477:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8C1582D10>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8C2023C10>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 08:45:22,477:INFO:Checking exceptions
2023-06-14 08:45:22,477:INFO:Importing libraries
2023-06-14 08:45:22,477:INFO:Copying training dataset
2023-06-14 08:45:22,486:INFO:Defining folds
2023-06-14 08:45:22,486:INFO:Declaring metric variables
2023-06-14 08:45:22,487:INFO:Importing untrained model
2023-06-14 08:45:22,487:INFO:Linear Regression Imported successfully
2023-06-14 08:45:22,499:INFO:Starting cross validation
2023-06-14 08:45:22,518:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 08:45:28,682:INFO:Calculating mean and std
2023-06-14 08:45:28,684:INFO:Creating metrics dataframe
2023-06-14 08:45:28,816:INFO:Uploading results into container
2023-06-14 08:45:28,816:INFO:Uploading model into container now
2023-06-14 08:45:28,816:INFO:_master_model_container: 1
2023-06-14 08:45:28,816:INFO:_display_container: 2
2023-06-14 08:45:28,816:INFO:LinearRegression(n_jobs=-1)
2023-06-14 08:45:28,816:INFO:create_model() successfully completed......................................
2023-06-14 08:45:28,955:INFO:SubProcess create_model() end ==================================
2023-06-14 08:45:28,955:INFO:Creating metrics dataframe
2023-06-14 08:45:28,964:INFO:Initializing Lasso Regression
2023-06-14 08:45:28,964:INFO:Total runtime is 0.10823992093404135 minutes
2023-06-14 08:45:28,967:INFO:SubProcess create_model() called ==================================
2023-06-14 08:45:28,967:INFO:Initializing create_model()
2023-06-14 08:45:28,967:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8C1582D10>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8C2023C10>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 08:45:28,967:INFO:Checking exceptions
2023-06-14 08:45:28,967:INFO:Importing libraries
2023-06-14 08:45:28,967:INFO:Copying training dataset
2023-06-14 08:45:28,975:INFO:Defining folds
2023-06-14 08:45:28,975:INFO:Declaring metric variables
2023-06-14 08:45:28,975:INFO:Importing untrained model
2023-06-14 08:45:28,982:INFO:Lasso Regression Imported successfully
2023-06-14 08:45:28,991:INFO:Starting cross validation
2023-06-14 08:45:28,993:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 08:45:31,705:INFO:Calculating mean and std
2023-06-14 08:45:31,705:INFO:Creating metrics dataframe
2023-06-14 08:45:31,829:INFO:Uploading results into container
2023-06-14 08:45:31,830:INFO:Uploading model into container now
2023-06-14 08:45:31,830:INFO:_master_model_container: 2
2023-06-14 08:45:31,831:INFO:_display_container: 2
2023-06-14 08:45:31,831:INFO:Lasso(random_state=42)
2023-06-14 08:45:31,831:INFO:create_model() successfully completed......................................
2023-06-14 08:45:31,935:INFO:SubProcess create_model() end ==================================
2023-06-14 08:45:31,935:INFO:Creating metrics dataframe
2023-06-14 08:45:31,935:INFO:Initializing Ridge Regression
2023-06-14 08:45:31,935:INFO:Total runtime is 0.15776265064875286 minutes
2023-06-14 08:45:31,945:INFO:SubProcess create_model() called ==================================
2023-06-14 08:45:31,945:INFO:Initializing create_model()
2023-06-14 08:45:31,945:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8C1582D10>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8C2023C10>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 08:45:31,945:INFO:Checking exceptions
2023-06-14 08:45:31,945:INFO:Importing libraries
2023-06-14 08:45:31,945:INFO:Copying training dataset
2023-06-14 08:45:31,945:INFO:Defining folds
2023-06-14 08:45:31,945:INFO:Declaring metric variables
2023-06-14 08:45:31,957:INFO:Importing untrained model
2023-06-14 08:45:31,957:INFO:Ridge Regression Imported successfully
2023-06-14 08:45:31,966:INFO:Starting cross validation
2023-06-14 08:45:31,966:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 08:45:32,406:INFO:Calculating mean and std
2023-06-14 08:45:32,406:INFO:Creating metrics dataframe
2023-06-14 08:45:32,525:INFO:Uploading results into container
2023-06-14 08:45:32,525:INFO:Uploading model into container now
2023-06-14 08:45:32,525:INFO:_master_model_container: 3
2023-06-14 08:45:32,525:INFO:_display_container: 2
2023-06-14 08:45:32,525:INFO:Ridge(random_state=42)
2023-06-14 08:45:32,525:INFO:create_model() successfully completed......................................
2023-06-14 08:45:32,625:INFO:SubProcess create_model() end ==================================
2023-06-14 08:45:32,625:INFO:Creating metrics dataframe
2023-06-14 08:45:32,629:INFO:Initializing Elastic Net
2023-06-14 08:45:32,629:INFO:Total runtime is 0.16932078599929812 minutes
2023-06-14 08:45:32,635:INFO:SubProcess create_model() called ==================================
2023-06-14 08:45:32,635:INFO:Initializing create_model()
2023-06-14 08:45:32,635:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8C1582D10>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8C2023C10>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 08:45:32,635:INFO:Checking exceptions
2023-06-14 08:45:32,635:INFO:Importing libraries
2023-06-14 08:45:32,635:INFO:Copying training dataset
2023-06-14 08:45:32,645:INFO:Defining folds
2023-06-14 08:45:32,646:INFO:Declaring metric variables
2023-06-14 08:45:32,651:INFO:Importing untrained model
2023-06-14 08:45:32,656:INFO:Elastic Net Imported successfully
2023-06-14 08:45:32,661:INFO:Starting cross validation
2023-06-14 08:45:32,665:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 08:45:33,185:INFO:Calculating mean and std
2023-06-14 08:45:33,193:INFO:Creating metrics dataframe
2023-06-14 08:45:33,305:INFO:Uploading results into container
2023-06-14 08:45:33,307:INFO:Uploading model into container now
2023-06-14 08:45:33,307:INFO:_master_model_container: 4
2023-06-14 08:45:33,307:INFO:_display_container: 2
2023-06-14 08:45:33,308:INFO:ElasticNet(random_state=42)
2023-06-14 08:45:33,308:INFO:create_model() successfully completed......................................
2023-06-14 08:45:33,394:INFO:SubProcess create_model() end ==================================
2023-06-14 08:45:33,394:INFO:Creating metrics dataframe
2023-06-14 08:45:33,411:INFO:Initializing Least Angle Regression
2023-06-14 08:45:33,411:INFO:Total runtime is 0.1823608199755351 minutes
2023-06-14 08:45:33,414:INFO:SubProcess create_model() called ==================================
2023-06-14 08:45:33,414:INFO:Initializing create_model()
2023-06-14 08:45:33,414:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8C1582D10>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8C2023C10>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 08:45:33,414:INFO:Checking exceptions
2023-06-14 08:45:33,414:INFO:Importing libraries
2023-06-14 08:45:33,414:INFO:Copying training dataset
2023-06-14 08:45:33,422:INFO:Defining folds
2023-06-14 08:45:33,422:INFO:Declaring metric variables
2023-06-14 08:45:33,428:INFO:Importing untrained model
2023-06-14 08:45:33,435:INFO:Least Angle Regression Imported successfully
2023-06-14 08:45:33,442:INFO:Starting cross validation
2023-06-14 08:45:33,442:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 08:45:33,896:INFO:Calculating mean and std
2023-06-14 08:45:33,897:INFO:Creating metrics dataframe
2023-06-14 08:45:34,020:INFO:Uploading results into container
2023-06-14 08:45:34,021:INFO:Uploading model into container now
2023-06-14 08:45:34,021:INFO:_master_model_container: 5
2023-06-14 08:45:34,021:INFO:_display_container: 2
2023-06-14 08:45:34,021:INFO:Lars(random_state=42)
2023-06-14 08:45:34,021:INFO:create_model() successfully completed......................................
2023-06-14 08:45:34,116:INFO:SubProcess create_model() end ==================================
2023-06-14 08:45:34,116:INFO:Creating metrics dataframe
2023-06-14 08:45:34,132:INFO:Initializing Lasso Least Angle Regression
2023-06-14 08:45:34,132:INFO:Total runtime is 0.19437526861826582 minutes
2023-06-14 08:45:34,133:INFO:SubProcess create_model() called ==================================
2023-06-14 08:45:34,133:INFO:Initializing create_model()
2023-06-14 08:45:34,133:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8C1582D10>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8C2023C10>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 08:45:34,133:INFO:Checking exceptions
2023-06-14 08:45:34,133:INFO:Importing libraries
2023-06-14 08:45:34,133:INFO:Copying training dataset
2023-06-14 08:45:34,139:INFO:Defining folds
2023-06-14 08:45:34,139:INFO:Declaring metric variables
2023-06-14 08:45:34,139:INFO:Importing untrained model
2023-06-14 08:45:34,150:INFO:Lasso Least Angle Regression Imported successfully
2023-06-14 08:45:34,158:INFO:Starting cross validation
2023-06-14 08:45:34,158:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 08:45:34,627:INFO:Calculating mean and std
2023-06-14 08:45:34,627:INFO:Creating metrics dataframe
2023-06-14 08:45:34,774:INFO:Uploading results into container
2023-06-14 08:45:34,774:INFO:Uploading model into container now
2023-06-14 08:45:34,775:INFO:_master_model_container: 6
2023-06-14 08:45:34,775:INFO:_display_container: 2
2023-06-14 08:45:34,775:INFO:LassoLars(random_state=42)
2023-06-14 08:45:34,775:INFO:create_model() successfully completed......................................
2023-06-14 08:45:34,883:INFO:SubProcess create_model() end ==================================
2023-06-14 08:45:34,883:INFO:Creating metrics dataframe
2023-06-14 08:45:34,893:INFO:Initializing Orthogonal Matching Pursuit
2023-06-14 08:45:34,893:INFO:Total runtime is 0.20705632766087853 minutes
2023-06-14 08:45:34,897:INFO:SubProcess create_model() called ==================================
2023-06-14 08:45:34,897:INFO:Initializing create_model()
2023-06-14 08:45:34,897:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8C1582D10>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8C2023C10>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 08:45:34,899:INFO:Checking exceptions
2023-06-14 08:45:34,900:INFO:Importing libraries
2023-06-14 08:45:34,900:INFO:Copying training dataset
2023-06-14 08:45:34,905:INFO:Defining folds
2023-06-14 08:45:34,905:INFO:Declaring metric variables
2023-06-14 08:45:34,905:INFO:Importing untrained model
2023-06-14 08:45:34,905:INFO:Orthogonal Matching Pursuit Imported successfully
2023-06-14 08:45:34,917:INFO:Starting cross validation
2023-06-14 08:45:34,917:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 08:45:35,366:INFO:Calculating mean and std
2023-06-14 08:45:35,368:INFO:Creating metrics dataframe
2023-06-14 08:45:35,510:INFO:Uploading results into container
2023-06-14 08:45:35,510:INFO:Uploading model into container now
2023-06-14 08:45:35,510:INFO:_master_model_container: 7
2023-06-14 08:45:35,510:INFO:_display_container: 2
2023-06-14 08:45:35,512:INFO:OrthogonalMatchingPursuit()
2023-06-14 08:45:35,512:INFO:create_model() successfully completed......................................
2023-06-14 08:45:35,595:INFO:SubProcess create_model() end ==================================
2023-06-14 08:45:35,595:INFO:Creating metrics dataframe
2023-06-14 08:45:35,611:INFO:Initializing Bayesian Ridge
2023-06-14 08:45:35,611:INFO:Total runtime is 0.21902303695678715 minutes
2023-06-14 08:45:35,622:INFO:SubProcess create_model() called ==================================
2023-06-14 08:45:35,622:INFO:Initializing create_model()
2023-06-14 08:45:35,622:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8C1582D10>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8C2023C10>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 08:45:35,623:INFO:Checking exceptions
2023-06-14 08:45:35,623:INFO:Importing libraries
2023-06-14 08:45:35,623:INFO:Copying training dataset
2023-06-14 08:45:35,627:INFO:Defining folds
2023-06-14 08:45:35,627:INFO:Declaring metric variables
2023-06-14 08:45:35,632:INFO:Importing untrained model
2023-06-14 08:45:35,634:INFO:Bayesian Ridge Imported successfully
2023-06-14 08:45:35,634:INFO:Starting cross validation
2023-06-14 08:45:35,648:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 08:45:36,102:INFO:Calculating mean and std
2023-06-14 08:45:36,102:INFO:Creating metrics dataframe
2023-06-14 08:45:36,258:INFO:Uploading results into container
2023-06-14 08:45:36,258:INFO:Uploading model into container now
2023-06-14 08:45:36,261:INFO:_master_model_container: 8
2023-06-14 08:45:36,261:INFO:_display_container: 2
2023-06-14 08:45:36,261:INFO:BayesianRidge()
2023-06-14 08:45:36,261:INFO:create_model() successfully completed......................................
2023-06-14 08:45:36,358:INFO:SubProcess create_model() end ==================================
2023-06-14 08:45:36,358:INFO:Creating metrics dataframe
2023-06-14 08:45:36,379:INFO:Initializing Passive Aggressive Regressor
2023-06-14 08:45:36,379:INFO:Total runtime is 0.23182481924692794 minutes
2023-06-14 08:45:36,382:INFO:SubProcess create_model() called ==================================
2023-06-14 08:45:36,382:INFO:Initializing create_model()
2023-06-14 08:45:36,382:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8C1582D10>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8C2023C10>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 08:45:36,382:INFO:Checking exceptions
2023-06-14 08:45:36,382:INFO:Importing libraries
2023-06-14 08:45:36,382:INFO:Copying training dataset
2023-06-14 08:45:36,382:INFO:Defining folds
2023-06-14 08:45:36,382:INFO:Declaring metric variables
2023-06-14 08:45:36,382:INFO:Importing untrained model
2023-06-14 08:45:36,402:INFO:Passive Aggressive Regressor Imported successfully
2023-06-14 08:45:36,404:INFO:Starting cross validation
2023-06-14 08:45:36,415:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 08:45:36,894:INFO:Calculating mean and std
2023-06-14 08:45:36,894:INFO:Creating metrics dataframe
2023-06-14 08:45:36,997:INFO:Uploading results into container
2023-06-14 08:45:36,997:INFO:Uploading model into container now
2023-06-14 08:45:36,997:INFO:_master_model_container: 9
2023-06-14 08:45:36,997:INFO:_display_container: 2
2023-06-14 08:45:37,013:INFO:PassiveAggressiveRegressor(random_state=42)
2023-06-14 08:45:37,013:INFO:create_model() successfully completed......................................
2023-06-14 08:45:37,100:INFO:SubProcess create_model() end ==================================
2023-06-14 08:45:37,100:INFO:Creating metrics dataframe
2023-06-14 08:45:37,116:INFO:Initializing Huber Regressor
2023-06-14 08:45:37,116:INFO:Total runtime is 0.24409865935643518 minutes
2023-06-14 08:45:37,116:INFO:SubProcess create_model() called ==================================
2023-06-14 08:45:37,116:INFO:Initializing create_model()
2023-06-14 08:45:37,116:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8C1582D10>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8C2023C10>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 08:45:37,116:INFO:Checking exceptions
2023-06-14 08:45:37,116:INFO:Importing libraries
2023-06-14 08:45:37,116:INFO:Copying training dataset
2023-06-14 08:45:37,136:INFO:Defining folds
2023-06-14 08:45:37,137:INFO:Declaring metric variables
2023-06-14 08:45:37,142:INFO:Importing untrained model
2023-06-14 08:45:37,145:INFO:Huber Regressor Imported successfully
2023-06-14 08:45:37,150:INFO:Starting cross validation
2023-06-14 08:45:37,150:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 08:45:37,295:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 08:45:37,312:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 08:45:37,312:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 08:45:37,312:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 08:45:37,312:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 08:45:37,684:INFO:Calculating mean and std
2023-06-14 08:45:37,684:INFO:Creating metrics dataframe
2023-06-14 08:45:37,801:INFO:Uploading results into container
2023-06-14 08:45:37,801:INFO:Uploading model into container now
2023-06-14 08:45:37,801:INFO:_master_model_container: 10
2023-06-14 08:45:37,815:INFO:_display_container: 2
2023-06-14 08:45:37,815:INFO:HuberRegressor()
2023-06-14 08:45:37,815:INFO:create_model() successfully completed......................................
2023-06-14 08:45:37,915:INFO:SubProcess create_model() end ==================================
2023-06-14 08:45:37,915:INFO:Creating metrics dataframe
2023-06-14 08:45:37,915:INFO:Initializing K Neighbors Regressor
2023-06-14 08:45:37,915:INFO:Total runtime is 0.2574217240015666 minutes
2023-06-14 08:45:37,932:INFO:SubProcess create_model() called ==================================
2023-06-14 08:45:37,932:INFO:Initializing create_model()
2023-06-14 08:45:37,933:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8C1582D10>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8C2023C10>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 08:45:37,933:INFO:Checking exceptions
2023-06-14 08:45:37,933:INFO:Importing libraries
2023-06-14 08:45:37,933:INFO:Copying training dataset
2023-06-14 08:45:37,941:INFO:Defining folds
2023-06-14 08:45:37,941:INFO:Declaring metric variables
2023-06-14 08:45:37,943:INFO:Importing untrained model
2023-06-14 08:45:37,950:INFO:K Neighbors Regressor Imported successfully
2023-06-14 08:45:37,953:INFO:Starting cross validation
2023-06-14 08:45:37,960:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 08:45:38,501:INFO:Calculating mean and std
2023-06-14 08:45:38,501:INFO:Creating metrics dataframe
2023-06-14 08:45:38,630:INFO:Uploading results into container
2023-06-14 08:45:38,630:INFO:Uploading model into container now
2023-06-14 08:45:38,630:INFO:_master_model_container: 11
2023-06-14 08:45:38,630:INFO:_display_container: 2
2023-06-14 08:45:38,630:INFO:KNeighborsRegressor(n_jobs=-1)
2023-06-14 08:45:38,630:INFO:create_model() successfully completed......................................
2023-06-14 08:45:38,731:INFO:SubProcess create_model() end ==================================
2023-06-14 08:45:38,731:INFO:Creating metrics dataframe
2023-06-14 08:45:38,731:INFO:Initializing Decision Tree Regressor
2023-06-14 08:45:38,731:INFO:Total runtime is 0.2710172017415365 minutes
2023-06-14 08:45:38,749:INFO:SubProcess create_model() called ==================================
2023-06-14 08:45:38,749:INFO:Initializing create_model()
2023-06-14 08:45:38,749:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8C1582D10>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8C2023C10>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 08:45:38,750:INFO:Checking exceptions
2023-06-14 08:45:38,750:INFO:Importing libraries
2023-06-14 08:45:38,750:INFO:Copying training dataset
2023-06-14 08:45:38,758:INFO:Defining folds
2023-06-14 08:45:38,758:INFO:Declaring metric variables
2023-06-14 08:45:38,760:INFO:Importing untrained model
2023-06-14 08:45:38,769:INFO:Decision Tree Regressor Imported successfully
2023-06-14 08:45:38,778:INFO:Starting cross validation
2023-06-14 08:45:38,780:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 08:45:39,299:INFO:Calculating mean and std
2023-06-14 08:45:39,299:INFO:Creating metrics dataframe
2023-06-14 08:45:39,414:INFO:Uploading results into container
2023-06-14 08:45:39,430:INFO:Uploading model into container now
2023-06-14 08:45:39,430:INFO:_master_model_container: 12
2023-06-14 08:45:39,430:INFO:_display_container: 2
2023-06-14 08:45:39,430:INFO:DecisionTreeRegressor(random_state=42)
2023-06-14 08:45:39,430:INFO:create_model() successfully completed......................................
2023-06-14 08:45:39,515:INFO:SubProcess create_model() end ==================================
2023-06-14 08:45:39,515:INFO:Creating metrics dataframe
2023-06-14 08:45:39,531:INFO:Initializing Random Forest Regressor
2023-06-14 08:45:39,531:INFO:Total runtime is 0.28435453176498415 minutes
2023-06-14 08:45:39,531:INFO:SubProcess create_model() called ==================================
2023-06-14 08:45:39,531:INFO:Initializing create_model()
2023-06-14 08:45:39,531:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8C1582D10>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8C2023C10>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 08:45:39,531:INFO:Checking exceptions
2023-06-14 08:45:39,531:INFO:Importing libraries
2023-06-14 08:45:39,531:INFO:Copying training dataset
2023-06-14 08:45:39,552:INFO:Defining folds
2023-06-14 08:45:39,552:INFO:Declaring metric variables
2023-06-14 08:45:39,555:INFO:Importing untrained model
2023-06-14 08:45:39,560:INFO:Random Forest Regressor Imported successfully
2023-06-14 08:45:39,566:INFO:Starting cross validation
2023-06-14 08:45:39,566:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 08:45:40,339:INFO:Calculating mean and std
2023-06-14 08:45:40,339:INFO:Creating metrics dataframe
2023-06-14 08:45:40,463:INFO:Uploading results into container
2023-06-14 08:45:40,463:INFO:Uploading model into container now
2023-06-14 08:45:40,463:INFO:_master_model_container: 13
2023-06-14 08:45:40,463:INFO:_display_container: 2
2023-06-14 08:45:40,463:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-14 08:45:40,463:INFO:create_model() successfully completed......................................
2023-06-14 08:45:40,561:INFO:SubProcess create_model() end ==================================
2023-06-14 08:45:40,561:INFO:Creating metrics dataframe
2023-06-14 08:45:40,568:INFO:Initializing Extra Trees Regressor
2023-06-14 08:45:40,568:INFO:Total runtime is 0.3016363501548767 minutes
2023-06-14 08:45:40,576:INFO:SubProcess create_model() called ==================================
2023-06-14 08:45:40,576:INFO:Initializing create_model()
2023-06-14 08:45:40,577:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8C1582D10>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8C2023C10>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 08:45:40,577:INFO:Checking exceptions
2023-06-14 08:45:40,577:INFO:Importing libraries
2023-06-14 08:45:40,577:INFO:Copying training dataset
2023-06-14 08:45:40,585:INFO:Defining folds
2023-06-14 08:45:40,585:INFO:Declaring metric variables
2023-06-14 08:45:40,590:INFO:Importing untrained model
2023-06-14 08:45:40,590:INFO:Extra Trees Regressor Imported successfully
2023-06-14 08:45:40,603:INFO:Starting cross validation
2023-06-14 08:45:40,603:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 08:45:41,368:INFO:Calculating mean and std
2023-06-14 08:45:41,368:INFO:Creating metrics dataframe
2023-06-14 08:45:41,466:INFO:Uploading results into container
2023-06-14 08:45:41,466:INFO:Uploading model into container now
2023-06-14 08:45:41,466:INFO:_master_model_container: 14
2023-06-14 08:45:41,466:INFO:_display_container: 2
2023-06-14 08:45:41,481:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2023-06-14 08:45:41,481:INFO:create_model() successfully completed......................................
2023-06-14 08:45:41,576:INFO:SubProcess create_model() end ==================================
2023-06-14 08:45:41,576:INFO:Creating metrics dataframe
2023-06-14 08:45:41,576:INFO:Initializing AdaBoost Regressor
2023-06-14 08:45:41,576:INFO:Total runtime is 0.3184468507766724 minutes
2023-06-14 08:45:41,592:INFO:SubProcess create_model() called ==================================
2023-06-14 08:45:41,592:INFO:Initializing create_model()
2023-06-14 08:45:41,593:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8C1582D10>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8C2023C10>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 08:45:41,593:INFO:Checking exceptions
2023-06-14 08:45:41,593:INFO:Importing libraries
2023-06-14 08:45:41,593:INFO:Copying training dataset
2023-06-14 08:45:41,600:INFO:Defining folds
2023-06-14 08:45:41,600:INFO:Declaring metric variables
2023-06-14 08:45:41,604:INFO:Importing untrained model
2023-06-14 08:45:41,604:INFO:AdaBoost Regressor Imported successfully
2023-06-14 08:45:41,620:INFO:Starting cross validation
2023-06-14 08:45:41,621:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 08:45:42,110:INFO:Calculating mean and std
2023-06-14 08:45:42,110:INFO:Creating metrics dataframe
2023-06-14 08:45:42,230:INFO:Uploading results into container
2023-06-14 08:45:42,230:INFO:Uploading model into container now
2023-06-14 08:45:42,230:INFO:_master_model_container: 15
2023-06-14 08:45:42,230:INFO:_display_container: 2
2023-06-14 08:45:42,230:INFO:AdaBoostRegressor(random_state=42)
2023-06-14 08:45:42,230:INFO:create_model() successfully completed......................................
2023-06-14 08:45:42,348:INFO:SubProcess create_model() end ==================================
2023-06-14 08:45:42,348:INFO:Creating metrics dataframe
2023-06-14 08:45:42,363:INFO:Initializing Gradient Boosting Regressor
2023-06-14 08:45:42,363:INFO:Total runtime is 0.3315582076708476 minutes
2023-06-14 08:45:42,369:INFO:SubProcess create_model() called ==================================
2023-06-14 08:45:42,369:INFO:Initializing create_model()
2023-06-14 08:45:42,369:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8C1582D10>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8C2023C10>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 08:45:42,369:INFO:Checking exceptions
2023-06-14 08:45:42,370:INFO:Importing libraries
2023-06-14 08:45:42,370:INFO:Copying training dataset
2023-06-14 08:45:42,374:INFO:Defining folds
2023-06-14 08:45:42,374:INFO:Declaring metric variables
2023-06-14 08:45:42,377:INFO:Importing untrained model
2023-06-14 08:45:42,377:INFO:Gradient Boosting Regressor Imported successfully
2023-06-14 08:45:42,386:INFO:Starting cross validation
2023-06-14 08:45:42,386:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 08:45:42,936:INFO:Calculating mean and std
2023-06-14 08:45:42,937:INFO:Creating metrics dataframe
2023-06-14 08:45:43,031:INFO:Uploading results into container
2023-06-14 08:45:43,046:INFO:Uploading model into container now
2023-06-14 08:45:43,046:INFO:_master_model_container: 16
2023-06-14 08:45:43,046:INFO:_display_container: 2
2023-06-14 08:45:43,046:INFO:GradientBoostingRegressor(random_state=42)
2023-06-14 08:45:43,046:INFO:create_model() successfully completed......................................
2023-06-14 08:45:43,166:INFO:SubProcess create_model() end ==================================
2023-06-14 08:45:43,166:INFO:Creating metrics dataframe
2023-06-14 08:45:43,180:INFO:Initializing Extreme Gradient Boosting
2023-06-14 08:45:43,181:INFO:Total runtime is 0.3451828559239706 minutes
2023-06-14 08:45:43,185:INFO:SubProcess create_model() called ==================================
2023-06-14 08:45:43,185:INFO:Initializing create_model()
2023-06-14 08:45:43,185:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8C1582D10>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8C2023C10>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 08:45:43,185:INFO:Checking exceptions
2023-06-14 08:45:43,185:INFO:Importing libraries
2023-06-14 08:45:43,186:INFO:Copying training dataset
2023-06-14 08:45:43,192:INFO:Defining folds
2023-06-14 08:45:43,192:INFO:Declaring metric variables
2023-06-14 08:45:43,196:INFO:Importing untrained model
2023-06-14 08:45:43,201:INFO:Extreme Gradient Boosting Imported successfully
2023-06-14 08:45:43,204:INFO:Starting cross validation
2023-06-14 08:45:43,204:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 08:45:43,786:INFO:Calculating mean and std
2023-06-14 08:45:43,786:INFO:Creating metrics dataframe
2023-06-14 08:45:43,916:INFO:Uploading results into container
2023-06-14 08:45:43,916:INFO:Uploading model into container now
2023-06-14 08:45:43,917:INFO:_master_model_container: 17
2023-06-14 08:45:43,917:INFO:_display_container: 2
2023-06-14 08:45:43,918:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=42, ...)
2023-06-14 08:45:43,919:INFO:create_model() successfully completed......................................
2023-06-14 08:45:44,057:INFO:SubProcess create_model() end ==================================
2023-06-14 08:45:44,057:INFO:Creating metrics dataframe
2023-06-14 08:45:44,078:INFO:Initializing Light Gradient Boosting Machine
2023-06-14 08:45:44,078:INFO:Total runtime is 0.36013379096984866 minutes
2023-06-14 08:45:44,085:INFO:SubProcess create_model() called ==================================
2023-06-14 08:45:44,086:INFO:Initializing create_model()
2023-06-14 08:45:44,086:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8C1582D10>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8C2023C10>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 08:45:44,086:INFO:Checking exceptions
2023-06-14 08:45:44,086:INFO:Importing libraries
2023-06-14 08:45:44,086:INFO:Copying training dataset
2023-06-14 08:45:44,096:INFO:Defining folds
2023-06-14 08:45:44,096:INFO:Declaring metric variables
2023-06-14 08:45:44,104:INFO:Importing untrained model
2023-06-14 08:45:44,110:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-14 08:45:44,123:INFO:Starting cross validation
2023-06-14 08:45:44,125:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 08:45:45,870:INFO:Calculating mean and std
2023-06-14 08:45:45,872:INFO:Creating metrics dataframe
2023-06-14 08:45:45,989:INFO:Uploading results into container
2023-06-14 08:45:45,990:INFO:Uploading model into container now
2023-06-14 08:45:45,990:INFO:_master_model_container: 18
2023-06-14 08:45:45,990:INFO:_display_container: 2
2023-06-14 08:45:45,991:INFO:LGBMRegressor(random_state=42)
2023-06-14 08:45:45,991:INFO:create_model() successfully completed......................................
2023-06-14 08:45:46,089:INFO:SubProcess create_model() end ==================================
2023-06-14 08:45:46,089:INFO:Creating metrics dataframe
2023-06-14 08:45:46,102:INFO:Initializing Dummy Regressor
2023-06-14 08:45:46,103:INFO:Total runtime is 0.3938816666603089 minutes
2023-06-14 08:45:46,107:INFO:SubProcess create_model() called ==================================
2023-06-14 08:45:46,108:INFO:Initializing create_model()
2023-06-14 08:45:46,108:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8C1582D10>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8C2023C10>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 08:45:46,108:INFO:Checking exceptions
2023-06-14 08:45:46,108:INFO:Importing libraries
2023-06-14 08:45:46,108:INFO:Copying training dataset
2023-06-14 08:45:46,115:INFO:Defining folds
2023-06-14 08:45:46,116:INFO:Declaring metric variables
2023-06-14 08:45:46,119:INFO:Importing untrained model
2023-06-14 08:45:46,122:INFO:Dummy Regressor Imported successfully
2023-06-14 08:45:46,129:INFO:Starting cross validation
2023-06-14 08:45:46,130:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 08:45:46,617:INFO:Calculating mean and std
2023-06-14 08:45:46,618:INFO:Creating metrics dataframe
2023-06-14 08:45:46,741:INFO:Uploading results into container
2023-06-14 08:45:46,741:INFO:Uploading model into container now
2023-06-14 08:45:46,743:INFO:_master_model_container: 19
2023-06-14 08:45:46,743:INFO:_display_container: 2
2023-06-14 08:45:46,743:INFO:DummyRegressor()
2023-06-14 08:45:46,743:INFO:create_model() successfully completed......................................
2023-06-14 08:45:46,847:INFO:SubProcess create_model() end ==================================
2023-06-14 08:45:46,847:INFO:Creating metrics dataframe
2023-06-14 08:45:46,867:INFO:Initializing create_model()
2023-06-14 08:45:46,867:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8C1582D10>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-14 08:45:46,867:INFO:Checking exceptions
2023-06-14 08:45:46,868:INFO:Importing libraries
2023-06-14 08:45:46,868:INFO:Copying training dataset
2023-06-14 08:45:46,872:INFO:Defining folds
2023-06-14 08:45:46,872:INFO:Declaring metric variables
2023-06-14 08:45:46,872:INFO:Importing untrained model
2023-06-14 08:45:46,872:INFO:Declaring custom model
2023-06-14 08:45:46,872:INFO:Random Forest Regressor Imported successfully
2023-06-14 08:45:46,873:INFO:Cross validation set to False
2023-06-14 08:45:46,873:INFO:Fitting Model
2023-06-14 08:45:47,074:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-14 08:45:47,074:INFO:create_model() successfully completed......................................
2023-06-14 08:45:47,214:INFO:_master_model_container: 19
2023-06-14 08:45:47,214:INFO:_display_container: 2
2023-06-14 08:45:47,215:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-14 08:45:47,215:INFO:compare_models() successfully completed......................................
2023-06-14 08:46:06,537:INFO:Initializing create_model()
2023-06-14 08:46:06,537:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8C1582D10>, estimator=rf, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-14 08:46:06,537:INFO:Checking exceptions
2023-06-14 08:46:06,558:INFO:Importing libraries
2023-06-14 08:46:06,558:INFO:Copying training dataset
2023-06-14 08:46:06,568:INFO:Defining folds
2023-06-14 08:46:06,568:INFO:Declaring metric variables
2023-06-14 08:46:06,573:INFO:Importing untrained model
2023-06-14 08:46:06,577:INFO:Random Forest Regressor Imported successfully
2023-06-14 08:46:06,585:INFO:Starting cross validation
2023-06-14 08:46:06,586:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 08:46:07,244:INFO:Calculating mean and std
2023-06-14 08:46:07,244:INFO:Creating metrics dataframe
2023-06-14 08:46:07,251:INFO:Finalizing model
2023-06-14 08:46:07,431:INFO:Uploading results into container
2023-06-14 08:46:07,432:INFO:Uploading model into container now
2023-06-14 08:46:07,441:INFO:_master_model_container: 20
2023-06-14 08:46:07,441:INFO:_display_container: 3
2023-06-14 08:46:07,442:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-14 08:46:07,442:INFO:create_model() successfully completed......................................
2023-06-14 08:46:29,090:INFO:Initializing tune_model()
2023-06-14 08:46:29,090:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=5, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8C1582D10>)
2023-06-14 08:46:29,090:INFO:Checking exceptions
2023-06-14 08:46:29,116:INFO:Copying training dataset
2023-06-14 08:46:29,124:INFO:Checking base model
2023-06-14 08:46:29,124:INFO:Base model : Random Forest Regressor
2023-06-14 08:46:29,129:INFO:Declaring metric variables
2023-06-14 08:46:29,133:INFO:Defining Hyperparameters
2023-06-14 08:46:29,236:INFO:Tuning with n_jobs=-1
2023-06-14 08:46:29,236:INFO:Initializing RandomizedSearchCV
2023-06-14 08:46:35,950:INFO:best_params: {'actual_estimator__n_estimators': 190, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 4, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': True}
2023-06-14 08:46:35,951:INFO:Hyperparameter search completed
2023-06-14 08:46:35,951:INFO:SubProcess create_model() called ==================================
2023-06-14 08:46:35,952:INFO:Initializing create_model()
2023-06-14 08:46:35,952:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8C1582D10>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8C156B8E0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 190, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.3, 'max_features': 1.0, 'max_depth': 4, 'criterion': 'squared_error', 'bootstrap': True})
2023-06-14 08:46:35,952:INFO:Checking exceptions
2023-06-14 08:46:35,952:INFO:Importing libraries
2023-06-14 08:46:35,952:INFO:Copying training dataset
2023-06-14 08:46:35,958:INFO:Defining folds
2023-06-14 08:46:35,958:INFO:Declaring metric variables
2023-06-14 08:46:35,963:INFO:Importing untrained model
2023-06-14 08:46:35,964:INFO:Declaring custom model
2023-06-14 08:46:35,968:INFO:Random Forest Regressor Imported successfully
2023-06-14 08:46:35,977:INFO:Starting cross validation
2023-06-14 08:46:35,978:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 08:46:36,723:INFO:Calculating mean and std
2023-06-14 08:46:36,724:INFO:Creating metrics dataframe
2023-06-14 08:46:36,731:INFO:Finalizing model
2023-06-14 08:46:36,929:INFO:Uploading results into container
2023-06-14 08:46:36,930:INFO:Uploading model into container now
2023-06-14 08:46:36,931:INFO:_master_model_container: 21
2023-06-14 08:46:36,931:INFO:_display_container: 4
2023-06-14 08:46:36,932:INFO:RandomForestRegressor(max_depth=4, min_impurity_decrease=0.3,
                      min_samples_leaf=2, n_estimators=190, n_jobs=-1,
                      random_state=42)
2023-06-14 08:46:36,932:INFO:create_model() successfully completed......................................
2023-06-14 08:46:37,031:INFO:SubProcess create_model() end ==================================
2023-06-14 08:46:37,031:INFO:choose_better activated
2023-06-14 08:46:37,033:INFO:SubProcess create_model() called ==================================
2023-06-14 08:46:37,034:INFO:Initializing create_model()
2023-06-14 08:46:37,034:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8C1582D10>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-14 08:46:37,034:INFO:Checking exceptions
2023-06-14 08:46:37,037:INFO:Importing libraries
2023-06-14 08:46:37,038:INFO:Copying training dataset
2023-06-14 08:46:37,043:INFO:Defining folds
2023-06-14 08:46:37,043:INFO:Declaring metric variables
2023-06-14 08:46:37,043:INFO:Importing untrained model
2023-06-14 08:46:37,043:INFO:Declaring custom model
2023-06-14 08:46:37,043:INFO:Random Forest Regressor Imported successfully
2023-06-14 08:46:37,044:INFO:Starting cross validation
2023-06-14 08:46:37,044:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 08:46:37,664:INFO:Calculating mean and std
2023-06-14 08:46:37,664:INFO:Creating metrics dataframe
2023-06-14 08:46:37,666:INFO:Finalizing model
2023-06-14 08:46:37,836:INFO:Uploading results into container
2023-06-14 08:46:37,837:INFO:Uploading model into container now
2023-06-14 08:46:37,837:INFO:_master_model_container: 22
2023-06-14 08:46:37,838:INFO:_display_container: 5
2023-06-14 08:46:37,838:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-14 08:46:37,838:INFO:create_model() successfully completed......................................
2023-06-14 08:46:37,938:INFO:SubProcess create_model() end ==================================
2023-06-14 08:46:37,938:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) result for R2 is 0.9102
2023-06-14 08:46:37,939:INFO:RandomForestRegressor(max_depth=4, min_impurity_decrease=0.3,
                      min_samples_leaf=2, n_estimators=190, n_jobs=-1,
                      random_state=42) result for R2 is 0.8871
2023-06-14 08:46:37,939:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) is best model
2023-06-14 08:46:37,939:INFO:choose_better completed
2023-06-14 08:46:37,939:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-06-14 08:46:37,947:INFO:_master_model_container: 22
2023-06-14 08:46:37,947:INFO:_display_container: 4
2023-06-14 08:46:37,948:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-14 08:46:37,948:INFO:tune_model() successfully completed......................................
2023-06-14 09:18:28,553:INFO:Initializing plot_model()
2023-06-14 09:18:28,553:INFO:plot_model(plot=AlphaSelection, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8C1582D10>, system=True)
2023-06-14 09:18:28,553:INFO:Checking exceptions
2023-06-14 09:18:43,576:INFO:Initializing plot_model()
2023-06-14 09:18:43,576:INFO:plot_model(plot=alphaselection, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8C1582D10>, system=True)
2023-06-14 09:18:43,576:INFO:Checking exceptions
2023-06-14 09:19:05,016:INFO:Initializing plot_model()
2023-06-14 09:19:05,016:INFO:plot_model(plot=alphas, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8C1582D10>, system=True)
2023-06-14 09:19:05,017:INFO:Checking exceptions
2023-06-14 09:21:15,976:INFO:Initializing plot_model()
2023-06-14 09:21:15,976:INFO:plot_model(plot=alpha, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8C1582D10>, system=True)
2023-06-14 09:21:15,976:INFO:Checking exceptions
2023-06-14 09:42:03,834:INFO:Initializing plot_model()
2023-06-14 09:42:03,835:INFO:plot_model(plot=Alpha, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8C1582D10>, system=True)
2023-06-14 09:42:03,835:INFO:Checking exceptions
2023-06-14 09:54:24,599:INFO:Initializing plot_model()
2023-06-14 09:54:24,599:INFO:plot_model(plot=Alphas, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8C1582D10>, system=True)
2023-06-14 09:54:24,600:INFO:Checking exceptions
2023-06-14 09:54:29,694:INFO:Initializing plot_model()
2023-06-14 09:54:29,694:INFO:plot_model(plot=alphas, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8C1582D10>, system=True)
2023-06-14 09:54:29,694:INFO:Checking exceptions
2023-06-14 09:54:43,974:INFO:Initializing plot_model()
2023-06-14 09:54:43,974:INFO:plot_model(plot=alpha, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8C1582D10>, system=True)
2023-06-14 09:54:43,974:INFO:Checking exceptions
2023-06-14 09:56:25,633:INFO:Initializing plot_model()
2023-06-14 09:56:25,634:INFO:plot_model(plot=selection, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8C1582D10>, system=True)
2023-06-14 09:56:25,634:INFO:Checking exceptions
2023-06-14 09:56:36,225:INFO:Initializing plot_model()
2023-06-14 09:56:36,226:INFO:plot_model(plot=selections, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8C1582D10>, system=True)
2023-06-14 09:56:36,226:INFO:Checking exceptions
2023-06-14 09:56:42,704:INFO:Initializing plot_model()
2023-06-14 09:56:42,704:INFO:plot_model(plot=Selections, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8C1582D10>, system=True)
2023-06-14 09:56:42,704:INFO:Checking exceptions
2023-06-14 10:01:39,925:INFO:Initializing plot_model()
2023-06-14 10:01:39,926:INFO:plot_model(plot=cooks, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8C1582D10>, system=True)
2023-06-14 10:01:39,926:INFO:Checking exceptions
2023-06-14 10:01:39,967:INFO:Preloading libraries
2023-06-14 10:01:39,997:INFO:Copying training dataset
2023-06-14 10:01:39,997:INFO:Plot type: cooks
2023-06-14 10:01:40,079:INFO:Fitting Model
2023-06-14 10:01:40,506:INFO:Visual Rendered Successfully
2023-06-14 10:01:40,634:INFO:plot_model() successfully completed......................................
2023-06-14 10:03:32,314:INFO:Initializing plot_model()
2023-06-14 10:03:32,314:INFO:plot_model(plot=vc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8C1582D10>, system=True)
2023-06-14 10:03:32,315:INFO:Checking exceptions
2023-06-14 10:03:32,340:INFO:Preloading libraries
2023-06-14 10:03:32,368:INFO:Copying training dataset
2023-06-14 10:03:32,368:INFO:Plot type: vc
2023-06-14 10:03:32,370:INFO:Determining param_name
2023-06-14 10:03:32,370:INFO:param_name: max_depth
2023-06-14 10:03:32,453:INFO:Fitting Model
2023-06-14 10:04:19,881:INFO:Visual Rendered Successfully
2023-06-14 10:04:20,043:INFO:plot_model() successfully completed......................................
2023-06-14 10:07:15,245:INFO:Initializing plot_model()
2023-06-14 10:07:15,246:INFO:plot_model(plot=manifold, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8C1582D10>, system=True)
2023-06-14 10:07:15,246:INFO:Checking exceptions
2023-06-14 10:07:15,274:INFO:Preloading libraries
2023-06-14 10:07:15,302:INFO:Copying training dataset
2023-06-14 10:07:15,302:INFO:Plot type: manifold
2023-06-14 10:07:15,410:INFO:Fitting & Transforming Model
2023-06-14 10:07:24,770:INFO:Visual Rendered Successfully
2023-06-14 10:07:24,890:INFO:plot_model() successfully completed......................................
2023-06-14 10:39:00,778:INFO:PyCaret RegressionExperiment
2023-06-14 10:39:00,778:INFO:Logging name: reg-default-name
2023-06-14 10:39:00,778:INFO:ML Usecase: MLUsecase.REGRESSION
2023-06-14 10:39:00,778:INFO:version 3.0.2
2023-06-14 10:39:00,778:INFO:Initializing setup()
2023-06-14 10:39:00,778:INFO:self.USI: 5449
2023-06-14 10:39:00,778:INFO:self._variable_keys: {'fold_groups_param', 'idx', 'logging_param', 'fold_shuffle_param', 'X_train', 'y_test', 'transform_target_param', 'exp_name_log', 'n_jobs_param', 'X', 'gpu_param', '_available_plots', 'seed', 'gpu_n_jobs_param', 'y', 'y_train', 'X_test', 'log_plots_param', 'html_param', 'target_param', '_ml_usecase', 'data', 'pipeline', 'memory', 'fold_generator', 'exp_id', 'USI'}
2023-06-14 10:39:00,778:INFO:Checking environment
2023-06-14 10:39:00,778:INFO:python_version: 3.10.9
2023-06-14 10:39:00,778:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-06-14 10:39:00,778:INFO:machine: AMD64
2023-06-14 10:39:00,778:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-14 10:39:00,778:INFO:Memory: svmem(total=16901767168, available=6042148864, percent=64.3, used=10859618304, free=6042148864)
2023-06-14 10:39:00,778:INFO:Physical Core: 4
2023-06-14 10:39:00,778:INFO:Logical Core: 8
2023-06-14 10:39:00,778:INFO:Checking libraries
2023-06-14 10:39:00,778:INFO:System:
2023-06-14 10:39:00,779:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-06-14 10:39:00,779:INFO:executable: C:\Users\lapei\anaconda3\python.exe
2023-06-14 10:39:00,779:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-14 10:39:00,779:INFO:PyCaret required dependencies:
2023-06-14 10:39:00,779:INFO:                 pip: 22.3.1
2023-06-14 10:39:00,779:INFO:          setuptools: 65.6.3
2023-06-14 10:39:00,779:INFO:             pycaret: 3.0.2
2023-06-14 10:39:00,779:INFO:             IPython: 8.10.0
2023-06-14 10:39:00,779:INFO:          ipywidgets: 7.6.5
2023-06-14 10:39:00,779:INFO:                tqdm: 4.64.1
2023-06-14 10:39:00,779:INFO:               numpy: 1.23.5
2023-06-14 10:39:00,779:INFO:              pandas: 1.5.3
2023-06-14 10:39:00,779:INFO:              jinja2: 3.1.2
2023-06-14 10:39:00,779:INFO:               scipy: 1.10.0
2023-06-14 10:39:00,779:INFO:              joblib: 1.2.0
2023-06-14 10:39:00,779:INFO:             sklearn: 1.2.1
2023-06-14 10:39:00,779:INFO:                pyod: 1.0.9
2023-06-14 10:39:00,779:INFO:            imblearn: 0.10.1
2023-06-14 10:39:00,779:INFO:   category_encoders: 2.6.1
2023-06-14 10:39:00,779:INFO:            lightgbm: 3.3.5
2023-06-14 10:39:00,779:INFO:               numba: 0.56.4
2023-06-14 10:39:00,779:INFO:            requests: 2.28.1
2023-06-14 10:39:00,779:INFO:          matplotlib: 3.7.0
2023-06-14 10:39:00,779:INFO:          scikitplot: 0.3.7
2023-06-14 10:39:00,779:INFO:         yellowbrick: 1.5
2023-06-14 10:39:00,779:INFO:              plotly: 5.9.0
2023-06-14 10:39:00,779:INFO:             kaleido: 0.2.1
2023-06-14 10:39:00,779:INFO:         statsmodels: 0.13.5
2023-06-14 10:39:00,779:INFO:              sktime: 0.17.0
2023-06-14 10:39:00,779:INFO:               tbats: 1.1.3
2023-06-14 10:39:00,779:INFO:            pmdarima: 2.0.3
2023-06-14 10:39:00,779:INFO:              psutil: 5.9.0
2023-06-14 10:39:00,779:INFO:PyCaret optional dependencies:
2023-06-14 10:39:00,779:INFO:                shap: 0.41.0
2023-06-14 10:39:00,780:INFO:           interpret: Not installed
2023-06-14 10:39:00,780:INFO:                umap: Not installed
2023-06-14 10:39:00,780:INFO:    pandas_profiling: Not installed
2023-06-14 10:39:00,780:INFO:  explainerdashboard: Not installed
2023-06-14 10:39:00,780:INFO:             autoviz: Not installed
2023-06-14 10:39:00,780:INFO:           fairlearn: Not installed
2023-06-14 10:39:00,780:INFO:             xgboost: 1.7.3
2023-06-14 10:39:00,780:INFO:            catboost: Not installed
2023-06-14 10:39:00,780:INFO:              kmodes: Not installed
2023-06-14 10:39:00,780:INFO:             mlxtend: Not installed
2023-06-14 10:39:00,780:INFO:       statsforecast: Not installed
2023-06-14 10:39:00,780:INFO:        tune_sklearn: Not installed
2023-06-14 10:39:00,780:INFO:                 ray: Not installed
2023-06-14 10:39:00,780:INFO:            hyperopt: Not installed
2023-06-14 10:39:00,780:INFO:              optuna: Not installed
2023-06-14 10:39:00,780:INFO:               skopt: 0.9.0
2023-06-14 10:39:00,780:INFO:              mlflow: Not installed
2023-06-14 10:39:00,780:INFO:              gradio: Not installed
2023-06-14 10:39:00,780:INFO:             fastapi: Not installed
2023-06-14 10:39:00,780:INFO:             uvicorn: Not installed
2023-06-14 10:39:00,780:INFO:              m2cgen: Not installed
2023-06-14 10:39:00,780:INFO:           evidently: Not installed
2023-06-14 10:39:00,780:INFO:               fugue: Not installed
2023-06-14 10:39:00,780:INFO:           streamlit: Not installed
2023-06-14 10:39:00,780:INFO:             prophet: Not installed
2023-06-14 10:39:00,780:INFO:None
2023-06-14 10:39:00,780:INFO:Set up data.
2023-06-14 10:41:06,811:INFO:PyCaret RegressionExperiment
2023-06-14 10:41:06,812:INFO:Logging name: reg-default-name
2023-06-14 10:41:06,812:INFO:ML Usecase: MLUsecase.REGRESSION
2023-06-14 10:41:06,812:INFO:version 3.0.2
2023-06-14 10:41:06,812:INFO:Initializing setup()
2023-06-14 10:41:06,812:INFO:self.USI: d1ef
2023-06-14 10:41:06,812:INFO:self._variable_keys: {'fold_groups_param', 'idx', 'logging_param', 'fold_shuffle_param', 'X_train', 'y_test', 'transform_target_param', 'exp_name_log', 'n_jobs_param', 'X', 'gpu_param', '_available_plots', 'seed', 'gpu_n_jobs_param', 'y', 'y_train', 'X_test', 'log_plots_param', 'html_param', 'target_param', '_ml_usecase', 'data', 'pipeline', 'memory', 'fold_generator', 'exp_id', 'USI'}
2023-06-14 10:41:06,812:INFO:Checking environment
2023-06-14 10:41:06,812:INFO:python_version: 3.10.9
2023-06-14 10:41:06,812:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-06-14 10:41:06,812:INFO:machine: AMD64
2023-06-14 10:41:06,812:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-14 10:41:06,812:INFO:Memory: svmem(total=16901767168, available=6091653120, percent=64.0, used=10810114048, free=6091653120)
2023-06-14 10:41:06,812:INFO:Physical Core: 4
2023-06-14 10:41:06,812:INFO:Logical Core: 8
2023-06-14 10:41:06,812:INFO:Checking libraries
2023-06-14 10:41:06,812:INFO:System:
2023-06-14 10:41:06,812:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-06-14 10:41:06,812:INFO:executable: C:\Users\lapei\anaconda3\python.exe
2023-06-14 10:41:06,812:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-14 10:41:06,812:INFO:PyCaret required dependencies:
2023-06-14 10:41:06,812:INFO:                 pip: 22.3.1
2023-06-14 10:41:06,812:INFO:          setuptools: 65.6.3
2023-06-14 10:41:06,812:INFO:             pycaret: 3.0.2
2023-06-14 10:41:06,812:INFO:             IPython: 8.10.0
2023-06-14 10:41:06,813:INFO:          ipywidgets: 7.6.5
2023-06-14 10:41:06,813:INFO:                tqdm: 4.64.1
2023-06-14 10:41:06,813:INFO:               numpy: 1.23.5
2023-06-14 10:41:06,813:INFO:              pandas: 1.5.3
2023-06-14 10:41:06,813:INFO:              jinja2: 3.1.2
2023-06-14 10:41:06,813:INFO:               scipy: 1.10.0
2023-06-14 10:41:06,813:INFO:              joblib: 1.2.0
2023-06-14 10:41:06,813:INFO:             sklearn: 1.2.1
2023-06-14 10:41:06,813:INFO:                pyod: 1.0.9
2023-06-14 10:41:06,813:INFO:            imblearn: 0.10.1
2023-06-14 10:41:06,813:INFO:   category_encoders: 2.6.1
2023-06-14 10:41:06,813:INFO:            lightgbm: 3.3.5
2023-06-14 10:41:06,813:INFO:               numba: 0.56.4
2023-06-14 10:41:06,813:INFO:            requests: 2.28.1
2023-06-14 10:41:06,813:INFO:          matplotlib: 3.7.0
2023-06-14 10:41:06,813:INFO:          scikitplot: 0.3.7
2023-06-14 10:41:06,813:INFO:         yellowbrick: 1.5
2023-06-14 10:41:06,813:INFO:              plotly: 5.9.0
2023-06-14 10:41:06,813:INFO:             kaleido: 0.2.1
2023-06-14 10:41:06,813:INFO:         statsmodels: 0.13.5
2023-06-14 10:41:06,813:INFO:              sktime: 0.17.0
2023-06-14 10:41:06,813:INFO:               tbats: 1.1.3
2023-06-14 10:41:06,813:INFO:            pmdarima: 2.0.3
2023-06-14 10:41:06,813:INFO:              psutil: 5.9.0
2023-06-14 10:41:06,813:INFO:PyCaret optional dependencies:
2023-06-14 10:41:06,813:INFO:                shap: 0.41.0
2023-06-14 10:41:06,813:INFO:           interpret: Not installed
2023-06-14 10:41:06,813:INFO:                umap: Not installed
2023-06-14 10:41:06,813:INFO:    pandas_profiling: Not installed
2023-06-14 10:41:06,813:INFO:  explainerdashboard: Not installed
2023-06-14 10:41:06,813:INFO:             autoviz: Not installed
2023-06-14 10:41:06,813:INFO:           fairlearn: Not installed
2023-06-14 10:41:06,813:INFO:             xgboost: 1.7.3
2023-06-14 10:41:06,814:INFO:            catboost: Not installed
2023-06-14 10:41:06,814:INFO:              kmodes: Not installed
2023-06-14 10:41:06,814:INFO:             mlxtend: Not installed
2023-06-14 10:41:06,814:INFO:       statsforecast: Not installed
2023-06-14 10:41:06,814:INFO:        tune_sklearn: Not installed
2023-06-14 10:41:06,814:INFO:                 ray: Not installed
2023-06-14 10:41:06,814:INFO:            hyperopt: Not installed
2023-06-14 10:41:06,814:INFO:              optuna: Not installed
2023-06-14 10:41:06,814:INFO:               skopt: 0.9.0
2023-06-14 10:41:06,814:INFO:              mlflow: Not installed
2023-06-14 10:41:06,814:INFO:              gradio: Not installed
2023-06-14 10:41:06,814:INFO:             fastapi: Not installed
2023-06-14 10:41:06,814:INFO:             uvicorn: Not installed
2023-06-14 10:41:06,814:INFO:              m2cgen: Not installed
2023-06-14 10:41:06,814:INFO:           evidently: Not installed
2023-06-14 10:41:06,814:INFO:               fugue: Not installed
2023-06-14 10:41:06,814:INFO:           streamlit: Not installed
2023-06-14 10:41:06,814:INFO:             prophet: Not installed
2023-06-14 10:41:06,814:INFO:None
2023-06-14 10:41:06,814:INFO:Set up data.
2023-06-14 10:41:06,825:INFO:Set up train/test split.
2023-06-14 10:41:06,830:INFO:Set up index.
2023-06-14 10:41:06,830:INFO:Set up folding strategy.
2023-06-14 10:41:06,830:INFO:Assigning column types.
2023-06-14 10:41:06,833:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-14 10:41:06,833:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-14 10:41:06,837:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 10:41:06,840:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 10:41:06,885:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 10:41:06,919:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 10:41:06,920:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 10:41:06,922:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 10:41:06,922:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-14 10:41:06,926:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 10:41:06,930:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 10:41:06,976:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 10:41:07,011:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 10:41:07,012:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 10:41:07,014:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 10:41:07,014:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-06-14 10:41:07,018:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 10:41:07,021:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 10:41:07,069:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 10:41:07,104:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 10:41:07,104:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 10:41:07,106:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 10:41:07,110:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 10:41:07,114:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 10:41:07,160:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 10:41:07,201:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 10:41:07,202:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 10:41:07,203:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 10:41:07,204:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-06-14 10:41:07,210:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 10:41:07,257:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 10:41:07,288:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 10:41:07,289:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 10:41:07,291:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 10:41:07,302:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 10:41:07,349:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 10:41:07,389:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 10:41:07,390:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 10:41:07,392:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 10:41:07,392:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-06-14 10:41:07,453:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 10:41:07,488:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 10:41:07,489:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 10:41:07,491:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 10:41:07,546:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 10:41:07,582:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 10:41:07,583:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 10:41:07,586:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 10:41:07,587:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-14 10:41:07,645:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 10:41:07,682:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 10:41:07,686:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 10:41:07,751:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 10:41:07,791:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 10:41:07,793:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 10:41:07,794:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-06-14 10:41:07,895:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 10:41:07,897:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 10:41:07,989:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 10:41:07,990:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 10:41:07,991:INFO:Preparing preprocessing pipeline...
2023-06-14 10:41:07,991:INFO:Set up simple imputation.
2023-06-14 10:41:07,992:INFO:Set up column name cleaning.
2023-06-14 10:41:08,038:INFO:Finished creating preprocessing pipeline.
2023-06-14 10:41:08,042:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\lapei\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['taxa_homicidio', 'RH_adm_dir',
                                             'densidade_banda_larga',
                                             'densidade_telefonia_movel',
                                             'qtd_cursos_engenharias',
                                             'qtd_cursos_negocios_direito',
                                             'media_notas_CN', 'media_notas_CH',
                                             'media_NU_NOTA_LC',
                                             'media_NU_NOTA_MT',
                                             'media_...
                                             'Isencao_ISSQN_Sim',
                                             'Isencao_Tx_Sim',
                                             'Cessao_terrenos_Sim',
                                             'Doacao_terrenos_Sim',
                                             'Outros_mecanismos_Sim',
                                             'ISH_Baixa', 'ISH_Máxima',
                                             'ISH_Média', 'ISH_Mínima'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-06-14 10:41:08,042:INFO:Creating final display dataframe.
2023-06-14 10:41:08,113:INFO:Setup _display_container:                     Description                              Value
0                    Session id                                 42
1                        Target  qtd_abertas_Empresario_Individual
2                   Target type                         Regression
3           Original data shape                         (4456, 30)
4        Transformed data shape                         (4456, 30)
5   Transformed train set shape                         (3119, 30)
6    Transformed test set shape                         (1337, 30)
7              Numeric features                                 29
8                    Preprocess                               True
9               Imputation type                             simple
10           Numeric imputation                               mean
11       Categorical imputation                               mode
12               Fold Generator                              KFold
13                  Fold Number                                 10
14                     CPU Jobs                                 -1
15                      Use GPU                              False
16               Log Experiment                              False
17              Experiment Name                   reg-default-name
18                          USI                               d1ef
2023-06-14 10:41:08,225:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 10:41:08,228:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 10:41:08,319:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 10:41:08,321:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 10:41:08,322:INFO:setup() successfully completed in 1.57s...............
2023-06-14 10:45:45,111:INFO:Initializing evaluate_model()
2023-06-14 10:45:45,111:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8CE0E06D0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-06-14 10:45:45,132:INFO:Initializing plot_model()
2023-06-14 10:45:45,132:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8CE0E06D0>, system=True)
2023-06-14 10:45:45,133:INFO:Checking exceptions
2023-06-14 10:45:45,160:INFO:Preloading libraries
2023-06-14 10:45:45,189:INFO:Copying training dataset
2023-06-14 10:45:45,189:INFO:Plot type: pipeline
2023-06-14 10:45:45,326:INFO:Visual Rendered Successfully
2023-06-14 10:45:45,453:INFO:plot_model() successfully completed......................................
2023-06-14 10:45:52,810:INFO:Initializing plot_model()
2023-06-14 10:45:52,810:INFO:plot_model(plot=parameter, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8CE0E06D0>, system=True)
2023-06-14 10:45:52,810:INFO:Checking exceptions
2023-06-14 10:45:52,839:INFO:Preloading libraries
2023-06-14 10:45:52,867:INFO:Copying training dataset
2023-06-14 10:45:52,867:INFO:Plot type: parameter
2023-06-14 10:45:52,870:INFO:Visual Rendered Successfully
2023-06-14 10:45:52,983:INFO:plot_model() successfully completed......................................
2023-06-14 10:45:55,470:INFO:Initializing plot_model()
2023-06-14 10:45:55,470:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8CE0E06D0>, system=True)
2023-06-14 10:45:55,470:INFO:Checking exceptions
2023-06-14 10:45:55,506:INFO:Preloading libraries
2023-06-14 10:45:55,534:INFO:Copying training dataset
2023-06-14 10:45:55,534:INFO:Plot type: residuals
2023-06-14 10:45:55,624:INFO:Fitting Model
2023-06-14 10:45:55,624:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2023-06-14 10:45:55,744:INFO:Scoring test/hold-out set
2023-06-14 10:45:56,125:INFO:Visual Rendered Successfully
2023-06-14 10:45:56,241:INFO:plot_model() successfully completed......................................
2023-06-14 10:46:00,329:INFO:Initializing plot_model()
2023-06-14 10:46:00,329:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8CE0E06D0>, system=True)
2023-06-14 10:46:00,329:INFO:Checking exceptions
2023-06-14 10:46:00,353:INFO:Preloading libraries
2023-06-14 10:46:00,379:INFO:Copying training dataset
2023-06-14 10:46:00,379:INFO:Plot type: error
2023-06-14 10:46:00,448:INFO:Fitting Model
2023-06-14 10:46:00,448:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2023-06-14 10:46:00,448:INFO:Scoring test/hold-out set
2023-06-14 10:46:00,703:INFO:Visual Rendered Successfully
2023-06-14 10:46:00,817:INFO:plot_model() successfully completed......................................
2023-06-14 10:46:03,711:INFO:Initializing plot_model()
2023-06-14 10:46:03,712:INFO:plot_model(plot=cooks, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8CE0E06D0>, system=True)
2023-06-14 10:46:03,712:INFO:Checking exceptions
2023-06-14 10:46:03,736:INFO:Preloading libraries
2023-06-14 10:46:03,762:INFO:Copying training dataset
2023-06-14 10:46:03,762:INFO:Plot type: cooks
2023-06-14 10:46:03,830:INFO:Fitting Model
2023-06-14 10:46:04,099:INFO:Visual Rendered Successfully
2023-06-14 10:46:04,223:INFO:plot_model() successfully completed......................................
2023-06-14 10:46:06,943:INFO:Initializing plot_model()
2023-06-14 10:46:06,944:INFO:plot_model(plot=rfe, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8CE0E06D0>, system=True)
2023-06-14 10:46:06,944:INFO:Checking exceptions
2023-06-14 10:46:06,973:INFO:Preloading libraries
2023-06-14 10:46:07,000:INFO:Copying training dataset
2023-06-14 10:46:07,000:INFO:Plot type: rfe
2023-06-14 10:46:07,069:INFO:Fitting Model
2023-06-14 11:09:40,221:WARNING:exception calling callback for <Future at 0x1f8c361dfc0 state=finished raised TerminatedWorkerError>
2023-06-14 11:09:40,221:WARNING:Traceback (most recent call last):
2023-06-14 11:09:40,221:WARNING:  File "C:\Users\lapei\anaconda3\lib\site-packages\joblib\externals\loky\_base.py", line 26, in _invoke_callbacks
2023-06-14 11:09:40,221:WARNING:    callback(self)
2023-06-14 11:09:40,222:WARNING:  File "C:\Users\lapei\anaconda3\lib\site-packages\joblib\parallel.py", line 385, in __call__
2023-06-14 11:09:40,222:WARNING:    self.parallel.dispatch_next()
2023-06-14 11:09:40,222:WARNING:  File "C:\Users\lapei\anaconda3\lib\site-packages\joblib\parallel.py", line 834, in dispatch_next
2023-06-14 11:09:40,222:WARNING:    if not self.dispatch_one_batch(self._original_iterator):
2023-06-14 11:09:40,222:WARNING:  File "C:\Users\lapei\anaconda3\lib\site-packages\joblib\parallel.py", line 901, in dispatch_one_batch
2023-06-14 11:09:40,222:WARNING:    self._dispatch(tasks)
2023-06-14 11:09:40,222:WARNING:  File "C:\Users\lapei\anaconda3\lib\site-packages\joblib\parallel.py", line 819, in _dispatch
2023-06-14 11:09:40,222:WARNING:    job = self._backend.apply_async(batch, callback=cb)
2023-06-14 11:09:40,222:WARNING:  File "C:\Users\lapei\anaconda3\lib\site-packages\joblib\_parallel_backends.py", line 556, in apply_async
2023-06-14 11:09:40,222:WARNING:    future = self._workers.submit(SafeFunction(func))
2023-06-14 11:09:40,222:WARNING:  File "C:\Users\lapei\anaconda3\lib\site-packages\joblib\externals\loky\reusable_executor.py", line 176, in submit
2023-06-14 11:09:40,223:WARNING:    return super().submit(fn, *args, **kwargs)
2023-06-14 11:09:40,223:WARNING:  File "C:\Users\lapei\anaconda3\lib\site-packages\joblib\externals\loky\process_executor.py", line 1129, in submit
2023-06-14 11:09:40,223:WARNING:    raise self._flags.broken
2023-06-14 11:09:40,223:WARNING:joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.
2023-06-14 11:09:40,223:WARNING:
2023-06-14 11:11:14,281:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 11:11:14,282:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 11:11:14,282:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 11:11:14,282:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 11:11:15,437:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-14 11:11:31,996:INFO:PyCaret RegressionExperiment
2023-06-14 11:11:31,996:INFO:Logging name: reg-default-name
2023-06-14 11:11:31,996:INFO:ML Usecase: MLUsecase.REGRESSION
2023-06-14 11:11:31,996:INFO:version 3.0.2
2023-06-14 11:11:31,996:INFO:Initializing setup()
2023-06-14 11:11:31,996:INFO:self.USI: 832f
2023-06-14 11:11:31,996:INFO:self._variable_keys: {'exp_id', 'memory', 'n_jobs_param', 'log_plots_param', 'fold_groups_param', '_ml_usecase', 'y_train', 'y_test', 'pipeline', 'html_param', 'fold_generator', 'transform_target_param', 'USI', 'y', 'fold_shuffle_param', 'gpu_param', 'gpu_n_jobs_param', 'exp_name_log', 'target_param', 'idx', 'X_test', 'X_train', 'data', 'logging_param', 'seed', 'X', '_available_plots'}
2023-06-14 11:11:31,996:INFO:Checking environment
2023-06-14 11:11:31,997:INFO:python_version: 3.10.9
2023-06-14 11:11:31,997:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-06-14 11:11:31,997:INFO:machine: AMD64
2023-06-14 11:11:31,997:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-14 11:11:31,997:INFO:Memory: svmem(total=16901767168, available=6645096448, percent=60.7, used=10256670720, free=6645096448)
2023-06-14 11:11:31,997:INFO:Physical Core: 4
2023-06-14 11:11:31,997:INFO:Logical Core: 8
2023-06-14 11:11:31,997:INFO:Checking libraries
2023-06-14 11:11:31,997:INFO:System:
2023-06-14 11:11:31,997:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-06-14 11:11:31,997:INFO:executable: C:\Users\lapei\anaconda3\python.exe
2023-06-14 11:11:31,997:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-14 11:11:31,997:INFO:PyCaret required dependencies:
2023-06-14 11:11:31,997:INFO:                 pip: 22.3.1
2023-06-14 11:11:31,997:INFO:          setuptools: 65.6.3
2023-06-14 11:11:31,997:INFO:             pycaret: 3.0.2
2023-06-14 11:11:31,997:INFO:             IPython: 8.10.0
2023-06-14 11:11:31,997:INFO:          ipywidgets: 7.6.5
2023-06-14 11:11:31,997:INFO:                tqdm: 4.64.1
2023-06-14 11:11:31,997:INFO:               numpy: 1.23.5
2023-06-14 11:11:31,997:INFO:              pandas: 1.5.3
2023-06-14 11:11:31,997:INFO:              jinja2: 3.1.2
2023-06-14 11:11:31,997:INFO:               scipy: 1.10.0
2023-06-14 11:11:31,997:INFO:              joblib: 1.2.0
2023-06-14 11:11:31,997:INFO:             sklearn: 1.2.1
2023-06-14 11:11:31,998:INFO:                pyod: 1.0.9
2023-06-14 11:11:31,998:INFO:            imblearn: 0.10.1
2023-06-14 11:11:31,998:INFO:   category_encoders: 2.6.1
2023-06-14 11:11:31,998:INFO:            lightgbm: 3.3.5
2023-06-14 11:11:31,998:INFO:               numba: 0.56.4
2023-06-14 11:11:31,998:INFO:            requests: 2.28.1
2023-06-14 11:11:31,998:INFO:          matplotlib: 3.7.0
2023-06-14 11:11:31,998:INFO:          scikitplot: 0.3.7
2023-06-14 11:11:31,998:INFO:         yellowbrick: 1.5
2023-06-14 11:11:31,998:INFO:              plotly: 5.9.0
2023-06-14 11:11:31,998:INFO:             kaleido: 0.2.1
2023-06-14 11:11:31,998:INFO:         statsmodels: 0.13.5
2023-06-14 11:11:31,998:INFO:              sktime: 0.17.0
2023-06-14 11:11:31,998:INFO:               tbats: 1.1.3
2023-06-14 11:11:31,998:INFO:            pmdarima: 2.0.3
2023-06-14 11:11:31,998:INFO:              psutil: 5.9.0
2023-06-14 11:11:31,998:INFO:PyCaret optional dependencies:
2023-06-14 11:11:32,040:INFO:                shap: 0.41.0
2023-06-14 11:11:32,040:INFO:           interpret: Not installed
2023-06-14 11:11:32,040:INFO:                umap: Not installed
2023-06-14 11:11:32,040:INFO:    pandas_profiling: Not installed
2023-06-14 11:11:32,040:INFO:  explainerdashboard: Not installed
2023-06-14 11:11:32,040:INFO:             autoviz: Not installed
2023-06-14 11:11:32,040:INFO:           fairlearn: Not installed
2023-06-14 11:11:32,040:INFO:             xgboost: 1.7.3
2023-06-14 11:11:32,040:INFO:            catboost: Not installed
2023-06-14 11:11:32,040:INFO:              kmodes: Not installed
2023-06-14 11:11:32,040:INFO:             mlxtend: Not installed
2023-06-14 11:11:32,040:INFO:       statsforecast: Not installed
2023-06-14 11:11:32,040:INFO:        tune_sklearn: Not installed
2023-06-14 11:11:32,040:INFO:                 ray: Not installed
2023-06-14 11:11:32,040:INFO:            hyperopt: Not installed
2023-06-14 11:11:32,040:INFO:              optuna: Not installed
2023-06-14 11:11:32,040:INFO:               skopt: 0.9.0
2023-06-14 11:11:32,040:INFO:              mlflow: Not installed
2023-06-14 11:11:32,040:INFO:              gradio: Not installed
2023-06-14 11:11:32,040:INFO:             fastapi: Not installed
2023-06-14 11:11:32,040:INFO:             uvicorn: Not installed
2023-06-14 11:11:32,040:INFO:              m2cgen: Not installed
2023-06-14 11:11:32,041:INFO:           evidently: Not installed
2023-06-14 11:11:32,041:INFO:               fugue: Not installed
2023-06-14 11:11:32,041:INFO:           streamlit: Not installed
2023-06-14 11:11:32,041:INFO:             prophet: Not installed
2023-06-14 11:11:32,041:INFO:None
2023-06-14 11:11:32,041:INFO:Set up data.
2023-06-14 11:11:32,049:INFO:Set up train/test split.
2023-06-14 11:11:32,053:INFO:Set up index.
2023-06-14 11:11:32,053:INFO:Set up folding strategy.
2023-06-14 11:11:32,053:INFO:Assigning column types.
2023-06-14 11:11:32,056:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-14 11:11:32,056:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-14 11:11:32,060:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 11:11:32,064:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 11:11:32,117:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 11:11:32,153:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 11:11:32,153:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 11:11:32,389:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 11:11:32,389:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-14 11:11:32,394:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 11:11:32,398:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 11:11:32,448:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 11:11:32,484:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 11:11:32,485:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 11:11:32,486:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 11:11:32,488:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-06-14 11:11:32,491:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 11:11:32,495:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 11:11:32,544:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 11:11:32,583:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 11:11:32,584:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 11:11:32,586:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 11:11:32,590:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 11:11:32,594:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 11:11:32,641:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 11:11:32,678:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 11:11:32,678:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 11:11:32,680:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 11:11:32,680:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-06-14 11:11:32,687:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 11:11:32,733:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 11:11:32,769:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 11:11:32,770:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 11:11:32,772:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 11:11:32,779:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 11:11:32,827:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 11:11:32,865:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 11:11:32,865:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 11:11:32,867:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 11:11:32,868:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-06-14 11:11:32,923:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 11:11:32,964:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 11:11:32,965:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 11:11:32,967:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 11:11:33,024:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 11:11:33,058:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 11:11:33,058:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 11:11:33,060:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 11:11:33,060:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-14 11:11:33,114:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 11:11:33,150:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 11:11:33,152:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 11:11:33,208:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 11:11:33,244:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 11:11:33,246:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 11:11:33,246:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-06-14 11:11:33,337:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 11:11:33,339:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 11:11:33,435:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 11:11:33,437:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 11:11:33,438:INFO:Preparing preprocessing pipeline...
2023-06-14 11:11:33,439:INFO:Set up simple imputation.
2023-06-14 11:11:33,440:INFO:Set up column name cleaning.
2023-06-14 11:11:33,465:INFO:Finished creating preprocessing pipeline.
2023-06-14 11:11:33,474:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\lapei\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['taxa_homicidio', 'RH_adm_dir',
                                             'densidade_banda_larga',
                                             'densidade_telefonia_movel',
                                             'qtd_cursos_engenharias',
                                             'qtd_cursos_negocios_direito',
                                             'media_notas_CN', 'media_notas_CH',
                                             'media_NU_NOTA_LC',
                                             'media_NU_NOTA_MT',
                                             'media_...
                                             'Isencao_ISSQN_Sim',
                                             'Isencao_Tx_Sim',
                                             'Cessao_terrenos_Sim',
                                             'Doacao_terrenos_Sim',
                                             'Outros_mecanismos_Sim',
                                             'ISH_Baixa', 'ISH_Máxima',
                                             'ISH_Média', 'ISH_Mínima'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-06-14 11:11:33,474:INFO:Creating final display dataframe.
2023-06-14 11:11:33,544:INFO:Setup _display_container:                     Description                              Value
0                    Session id                                 42
1                        Target  qtd_abertas_Empresario_Individual
2                   Target type                         Regression
3           Original data shape                         (4456, 30)
4        Transformed data shape                         (4456, 30)
5   Transformed train set shape                         (3119, 30)
6    Transformed test set shape                         (1337, 30)
7              Numeric features                                 29
8                    Preprocess                               True
9               Imputation type                             simple
10           Numeric imputation                               mean
11       Categorical imputation                               mode
12               Fold Generator                              KFold
13                  Fold Number                                 10
14                     CPU Jobs                                 -1
15                      Use GPU                              False
16               Log Experiment                              False
17              Experiment Name                   reg-default-name
18                          USI                               832f
2023-06-14 11:11:33,652:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 11:11:33,654:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 11:11:33,749:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 11:11:33,751:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 11:11:33,751:INFO:setup() successfully completed in 1.82s...............
2023-06-14 11:11:35,910:INFO:Initializing compare_models()
2023-06-14 11:11:35,910:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002261BA4F670>, include=None, fold=5, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002261BA4F670>, 'include': None, 'exclude': None, 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-06-14 11:11:35,911:INFO:Checking exceptions
2023-06-14 11:11:35,913:INFO:Preparing display monitor
2023-06-14 11:11:35,941:INFO:Initializing Linear Regression
2023-06-14 11:11:35,941:INFO:Total runtime is 0.0 minutes
2023-06-14 11:11:35,947:INFO:SubProcess create_model() called ==================================
2023-06-14 11:11:35,947:INFO:Initializing create_model()
2023-06-14 11:11:35,947:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002261BA4F670>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002261C325DE0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:11:35,947:INFO:Checking exceptions
2023-06-14 11:11:35,947:INFO:Importing libraries
2023-06-14 11:11:35,947:INFO:Copying training dataset
2023-06-14 11:11:35,952:INFO:Defining folds
2023-06-14 11:11:35,952:INFO:Declaring metric variables
2023-06-14 11:11:35,957:INFO:Importing untrained model
2023-06-14 11:11:35,959:INFO:Linear Regression Imported successfully
2023-06-14 11:11:35,966:INFO:Starting cross validation
2023-06-14 11:11:35,975:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:11:40,789:INFO:Calculating mean and std
2023-06-14 11:11:40,791:INFO:Creating metrics dataframe
2023-06-14 11:11:40,892:INFO:Uploading results into container
2023-06-14 11:11:40,892:INFO:Uploading model into container now
2023-06-14 11:11:40,893:INFO:_master_model_container: 1
2023-06-14 11:11:40,893:INFO:_display_container: 2
2023-06-14 11:11:40,893:INFO:LinearRegression(n_jobs=-1)
2023-06-14 11:11:40,893:INFO:create_model() successfully completed......................................
2023-06-14 11:11:40,987:INFO:SubProcess create_model() end ==================================
2023-06-14 11:11:40,987:INFO:Creating metrics dataframe
2023-06-14 11:11:40,996:INFO:Initializing Lasso Regression
2023-06-14 11:11:40,996:INFO:Total runtime is 0.0842615803082784 minutes
2023-06-14 11:11:41,000:INFO:SubProcess create_model() called ==================================
2023-06-14 11:11:41,000:INFO:Initializing create_model()
2023-06-14 11:11:41,000:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002261BA4F670>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002261C325DE0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:11:41,001:INFO:Checking exceptions
2023-06-14 11:11:41,001:INFO:Importing libraries
2023-06-14 11:11:41,001:INFO:Copying training dataset
2023-06-14 11:11:41,006:INFO:Defining folds
2023-06-14 11:11:41,006:INFO:Declaring metric variables
2023-06-14 11:11:41,010:INFO:Importing untrained model
2023-06-14 11:11:41,015:INFO:Lasso Regression Imported successfully
2023-06-14 11:11:41,022:INFO:Starting cross validation
2023-06-14 11:11:41,023:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:11:43,520:INFO:Calculating mean and std
2023-06-14 11:11:43,521:INFO:Creating metrics dataframe
2023-06-14 11:11:43,621:INFO:Uploading results into container
2023-06-14 11:11:43,621:INFO:Uploading model into container now
2023-06-14 11:11:43,622:INFO:_master_model_container: 2
2023-06-14 11:11:43,622:INFO:_display_container: 2
2023-06-14 11:11:43,622:INFO:Lasso(random_state=42)
2023-06-14 11:11:43,622:INFO:create_model() successfully completed......................................
2023-06-14 11:11:43,724:INFO:SubProcess create_model() end ==================================
2023-06-14 11:11:43,724:INFO:Creating metrics dataframe
2023-06-14 11:11:43,732:INFO:Initializing Ridge Regression
2023-06-14 11:11:43,732:INFO:Total runtime is 0.12984834909439086 minutes
2023-06-14 11:11:43,734:INFO:SubProcess create_model() called ==================================
2023-06-14 11:11:43,734:INFO:Initializing create_model()
2023-06-14 11:11:43,734:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002261BA4F670>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002261C325DE0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:11:43,734:INFO:Checking exceptions
2023-06-14 11:11:43,735:INFO:Importing libraries
2023-06-14 11:11:43,735:INFO:Copying training dataset
2023-06-14 11:11:43,741:INFO:Defining folds
2023-06-14 11:11:43,741:INFO:Declaring metric variables
2023-06-14 11:11:43,745:INFO:Importing untrained model
2023-06-14 11:11:43,748:INFO:Ridge Regression Imported successfully
2023-06-14 11:11:43,754:INFO:Starting cross validation
2023-06-14 11:11:43,755:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:11:44,152:INFO:Calculating mean and std
2023-06-14 11:11:44,153:INFO:Creating metrics dataframe
2023-06-14 11:11:44,267:INFO:Uploading results into container
2023-06-14 11:11:44,267:INFO:Uploading model into container now
2023-06-14 11:11:44,268:INFO:_master_model_container: 3
2023-06-14 11:11:44,268:INFO:_display_container: 2
2023-06-14 11:11:44,268:INFO:Ridge(random_state=42)
2023-06-14 11:11:44,268:INFO:create_model() successfully completed......................................
2023-06-14 11:11:44,362:INFO:SubProcess create_model() end ==================================
2023-06-14 11:11:44,362:INFO:Creating metrics dataframe
2023-06-14 11:11:44,370:INFO:Initializing Elastic Net
2023-06-14 11:11:44,370:INFO:Total runtime is 0.1404875874519348 minutes
2023-06-14 11:11:44,373:INFO:SubProcess create_model() called ==================================
2023-06-14 11:11:44,374:INFO:Initializing create_model()
2023-06-14 11:11:44,374:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002261BA4F670>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002261C325DE0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:11:44,374:INFO:Checking exceptions
2023-06-14 11:11:44,374:INFO:Importing libraries
2023-06-14 11:11:44,374:INFO:Copying training dataset
2023-06-14 11:11:44,379:INFO:Defining folds
2023-06-14 11:11:44,379:INFO:Declaring metric variables
2023-06-14 11:11:44,383:INFO:Importing untrained model
2023-06-14 11:11:44,386:INFO:Elastic Net Imported successfully
2023-06-14 11:11:44,391:INFO:Starting cross validation
2023-06-14 11:11:44,393:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:11:44,786:INFO:Calculating mean and std
2023-06-14 11:11:44,787:INFO:Creating metrics dataframe
2023-06-14 11:11:44,918:INFO:Uploading results into container
2023-06-14 11:11:44,920:INFO:Uploading model into container now
2023-06-14 11:11:44,920:INFO:_master_model_container: 4
2023-06-14 11:11:44,920:INFO:_display_container: 2
2023-06-14 11:11:44,920:INFO:ElasticNet(random_state=42)
2023-06-14 11:11:44,921:INFO:create_model() successfully completed......................................
2023-06-14 11:11:45,016:INFO:SubProcess create_model() end ==================================
2023-06-14 11:11:45,017:INFO:Creating metrics dataframe
2023-06-14 11:11:45,024:INFO:Initializing Least Angle Regression
2023-06-14 11:11:45,024:INFO:Total runtime is 0.1513920704523722 minutes
2023-06-14 11:11:45,028:INFO:SubProcess create_model() called ==================================
2023-06-14 11:11:45,028:INFO:Initializing create_model()
2023-06-14 11:11:45,028:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002261BA4F670>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002261C325DE0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:11:45,028:INFO:Checking exceptions
2023-06-14 11:11:45,028:INFO:Importing libraries
2023-06-14 11:11:45,028:INFO:Copying training dataset
2023-06-14 11:11:45,035:INFO:Defining folds
2023-06-14 11:11:45,036:INFO:Declaring metric variables
2023-06-14 11:11:45,039:INFO:Importing untrained model
2023-06-14 11:11:45,044:INFO:Least Angle Regression Imported successfully
2023-06-14 11:11:45,052:INFO:Starting cross validation
2023-06-14 11:11:45,054:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:11:45,456:INFO:Calculating mean and std
2023-06-14 11:11:45,457:INFO:Creating metrics dataframe
2023-06-14 11:11:45,561:INFO:Uploading results into container
2023-06-14 11:11:45,562:INFO:Uploading model into container now
2023-06-14 11:11:45,563:INFO:_master_model_container: 5
2023-06-14 11:11:45,563:INFO:_display_container: 2
2023-06-14 11:11:45,563:INFO:Lars(random_state=42)
2023-06-14 11:11:45,563:INFO:create_model() successfully completed......................................
2023-06-14 11:11:45,658:INFO:SubProcess create_model() end ==================================
2023-06-14 11:11:45,658:INFO:Creating metrics dataframe
2023-06-14 11:11:45,666:INFO:Initializing Lasso Least Angle Regression
2023-06-14 11:11:45,666:INFO:Total runtime is 0.1620875279108683 minutes
2023-06-14 11:11:45,668:INFO:SubProcess create_model() called ==================================
2023-06-14 11:11:45,669:INFO:Initializing create_model()
2023-06-14 11:11:45,669:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002261BA4F670>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002261C325DE0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:11:45,669:INFO:Checking exceptions
2023-06-14 11:11:45,669:INFO:Importing libraries
2023-06-14 11:11:45,669:INFO:Copying training dataset
2023-06-14 11:11:45,678:INFO:Defining folds
2023-06-14 11:11:45,678:INFO:Declaring metric variables
2023-06-14 11:11:45,682:INFO:Importing untrained model
2023-06-14 11:11:45,686:INFO:Lasso Least Angle Regression Imported successfully
2023-06-14 11:11:45,693:INFO:Starting cross validation
2023-06-14 11:11:45,695:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:11:46,072:INFO:Calculating mean and std
2023-06-14 11:11:46,073:INFO:Creating metrics dataframe
2023-06-14 11:11:46,205:INFO:Uploading results into container
2023-06-14 11:11:46,206:INFO:Uploading model into container now
2023-06-14 11:11:46,206:INFO:_master_model_container: 6
2023-06-14 11:11:46,207:INFO:_display_container: 2
2023-06-14 11:11:46,207:INFO:LassoLars(random_state=42)
2023-06-14 11:11:46,207:INFO:create_model() successfully completed......................................
2023-06-14 11:11:46,311:INFO:SubProcess create_model() end ==================================
2023-06-14 11:11:46,311:INFO:Creating metrics dataframe
2023-06-14 11:11:46,319:INFO:Initializing Orthogonal Matching Pursuit
2023-06-14 11:11:46,319:INFO:Total runtime is 0.1729745268821716 minutes
2023-06-14 11:11:46,321:INFO:SubProcess create_model() called ==================================
2023-06-14 11:11:46,322:INFO:Initializing create_model()
2023-06-14 11:11:46,322:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002261BA4F670>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002261C325DE0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:11:46,322:INFO:Checking exceptions
2023-06-14 11:11:46,322:INFO:Importing libraries
2023-06-14 11:11:46,322:INFO:Copying training dataset
2023-06-14 11:11:46,328:INFO:Defining folds
2023-06-14 11:11:46,328:INFO:Declaring metric variables
2023-06-14 11:11:46,332:INFO:Importing untrained model
2023-06-14 11:11:46,335:INFO:Orthogonal Matching Pursuit Imported successfully
2023-06-14 11:11:46,342:INFO:Starting cross validation
2023-06-14 11:11:46,343:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:11:46,722:INFO:Calculating mean and std
2023-06-14 11:11:46,723:INFO:Creating metrics dataframe
2023-06-14 11:11:46,849:INFO:Uploading results into container
2023-06-14 11:11:46,849:INFO:Uploading model into container now
2023-06-14 11:11:46,850:INFO:_master_model_container: 7
2023-06-14 11:11:46,850:INFO:_display_container: 2
2023-06-14 11:11:46,850:INFO:OrthogonalMatchingPursuit()
2023-06-14 11:11:46,850:INFO:create_model() successfully completed......................................
2023-06-14 11:11:46,940:INFO:SubProcess create_model() end ==================================
2023-06-14 11:11:46,941:INFO:Creating metrics dataframe
2023-06-14 11:11:46,949:INFO:Initializing Bayesian Ridge
2023-06-14 11:11:46,949:INFO:Total runtime is 0.18347322940826413 minutes
2023-06-14 11:11:46,951:INFO:SubProcess create_model() called ==================================
2023-06-14 11:11:46,952:INFO:Initializing create_model()
2023-06-14 11:11:46,952:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002261BA4F670>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002261C325DE0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:11:46,952:INFO:Checking exceptions
2023-06-14 11:11:46,952:INFO:Importing libraries
2023-06-14 11:11:46,952:INFO:Copying training dataset
2023-06-14 11:11:46,958:INFO:Defining folds
2023-06-14 11:11:46,958:INFO:Declaring metric variables
2023-06-14 11:11:46,963:INFO:Importing untrained model
2023-06-14 11:11:46,969:INFO:Bayesian Ridge Imported successfully
2023-06-14 11:11:46,976:INFO:Starting cross validation
2023-06-14 11:11:46,978:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:11:47,349:INFO:Calculating mean and std
2023-06-14 11:11:47,350:INFO:Creating metrics dataframe
2023-06-14 11:11:47,477:INFO:Uploading results into container
2023-06-14 11:11:47,478:INFO:Uploading model into container now
2023-06-14 11:11:47,479:INFO:_master_model_container: 8
2023-06-14 11:11:47,479:INFO:_display_container: 2
2023-06-14 11:11:47,479:INFO:BayesianRidge()
2023-06-14 11:11:47,479:INFO:create_model() successfully completed......................................
2023-06-14 11:11:47,572:INFO:SubProcess create_model() end ==================================
2023-06-14 11:11:47,572:INFO:Creating metrics dataframe
2023-06-14 11:11:47,581:INFO:Initializing Passive Aggressive Regressor
2023-06-14 11:11:47,581:INFO:Total runtime is 0.19400149583816526 minutes
2023-06-14 11:11:47,583:INFO:SubProcess create_model() called ==================================
2023-06-14 11:11:47,584:INFO:Initializing create_model()
2023-06-14 11:11:47,584:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002261BA4F670>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002261C325DE0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:11:47,584:INFO:Checking exceptions
2023-06-14 11:11:47,584:INFO:Importing libraries
2023-06-14 11:11:47,584:INFO:Copying training dataset
2023-06-14 11:11:47,589:INFO:Defining folds
2023-06-14 11:11:47,589:INFO:Declaring metric variables
2023-06-14 11:11:47,593:INFO:Importing untrained model
2023-06-14 11:11:47,599:INFO:Passive Aggressive Regressor Imported successfully
2023-06-14 11:11:47,606:INFO:Starting cross validation
2023-06-14 11:11:47,608:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:11:48,005:INFO:Calculating mean and std
2023-06-14 11:11:48,006:INFO:Creating metrics dataframe
2023-06-14 11:11:48,125:INFO:Uploading results into container
2023-06-14 11:11:48,126:INFO:Uploading model into container now
2023-06-14 11:11:48,126:INFO:_master_model_container: 9
2023-06-14 11:11:48,127:INFO:_display_container: 2
2023-06-14 11:11:48,127:INFO:PassiveAggressiveRegressor(random_state=42)
2023-06-14 11:11:48,127:INFO:create_model() successfully completed......................................
2023-06-14 11:11:48,218:INFO:SubProcess create_model() end ==================================
2023-06-14 11:11:48,218:INFO:Creating metrics dataframe
2023-06-14 11:11:48,229:INFO:Initializing Huber Regressor
2023-06-14 11:11:48,229:INFO:Total runtime is 0.20480485359827674 minutes
2023-06-14 11:11:48,232:INFO:SubProcess create_model() called ==================================
2023-06-14 11:11:48,232:INFO:Initializing create_model()
2023-06-14 11:11:48,232:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002261BA4F670>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002261C325DE0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:11:48,232:INFO:Checking exceptions
2023-06-14 11:11:48,232:INFO:Importing libraries
2023-06-14 11:11:48,233:INFO:Copying training dataset
2023-06-14 11:11:48,241:INFO:Defining folds
2023-06-14 11:11:48,241:INFO:Declaring metric variables
2023-06-14 11:11:48,246:INFO:Importing untrained model
2023-06-14 11:11:48,250:INFO:Huber Regressor Imported successfully
2023-06-14 11:11:48,257:INFO:Starting cross validation
2023-06-14 11:11:48,259:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:11:48,386:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 11:11:48,389:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 11:11:48,395:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 11:11:48,401:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 11:11:48,419:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 11:11:48,709:INFO:Calculating mean and std
2023-06-14 11:11:48,711:INFO:Creating metrics dataframe
2023-06-14 11:11:48,817:INFO:Uploading results into container
2023-06-14 11:11:48,818:INFO:Uploading model into container now
2023-06-14 11:11:48,818:INFO:_master_model_container: 10
2023-06-14 11:11:48,819:INFO:_display_container: 2
2023-06-14 11:11:48,819:INFO:HuberRegressor()
2023-06-14 11:11:48,819:INFO:create_model() successfully completed......................................
2023-06-14 11:11:48,912:INFO:SubProcess create_model() end ==================================
2023-06-14 11:11:48,912:INFO:Creating metrics dataframe
2023-06-14 11:11:48,921:INFO:Initializing K Neighbors Regressor
2023-06-14 11:11:48,921:INFO:Total runtime is 0.21633064746856687 minutes
2023-06-14 11:11:48,923:INFO:SubProcess create_model() called ==================================
2023-06-14 11:11:48,923:INFO:Initializing create_model()
2023-06-14 11:11:48,923:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002261BA4F670>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002261C325DE0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:11:48,924:INFO:Checking exceptions
2023-06-14 11:11:48,924:INFO:Importing libraries
2023-06-14 11:11:48,924:INFO:Copying training dataset
2023-06-14 11:11:48,928:INFO:Defining folds
2023-06-14 11:11:48,928:INFO:Declaring metric variables
2023-06-14 11:11:48,932:INFO:Importing untrained model
2023-06-14 11:11:48,937:INFO:K Neighbors Regressor Imported successfully
2023-06-14 11:11:48,943:INFO:Starting cross validation
2023-06-14 11:11:48,945:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:11:49,405:INFO:Calculating mean and std
2023-06-14 11:11:49,407:INFO:Creating metrics dataframe
2023-06-14 11:11:49,516:INFO:Uploading results into container
2023-06-14 11:11:49,517:INFO:Uploading model into container now
2023-06-14 11:11:49,517:INFO:_master_model_container: 11
2023-06-14 11:11:49,517:INFO:_display_container: 2
2023-06-14 11:11:49,517:INFO:KNeighborsRegressor(n_jobs=-1)
2023-06-14 11:11:49,518:INFO:create_model() successfully completed......................................
2023-06-14 11:11:49,610:INFO:SubProcess create_model() end ==================================
2023-06-14 11:11:49,611:INFO:Creating metrics dataframe
2023-06-14 11:11:49,620:INFO:Initializing Decision Tree Regressor
2023-06-14 11:11:49,620:INFO:Total runtime is 0.22799391746520994 minutes
2023-06-14 11:11:49,623:INFO:SubProcess create_model() called ==================================
2023-06-14 11:11:49,623:INFO:Initializing create_model()
2023-06-14 11:11:49,623:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002261BA4F670>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002261C325DE0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:11:49,623:INFO:Checking exceptions
2023-06-14 11:11:49,623:INFO:Importing libraries
2023-06-14 11:11:49,623:INFO:Copying training dataset
2023-06-14 11:11:49,629:INFO:Defining folds
2023-06-14 11:11:49,630:INFO:Declaring metric variables
2023-06-14 11:11:49,634:INFO:Importing untrained model
2023-06-14 11:11:49,641:INFO:Decision Tree Regressor Imported successfully
2023-06-14 11:11:49,650:INFO:Starting cross validation
2023-06-14 11:11:49,652:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:11:50,096:INFO:Calculating mean and std
2023-06-14 11:11:50,097:INFO:Creating metrics dataframe
2023-06-14 11:11:50,188:INFO:Uploading results into container
2023-06-14 11:11:50,189:INFO:Uploading model into container now
2023-06-14 11:11:50,189:INFO:_master_model_container: 12
2023-06-14 11:11:50,189:INFO:_display_container: 2
2023-06-14 11:11:50,189:INFO:DecisionTreeRegressor(random_state=42)
2023-06-14 11:11:50,191:INFO:create_model() successfully completed......................................
2023-06-14 11:11:50,280:INFO:SubProcess create_model() end ==================================
2023-06-14 11:11:50,280:INFO:Creating metrics dataframe
2023-06-14 11:11:50,289:INFO:Initializing Random Forest Regressor
2023-06-14 11:11:50,289:INFO:Total runtime is 0.23914226293563842 minutes
2023-06-14 11:11:50,293:INFO:SubProcess create_model() called ==================================
2023-06-14 11:11:50,293:INFO:Initializing create_model()
2023-06-14 11:11:50,294:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002261BA4F670>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002261C325DE0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:11:50,294:INFO:Checking exceptions
2023-06-14 11:11:50,294:INFO:Importing libraries
2023-06-14 11:11:50,294:INFO:Copying training dataset
2023-06-14 11:11:50,299:INFO:Defining folds
2023-06-14 11:11:50,299:INFO:Declaring metric variables
2023-06-14 11:11:50,303:INFO:Importing untrained model
2023-06-14 11:11:50,306:INFO:Random Forest Regressor Imported successfully
2023-06-14 11:11:50,313:INFO:Starting cross validation
2023-06-14 11:11:50,314:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:11:50,875:INFO:Calculating mean and std
2023-06-14 11:11:50,877:INFO:Creating metrics dataframe
2023-06-14 11:11:50,974:INFO:Uploading results into container
2023-06-14 11:11:50,975:INFO:Uploading model into container now
2023-06-14 11:11:50,975:INFO:_master_model_container: 13
2023-06-14 11:11:50,975:INFO:_display_container: 2
2023-06-14 11:11:50,976:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-14 11:11:50,976:INFO:create_model() successfully completed......................................
2023-06-14 11:11:51,064:INFO:SubProcess create_model() end ==================================
2023-06-14 11:11:51,064:INFO:Creating metrics dataframe
2023-06-14 11:11:51,073:INFO:Initializing Extra Trees Regressor
2023-06-14 11:11:51,074:INFO:Total runtime is 0.2522276600201925 minutes
2023-06-14 11:11:51,079:INFO:SubProcess create_model() called ==================================
2023-06-14 11:11:51,079:INFO:Initializing create_model()
2023-06-14 11:11:51,079:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002261BA4F670>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002261C325DE0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:11:51,079:INFO:Checking exceptions
2023-06-14 11:11:51,079:INFO:Importing libraries
2023-06-14 11:11:51,079:INFO:Copying training dataset
2023-06-14 11:11:51,084:INFO:Defining folds
2023-06-14 11:11:51,085:INFO:Declaring metric variables
2023-06-14 11:11:51,089:INFO:Importing untrained model
2023-06-14 11:11:51,095:INFO:Extra Trees Regressor Imported successfully
2023-06-14 11:11:51,104:INFO:Starting cross validation
2023-06-14 11:11:51,105:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:11:51,711:INFO:Calculating mean and std
2023-06-14 11:11:51,711:INFO:Creating metrics dataframe
2023-06-14 11:11:51,821:INFO:Uploading results into container
2023-06-14 11:11:51,822:INFO:Uploading model into container now
2023-06-14 11:11:51,822:INFO:_master_model_container: 14
2023-06-14 11:11:51,822:INFO:_display_container: 2
2023-06-14 11:11:51,822:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2023-06-14 11:11:51,822:INFO:create_model() successfully completed......................................
2023-06-14 11:11:51,929:INFO:SubProcess create_model() end ==================================
2023-06-14 11:11:51,929:INFO:Creating metrics dataframe
2023-06-14 11:11:51,942:INFO:Initializing AdaBoost Regressor
2023-06-14 11:11:51,942:INFO:Total runtime is 0.2666911760965983 minutes
2023-06-14 11:11:51,947:INFO:SubProcess create_model() called ==================================
2023-06-14 11:11:51,947:INFO:Initializing create_model()
2023-06-14 11:11:51,947:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002261BA4F670>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002261C325DE0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:11:51,947:INFO:Checking exceptions
2023-06-14 11:11:51,947:INFO:Importing libraries
2023-06-14 11:11:51,948:INFO:Copying training dataset
2023-06-14 11:11:51,953:INFO:Defining folds
2023-06-14 11:11:51,953:INFO:Declaring metric variables
2023-06-14 11:11:51,956:INFO:Importing untrained model
2023-06-14 11:11:51,960:INFO:AdaBoost Regressor Imported successfully
2023-06-14 11:11:51,966:INFO:Starting cross validation
2023-06-14 11:11:51,967:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:11:52,431:INFO:Calculating mean and std
2023-06-14 11:11:52,432:INFO:Creating metrics dataframe
2023-06-14 11:11:52,552:INFO:Uploading results into container
2023-06-14 11:11:52,553:INFO:Uploading model into container now
2023-06-14 11:11:52,554:INFO:_master_model_container: 15
2023-06-14 11:11:52,554:INFO:_display_container: 2
2023-06-14 11:11:52,554:INFO:AdaBoostRegressor(random_state=42)
2023-06-14 11:11:52,554:INFO:create_model() successfully completed......................................
2023-06-14 11:11:52,655:INFO:SubProcess create_model() end ==================================
2023-06-14 11:11:52,656:INFO:Creating metrics dataframe
2023-06-14 11:11:52,666:INFO:Initializing Gradient Boosting Regressor
2023-06-14 11:11:52,666:INFO:Total runtime is 0.27874977588653566 minutes
2023-06-14 11:11:52,668:INFO:SubProcess create_model() called ==================================
2023-06-14 11:11:52,669:INFO:Initializing create_model()
2023-06-14 11:11:52,669:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002261BA4F670>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002261C325DE0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:11:52,669:INFO:Checking exceptions
2023-06-14 11:11:52,669:INFO:Importing libraries
2023-06-14 11:11:52,669:INFO:Copying training dataset
2023-06-14 11:11:52,676:INFO:Defining folds
2023-06-14 11:11:52,676:INFO:Declaring metric variables
2023-06-14 11:11:52,681:INFO:Importing untrained model
2023-06-14 11:11:52,686:INFO:Gradient Boosting Regressor Imported successfully
2023-06-14 11:11:52,692:INFO:Starting cross validation
2023-06-14 11:11:52,693:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:11:53,169:INFO:Calculating mean and std
2023-06-14 11:11:53,170:INFO:Creating metrics dataframe
2023-06-14 11:11:53,293:INFO:Uploading results into container
2023-06-14 11:11:53,294:INFO:Uploading model into container now
2023-06-14 11:11:53,294:INFO:_master_model_container: 16
2023-06-14 11:11:53,294:INFO:_display_container: 2
2023-06-14 11:11:53,295:INFO:GradientBoostingRegressor(random_state=42)
2023-06-14 11:11:53,295:INFO:create_model() successfully completed......................................
2023-06-14 11:11:53,394:INFO:SubProcess create_model() end ==================================
2023-06-14 11:11:53,395:INFO:Creating metrics dataframe
2023-06-14 11:11:53,407:INFO:Initializing Extreme Gradient Boosting
2023-06-14 11:11:53,407:INFO:Total runtime is 0.2911095221837362 minutes
2023-06-14 11:11:53,411:INFO:SubProcess create_model() called ==================================
2023-06-14 11:11:53,412:INFO:Initializing create_model()
2023-06-14 11:11:53,412:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002261BA4F670>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002261C325DE0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:11:53,412:INFO:Checking exceptions
2023-06-14 11:11:53,412:INFO:Importing libraries
2023-06-14 11:11:53,412:INFO:Copying training dataset
2023-06-14 11:11:53,418:INFO:Defining folds
2023-06-14 11:11:53,418:INFO:Declaring metric variables
2023-06-14 11:11:53,421:INFO:Importing untrained model
2023-06-14 11:11:53,426:INFO:Extreme Gradient Boosting Imported successfully
2023-06-14 11:11:53,434:INFO:Starting cross validation
2023-06-14 11:11:53,435:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:11:53,903:INFO:Calculating mean and std
2023-06-14 11:11:53,904:INFO:Creating metrics dataframe
2023-06-14 11:11:54,011:INFO:Uploading results into container
2023-06-14 11:11:54,012:INFO:Uploading model into container now
2023-06-14 11:11:54,012:INFO:_master_model_container: 17
2023-06-14 11:11:54,012:INFO:_display_container: 2
2023-06-14 11:11:54,013:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=42, ...)
2023-06-14 11:11:54,013:INFO:create_model() successfully completed......................................
2023-06-14 11:11:54,105:INFO:SubProcess create_model() end ==================================
2023-06-14 11:11:54,105:INFO:Creating metrics dataframe
2023-06-14 11:11:54,120:INFO:Initializing Light Gradient Boosting Machine
2023-06-14 11:11:54,120:INFO:Total runtime is 0.30298427343368534 minutes
2023-06-14 11:11:54,122:INFO:SubProcess create_model() called ==================================
2023-06-14 11:11:54,122:INFO:Initializing create_model()
2023-06-14 11:11:54,122:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002261BA4F670>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002261C325DE0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:11:54,122:INFO:Checking exceptions
2023-06-14 11:11:54,122:INFO:Importing libraries
2023-06-14 11:11:54,122:INFO:Copying training dataset
2023-06-14 11:11:54,130:INFO:Defining folds
2023-06-14 11:11:54,130:INFO:Declaring metric variables
2023-06-14 11:11:54,135:INFO:Importing untrained model
2023-06-14 11:11:54,138:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-14 11:11:54,147:INFO:Starting cross validation
2023-06-14 11:11:54,148:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:11:55,556:INFO:Calculating mean and std
2023-06-14 11:11:55,558:INFO:Creating metrics dataframe
2023-06-14 11:11:55,677:INFO:Uploading results into container
2023-06-14 11:11:55,677:INFO:Uploading model into container now
2023-06-14 11:11:55,678:INFO:_master_model_container: 18
2023-06-14 11:11:55,678:INFO:_display_container: 2
2023-06-14 11:11:55,678:INFO:LGBMRegressor(random_state=42)
2023-06-14 11:11:55,679:INFO:create_model() successfully completed......................................
2023-06-14 11:11:55,776:INFO:SubProcess create_model() end ==================================
2023-06-14 11:11:55,777:INFO:Creating metrics dataframe
2023-06-14 11:11:55,790:INFO:Initializing Dummy Regressor
2023-06-14 11:11:55,790:INFO:Total runtime is 0.3308147788047791 minutes
2023-06-14 11:11:55,793:INFO:SubProcess create_model() called ==================================
2023-06-14 11:11:55,794:INFO:Initializing create_model()
2023-06-14 11:11:55,794:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002261BA4F670>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002261C325DE0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:11:55,794:INFO:Checking exceptions
2023-06-14 11:11:55,794:INFO:Importing libraries
2023-06-14 11:11:55,794:INFO:Copying training dataset
2023-06-14 11:11:55,801:INFO:Defining folds
2023-06-14 11:11:55,802:INFO:Declaring metric variables
2023-06-14 11:11:55,805:INFO:Importing untrained model
2023-06-14 11:11:55,807:INFO:Dummy Regressor Imported successfully
2023-06-14 11:11:55,813:INFO:Starting cross validation
2023-06-14 11:11:55,815:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:11:56,212:INFO:Calculating mean and std
2023-06-14 11:11:56,213:INFO:Creating metrics dataframe
2023-06-14 11:11:56,331:INFO:Uploading results into container
2023-06-14 11:11:56,332:INFO:Uploading model into container now
2023-06-14 11:11:56,332:INFO:_master_model_container: 19
2023-06-14 11:11:56,332:INFO:_display_container: 2
2023-06-14 11:11:56,332:INFO:DummyRegressor()
2023-06-14 11:11:56,332:INFO:create_model() successfully completed......................................
2023-06-14 11:11:56,430:INFO:SubProcess create_model() end ==================================
2023-06-14 11:11:56,430:INFO:Creating metrics dataframe
2023-06-14 11:11:56,452:INFO:Initializing create_model()
2023-06-14 11:11:56,452:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002261BA4F670>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:11:56,452:INFO:Checking exceptions
2023-06-14 11:11:56,454:INFO:Importing libraries
2023-06-14 11:11:56,454:INFO:Copying training dataset
2023-06-14 11:11:56,458:INFO:Defining folds
2023-06-14 11:11:56,458:INFO:Declaring metric variables
2023-06-14 11:11:56,459:INFO:Importing untrained model
2023-06-14 11:11:56,459:INFO:Declaring custom model
2023-06-14 11:11:56,460:INFO:Random Forest Regressor Imported successfully
2023-06-14 11:11:56,461:INFO:Cross validation set to False
2023-06-14 11:11:56,461:INFO:Fitting Model
2023-06-14 11:11:56,607:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-14 11:11:56,607:INFO:create_model() successfully completed......................................
2023-06-14 11:11:56,729:INFO:_master_model_container: 19
2023-06-14 11:11:56,729:INFO:_display_container: 2
2023-06-14 11:11:56,729:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-14 11:11:56,730:INFO:compare_models() successfully completed......................................
2023-06-14 11:12:00,861:INFO:Initializing create_model()
2023-06-14 11:12:00,861:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002261BA4F670>, estimator=rf, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:12:00,862:INFO:Checking exceptions
2023-06-14 11:12:00,880:INFO:Importing libraries
2023-06-14 11:12:00,880:INFO:Copying training dataset
2023-06-14 11:12:00,888:INFO:Defining folds
2023-06-14 11:12:00,889:INFO:Declaring metric variables
2023-06-14 11:12:00,892:INFO:Importing untrained model
2023-06-14 11:12:00,897:INFO:Random Forest Regressor Imported successfully
2023-06-14 11:12:00,907:INFO:Starting cross validation
2023-06-14 11:12:00,908:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:12:01,419:INFO:Calculating mean and std
2023-06-14 11:12:01,419:INFO:Creating metrics dataframe
2023-06-14 11:12:01,425:INFO:Finalizing model
2023-06-14 11:12:01,610:INFO:Uploading results into container
2023-06-14 11:12:01,611:INFO:Uploading model into container now
2023-06-14 11:12:01,617:INFO:_master_model_container: 20
2023-06-14 11:12:01,617:INFO:_display_container: 3
2023-06-14 11:12:01,618:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-14 11:12:01,618:INFO:create_model() successfully completed......................................
2023-06-14 11:12:19,509:INFO:Initializing tune_model()
2023-06-14 11:12:19,509:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=5, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002261BA4F670>)
2023-06-14 11:12:19,509:INFO:Checking exceptions
2023-06-14 11:12:19,533:INFO:Copying training dataset
2023-06-14 11:12:19,539:INFO:Checking base model
2023-06-14 11:12:19,540:INFO:Base model : Random Forest Regressor
2023-06-14 11:12:19,545:INFO:Declaring metric variables
2023-06-14 11:12:19,549:INFO:Defining Hyperparameters
2023-06-14 11:12:19,644:INFO:Tuning with n_jobs=-1
2023-06-14 11:12:19,644:INFO:Initializing RandomizedSearchCV
2023-06-14 11:12:24,650:INFO:best_params: {'actual_estimator__n_estimators': 190, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 4, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': True}
2023-06-14 11:12:24,651:INFO:Hyperparameter search completed
2023-06-14 11:12:24,651:INFO:SubProcess create_model() called ==================================
2023-06-14 11:12:24,651:INFO:Initializing create_model()
2023-06-14 11:12:24,651:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002261BA4F670>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002261B9DD4E0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 190, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.3, 'max_features': 1.0, 'max_depth': 4, 'criterion': 'squared_error', 'bootstrap': True})
2023-06-14 11:12:24,651:INFO:Checking exceptions
2023-06-14 11:12:24,651:INFO:Importing libraries
2023-06-14 11:12:24,651:INFO:Copying training dataset
2023-06-14 11:12:24,658:INFO:Defining folds
2023-06-14 11:12:24,658:INFO:Declaring metric variables
2023-06-14 11:12:24,660:INFO:Importing untrained model
2023-06-14 11:12:24,661:INFO:Declaring custom model
2023-06-14 11:12:24,664:INFO:Random Forest Regressor Imported successfully
2023-06-14 11:12:24,671:INFO:Starting cross validation
2023-06-14 11:12:24,672:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:12:25,197:INFO:Calculating mean and std
2023-06-14 11:12:25,198:INFO:Creating metrics dataframe
2023-06-14 11:12:25,202:INFO:Finalizing model
2023-06-14 11:12:25,373:INFO:Uploading results into container
2023-06-14 11:12:25,373:INFO:Uploading model into container now
2023-06-14 11:12:25,374:INFO:_master_model_container: 21
2023-06-14 11:12:25,374:INFO:_display_container: 4
2023-06-14 11:12:25,374:INFO:RandomForestRegressor(max_depth=4, min_impurity_decrease=0.3,
                      min_samples_leaf=2, n_estimators=190, n_jobs=-1,
                      random_state=42)
2023-06-14 11:12:25,375:INFO:create_model() successfully completed......................................
2023-06-14 11:12:25,468:INFO:SubProcess create_model() end ==================================
2023-06-14 11:12:25,468:INFO:choose_better activated
2023-06-14 11:12:25,471:INFO:SubProcess create_model() called ==================================
2023-06-14 11:12:25,471:INFO:Initializing create_model()
2023-06-14 11:12:25,471:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002261BA4F670>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:12:25,471:INFO:Checking exceptions
2023-06-14 11:12:25,472:INFO:Importing libraries
2023-06-14 11:12:25,472:INFO:Copying training dataset
2023-06-14 11:12:25,477:INFO:Defining folds
2023-06-14 11:12:25,477:INFO:Declaring metric variables
2023-06-14 11:12:25,477:INFO:Importing untrained model
2023-06-14 11:12:25,477:INFO:Declaring custom model
2023-06-14 11:12:25,477:INFO:Random Forest Regressor Imported successfully
2023-06-14 11:12:25,478:INFO:Starting cross validation
2023-06-14 11:12:25,478:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:12:25,978:INFO:Calculating mean and std
2023-06-14 11:12:25,978:INFO:Creating metrics dataframe
2023-06-14 11:12:25,980:INFO:Finalizing model
2023-06-14 11:12:26,133:INFO:Uploading results into container
2023-06-14 11:12:26,134:INFO:Uploading model into container now
2023-06-14 11:12:26,134:INFO:_master_model_container: 22
2023-06-14 11:12:26,134:INFO:_display_container: 5
2023-06-14 11:12:26,135:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-14 11:12:26,135:INFO:create_model() successfully completed......................................
2023-06-14 11:12:26,226:INFO:SubProcess create_model() end ==================================
2023-06-14 11:12:26,227:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) result for R2 is 0.9102
2023-06-14 11:12:26,228:INFO:RandomForestRegressor(max_depth=4, min_impurity_decrease=0.3,
                      min_samples_leaf=2, n_estimators=190, n_jobs=-1,
                      random_state=42) result for R2 is 0.8871
2023-06-14 11:12:26,228:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) is best model
2023-06-14 11:12:26,228:INFO:choose_better completed
2023-06-14 11:12:26,228:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-06-14 11:12:26,235:INFO:_master_model_container: 22
2023-06-14 11:12:26,235:INFO:_display_container: 4
2023-06-14 11:12:26,237:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-14 11:12:26,237:INFO:tune_model() successfully completed......................................
2023-06-14 11:12:53,665:INFO:Initializing create_model()
2023-06-14 11:12:53,665:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002261BA4F670>, estimator=rf, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:12:53,665:INFO:Checking exceptions
2023-06-14 11:12:53,683:INFO:Importing libraries
2023-06-14 11:12:53,683:INFO:Copying training dataset
2023-06-14 11:12:53,694:INFO:Defining folds
2023-06-14 11:12:53,694:INFO:Declaring metric variables
2023-06-14 11:12:53,698:INFO:Importing untrained model
2023-06-14 11:12:53,703:INFO:Random Forest Regressor Imported successfully
2023-06-14 11:12:53,712:INFO:Starting cross validation
2023-06-14 11:12:53,712:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:12:54,200:INFO:Calculating mean and std
2023-06-14 11:12:54,201:INFO:Creating metrics dataframe
2023-06-14 11:12:54,205:INFO:Finalizing model
2023-06-14 11:12:54,382:INFO:Uploading results into container
2023-06-14 11:12:54,382:INFO:Uploading model into container now
2023-06-14 11:12:54,388:INFO:_master_model_container: 23
2023-06-14 11:12:54,388:INFO:_display_container: 5
2023-06-14 11:12:54,389:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-14 11:12:54,389:INFO:create_model() successfully completed......................................
2023-06-14 11:13:02,303:INFO:Initializing tune_model()
2023-06-14 11:13:02,303:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=5, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002261BA4F670>)
2023-06-14 11:13:02,303:INFO:Checking exceptions
2023-06-14 11:13:02,326:INFO:Copying training dataset
2023-06-14 11:13:02,332:INFO:Checking base model
2023-06-14 11:13:02,332:INFO:Base model : Random Forest Regressor
2023-06-14 11:13:02,337:INFO:Declaring metric variables
2023-06-14 11:13:02,340:INFO:Defining Hyperparameters
2023-06-14 11:13:02,433:INFO:Tuning with n_jobs=-1
2023-06-14 11:13:02,433:INFO:Initializing RandomizedSearchCV
2023-06-14 11:13:07,200:INFO:best_params: {'actual_estimator__n_estimators': 190, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 4, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': True}
2023-06-14 11:13:07,201:INFO:Hyperparameter search completed
2023-06-14 11:13:07,201:INFO:SubProcess create_model() called ==================================
2023-06-14 11:13:07,202:INFO:Initializing create_model()
2023-06-14 11:13:07,202:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002261BA4F670>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002261BA12D70>, model_only=True, return_train_score=False, kwargs={'n_estimators': 190, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.3, 'max_features': 1.0, 'max_depth': 4, 'criterion': 'squared_error', 'bootstrap': True})
2023-06-14 11:13:07,202:INFO:Checking exceptions
2023-06-14 11:13:07,202:INFO:Importing libraries
2023-06-14 11:13:07,202:INFO:Copying training dataset
2023-06-14 11:13:07,210:INFO:Defining folds
2023-06-14 11:13:07,210:INFO:Declaring metric variables
2023-06-14 11:13:07,212:INFO:Importing untrained model
2023-06-14 11:13:07,212:INFO:Declaring custom model
2023-06-14 11:13:07,217:INFO:Random Forest Regressor Imported successfully
2023-06-14 11:13:07,223:INFO:Starting cross validation
2023-06-14 11:13:07,226:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:13:07,774:INFO:Calculating mean and std
2023-06-14 11:13:07,775:INFO:Creating metrics dataframe
2023-06-14 11:13:07,781:INFO:Finalizing model
2023-06-14 11:13:07,936:INFO:Uploading results into container
2023-06-14 11:13:07,936:INFO:Uploading model into container now
2023-06-14 11:13:07,937:INFO:_master_model_container: 24
2023-06-14 11:13:07,937:INFO:_display_container: 6
2023-06-14 11:13:07,938:INFO:RandomForestRegressor(max_depth=4, min_impurity_decrease=0.3,
                      min_samples_leaf=2, n_estimators=190, n_jobs=-1,
                      random_state=42)
2023-06-14 11:13:07,938:INFO:create_model() successfully completed......................................
2023-06-14 11:13:08,040:INFO:SubProcess create_model() end ==================================
2023-06-14 11:13:08,040:INFO:choose_better activated
2023-06-14 11:13:08,043:INFO:SubProcess create_model() called ==================================
2023-06-14 11:13:08,043:INFO:Initializing create_model()
2023-06-14 11:13:08,043:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002261BA4F670>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:13:08,043:INFO:Checking exceptions
2023-06-14 11:13:08,045:INFO:Importing libraries
2023-06-14 11:13:08,046:INFO:Copying training dataset
2023-06-14 11:13:08,050:INFO:Defining folds
2023-06-14 11:13:08,050:INFO:Declaring metric variables
2023-06-14 11:13:08,050:INFO:Importing untrained model
2023-06-14 11:13:08,050:INFO:Declaring custom model
2023-06-14 11:13:08,051:INFO:Random Forest Regressor Imported successfully
2023-06-14 11:13:08,051:INFO:Starting cross validation
2023-06-14 11:13:08,051:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:13:08,545:INFO:Calculating mean and std
2023-06-14 11:13:08,545:INFO:Creating metrics dataframe
2023-06-14 11:13:08,547:INFO:Finalizing model
2023-06-14 11:13:08,714:INFO:Uploading results into container
2023-06-14 11:13:08,715:INFO:Uploading model into container now
2023-06-14 11:13:08,715:INFO:_master_model_container: 25
2023-06-14 11:13:08,715:INFO:_display_container: 7
2023-06-14 11:13:08,715:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-14 11:13:08,715:INFO:create_model() successfully completed......................................
2023-06-14 11:13:08,809:INFO:SubProcess create_model() end ==================================
2023-06-14 11:13:08,810:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) result for R2 is 0.9102
2023-06-14 11:13:08,810:INFO:RandomForestRegressor(max_depth=4, min_impurity_decrease=0.3,
                      min_samples_leaf=2, n_estimators=190, n_jobs=-1,
                      random_state=42) result for R2 is 0.8871
2023-06-14 11:13:08,811:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) is best model
2023-06-14 11:13:08,811:INFO:choose_better completed
2023-06-14 11:13:08,811:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-06-14 11:13:08,819:INFO:_master_model_container: 25
2023-06-14 11:13:08,819:INFO:_display_container: 6
2023-06-14 11:13:08,820:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-14 11:13:08,820:INFO:tune_model() successfully completed......................................
2023-06-14 11:13:50,541:INFO:Initializing interpret_model()
2023-06-14 11:13:50,542:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=pdp, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002261BA4F670>)
2023-06-14 11:13:50,542:INFO:Checking exceptions
2023-06-14 11:13:50,542:ERROR:
'interpret' is a soft dependency and not included in the pycaret installation. Please run: `pip install interpret` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2023-06-14 11:15:55,084:INFO:Initializing evaluate_model()
2023-06-14 11:15:55,084:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002261BA4F670>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-06-14 11:15:55,103:INFO:Initializing plot_model()
2023-06-14 11:15:55,103:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002261BA4F670>, system=True)
2023-06-14 11:15:55,104:INFO:Checking exceptions
2023-06-14 11:15:55,135:INFO:Preloading libraries
2023-06-14 11:15:55,159:INFO:Copying training dataset
2023-06-14 11:15:55,159:INFO:Plot type: pipeline
2023-06-14 11:15:55,281:INFO:Visual Rendered Successfully
2023-06-14 11:15:55,426:INFO:plot_model() successfully completed......................................
2023-06-14 11:15:57,262:INFO:Initializing plot_model()
2023-06-14 11:15:57,262:INFO:plot_model(plot=feature_all, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002261BA4F670>, system=True)
2023-06-14 11:15:57,262:INFO:Checking exceptions
2023-06-14 11:15:57,286:INFO:Preloading libraries
2023-06-14 11:15:57,308:INFO:Copying training dataset
2023-06-14 11:15:57,308:INFO:Plot type: feature_all
2023-06-14 11:15:57,326:WARNING:No coef_ found. Trying feature_importances_
2023-06-14 11:15:57,580:INFO:Visual Rendered Successfully
2023-06-14 11:15:57,700:INFO:plot_model() successfully completed......................................
2023-06-14 11:15:59,373:INFO:Initializing plot_model()
2023-06-14 11:15:59,373:INFO:plot_model(plot=tree, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002261BA4F670>, system=True)
2023-06-14 11:15:59,374:INFO:Checking exceptions
2023-06-14 11:15:59,397:INFO:Preloading libraries
2023-06-14 11:15:59,421:INFO:Copying training dataset
2023-06-14 11:15:59,421:INFO:Plot type: tree
2023-06-14 11:16:00,654:INFO:Plotting decision trees
2023-06-14 11:16:00,672:INFO:Plotting tree 0
2023-06-14 11:16:07,934:INFO:Plotting tree 1
2023-06-14 11:16:14,908:INFO:Plotting tree 2
2023-06-14 11:16:22,103:INFO:Plotting tree 3
2023-06-14 11:16:28,883:INFO:Plotting tree 4
2023-06-14 11:16:35,847:INFO:Plotting tree 5
2023-06-14 11:16:42,783:INFO:Plotting tree 6
2023-06-14 11:16:50,050:INFO:Plotting tree 7
2023-06-14 11:16:57,128:INFO:Plotting tree 8
2023-06-14 11:17:04,738:INFO:Plotting tree 9
2023-06-14 11:17:11,813:INFO:Plotting tree 10
2023-06-14 11:17:18,760:INFO:Plotting tree 11
2023-06-14 11:17:26,407:INFO:Plotting tree 12
2023-06-14 11:17:33,879:INFO:Plotting tree 13
2023-06-14 11:17:41,203:INFO:Plotting tree 14
2023-06-14 11:17:48,902:INFO:Plotting tree 15
2023-06-14 11:17:55,642:INFO:Plotting tree 16
2023-06-14 11:18:02,412:INFO:Plotting tree 17
2023-06-14 11:18:09,363:INFO:Plotting tree 18
2023-06-14 11:18:17,063:INFO:Plotting tree 19
2023-06-14 11:18:24,010:INFO:Plotting tree 20
2023-06-14 11:18:30,982:INFO:Plotting tree 21
2023-06-14 11:18:37,875:INFO:Plotting tree 22
2023-06-14 11:18:45,500:INFO:Plotting tree 23
2023-06-14 11:18:52,256:INFO:Plotting tree 24
2023-06-14 11:18:59,298:INFO:Plotting tree 25
2023-06-14 11:19:06,997:INFO:Plotting tree 26
2023-06-14 11:19:13,841:INFO:Plotting tree 27
2023-06-14 11:19:20,704:INFO:Plotting tree 28
2023-06-14 11:19:28,533:INFO:Plotting tree 29
2023-06-14 11:19:37,013:INFO:Plotting tree 30
2023-06-14 11:19:43,857:INFO:Plotting tree 31
2023-06-14 11:19:50,840:INFO:Plotting tree 32
2023-06-14 11:19:57,904:INFO:Plotting tree 33
2023-06-14 11:20:05,306:INFO:Plotting tree 34
2023-06-14 11:20:14,753:INFO:Plotting tree 35
2023-06-14 11:20:21,897:INFO:Plotting tree 36
2023-06-14 11:20:30,547:INFO:Plotting tree 37
2023-06-14 11:20:37,427:INFO:Plotting tree 38
2023-06-14 11:20:44,068:INFO:Plotting tree 39
2023-06-14 11:20:50,809:INFO:Plotting tree 40
2023-06-14 11:20:57,569:INFO:Plotting tree 41
2023-06-14 11:21:04,339:INFO:Plotting tree 42
2023-06-14 11:21:12,723:INFO:Plotting tree 43
2023-06-14 11:21:19,570:INFO:Plotting tree 44
2023-06-14 11:21:26,332:INFO:Plotting tree 45
2023-06-14 11:21:33,029:INFO:Plotting tree 46
2023-06-14 11:21:39,750:INFO:Plotting tree 47
2023-06-14 11:21:46,710:INFO:Plotting tree 48
2023-06-14 11:21:53,611:INFO:Plotting tree 49
2023-06-14 11:22:00,437:INFO:Plotting tree 50
2023-06-14 11:22:07,340:INFO:Plotting tree 51
2023-06-14 11:22:16,035:INFO:Plotting tree 52
2023-06-14 11:22:22,874:INFO:Plotting tree 53
2023-06-14 11:22:29,732:INFO:Plotting tree 54
2023-06-14 11:22:36,513:INFO:Plotting tree 55
2023-06-14 11:22:43,336:INFO:Plotting tree 56
2023-06-14 11:22:50,167:INFO:Plotting tree 57
2023-06-14 11:22:57,132:INFO:Plotting tree 58
2023-06-14 11:23:03,912:INFO:Plotting tree 59
2023-06-14 11:23:10,559:INFO:Plotting tree 60
2023-06-14 11:23:17,378:INFO:Plotting tree 61
2023-06-14 11:23:24,112:INFO:Plotting tree 62
2023-06-14 11:23:33,454:INFO:Plotting tree 63
2023-06-14 11:23:41,022:INFO:Plotting tree 64
2023-06-14 11:23:49,252:INFO:Plotting tree 65
2023-06-14 11:23:56,828:INFO:Plotting tree 66
2023-06-14 11:24:04,479:INFO:Plotting tree 67
2023-06-14 11:24:11,695:INFO:Plotting tree 68
2023-06-14 11:24:19,247:INFO:Plotting tree 69
2023-06-14 11:24:26,163:INFO:Plotting tree 70
2023-06-14 11:24:33,148:INFO:Plotting tree 71
2023-06-14 11:24:40,289:INFO:Plotting tree 72
2023-06-14 11:25:17,039:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 11:25:17,039:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 11:25:17,039:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 11:25:17,040:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 11:25:17,823:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-14 11:39:21,063:INFO:PyCaret RegressionExperiment
2023-06-14 11:39:21,063:INFO:Logging name: reg-default-name
2023-06-14 11:39:21,063:INFO:ML Usecase: MLUsecase.REGRESSION
2023-06-14 11:39:21,064:INFO:version 3.0.2
2023-06-14 11:39:21,064:INFO:Initializing setup()
2023-06-14 11:39:21,064:INFO:self.USI: cd99
2023-06-14 11:39:21,064:INFO:self._variable_keys: {'log_plots_param', '_available_plots', 'target_param', 'pipeline', 'X_test', 'exp_name_log', 'fold_shuffle_param', 'X_train', 'exp_id', 'USI', 'n_jobs_param', 'data', 'memory', 'html_param', 'gpu_n_jobs_param', 'idx', 'y_train', 'seed', 'y_test', 'gpu_param', '_ml_usecase', 'fold_groups_param', 'X', 'fold_generator', 'y', 'logging_param', 'transform_target_param'}
2023-06-14 11:39:21,064:INFO:Checking environment
2023-06-14 11:39:21,064:INFO:python_version: 3.10.9
2023-06-14 11:39:21,064:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-06-14 11:39:21,064:INFO:machine: AMD64
2023-06-14 11:39:21,064:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-14 11:39:21,065:INFO:Memory: svmem(total=16901767168, available=6328070144, percent=62.6, used=10573697024, free=6328070144)
2023-06-14 11:39:21,065:INFO:Physical Core: 4
2023-06-14 11:39:21,065:INFO:Logical Core: 8
2023-06-14 11:39:21,065:INFO:Checking libraries
2023-06-14 11:39:21,065:INFO:System:
2023-06-14 11:39:21,065:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-06-14 11:39:21,065:INFO:executable: C:\Users\lapei\anaconda3\python.exe
2023-06-14 11:39:21,065:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-14 11:39:21,065:INFO:PyCaret required dependencies:
2023-06-14 11:39:21,066:INFO:                 pip: 22.3.1
2023-06-14 11:39:21,066:INFO:          setuptools: 65.6.3
2023-06-14 11:39:21,066:INFO:             pycaret: 3.0.2
2023-06-14 11:39:21,066:INFO:             IPython: 8.10.0
2023-06-14 11:39:21,066:INFO:          ipywidgets: 7.6.5
2023-06-14 11:39:21,066:INFO:                tqdm: 4.64.1
2023-06-14 11:39:21,066:INFO:               numpy: 1.23.5
2023-06-14 11:39:21,066:INFO:              pandas: 1.5.3
2023-06-14 11:39:21,066:INFO:              jinja2: 3.1.2
2023-06-14 11:39:21,066:INFO:               scipy: 1.10.0
2023-06-14 11:39:21,067:INFO:              joblib: 1.2.0
2023-06-14 11:39:21,067:INFO:             sklearn: 1.2.1
2023-06-14 11:39:21,067:INFO:                pyod: 1.0.9
2023-06-14 11:39:21,067:INFO:            imblearn: 0.10.1
2023-06-14 11:39:21,067:INFO:   category_encoders: 2.6.1
2023-06-14 11:39:21,067:INFO:            lightgbm: 3.3.5
2023-06-14 11:39:21,067:INFO:               numba: 0.56.4
2023-06-14 11:39:21,067:INFO:            requests: 2.28.1
2023-06-14 11:39:21,067:INFO:          matplotlib: 3.7.0
2023-06-14 11:39:21,067:INFO:          scikitplot: 0.3.7
2023-06-14 11:39:21,067:INFO:         yellowbrick: 1.5
2023-06-14 11:39:21,068:INFO:              plotly: 5.9.0
2023-06-14 11:39:21,068:INFO:             kaleido: 0.2.1
2023-06-14 11:39:21,068:INFO:         statsmodels: 0.13.5
2023-06-14 11:39:21,068:INFO:              sktime: 0.17.0
2023-06-14 11:39:21,068:INFO:               tbats: 1.1.3
2023-06-14 11:39:21,068:INFO:            pmdarima: 2.0.3
2023-06-14 11:39:21,068:INFO:              psutil: 5.9.0
2023-06-14 11:39:21,068:INFO:PyCaret optional dependencies:
2023-06-14 11:39:21,131:INFO:                shap: 0.41.0
2023-06-14 11:39:21,131:INFO:           interpret: Not installed
2023-06-14 11:39:21,131:INFO:                umap: Not installed
2023-06-14 11:39:21,131:INFO:    pandas_profiling: Not installed
2023-06-14 11:39:21,131:INFO:  explainerdashboard: Not installed
2023-06-14 11:39:21,131:INFO:             autoviz: Not installed
2023-06-14 11:39:21,131:INFO:           fairlearn: Not installed
2023-06-14 11:39:21,131:INFO:             xgboost: 1.7.3
2023-06-14 11:39:21,131:INFO:            catboost: Not installed
2023-06-14 11:39:21,131:INFO:              kmodes: Not installed
2023-06-14 11:39:21,131:INFO:             mlxtend: Not installed
2023-06-14 11:39:21,131:INFO:       statsforecast: Not installed
2023-06-14 11:39:21,131:INFO:        tune_sklearn: Not installed
2023-06-14 11:39:21,131:INFO:                 ray: Not installed
2023-06-14 11:39:21,131:INFO:            hyperopt: Not installed
2023-06-14 11:39:21,131:INFO:              optuna: Not installed
2023-06-14 11:39:21,131:INFO:               skopt: 0.9.0
2023-06-14 11:39:21,131:INFO:              mlflow: Not installed
2023-06-14 11:39:21,131:INFO:              gradio: Not installed
2023-06-14 11:39:21,131:INFO:             fastapi: Not installed
2023-06-14 11:39:21,131:INFO:             uvicorn: Not installed
2023-06-14 11:39:21,132:INFO:              m2cgen: Not installed
2023-06-14 11:39:21,132:INFO:           evidently: Not installed
2023-06-14 11:39:21,132:INFO:               fugue: Not installed
2023-06-14 11:39:21,132:INFO:           streamlit: Not installed
2023-06-14 11:39:21,132:INFO:             prophet: Not installed
2023-06-14 11:39:21,132:INFO:None
2023-06-14 11:39:21,132:INFO:Set up data.
2023-06-14 11:39:21,143:INFO:Set up train/test split.
2023-06-14 11:39:21,147:INFO:Set up index.
2023-06-14 11:39:21,147:INFO:Set up folding strategy.
2023-06-14 11:39:21,147:INFO:Assigning column types.
2023-06-14 11:39:21,151:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-14 11:39:21,151:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-14 11:39:21,156:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 11:39:21,162:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 11:39:21,276:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 11:39:21,355:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 11:39:21,355:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 11:39:21,524:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 11:39:21,524:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-14 11:39:21,529:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 11:39:21,534:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 11:39:21,594:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 11:39:21,636:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 11:39:21,637:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 11:39:21,639:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 11:39:21,640:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-06-14 11:39:21,644:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 11:39:21,648:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 11:39:21,727:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 11:39:21,768:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 11:39:21,768:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 11:39:21,771:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 11:39:21,775:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 11:39:21,780:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 11:39:21,837:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 11:39:21,884:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 11:39:21,885:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 11:39:21,893:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 11:39:21,894:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-06-14 11:39:21,905:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 11:39:21,973:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 11:39:22,021:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 11:39:22,021:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 11:39:22,024:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 11:39:22,038:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 11:39:22,104:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 11:39:22,146:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 11:39:22,147:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 11:39:22,149:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 11:39:22,149:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-06-14 11:39:22,211:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 11:39:22,262:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 11:39:22,262:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 11:39:22,266:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 11:39:22,347:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 11:39:22,387:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 11:39:22,387:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 11:39:22,389:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 11:39:22,389:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-14 11:39:22,475:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 11:39:22,515:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 11:39:22,518:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 11:39:22,590:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 11:39:22,636:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 11:39:22,640:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 11:39:22,640:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-06-14 11:39:22,750:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 11:39:22,753:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 11:39:22,874:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 11:39:22,876:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 11:39:22,878:INFO:Preparing preprocessing pipeline...
2023-06-14 11:39:22,878:INFO:Set up simple imputation.
2023-06-14 11:39:22,879:INFO:Set up column name cleaning.
2023-06-14 11:39:22,905:INFO:Finished creating preprocessing pipeline.
2023-06-14 11:39:22,912:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\lapei\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['taxa_homicidio', 'RH_adm_dir',
                                             'densidade_banda_larga',
                                             'densidade_telefonia_movel',
                                             'qtd_cursos_engenharias',
                                             'qtd_cursos_negocios_direito',
                                             'media_notas_CN', 'media_notas_CH',
                                             'media_NU_NOTA_LC',
                                             'media_NU_NOTA_MT',
                                             'media_...
                                             'Isencao_ISSQN_Sim',
                                             'Isencao_Tx_Sim',
                                             'Cessao_terrenos_Sim',
                                             'Doacao_terrenos_Sim',
                                             'Outros_mecanismos_Sim',
                                             'ISH_Baixa', 'ISH_Máxima',
                                             'ISH_Média', 'ISH_Mínima'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-06-14 11:39:22,912:INFO:Creating final display dataframe.
2023-06-14 11:39:23,030:INFO:Setup _display_container:                     Description                              Value
0                    Session id                                 42
1                        Target  qtd_abertas_Empresario_Individual
2                   Target type                         Regression
3           Original data shape                         (4456, 30)
4        Transformed data shape                         (4456, 30)
5   Transformed train set shape                         (3119, 30)
6    Transformed test set shape                         (1337, 30)
7              Numeric features                                 29
8                    Preprocess                               True
9               Imputation type                             simple
10           Numeric imputation                               mean
11       Categorical imputation                               mode
12               Fold Generator                              KFold
13                  Fold Number                                 10
14                     CPU Jobs                                 -1
15                      Use GPU                              False
16               Log Experiment                              False
17              Experiment Name                   reg-default-name
18                          USI                               cd99
2023-06-14 11:39:23,168:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 11:39:23,173:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 11:39:23,324:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 11:39:23,327:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 11:39:23,328:INFO:setup() successfully completed in 2.35s...............
2023-06-14 11:39:41,196:INFO:Initializing compare_models()
2023-06-14 11:39:41,196:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248AF8433A0>, include=None, fold=5, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000248AF8433A0>, 'include': None, 'exclude': None, 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-06-14 11:39:41,196:INFO:Checking exceptions
2023-06-14 11:39:41,199:INFO:Preparing display monitor
2023-06-14 11:39:41,233:INFO:Initializing Linear Regression
2023-06-14 11:39:41,234:INFO:Total runtime is 1.6601880391438804e-05 minutes
2023-06-14 11:39:41,240:INFO:SubProcess create_model() called ==================================
2023-06-14 11:39:41,240:INFO:Initializing create_model()
2023-06-14 11:39:41,240:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248AF8433A0>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248AF2D4BB0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:39:41,241:INFO:Checking exceptions
2023-06-14 11:39:41,241:INFO:Importing libraries
2023-06-14 11:39:41,241:INFO:Copying training dataset
2023-06-14 11:39:41,250:INFO:Defining folds
2023-06-14 11:39:41,251:INFO:Declaring metric variables
2023-06-14 11:39:41,256:INFO:Importing untrained model
2023-06-14 11:39:41,260:INFO:Linear Regression Imported successfully
2023-06-14 11:39:41,267:INFO:Starting cross validation
2023-06-14 11:39:41,274:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:39:46,178:INFO:Calculating mean and std
2023-06-14 11:39:46,179:INFO:Creating metrics dataframe
2023-06-14 11:39:46,300:INFO:Uploading results into container
2023-06-14 11:39:46,300:INFO:Uploading model into container now
2023-06-14 11:39:46,301:INFO:_master_model_container: 1
2023-06-14 11:39:46,301:INFO:_display_container: 2
2023-06-14 11:39:46,301:INFO:LinearRegression(n_jobs=-1)
2023-06-14 11:39:46,302:INFO:create_model() successfully completed......................................
2023-06-14 11:39:46,448:INFO:SubProcess create_model() end ==================================
2023-06-14 11:39:46,448:INFO:Creating metrics dataframe
2023-06-14 11:39:46,461:INFO:Initializing Lasso Regression
2023-06-14 11:39:46,461:INFO:Total runtime is 0.08713635603586833 minutes
2023-06-14 11:39:46,465:INFO:SubProcess create_model() called ==================================
2023-06-14 11:39:46,465:INFO:Initializing create_model()
2023-06-14 11:39:46,465:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248AF8433A0>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248AF2D4BB0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:39:46,465:INFO:Checking exceptions
2023-06-14 11:39:46,466:INFO:Importing libraries
2023-06-14 11:39:46,466:INFO:Copying training dataset
2023-06-14 11:39:46,471:INFO:Defining folds
2023-06-14 11:39:46,471:INFO:Declaring metric variables
2023-06-14 11:39:46,474:INFO:Importing untrained model
2023-06-14 11:39:46,478:INFO:Lasso Regression Imported successfully
2023-06-14 11:39:46,488:INFO:Starting cross validation
2023-06-14 11:39:46,489:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:39:49,055:INFO:Calculating mean and std
2023-06-14 11:39:49,056:INFO:Creating metrics dataframe
2023-06-14 11:39:49,298:INFO:Uploading results into container
2023-06-14 11:39:49,299:INFO:Uploading model into container now
2023-06-14 11:39:49,300:INFO:_master_model_container: 2
2023-06-14 11:39:49,300:INFO:_display_container: 2
2023-06-14 11:39:49,301:INFO:Lasso(random_state=42)
2023-06-14 11:39:49,301:INFO:create_model() successfully completed......................................
2023-06-14 11:39:49,439:INFO:SubProcess create_model() end ==================================
2023-06-14 11:39:49,440:INFO:Creating metrics dataframe
2023-06-14 11:39:49,464:INFO:Initializing Ridge Regression
2023-06-14 11:39:49,464:INFO:Total runtime is 0.1371852199236552 minutes
2023-06-14 11:39:49,471:INFO:SubProcess create_model() called ==================================
2023-06-14 11:39:49,471:INFO:Initializing create_model()
2023-06-14 11:39:49,471:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248AF8433A0>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248AF2D4BB0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:39:49,472:INFO:Checking exceptions
2023-06-14 11:39:49,472:INFO:Importing libraries
2023-06-14 11:39:49,472:INFO:Copying training dataset
2023-06-14 11:39:49,480:INFO:Defining folds
2023-06-14 11:39:49,480:INFO:Declaring metric variables
2023-06-14 11:39:49,485:INFO:Importing untrained model
2023-06-14 11:39:49,489:INFO:Ridge Regression Imported successfully
2023-06-14 11:39:49,495:INFO:Starting cross validation
2023-06-14 11:39:49,496:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:39:49,983:INFO:Calculating mean and std
2023-06-14 11:39:49,984:INFO:Creating metrics dataframe
2023-06-14 11:39:50,143:INFO:Uploading results into container
2023-06-14 11:39:50,144:INFO:Uploading model into container now
2023-06-14 11:39:50,145:INFO:_master_model_container: 3
2023-06-14 11:39:50,145:INFO:_display_container: 2
2023-06-14 11:39:50,146:INFO:Ridge(random_state=42)
2023-06-14 11:39:50,146:INFO:create_model() successfully completed......................................
2023-06-14 11:39:50,279:INFO:SubProcess create_model() end ==================================
2023-06-14 11:39:50,280:INFO:Creating metrics dataframe
2023-06-14 11:39:50,301:INFO:Initializing Elastic Net
2023-06-14 11:39:50,301:INFO:Total runtime is 0.151130751768748 minutes
2023-06-14 11:39:50,309:INFO:SubProcess create_model() called ==================================
2023-06-14 11:39:50,310:INFO:Initializing create_model()
2023-06-14 11:39:50,310:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248AF8433A0>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248AF2D4BB0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:39:50,310:INFO:Checking exceptions
2023-06-14 11:39:50,310:INFO:Importing libraries
2023-06-14 11:39:50,310:INFO:Copying training dataset
2023-06-14 11:39:50,316:INFO:Defining folds
2023-06-14 11:39:50,316:INFO:Declaring metric variables
2023-06-14 11:39:50,320:INFO:Importing untrained model
2023-06-14 11:39:50,325:INFO:Elastic Net Imported successfully
2023-06-14 11:39:50,331:INFO:Starting cross validation
2023-06-14 11:39:50,332:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:39:50,897:INFO:Calculating mean and std
2023-06-14 11:39:50,899:INFO:Creating metrics dataframe
2023-06-14 11:39:51,076:INFO:Uploading results into container
2023-06-14 11:39:51,077:INFO:Uploading model into container now
2023-06-14 11:39:51,077:INFO:_master_model_container: 4
2023-06-14 11:39:51,078:INFO:_display_container: 2
2023-06-14 11:39:51,078:INFO:ElasticNet(random_state=42)
2023-06-14 11:39:51,078:INFO:create_model() successfully completed......................................
2023-06-14 11:39:51,222:INFO:SubProcess create_model() end ==================================
2023-06-14 11:39:51,222:INFO:Creating metrics dataframe
2023-06-14 11:39:51,232:INFO:Initializing Least Angle Regression
2023-06-14 11:39:51,233:INFO:Total runtime is 0.16666074196497602 minutes
2023-06-14 11:39:51,237:INFO:SubProcess create_model() called ==================================
2023-06-14 11:39:51,238:INFO:Initializing create_model()
2023-06-14 11:39:51,239:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248AF8433A0>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248AF2D4BB0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:39:51,239:INFO:Checking exceptions
2023-06-14 11:39:51,239:INFO:Importing libraries
2023-06-14 11:39:51,239:INFO:Copying training dataset
2023-06-14 11:39:51,250:INFO:Defining folds
2023-06-14 11:39:51,250:INFO:Declaring metric variables
2023-06-14 11:39:51,254:INFO:Importing untrained model
2023-06-14 11:39:51,257:INFO:Least Angle Regression Imported successfully
2023-06-14 11:39:51,263:INFO:Starting cross validation
2023-06-14 11:39:51,265:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:39:51,758:INFO:Calculating mean and std
2023-06-14 11:39:51,760:INFO:Creating metrics dataframe
2023-06-14 11:39:51,906:INFO:Uploading results into container
2023-06-14 11:39:51,906:INFO:Uploading model into container now
2023-06-14 11:39:51,907:INFO:_master_model_container: 5
2023-06-14 11:39:51,907:INFO:_display_container: 2
2023-06-14 11:39:51,908:INFO:Lars(random_state=42)
2023-06-14 11:39:51,908:INFO:create_model() successfully completed......................................
2023-06-14 11:39:52,028:INFO:SubProcess create_model() end ==================================
2023-06-14 11:39:52,029:INFO:Creating metrics dataframe
2023-06-14 11:39:52,045:INFO:Initializing Lasso Least Angle Regression
2023-06-14 11:39:52,045:INFO:Total runtime is 0.18019196589787803 minutes
2023-06-14 11:39:52,049:INFO:SubProcess create_model() called ==================================
2023-06-14 11:39:52,049:INFO:Initializing create_model()
2023-06-14 11:39:52,049:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248AF8433A0>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248AF2D4BB0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:39:52,049:INFO:Checking exceptions
2023-06-14 11:39:52,051:INFO:Importing libraries
2023-06-14 11:39:52,051:INFO:Copying training dataset
2023-06-14 11:39:52,055:INFO:Defining folds
2023-06-14 11:39:52,055:INFO:Declaring metric variables
2023-06-14 11:39:52,059:INFO:Importing untrained model
2023-06-14 11:39:52,061:INFO:Lasso Least Angle Regression Imported successfully
2023-06-14 11:39:52,068:INFO:Starting cross validation
2023-06-14 11:39:52,069:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:39:52,543:INFO:Calculating mean and std
2023-06-14 11:39:52,544:INFO:Creating metrics dataframe
2023-06-14 11:39:52,751:INFO:Uploading results into container
2023-06-14 11:39:52,753:INFO:Uploading model into container now
2023-06-14 11:39:52,753:INFO:_master_model_container: 6
2023-06-14 11:39:52,753:INFO:_display_container: 2
2023-06-14 11:39:52,754:INFO:LassoLars(random_state=42)
2023-06-14 11:39:52,754:INFO:create_model() successfully completed......................................
2023-06-14 11:39:52,882:INFO:SubProcess create_model() end ==================================
2023-06-14 11:39:52,882:INFO:Creating metrics dataframe
2023-06-14 11:39:52,897:INFO:Initializing Orthogonal Matching Pursuit
2023-06-14 11:39:52,897:INFO:Total runtime is 0.19439272085825604 minutes
2023-06-14 11:39:52,901:INFO:SubProcess create_model() called ==================================
2023-06-14 11:39:52,902:INFO:Initializing create_model()
2023-06-14 11:39:52,902:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248AF8433A0>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248AF2D4BB0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:39:52,902:INFO:Checking exceptions
2023-06-14 11:39:52,902:INFO:Importing libraries
2023-06-14 11:39:52,902:INFO:Copying training dataset
2023-06-14 11:39:52,909:INFO:Defining folds
2023-06-14 11:39:52,909:INFO:Declaring metric variables
2023-06-14 11:39:52,913:INFO:Importing untrained model
2023-06-14 11:39:52,917:INFO:Orthogonal Matching Pursuit Imported successfully
2023-06-14 11:39:52,924:INFO:Starting cross validation
2023-06-14 11:39:52,926:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:39:53,405:INFO:Calculating mean and std
2023-06-14 11:39:53,407:INFO:Creating metrics dataframe
2023-06-14 11:39:53,601:INFO:Uploading results into container
2023-06-14 11:39:53,603:INFO:Uploading model into container now
2023-06-14 11:39:53,603:INFO:_master_model_container: 7
2023-06-14 11:39:53,603:INFO:_display_container: 2
2023-06-14 11:39:53,604:INFO:OrthogonalMatchingPursuit()
2023-06-14 11:39:53,604:INFO:create_model() successfully completed......................................
2023-06-14 11:39:53,735:INFO:SubProcess create_model() end ==================================
2023-06-14 11:39:53,735:INFO:Creating metrics dataframe
2023-06-14 11:39:53,751:INFO:Initializing Bayesian Ridge
2023-06-14 11:39:53,751:INFO:Total runtime is 0.20863709847132367 minutes
2023-06-14 11:39:53,754:INFO:SubProcess create_model() called ==================================
2023-06-14 11:39:53,755:INFO:Initializing create_model()
2023-06-14 11:39:53,755:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248AF8433A0>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248AF2D4BB0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:39:53,755:INFO:Checking exceptions
2023-06-14 11:39:53,756:INFO:Importing libraries
2023-06-14 11:39:53,756:INFO:Copying training dataset
2023-06-14 11:39:53,761:INFO:Defining folds
2023-06-14 11:39:53,761:INFO:Declaring metric variables
2023-06-14 11:39:53,769:INFO:Importing untrained model
2023-06-14 11:39:53,774:INFO:Bayesian Ridge Imported successfully
2023-06-14 11:39:53,783:INFO:Starting cross validation
2023-06-14 11:39:53,785:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:39:54,312:INFO:Calculating mean and std
2023-06-14 11:39:54,313:INFO:Creating metrics dataframe
2023-06-14 11:39:54,479:INFO:Uploading results into container
2023-06-14 11:39:54,479:INFO:Uploading model into container now
2023-06-14 11:39:54,481:INFO:_master_model_container: 8
2023-06-14 11:39:54,481:INFO:_display_container: 2
2023-06-14 11:39:54,481:INFO:BayesianRidge()
2023-06-14 11:39:54,482:INFO:create_model() successfully completed......................................
2023-06-14 11:39:54,622:INFO:SubProcess create_model() end ==================================
2023-06-14 11:39:54,623:INFO:Creating metrics dataframe
2023-06-14 11:39:54,635:INFO:Initializing Passive Aggressive Regressor
2023-06-14 11:39:54,635:INFO:Total runtime is 0.2233713269233704 minutes
2023-06-14 11:39:54,640:INFO:SubProcess create_model() called ==================================
2023-06-14 11:39:54,641:INFO:Initializing create_model()
2023-06-14 11:39:54,641:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248AF8433A0>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248AF2D4BB0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:39:54,641:INFO:Checking exceptions
2023-06-14 11:39:54,641:INFO:Importing libraries
2023-06-14 11:39:54,641:INFO:Copying training dataset
2023-06-14 11:39:54,652:INFO:Defining folds
2023-06-14 11:39:54,653:INFO:Declaring metric variables
2023-06-14 11:39:54,659:INFO:Importing untrained model
2023-06-14 11:39:54,664:INFO:Passive Aggressive Regressor Imported successfully
2023-06-14 11:39:54,672:INFO:Starting cross validation
2023-06-14 11:39:54,673:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:39:55,158:INFO:Calculating mean and std
2023-06-14 11:39:55,159:INFO:Creating metrics dataframe
2023-06-14 11:39:55,350:INFO:Uploading results into container
2023-06-14 11:39:55,351:INFO:Uploading model into container now
2023-06-14 11:39:55,351:INFO:_master_model_container: 9
2023-06-14 11:39:55,351:INFO:_display_container: 2
2023-06-14 11:39:55,352:INFO:PassiveAggressiveRegressor(random_state=42)
2023-06-14 11:39:55,352:INFO:create_model() successfully completed......................................
2023-06-14 11:39:55,485:INFO:SubProcess create_model() end ==================================
2023-06-14 11:39:55,485:INFO:Creating metrics dataframe
2023-06-14 11:39:55,498:INFO:Initializing Huber Regressor
2023-06-14 11:39:55,498:INFO:Total runtime is 0.237742821375529 minutes
2023-06-14 11:39:55,508:INFO:SubProcess create_model() called ==================================
2023-06-14 11:39:55,508:INFO:Initializing create_model()
2023-06-14 11:39:55,508:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248AF8433A0>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248AF2D4BB0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:39:55,508:INFO:Checking exceptions
2023-06-14 11:39:55,508:INFO:Importing libraries
2023-06-14 11:39:55,508:INFO:Copying training dataset
2023-06-14 11:39:55,518:INFO:Defining folds
2023-06-14 11:39:55,518:INFO:Declaring metric variables
2023-06-14 11:39:55,524:INFO:Importing untrained model
2023-06-14 11:39:55,529:INFO:Huber Regressor Imported successfully
2023-06-14 11:39:55,536:INFO:Starting cross validation
2023-06-14 11:39:55,538:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:39:55,663:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 11:39:55,671:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 11:39:55,678:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 11:39:55,700:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 11:39:55,711:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 11:39:56,133:INFO:Calculating mean and std
2023-06-14 11:39:56,135:INFO:Creating metrics dataframe
2023-06-14 11:39:56,309:INFO:Uploading results into container
2023-06-14 11:39:56,310:INFO:Uploading model into container now
2023-06-14 11:39:56,310:INFO:_master_model_container: 10
2023-06-14 11:39:56,311:INFO:_display_container: 2
2023-06-14 11:39:56,311:INFO:HuberRegressor()
2023-06-14 11:39:56,311:INFO:create_model() successfully completed......................................
2023-06-14 11:39:56,453:INFO:SubProcess create_model() end ==================================
2023-06-14 11:39:56,453:INFO:Creating metrics dataframe
2023-06-14 11:39:56,466:INFO:Initializing K Neighbors Regressor
2023-06-14 11:39:56,467:INFO:Total runtime is 0.25388193527857467 minutes
2023-06-14 11:39:56,470:INFO:SubProcess create_model() called ==================================
2023-06-14 11:39:56,471:INFO:Initializing create_model()
2023-06-14 11:39:56,471:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248AF8433A0>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248AF2D4BB0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:39:56,471:INFO:Checking exceptions
2023-06-14 11:39:56,471:INFO:Importing libraries
2023-06-14 11:39:56,471:INFO:Copying training dataset
2023-06-14 11:39:56,477:INFO:Defining folds
2023-06-14 11:39:56,479:INFO:Declaring metric variables
2023-06-14 11:39:56,482:INFO:Importing untrained model
2023-06-14 11:39:56,487:INFO:K Neighbors Regressor Imported successfully
2023-06-14 11:39:56,497:INFO:Starting cross validation
2023-06-14 11:39:56,498:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:39:57,102:INFO:Calculating mean and std
2023-06-14 11:39:57,104:INFO:Creating metrics dataframe
2023-06-14 11:39:57,275:INFO:Uploading results into container
2023-06-14 11:39:57,276:INFO:Uploading model into container now
2023-06-14 11:39:57,276:INFO:_master_model_container: 11
2023-06-14 11:39:57,276:INFO:_display_container: 2
2023-06-14 11:39:57,277:INFO:KNeighborsRegressor(n_jobs=-1)
2023-06-14 11:39:57,277:INFO:create_model() successfully completed......................................
2023-06-14 11:39:57,413:INFO:SubProcess create_model() end ==================================
2023-06-14 11:39:57,413:INFO:Creating metrics dataframe
2023-06-14 11:39:57,436:INFO:Initializing Decision Tree Regressor
2023-06-14 11:39:57,437:INFO:Total runtime is 0.2700606187184652 minutes
2023-06-14 11:39:57,440:INFO:SubProcess create_model() called ==================================
2023-06-14 11:39:57,440:INFO:Initializing create_model()
2023-06-14 11:39:57,440:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248AF8433A0>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248AF2D4BB0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:39:57,440:INFO:Checking exceptions
2023-06-14 11:39:57,441:INFO:Importing libraries
2023-06-14 11:39:57,441:INFO:Copying training dataset
2023-06-14 11:39:57,449:INFO:Defining folds
2023-06-14 11:39:57,449:INFO:Declaring metric variables
2023-06-14 11:39:57,452:INFO:Importing untrained model
2023-06-14 11:39:57,457:INFO:Decision Tree Regressor Imported successfully
2023-06-14 11:39:57,468:INFO:Starting cross validation
2023-06-14 11:39:57,470:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:39:58,020:INFO:Calculating mean and std
2023-06-14 11:39:58,022:INFO:Creating metrics dataframe
2023-06-14 11:39:58,224:INFO:Uploading results into container
2023-06-14 11:39:58,225:INFO:Uploading model into container now
2023-06-14 11:39:58,225:INFO:_master_model_container: 12
2023-06-14 11:39:58,225:INFO:_display_container: 2
2023-06-14 11:39:58,226:INFO:DecisionTreeRegressor(random_state=42)
2023-06-14 11:39:58,226:INFO:create_model() successfully completed......................................
2023-06-14 11:39:58,390:INFO:SubProcess create_model() end ==================================
2023-06-14 11:39:58,391:INFO:Creating metrics dataframe
2023-06-14 11:39:58,412:INFO:Initializing Random Forest Regressor
2023-06-14 11:39:58,412:INFO:Total runtime is 0.2863211512565613 minutes
2023-06-14 11:39:58,419:INFO:SubProcess create_model() called ==================================
2023-06-14 11:39:58,421:INFO:Initializing create_model()
2023-06-14 11:39:58,421:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248AF8433A0>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248AF2D4BB0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:39:58,421:INFO:Checking exceptions
2023-06-14 11:39:58,421:INFO:Importing libraries
2023-06-14 11:39:58,421:INFO:Copying training dataset
2023-06-14 11:39:58,433:INFO:Defining folds
2023-06-14 11:39:58,433:INFO:Declaring metric variables
2023-06-14 11:39:58,438:INFO:Importing untrained model
2023-06-14 11:39:58,444:INFO:Random Forest Regressor Imported successfully
2023-06-14 11:39:58,451:INFO:Starting cross validation
2023-06-14 11:39:58,452:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:39:59,059:INFO:Calculating mean and std
2023-06-14 11:39:59,060:INFO:Creating metrics dataframe
2023-06-14 11:39:59,232:INFO:Uploading results into container
2023-06-14 11:39:59,233:INFO:Uploading model into container now
2023-06-14 11:39:59,234:INFO:_master_model_container: 13
2023-06-14 11:39:59,235:INFO:_display_container: 2
2023-06-14 11:39:59,235:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-14 11:39:59,235:INFO:create_model() successfully completed......................................
2023-06-14 11:39:59,357:INFO:SubProcess create_model() end ==================================
2023-06-14 11:39:59,358:INFO:Creating metrics dataframe
2023-06-14 11:39:59,371:INFO:Initializing Extra Trees Regressor
2023-06-14 11:39:59,371:INFO:Total runtime is 0.30229210058848066 minutes
2023-06-14 11:39:59,374:INFO:SubProcess create_model() called ==================================
2023-06-14 11:39:59,375:INFO:Initializing create_model()
2023-06-14 11:39:59,375:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248AF8433A0>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248AF2D4BB0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:39:59,375:INFO:Checking exceptions
2023-06-14 11:39:59,375:INFO:Importing libraries
2023-06-14 11:39:59,375:INFO:Copying training dataset
2023-06-14 11:39:59,385:INFO:Defining folds
2023-06-14 11:39:59,385:INFO:Declaring metric variables
2023-06-14 11:39:59,390:INFO:Importing untrained model
2023-06-14 11:39:59,397:INFO:Extra Trees Regressor Imported successfully
2023-06-14 11:39:59,410:INFO:Starting cross validation
2023-06-14 11:39:59,412:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:40:00,131:INFO:Calculating mean and std
2023-06-14 11:40:00,133:INFO:Creating metrics dataframe
2023-06-14 11:40:00,304:INFO:Uploading results into container
2023-06-14 11:40:00,306:INFO:Uploading model into container now
2023-06-14 11:40:00,307:INFO:_master_model_container: 14
2023-06-14 11:40:00,307:INFO:_display_container: 2
2023-06-14 11:40:00,308:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2023-06-14 11:40:00,308:INFO:create_model() successfully completed......................................
2023-06-14 11:40:00,463:INFO:SubProcess create_model() end ==================================
2023-06-14 11:40:00,463:INFO:Creating metrics dataframe
2023-06-14 11:40:00,477:INFO:Initializing AdaBoost Regressor
2023-06-14 11:40:00,477:INFO:Total runtime is 0.3207295338312785 minutes
2023-06-14 11:40:00,480:INFO:SubProcess create_model() called ==================================
2023-06-14 11:40:00,481:INFO:Initializing create_model()
2023-06-14 11:40:00,481:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248AF8433A0>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248AF2D4BB0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:40:00,481:INFO:Checking exceptions
2023-06-14 11:40:00,481:INFO:Importing libraries
2023-06-14 11:40:00,481:INFO:Copying training dataset
2023-06-14 11:40:00,486:INFO:Defining folds
2023-06-14 11:40:00,487:INFO:Declaring metric variables
2023-06-14 11:40:00,492:INFO:Importing untrained model
2023-06-14 11:40:00,496:INFO:AdaBoost Regressor Imported successfully
2023-06-14 11:40:00,504:INFO:Starting cross validation
2023-06-14 11:40:00,505:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:40:01,038:INFO:Calculating mean and std
2023-06-14 11:40:01,040:INFO:Creating metrics dataframe
2023-06-14 11:40:01,202:INFO:Uploading results into container
2023-06-14 11:40:01,203:INFO:Uploading model into container now
2023-06-14 11:40:01,203:INFO:_master_model_container: 15
2023-06-14 11:40:01,203:INFO:_display_container: 2
2023-06-14 11:40:01,204:INFO:AdaBoostRegressor(random_state=42)
2023-06-14 11:40:01,204:INFO:create_model() successfully completed......................................
2023-06-14 11:40:01,354:INFO:SubProcess create_model() end ==================================
2023-06-14 11:40:01,354:INFO:Creating metrics dataframe
2023-06-14 11:40:01,369:INFO:Initializing Gradient Boosting Regressor
2023-06-14 11:40:01,369:INFO:Total runtime is 0.3355919202168783 minutes
2023-06-14 11:40:01,372:INFO:SubProcess create_model() called ==================================
2023-06-14 11:40:01,372:INFO:Initializing create_model()
2023-06-14 11:40:01,372:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248AF8433A0>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248AF2D4BB0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:40:01,373:INFO:Checking exceptions
2023-06-14 11:40:01,373:INFO:Importing libraries
2023-06-14 11:40:01,373:INFO:Copying training dataset
2023-06-14 11:40:01,378:INFO:Defining folds
2023-06-14 11:40:01,378:INFO:Declaring metric variables
2023-06-14 11:40:01,385:INFO:Importing untrained model
2023-06-14 11:40:01,389:INFO:Gradient Boosting Regressor Imported successfully
2023-06-14 11:40:01,398:INFO:Starting cross validation
2023-06-14 11:40:01,399:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:40:01,923:INFO:Calculating mean and std
2023-06-14 11:40:01,924:INFO:Creating metrics dataframe
2023-06-14 11:40:02,080:INFO:Uploading results into container
2023-06-14 11:40:02,081:INFO:Uploading model into container now
2023-06-14 11:40:02,081:INFO:_master_model_container: 16
2023-06-14 11:40:02,081:INFO:_display_container: 2
2023-06-14 11:40:02,082:INFO:GradientBoostingRegressor(random_state=42)
2023-06-14 11:40:02,082:INFO:create_model() successfully completed......................................
2023-06-14 11:40:02,222:INFO:SubProcess create_model() end ==================================
2023-06-14 11:40:02,222:INFO:Creating metrics dataframe
2023-06-14 11:40:02,242:INFO:Initializing Extreme Gradient Boosting
2023-06-14 11:40:02,242:INFO:Total runtime is 0.35015168984731043 minutes
2023-06-14 11:40:02,247:INFO:SubProcess create_model() called ==================================
2023-06-14 11:40:02,247:INFO:Initializing create_model()
2023-06-14 11:40:02,248:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248AF8433A0>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248AF2D4BB0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:40:02,248:INFO:Checking exceptions
2023-06-14 11:40:02,248:INFO:Importing libraries
2023-06-14 11:40:02,248:INFO:Copying training dataset
2023-06-14 11:40:02,253:INFO:Defining folds
2023-06-14 11:40:02,253:INFO:Declaring metric variables
2023-06-14 11:40:02,257:INFO:Importing untrained model
2023-06-14 11:40:02,260:INFO:Extreme Gradient Boosting Imported successfully
2023-06-14 11:40:02,265:INFO:Starting cross validation
2023-06-14 11:40:02,267:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:40:02,733:INFO:Calculating mean and std
2023-06-14 11:40:02,734:INFO:Creating metrics dataframe
2023-06-14 11:40:02,902:INFO:Uploading results into container
2023-06-14 11:40:02,903:INFO:Uploading model into container now
2023-06-14 11:40:02,904:INFO:_master_model_container: 17
2023-06-14 11:40:02,904:INFO:_display_container: 2
2023-06-14 11:40:02,906:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=42, ...)
2023-06-14 11:40:02,906:INFO:create_model() successfully completed......................................
2023-06-14 11:40:03,026:INFO:SubProcess create_model() end ==================================
2023-06-14 11:40:03,027:INFO:Creating metrics dataframe
2023-06-14 11:40:03,039:INFO:Initializing Light Gradient Boosting Machine
2023-06-14 11:40:03,039:INFO:Total runtime is 0.363435975710551 minutes
2023-06-14 11:40:03,042:INFO:SubProcess create_model() called ==================================
2023-06-14 11:40:03,043:INFO:Initializing create_model()
2023-06-14 11:40:03,043:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248AF8433A0>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248AF2D4BB0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:40:03,043:INFO:Checking exceptions
2023-06-14 11:40:03,043:INFO:Importing libraries
2023-06-14 11:40:03,043:INFO:Copying training dataset
2023-06-14 11:40:03,048:INFO:Defining folds
2023-06-14 11:40:03,048:INFO:Declaring metric variables
2023-06-14 11:40:03,055:INFO:Importing untrained model
2023-06-14 11:40:03,064:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-14 11:40:03,077:INFO:Starting cross validation
2023-06-14 11:40:03,078:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:40:04,596:INFO:Calculating mean and std
2023-06-14 11:40:04,597:INFO:Creating metrics dataframe
2023-06-14 11:40:04,809:INFO:Uploading results into container
2023-06-14 11:40:04,810:INFO:Uploading model into container now
2023-06-14 11:40:04,812:INFO:_master_model_container: 18
2023-06-14 11:40:04,812:INFO:_display_container: 2
2023-06-14 11:40:04,813:INFO:LGBMRegressor(random_state=42)
2023-06-14 11:40:04,814:INFO:create_model() successfully completed......................................
2023-06-14 11:40:04,941:INFO:SubProcess create_model() end ==================================
2023-06-14 11:40:04,942:INFO:Creating metrics dataframe
2023-06-14 11:40:04,972:INFO:Initializing Dummy Regressor
2023-06-14 11:40:04,972:INFO:Total runtime is 0.3956541736920675 minutes
2023-06-14 11:40:04,978:INFO:SubProcess create_model() called ==================================
2023-06-14 11:40:04,979:INFO:Initializing create_model()
2023-06-14 11:40:04,979:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248AF8433A0>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248AF2D4BB0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:40:04,979:INFO:Checking exceptions
2023-06-14 11:40:04,979:INFO:Importing libraries
2023-06-14 11:40:04,979:INFO:Copying training dataset
2023-06-14 11:40:04,986:INFO:Defining folds
2023-06-14 11:40:04,986:INFO:Declaring metric variables
2023-06-14 11:40:04,992:INFO:Importing untrained model
2023-06-14 11:40:04,998:INFO:Dummy Regressor Imported successfully
2023-06-14 11:40:05,006:INFO:Starting cross validation
2023-06-14 11:40:05,007:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:40:05,439:INFO:Calculating mean and std
2023-06-14 11:40:05,441:INFO:Creating metrics dataframe
2023-06-14 11:40:05,612:INFO:Uploading results into container
2023-06-14 11:40:05,614:INFO:Uploading model into container now
2023-06-14 11:40:05,615:INFO:_master_model_container: 19
2023-06-14 11:40:05,615:INFO:_display_container: 2
2023-06-14 11:40:05,615:INFO:DummyRegressor()
2023-06-14 11:40:05,616:INFO:create_model() successfully completed......................................
2023-06-14 11:40:05,760:INFO:SubProcess create_model() end ==================================
2023-06-14 11:40:05,760:INFO:Creating metrics dataframe
2023-06-14 11:40:05,785:INFO:Initializing create_model()
2023-06-14 11:40:05,786:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248AF8433A0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:40:05,786:INFO:Checking exceptions
2023-06-14 11:40:05,787:INFO:Importing libraries
2023-06-14 11:40:05,788:INFO:Copying training dataset
2023-06-14 11:40:05,794:INFO:Defining folds
2023-06-14 11:40:05,794:INFO:Declaring metric variables
2023-06-14 11:40:05,794:INFO:Importing untrained model
2023-06-14 11:40:05,794:INFO:Declaring custom model
2023-06-14 11:40:05,795:INFO:Random Forest Regressor Imported successfully
2023-06-14 11:40:05,795:INFO:Cross validation set to False
2023-06-14 11:40:05,796:INFO:Fitting Model
2023-06-14 11:40:05,953:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-14 11:40:05,953:INFO:create_model() successfully completed......................................
2023-06-14 11:40:06,110:INFO:_master_model_container: 19
2023-06-14 11:40:06,110:INFO:_display_container: 2
2023-06-14 11:40:06,110:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-14 11:40:06,111:INFO:compare_models() successfully completed......................................
2023-06-14 11:40:12,705:INFO:Initializing create_model()
2023-06-14 11:40:12,705:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248AF8433A0>, estimator=rf, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:40:12,706:INFO:Checking exceptions
2023-06-14 11:40:12,725:INFO:Importing libraries
2023-06-14 11:40:12,727:INFO:Copying training dataset
2023-06-14 11:40:12,732:INFO:Defining folds
2023-06-14 11:40:12,732:INFO:Declaring metric variables
2023-06-14 11:40:12,736:INFO:Importing untrained model
2023-06-14 11:40:12,740:INFO:Random Forest Regressor Imported successfully
2023-06-14 11:40:12,746:INFO:Starting cross validation
2023-06-14 11:40:12,747:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:40:13,411:INFO:Calculating mean and std
2023-06-14 11:40:13,411:INFO:Creating metrics dataframe
2023-06-14 11:40:13,417:INFO:Finalizing model
2023-06-14 11:40:13,723:INFO:Uploading results into container
2023-06-14 11:40:13,724:INFO:Uploading model into container now
2023-06-14 11:40:13,732:INFO:_master_model_container: 20
2023-06-14 11:40:13,732:INFO:_display_container: 3
2023-06-14 11:40:13,732:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-14 11:40:13,732:INFO:create_model() successfully completed......................................
2023-06-14 11:40:14,844:INFO:Initializing tune_model()
2023-06-14 11:40:14,845:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=5, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248AF8433A0>)
2023-06-14 11:40:14,845:INFO:Checking exceptions
2023-06-14 11:40:14,871:INFO:Copying training dataset
2023-06-14 11:40:14,876:INFO:Checking base model
2023-06-14 11:40:14,876:INFO:Base model : Random Forest Regressor
2023-06-14 11:40:14,880:INFO:Declaring metric variables
2023-06-14 11:40:14,885:INFO:Defining Hyperparameters
2023-06-14 11:40:15,011:INFO:Tuning with n_jobs=-1
2023-06-14 11:40:15,012:INFO:Initializing RandomizedSearchCV
2023-06-14 11:40:21,659:INFO:best_params: {'actual_estimator__n_estimators': 190, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 4, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': True}
2023-06-14 11:40:21,660:INFO:Hyperparameter search completed
2023-06-14 11:40:21,660:INFO:SubProcess create_model() called ==================================
2023-06-14 11:40:21,661:INFO:Initializing create_model()
2023-06-14 11:40:21,661:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248AF8433A0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248B04CBAF0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 190, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.3, 'max_features': 1.0, 'max_depth': 4, 'criterion': 'squared_error', 'bootstrap': True})
2023-06-14 11:40:21,661:INFO:Checking exceptions
2023-06-14 11:40:21,661:INFO:Importing libraries
2023-06-14 11:40:21,661:INFO:Copying training dataset
2023-06-14 11:40:21,666:INFO:Defining folds
2023-06-14 11:40:21,666:INFO:Declaring metric variables
2023-06-14 11:40:21,670:INFO:Importing untrained model
2023-06-14 11:40:21,670:INFO:Declaring custom model
2023-06-14 11:40:21,673:INFO:Random Forest Regressor Imported successfully
2023-06-14 11:40:21,678:INFO:Starting cross validation
2023-06-14 11:40:21,678:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:40:22,417:INFO:Calculating mean and std
2023-06-14 11:40:22,419:INFO:Creating metrics dataframe
2023-06-14 11:40:22,430:INFO:Finalizing model
2023-06-14 11:40:22,780:INFO:Uploading results into container
2023-06-14 11:40:22,781:INFO:Uploading model into container now
2023-06-14 11:40:22,782:INFO:_master_model_container: 21
2023-06-14 11:40:22,782:INFO:_display_container: 4
2023-06-14 11:40:22,782:INFO:RandomForestRegressor(max_depth=4, min_impurity_decrease=0.3,
                      min_samples_leaf=2, n_estimators=190, n_jobs=-1,
                      random_state=42)
2023-06-14 11:40:22,782:INFO:create_model() successfully completed......................................
2023-06-14 11:40:22,909:INFO:SubProcess create_model() end ==================================
2023-06-14 11:40:22,909:INFO:choose_better activated
2023-06-14 11:40:22,913:INFO:SubProcess create_model() called ==================================
2023-06-14 11:40:22,913:INFO:Initializing create_model()
2023-06-14 11:40:22,913:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248AF8433A0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-14 11:40:22,913:INFO:Checking exceptions
2023-06-14 11:40:22,916:INFO:Importing libraries
2023-06-14 11:40:22,916:INFO:Copying training dataset
2023-06-14 11:40:22,921:INFO:Defining folds
2023-06-14 11:40:22,922:INFO:Declaring metric variables
2023-06-14 11:40:22,922:INFO:Importing untrained model
2023-06-14 11:40:22,922:INFO:Declaring custom model
2023-06-14 11:40:22,923:INFO:Random Forest Regressor Imported successfully
2023-06-14 11:40:22,924:INFO:Starting cross validation
2023-06-14 11:40:22,925:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 11:40:23,563:INFO:Calculating mean and std
2023-06-14 11:40:23,563:INFO:Creating metrics dataframe
2023-06-14 11:40:23,566:INFO:Finalizing model
2023-06-14 11:40:23,848:INFO:Uploading results into container
2023-06-14 11:40:23,849:INFO:Uploading model into container now
2023-06-14 11:40:23,850:INFO:_master_model_container: 22
2023-06-14 11:40:23,850:INFO:_display_container: 5
2023-06-14 11:40:23,850:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-14 11:40:23,850:INFO:create_model() successfully completed......................................
2023-06-14 11:40:24,002:INFO:SubProcess create_model() end ==================================
2023-06-14 11:40:24,003:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) result for R2 is 0.9102
2023-06-14 11:40:24,003:INFO:RandomForestRegressor(max_depth=4, min_impurity_decrease=0.3,
                      min_samples_leaf=2, n_estimators=190, n_jobs=-1,
                      random_state=42) result for R2 is 0.8871
2023-06-14 11:40:24,004:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) is best model
2023-06-14 11:40:24,004:INFO:choose_better completed
2023-06-14 11:40:24,004:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-06-14 11:40:24,012:INFO:_master_model_container: 22
2023-06-14 11:40:24,012:INFO:_display_container: 4
2023-06-14 11:40:24,013:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-14 11:40:24,013:INFO:tune_model() successfully completed......................................
2023-06-14 11:40:33,865:INFO:Initializing plot_model()
2023-06-14 11:40:33,865:INFO:plot_model(plot=learning, fold=None, use_train_data=True, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248AF8433A0>, system=True)
2023-06-14 11:40:33,865:INFO:Checking exceptions
2023-06-14 11:40:33,893:INFO:Preloading libraries
2023-06-14 11:40:33,934:INFO:Copying training dataset
2023-06-14 11:40:33,934:INFO:Plot type: learning
2023-06-14 11:40:34,028:INFO:Fitting Model
2023-06-14 11:41:55,776:INFO:Visual Rendered Successfully
2023-06-14 11:41:55,922:INFO:plot_model() successfully completed......................................
2023-06-14 11:43:24,325:INFO:Initializing plot_model()
2023-06-14 11:43:24,325:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248AF8433A0>, system=True)
2023-06-14 11:43:24,325:INFO:Checking exceptions
2023-06-14 11:43:24,351:INFO:Preloading libraries
2023-06-14 11:43:24,387:INFO:Copying training dataset
2023-06-14 11:43:24,387:INFO:Plot type: feature
2023-06-14 11:43:24,387:WARNING:No coef_ found. Trying feature_importances_
2023-06-14 11:43:24,596:INFO:Visual Rendered Successfully
2023-06-14 11:43:24,730:INFO:plot_model() successfully completed......................................
2023-06-14 11:45:32,629:INFO:Initializing evaluate_model()
2023-06-14 11:45:32,629:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248AF8433A0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-06-14 11:45:32,652:INFO:Initializing plot_model()
2023-06-14 11:45:32,652:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248AF8433A0>, system=True)
2023-06-14 11:45:32,652:INFO:Checking exceptions
2023-06-14 11:45:32,678:INFO:Preloading libraries
2023-06-14 11:45:32,707:INFO:Copying training dataset
2023-06-14 11:45:32,707:INFO:Plot type: pipeline
2023-06-14 11:45:32,863:INFO:Visual Rendered Successfully
2023-06-14 11:45:33,002:INFO:plot_model() successfully completed......................................
2023-06-14 11:45:37,855:INFO:Initializing plot_model()
2023-06-14 11:45:37,855:INFO:plot_model(plot=manifold, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248AF8433A0>, system=True)
2023-06-14 11:45:37,855:INFO:Checking exceptions
2023-06-14 11:45:37,878:INFO:Preloading libraries
2023-06-14 11:45:37,932:INFO:Copying training dataset
2023-06-14 11:45:37,932:INFO:Plot type: manifold
2023-06-14 11:45:38,097:INFO:Fitting & Transforming Model
2023-06-14 11:45:50,602:INFO:Visual Rendered Successfully
2023-06-14 11:45:50,750:INFO:plot_model() successfully completed......................................
2023-06-14 13:37:54,144:INFO:Initializing plot_model()
2023-06-14 13:37:54,145:INFO:plot_model(plot=train_trein_split, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248AF8433A0>, system=True)
2023-06-14 13:37:54,145:INFO:Checking exceptions
2023-06-14 13:38:25,692:INFO:Initializing plot_model()
2023-06-14 13:38:25,692:INFO:plot_model(plot=train_trein_split, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=      qtd_abertas_Empresario_Individual  taxa_homicidio  RH_adm_dir  \
0                                   194             8.0       926.0   
1                                  1275            38.0      2563.0   
2                                    49             0.0       344.0   
3                                  1258            21.0      1971.0   
4                                   257             3.0       591.0   
...                                 ...             ...         ...   
5565                                222             1.0       528.0   
5566                                 66             0.0       394.0   
5567                                 23             0.0       403.0   
5568                                 47             0.0       344.0   
5569                              54325           480.0    122197.0   

      densidade_banda_larga  densidade_telefonia_movel  \
0                  8.958074                  70.647540   
1                 21.363407                  93.858639   
2                  5.407539                  78.369844   
3                 19.480189                 105.350861   
4                  8.540527                 108.074341   
...                     ...                        ...   
5565               6.423907                 106.821408   
5566               8.442568                 104.276827   
5567               1.240118                  66.485816   
5568               7.187342                  39.892274   
5569              25.834035                 109.381529   

      qtd_cursos_engenharias  qtd_cursos_negocios_direito  media_notas_CN  \
0                        2.0                         30.0      497.721951   
1                       99.0                        342.0      474.773986   
2                        0.0                          0.0      477.266667   
3                      184.0                        422.0      489.744000   
4                        4.0                         35.0      479.268750   
...                      ...                          ...             ...   
5565                     4.0                         12.0      449.954054   
5566                     0.0                          0.0      450.285714   
5567                     0.0                          0.0      431.645455   
5568                     0.0                          0.0      432.055556   
5569                  2210.0                      13097.0      505.707532   

      media_notas_CH  media_NU_NOTA_LC  ...  Reducao_ISSQN_Sim  \
0         504.034091        491.079545  ...                  0   
1         495.727950        484.710248  ...                  0   
2         486.071429        447.628571  ...                  0   
3         505.006061        490.991919  ...                  1   
4         477.045714        454.722857  ...                  0   
...              ...               ...  ...                ...   
5565      479.917073        473.014634  ...                  0   
5566      464.383333        457.593333  ...                  0   
5567      443.025000        426.491667  ...                  0   
5568      417.394737        428.821053  ...                  0   
5569      534.044622        522.095562  ...                  0   

      Isencao_ISSQN_Sim  Isencao_Tx_Sim  Cessao_terrenos_Sim  \
0                     0               0                    0   
1                     0               1                    0   
2                     1               0                    0   
3                     0               1                    1   
4                     0               0                    0   
...                 ...             ...                  ...   
5565                  0               0                    0   
5566                  0               1                    0   
5567                  0               0                    1   
5568                  0               0                    1   
5569                  0               0                    1   

      Doacao_terrenos_Sim  Outros_mecanismos_Sim  ISH_Baixa  ISH_Máxima  \
0                       0                      0          0           0   
1                       1                      1          0           0   
2                       0                      1          0           0   
3                       1                      0          0           0   
4                       0                      0          1           0   
...                   ...                    ...        ...         ...   
5565                    0                      0          0           1   
5566                    1                      0          0           0   
5567                    1                      0          0           0   
5568                    0                      0          0           0   
5569                    0                      1          0           0   

      ISH_Média  ISH_Mínima  
0             0           0  
1             1           0  
2             0           0  
3             0           0  
4             0           0  
...         ...         ...  
5565          0           0  
5566          1           0  
5567          0           0  
5568          0           0  
5569          0           0  

[5570 rows x 31 columns], feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248AF8433A0>, system=True)
2023-06-14 13:38:25,692:INFO:Checking exceptions
2023-06-14 13:39:55,873:INFO:Initializing plot_model()
2023-06-14 13:39:55,873:INFO:plot_model(plot=train_test_split, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=      qtd_abertas_Empresario_Individual  taxa_homicidio  RH_adm_dir  \
0                                   194             8.0       926.0   
1                                  1275            38.0      2563.0   
2                                    49             0.0       344.0   
3                                  1258            21.0      1971.0   
4                                   257             3.0       591.0   
...                                 ...             ...         ...   
5565                                222             1.0       528.0   
5566                                 66             0.0       394.0   
5567                                 23             0.0       403.0   
5568                                 47             0.0       344.0   
5569                              54325           480.0    122197.0   

      densidade_banda_larga  densidade_telefonia_movel  \
0                  8.958074                  70.647540   
1                 21.363407                  93.858639   
2                  5.407539                  78.369844   
3                 19.480189                 105.350861   
4                  8.540527                 108.074341   
...                     ...                        ...   
5565               6.423907                 106.821408   
5566               8.442568                 104.276827   
5567               1.240118                  66.485816   
5568               7.187342                  39.892274   
5569              25.834035                 109.381529   

      qtd_cursos_engenharias  qtd_cursos_negocios_direito  media_notas_CN  \
0                        2.0                         30.0      497.721951   
1                       99.0                        342.0      474.773986   
2                        0.0                          0.0      477.266667   
3                      184.0                        422.0      489.744000   
4                        4.0                         35.0      479.268750   
...                      ...                          ...             ...   
5565                     4.0                         12.0      449.954054   
5566                     0.0                          0.0      450.285714   
5567                     0.0                          0.0      431.645455   
5568                     0.0                          0.0      432.055556   
5569                  2210.0                      13097.0      505.707532   

      media_notas_CH  media_NU_NOTA_LC  ...  Reducao_ISSQN_Sim  \
0         504.034091        491.079545  ...                  0   
1         495.727950        484.710248  ...                  0   
2         486.071429        447.628571  ...                  0   
3         505.006061        490.991919  ...                  1   
4         477.045714        454.722857  ...                  0   
...              ...               ...  ...                ...   
5565      479.917073        473.014634  ...                  0   
5566      464.383333        457.593333  ...                  0   
5567      443.025000        426.491667  ...                  0   
5568      417.394737        428.821053  ...                  0   
5569      534.044622        522.095562  ...                  0   

      Isencao_ISSQN_Sim  Isencao_Tx_Sim  Cessao_terrenos_Sim  \
0                     0               0                    0   
1                     0               1                    0   
2                     1               0                    0   
3                     0               1                    1   
4                     0               0                    0   
...                 ...             ...                  ...   
5565                  0               0                    0   
5566                  0               1                    0   
5567                  0               0                    1   
5568                  0               0                    1   
5569                  0               0                    1   

      Doacao_terrenos_Sim  Outros_mecanismos_Sim  ISH_Baixa  ISH_Máxima  \
0                       0                      0          0           0   
1                       1                      1          0           0   
2                       0                      1          0           0   
3                       1                      0          0           0   
4                       0                      0          1           0   
...                   ...                    ...        ...         ...   
5565                    0                      0          0           1   
5566                    1                      0          0           0   
5567                    1                      0          0           0   
5568                    0                      0          0           0   
5569                    0                      1          0           0   

      ISH_Média  ISH_Mínima  
0             0           0  
1             1           0  
2             0           0  
3             0           0  
4             0           0  
...         ...         ...  
5565          0           0  
5566          1           0  
5567          0           0  
5568          0           0  
5569          0           0  

[5570 rows x 31 columns], feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248AF8433A0>, system=True)
2023-06-14 13:39:55,873:INFO:Checking exceptions
2023-06-14 13:40:14,607:INFO:Initializing plot_model()
2023-06-14 13:40:14,607:INFO:plot_model(plot=train_test_split, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248AF8433A0>, system=True)
2023-06-14 13:40:14,607:INFO:Checking exceptions
2023-06-14 13:47:52,712:INFO:Initializing plot_model()
2023-06-14 13:47:52,712:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248AF8433A0>, system=True)
2023-06-14 13:47:52,712:INFO:Checking exceptions
2023-06-14 13:47:52,734:INFO:Preloading libraries
2023-06-14 13:47:52,767:INFO:Copying training dataset
2023-06-14 13:47:52,767:INFO:Plot type: pipeline
2023-06-14 13:47:52,862:INFO:Visual Rendered Successfully
2023-06-14 13:47:53,035:INFO:plot_model() successfully completed......................................
2023-06-14 13:47:57,278:INFO:Initializing plot_model()
2023-06-14 13:47:57,278:INFO:plot_model(plot=parameter, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248AF8433A0>, system=True)
2023-06-14 13:47:57,278:INFO:Checking exceptions
2023-06-14 13:47:57,301:INFO:Preloading libraries
2023-06-14 13:47:57,334:INFO:Copying training dataset
2023-06-14 13:47:57,334:INFO:Plot type: parameter
2023-06-14 13:47:57,340:INFO:Visual Rendered Successfully
2023-06-14 13:47:57,498:INFO:plot_model() successfully completed......................................
2023-06-14 13:48:26,494:INFO:Initializing plot_model()
2023-06-14 13:48:26,494:INFO:plot_model(plot=tree, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000248AF8433A0>, system=True)
2023-06-14 13:48:26,494:INFO:Checking exceptions
2023-06-14 13:48:26,519:INFO:Preloading libraries
2023-06-14 13:48:26,549:INFO:Copying training dataset
2023-06-14 13:48:26,549:INFO:Plot type: tree
2023-06-14 13:48:28,130:INFO:Plotting decision trees
2023-06-14 13:48:28,153:INFO:Plotting tree 0
2023-06-14 13:48:38,476:INFO:Plotting tree 1
2023-06-14 13:48:48,487:INFO:Plotting tree 2
2023-06-14 13:48:58,494:INFO:Plotting tree 3
2023-06-14 13:49:08,787:INFO:Plotting tree 4
2023-06-14 13:49:18,621:INFO:Plotting tree 5
2023-06-14 13:49:27,735:INFO:Plotting tree 6
2023-06-14 13:49:37,746:INFO:Plotting tree 7
2023-06-14 13:49:47,448:INFO:Plotting tree 8
2023-06-14 13:49:58,365:INFO:Plotting tree 9
2023-06-14 13:50:08,669:INFO:Plotting tree 10
2023-06-14 13:50:19,591:INFO:Plotting tree 11
2023-06-14 13:50:29,287:INFO:Plotting tree 12
2023-06-14 13:50:39,910:INFO:Plotting tree 13
2023-06-14 13:50:51,135:INFO:Plotting tree 14
2023-06-14 13:51:01,302:INFO:Plotting tree 15
2023-06-14 13:51:10,974:INFO:Plotting tree 16
2023-06-14 13:51:21,325:INFO:Plotting tree 17
2023-06-14 13:51:32,131:INFO:Plotting tree 18
2023-06-14 13:51:42,351:INFO:Plotting tree 19
2023-06-14 13:51:52,233:INFO:Plotting tree 20
2023-06-14 13:52:02,073:INFO:Plotting tree 21
2023-06-14 13:52:13,280:INFO:Plotting tree 22
2023-06-14 13:52:23,745:INFO:Plotting tree 23
2023-06-14 13:52:34,399:INFO:Plotting tree 24
2023-06-14 13:52:44,765:INFO:Plotting tree 25
2023-06-14 13:52:54,446:INFO:Plotting tree 26
2023-06-14 13:53:05,221:INFO:Plotting tree 27
2023-06-14 13:53:14,768:INFO:Plotting tree 28
2023-06-14 13:53:24,205:INFO:Plotting tree 29
2023-06-14 13:53:33,591:INFO:Plotting tree 30
2023-06-14 13:53:42,829:INFO:Plotting tree 31
2023-06-14 13:53:52,415:INFO:Plotting tree 32
2023-06-14 13:54:03,899:INFO:Plotting tree 33
2023-06-14 13:54:14,272:INFO:Plotting tree 34
2023-06-14 13:54:24,614:INFO:Plotting tree 35
2023-06-14 13:54:34,261:INFO:Plotting tree 36
2023-06-14 13:54:45,077:INFO:Plotting tree 37
2023-06-14 13:54:55,840:INFO:Plotting tree 38
2023-06-14 13:55:07,024:INFO:Plotting tree 39
2023-06-14 13:55:17,901:INFO:Plotting tree 40
2023-06-14 13:55:31,179:INFO:Plotting tree 41
2023-06-14 13:55:42,053:INFO:Plotting tree 42
2023-06-14 13:55:53,020:INFO:Plotting tree 43
2023-06-14 13:56:03,659:INFO:Plotting tree 44
2023-06-14 13:56:14,692:INFO:Plotting tree 45
2023-06-14 13:56:25,355:INFO:Plotting tree 46
2023-06-14 13:56:37,040:INFO:Plotting tree 47
2023-06-14 13:56:48,237:INFO:Plotting tree 48
2023-06-14 13:57:02,659:INFO:Plotting tree 49
2023-06-14 13:57:13,796:INFO:Plotting tree 50
2023-06-14 13:57:24,477:INFO:Plotting tree 51
2023-06-14 13:57:33,727:INFO:Plotting tree 52
2023-06-14 13:57:42,997:INFO:Plotting tree 53
2023-06-14 13:57:52,843:INFO:Plotting tree 54
2023-06-14 13:58:02,830:INFO:Plotting tree 55
2023-06-14 13:58:11,999:INFO:Plotting tree 56
2023-06-14 13:58:21,846:INFO:Plotting tree 57
2023-06-14 13:58:31,790:INFO:Plotting tree 58
2023-06-14 13:58:43,726:INFO:Plotting tree 59
2023-06-14 13:58:52,755:INFO:Plotting tree 60
2023-06-14 13:59:02,500:INFO:Plotting tree 61
2023-06-14 13:59:12,439:INFO:Plotting tree 62
2023-06-14 13:59:22,229:INFO:Plotting tree 63
2023-06-14 13:59:32,903:INFO:Plotting tree 64
2023-06-14 13:59:44,614:INFO:Plotting tree 65
2023-06-14 13:59:55,613:INFO:Plotting tree 66
2023-06-14 14:00:06,382:INFO:Plotting tree 67
2023-06-14 14:00:16,254:INFO:Plotting tree 68
2023-06-14 14:00:26,793:INFO:Plotting tree 69
2023-06-14 14:00:36,955:INFO:Plotting tree 70
2023-06-14 14:00:51,590:INFO:Plotting tree 71
2023-06-14 14:01:01,843:INFO:Plotting tree 72
2023-06-14 14:01:12,105:INFO:Plotting tree 73
2023-06-14 14:01:21,492:INFO:Plotting tree 74
2023-06-14 14:01:30,733:INFO:Plotting tree 75
2023-06-14 14:01:40,273:INFO:Plotting tree 76
2023-06-14 14:01:49,607:INFO:Plotting tree 77
2023-06-14 14:01:58,557:INFO:Plotting tree 78
2023-06-14 14:02:08,088:INFO:Plotting tree 79
2023-06-14 14:02:17,206:INFO:Plotting tree 80
2023-06-14 14:02:26,402:INFO:Plotting tree 81
2023-06-14 14:02:34,791:INFO:Plotting tree 82
2023-06-14 14:02:43,845:INFO:Plotting tree 83
2023-06-14 14:02:52,707:INFO:Plotting tree 84
2023-06-14 14:03:01,628:INFO:Plotting tree 85
2023-06-14 14:03:15,764:INFO:Plotting tree 86
2023-06-14 14:03:25,431:INFO:Plotting tree 87
2023-06-14 14:03:35,673:INFO:Plotting tree 88
2023-06-14 14:03:46,356:INFO:Plotting tree 89
2023-06-14 14:03:56,899:INFO:Plotting tree 90
2023-06-14 14:04:07,489:INFO:Plotting tree 91
2023-06-14 14:04:17,661:INFO:Plotting tree 92
2023-06-14 14:04:28,087:INFO:Plotting tree 93
2023-06-14 14:04:38,451:INFO:Plotting tree 94
2023-06-14 14:04:48,860:INFO:Plotting tree 95
2023-06-14 14:04:59,205:INFO:Plotting tree 96
2023-06-14 14:05:09,328:INFO:Plotting tree 97
2023-06-14 14:05:20,280:INFO:Plotting tree 98
2023-06-14 14:05:30,832:INFO:Plotting tree 99
2023-06-14 14:23:06,519:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 14:23:06,520:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 14:23:06,520:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 14:23:06,520:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 14:23:07,637:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-14 14:23:26,174:INFO:PyCaret RegressionExperiment
2023-06-14 14:23:26,175:INFO:Logging name: reg-default-name
2023-06-14 14:23:26,175:INFO:ML Usecase: MLUsecase.REGRESSION
2023-06-14 14:23:26,175:INFO:version 3.0.2
2023-06-14 14:23:26,175:INFO:Initializing setup()
2023-06-14 14:23:26,175:INFO:self.USI: 9e05
2023-06-14 14:23:26,175:INFO:self._variable_keys: {'y_train', 'data', 'fold_shuffle_param', '_available_plots', 'exp_name_log', 'target_param', 'X_train', 'n_jobs_param', 'idx', 'y', 'exp_id', 'seed', '_ml_usecase', 'y_test', 'log_plots_param', 'transform_target_param', 'pipeline', 'fold_groups_param', 'X_test', 'memory', 'html_param', 'gpu_n_jobs_param', 'gpu_param', 'logging_param', 'X', 'fold_generator', 'USI'}
2023-06-14 14:23:26,175:INFO:Checking environment
2023-06-14 14:23:26,175:INFO:python_version: 3.10.9
2023-06-14 14:23:26,175:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-06-14 14:23:26,175:INFO:machine: AMD64
2023-06-14 14:23:26,175:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-14 14:23:26,176:INFO:Memory: svmem(total=16901767168, available=7707480064, percent=54.4, used=9194287104, free=7707480064)
2023-06-14 14:23:26,176:INFO:Physical Core: 4
2023-06-14 14:23:26,176:INFO:Logical Core: 8
2023-06-14 14:23:26,176:INFO:Checking libraries
2023-06-14 14:23:26,176:INFO:System:
2023-06-14 14:23:26,176:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-06-14 14:23:26,176:INFO:executable: C:\Users\lapei\anaconda3\python.exe
2023-06-14 14:23:26,176:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-14 14:23:26,176:INFO:PyCaret required dependencies:
2023-06-14 14:23:26,176:INFO:                 pip: 22.3.1
2023-06-14 14:23:26,177:INFO:          setuptools: 65.6.3
2023-06-14 14:23:26,177:INFO:             pycaret: 3.0.2
2023-06-14 14:23:26,177:INFO:             IPython: 8.10.0
2023-06-14 14:23:26,177:INFO:          ipywidgets: 7.6.5
2023-06-14 14:23:26,177:INFO:                tqdm: 4.64.1
2023-06-14 14:23:26,177:INFO:               numpy: 1.23.5
2023-06-14 14:23:26,177:INFO:              pandas: 1.5.3
2023-06-14 14:23:26,177:INFO:              jinja2: 3.1.2
2023-06-14 14:23:26,177:INFO:               scipy: 1.10.0
2023-06-14 14:23:26,177:INFO:              joblib: 1.2.0
2023-06-14 14:23:26,177:INFO:             sklearn: 1.2.1
2023-06-14 14:23:26,177:INFO:                pyod: 1.0.9
2023-06-14 14:23:26,177:INFO:            imblearn: 0.10.1
2023-06-14 14:23:26,178:INFO:   category_encoders: 2.6.1
2023-06-14 14:23:26,178:INFO:            lightgbm: 3.3.5
2023-06-14 14:23:26,178:INFO:               numba: 0.56.4
2023-06-14 14:23:26,178:INFO:            requests: 2.28.1
2023-06-14 14:23:26,178:INFO:          matplotlib: 3.7.0
2023-06-14 14:23:26,178:INFO:          scikitplot: 0.3.7
2023-06-14 14:23:26,178:INFO:         yellowbrick: 1.5
2023-06-14 14:23:26,178:INFO:              plotly: 5.9.0
2023-06-14 14:23:26,178:INFO:             kaleido: 0.2.1
2023-06-14 14:23:26,178:INFO:         statsmodels: 0.13.5
2023-06-14 14:23:26,178:INFO:              sktime: 0.17.0
2023-06-14 14:23:26,178:INFO:               tbats: 1.1.3
2023-06-14 14:23:26,178:INFO:            pmdarima: 2.0.3
2023-06-14 14:23:26,178:INFO:              psutil: 5.9.0
2023-06-14 14:23:26,179:INFO:PyCaret optional dependencies:
2023-06-14 14:23:26,231:INFO:                shap: 0.41.0
2023-06-14 14:23:26,232:INFO:           interpret: Not installed
2023-06-14 14:23:26,232:INFO:                umap: Not installed
2023-06-14 14:23:26,232:INFO:    pandas_profiling: Not installed
2023-06-14 14:23:26,232:INFO:  explainerdashboard: Not installed
2023-06-14 14:23:26,232:INFO:             autoviz: Not installed
2023-06-14 14:23:26,232:INFO:           fairlearn: Not installed
2023-06-14 14:23:26,232:INFO:             xgboost: 1.7.3
2023-06-14 14:23:26,232:INFO:            catboost: Not installed
2023-06-14 14:23:26,232:INFO:              kmodes: Not installed
2023-06-14 14:23:26,232:INFO:             mlxtend: Not installed
2023-06-14 14:23:26,232:INFO:       statsforecast: Not installed
2023-06-14 14:23:26,232:INFO:        tune_sklearn: Not installed
2023-06-14 14:23:26,232:INFO:                 ray: Not installed
2023-06-14 14:23:26,232:INFO:            hyperopt: Not installed
2023-06-14 14:23:26,232:INFO:              optuna: Not installed
2023-06-14 14:23:26,232:INFO:               skopt: 0.9.0
2023-06-14 14:23:26,232:INFO:              mlflow: Not installed
2023-06-14 14:23:26,232:INFO:              gradio: Not installed
2023-06-14 14:23:26,232:INFO:             fastapi: Not installed
2023-06-14 14:23:26,232:INFO:             uvicorn: Not installed
2023-06-14 14:23:26,232:INFO:              m2cgen: Not installed
2023-06-14 14:23:26,232:INFO:           evidently: Not installed
2023-06-14 14:23:26,232:INFO:               fugue: Not installed
2023-06-14 14:23:26,232:INFO:           streamlit: Not installed
2023-06-14 14:23:26,232:INFO:             prophet: Not installed
2023-06-14 14:23:26,232:INFO:None
2023-06-14 14:23:26,232:INFO:Set up data.
2023-06-14 14:23:26,252:INFO:Set up train/test split.
2023-06-14 14:23:26,258:INFO:Set up index.
2023-06-14 14:23:26,258:INFO:Set up folding strategy.
2023-06-14 14:23:26,258:INFO:Assigning column types.
2023-06-14 14:23:26,264:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-14 14:23:26,264:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-14 14:23:26,276:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 14:23:26,288:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 14:23:26,457:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 14:23:26,586:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 14:23:26,587:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 14:23:26,969:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 14:23:26,970:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-14 14:23:26,978:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 14:23:26,983:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 14:23:27,058:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 14:23:27,118:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 14:23:27,118:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 14:23:27,121:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 14:23:27,121:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-06-14 14:23:27,125:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 14:23:27,130:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 14:23:27,194:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 14:23:27,240:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 14:23:27,241:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 14:23:27,244:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 14:23:27,249:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 14:23:27,253:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 14:23:27,314:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 14:23:27,355:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 14:23:27,356:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 14:23:27,358:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 14:23:27,358:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-06-14 14:23:27,367:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 14:23:27,422:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 14:23:27,464:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 14:23:27,465:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 14:23:27,467:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 14:23:27,477:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 14:23:27,537:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 14:23:27,600:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 14:23:27,601:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 14:23:27,603:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 14:23:27,604:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-06-14 14:23:27,670:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 14:23:27,713:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 14:23:27,714:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 14:23:27,719:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 14:23:27,822:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 14:23:27,875:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 14:23:27,880:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 14:23:27,884:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 14:23:27,884:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-14 14:23:27,952:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 14:23:28,017:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 14:23:28,022:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 14:23:28,095:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 14:23:28,139:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 14:23:28,141:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 14:23:28,141:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-06-14 14:23:28,265:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 14:23:28,267:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 14:23:28,370:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 14:23:28,372:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 14:23:28,378:INFO:Preparing preprocessing pipeline...
2023-06-14 14:23:28,378:INFO:Set up simple imputation.
2023-06-14 14:23:28,379:INFO:Set up column name cleaning.
2023-06-14 14:23:28,404:INFO:Finished creating preprocessing pipeline.
2023-06-14 14:23:28,409:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\lapei\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['taxa_homicidio', 'RH_adm_dir',
                                             'densidade_banda_larga',
                                             'densidade_telefonia_movel',
                                             'qtd_cursos_engenharias',
                                             'qtd_cursos_negocios_direito',
                                             'media_notas_CN', 'media_notas_CH',
                                             'media_NU_NOTA_LC',
                                             'media_NU_NOTA_MT',
                                             'media_...
                                             'Isencao_ISSQN_Sim',
                                             'Isencao_Tx_Sim',
                                             'Cessao_terrenos_Sim',
                                             'Doacao_terrenos_Sim',
                                             'Outros_mecanismos_Sim',
                                             'ISH_Baixa', 'ISH_Máxima',
                                             'ISH_Média', 'ISH_Mínima'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-06-14 14:23:28,410:INFO:Creating final display dataframe.
2023-06-14 14:23:28,526:INFO:Setup _display_container:                     Description                              Value
0                    Session id                                 42
1                        Target  qtd_abertas_Empresario_Individual
2                   Target type                         Regression
3           Original data shape                         (4456, 30)
4        Transformed data shape                         (4456, 30)
5   Transformed train set shape                         (3119, 30)
6    Transformed test set shape                         (1337, 30)
7              Numeric features                                 29
8                    Preprocess                               True
9               Imputation type                             simple
10           Numeric imputation                               mean
11       Categorical imputation                               mode
12               Fold Generator                              KFold
13                  Fold Number                                 10
14                     CPU Jobs                                 -1
15                      Use GPU                              False
16               Log Experiment                              False
17              Experiment Name                   reg-default-name
18                          USI                               9e05
2023-06-14 14:23:28,648:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 14:23:28,649:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 14:23:28,757:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-14 14:23:28,760:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 14:23:28,761:INFO:setup() successfully completed in 2.78s...............
2023-06-14 14:23:28,771:INFO:Initializing compare_models()
2023-06-14 14:23:28,772:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>, include=None, fold=5, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>, 'include': None, 'exclude': None, 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-06-14 14:23:28,772:INFO:Checking exceptions
2023-06-14 14:23:28,775:INFO:Preparing display monitor
2023-06-14 14:23:28,805:INFO:Initializing Linear Regression
2023-06-14 14:23:28,805:INFO:Total runtime is 0.0 minutes
2023-06-14 14:23:28,809:INFO:SubProcess create_model() called ==================================
2023-06-14 14:23:28,810:INFO:Initializing create_model()
2023-06-14 14:23:28,810:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000233315760B0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 14:23:28,810:INFO:Checking exceptions
2023-06-14 14:23:28,810:INFO:Importing libraries
2023-06-14 14:23:28,810:INFO:Copying training dataset
2023-06-14 14:23:28,815:INFO:Defining folds
2023-06-14 14:23:28,815:INFO:Declaring metric variables
2023-06-14 14:23:28,818:INFO:Importing untrained model
2023-06-14 14:23:28,822:INFO:Linear Regression Imported successfully
2023-06-14 14:23:28,828:INFO:Starting cross validation
2023-06-14 14:23:28,838:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 14:23:33,975:INFO:Calculating mean and std
2023-06-14 14:23:33,977:INFO:Creating metrics dataframe
2023-06-14 14:23:34,176:INFO:Uploading results into container
2023-06-14 14:23:34,177:INFO:Uploading model into container now
2023-06-14 14:23:34,178:INFO:_master_model_container: 1
2023-06-14 14:23:34,178:INFO:_display_container: 2
2023-06-14 14:23:34,179:INFO:LinearRegression(n_jobs=-1)
2023-06-14 14:23:34,179:INFO:create_model() successfully completed......................................
2023-06-14 14:23:34,337:INFO:SubProcess create_model() end ==================================
2023-06-14 14:23:34,337:INFO:Creating metrics dataframe
2023-06-14 14:23:34,346:INFO:Initializing Lasso Regression
2023-06-14 14:23:34,346:INFO:Total runtime is 0.09234139124552408 minutes
2023-06-14 14:23:34,349:INFO:SubProcess create_model() called ==================================
2023-06-14 14:23:34,351:INFO:Initializing create_model()
2023-06-14 14:23:34,351:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000233315760B0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 14:23:34,351:INFO:Checking exceptions
2023-06-14 14:23:34,351:INFO:Importing libraries
2023-06-14 14:23:34,352:INFO:Copying training dataset
2023-06-14 14:23:34,360:INFO:Defining folds
2023-06-14 14:23:34,361:INFO:Declaring metric variables
2023-06-14 14:23:34,366:INFO:Importing untrained model
2023-06-14 14:23:34,370:INFO:Lasso Regression Imported successfully
2023-06-14 14:23:34,381:INFO:Starting cross validation
2023-06-14 14:23:34,383:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 14:23:36,961:INFO:Calculating mean and std
2023-06-14 14:23:36,962:INFO:Creating metrics dataframe
2023-06-14 14:23:37,147:INFO:Uploading results into container
2023-06-14 14:23:37,149:INFO:Uploading model into container now
2023-06-14 14:23:37,149:INFO:_master_model_container: 2
2023-06-14 14:23:37,149:INFO:_display_container: 2
2023-06-14 14:23:37,150:INFO:Lasso(random_state=42)
2023-06-14 14:23:37,150:INFO:create_model() successfully completed......................................
2023-06-14 14:23:37,277:INFO:SubProcess create_model() end ==================================
2023-06-14 14:23:37,277:INFO:Creating metrics dataframe
2023-06-14 14:23:37,291:INFO:Initializing Ridge Regression
2023-06-14 14:23:37,291:INFO:Total runtime is 0.14143102566401164 minutes
2023-06-14 14:23:37,299:INFO:SubProcess create_model() called ==================================
2023-06-14 14:23:37,300:INFO:Initializing create_model()
2023-06-14 14:23:37,300:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000233315760B0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 14:23:37,300:INFO:Checking exceptions
2023-06-14 14:23:37,300:INFO:Importing libraries
2023-06-14 14:23:37,300:INFO:Copying training dataset
2023-06-14 14:23:37,308:INFO:Defining folds
2023-06-14 14:23:37,309:INFO:Declaring metric variables
2023-06-14 14:23:37,314:INFO:Importing untrained model
2023-06-14 14:23:37,318:INFO:Ridge Regression Imported successfully
2023-06-14 14:23:37,325:INFO:Starting cross validation
2023-06-14 14:23:37,327:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 14:23:37,808:INFO:Calculating mean and std
2023-06-14 14:23:37,809:INFO:Creating metrics dataframe
2023-06-14 14:23:37,947:INFO:Uploading results into container
2023-06-14 14:23:37,948:INFO:Uploading model into container now
2023-06-14 14:23:37,949:INFO:_master_model_container: 3
2023-06-14 14:23:37,949:INFO:_display_container: 2
2023-06-14 14:23:37,949:INFO:Ridge(random_state=42)
2023-06-14 14:23:37,950:INFO:create_model() successfully completed......................................
2023-06-14 14:23:38,067:INFO:SubProcess create_model() end ==================================
2023-06-14 14:23:38,068:INFO:Creating metrics dataframe
2023-06-14 14:23:38,091:INFO:Initializing Elastic Net
2023-06-14 14:23:38,091:INFO:Total runtime is 0.15475643078486126 minutes
2023-06-14 14:23:38,100:INFO:SubProcess create_model() called ==================================
2023-06-14 14:23:38,100:INFO:Initializing create_model()
2023-06-14 14:23:38,101:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000233315760B0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 14:23:38,101:INFO:Checking exceptions
2023-06-14 14:23:38,101:INFO:Importing libraries
2023-06-14 14:23:38,101:INFO:Copying training dataset
2023-06-14 14:23:38,108:INFO:Defining folds
2023-06-14 14:23:38,108:INFO:Declaring metric variables
2023-06-14 14:23:38,113:INFO:Importing untrained model
2023-06-14 14:23:38,117:INFO:Elastic Net Imported successfully
2023-06-14 14:23:38,126:INFO:Starting cross validation
2023-06-14 14:23:38,126:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 14:23:38,618:INFO:Calculating mean and std
2023-06-14 14:23:38,620:INFO:Creating metrics dataframe
2023-06-14 14:23:38,798:INFO:Uploading results into container
2023-06-14 14:23:38,799:INFO:Uploading model into container now
2023-06-14 14:23:38,799:INFO:_master_model_container: 4
2023-06-14 14:23:38,799:INFO:_display_container: 2
2023-06-14 14:23:38,799:INFO:ElasticNet(random_state=42)
2023-06-14 14:23:38,800:INFO:create_model() successfully completed......................................
2023-06-14 14:23:38,911:INFO:SubProcess create_model() end ==================================
2023-06-14 14:23:38,912:INFO:Creating metrics dataframe
2023-06-14 14:23:38,934:INFO:Initializing Least Angle Regression
2023-06-14 14:23:38,935:INFO:Total runtime is 0.16882617870966596 minutes
2023-06-14 14:23:38,944:INFO:SubProcess create_model() called ==================================
2023-06-14 14:23:38,945:INFO:Initializing create_model()
2023-06-14 14:23:38,945:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000233315760B0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 14:23:38,945:INFO:Checking exceptions
2023-06-14 14:23:38,946:INFO:Importing libraries
2023-06-14 14:23:38,946:INFO:Copying training dataset
2023-06-14 14:23:38,953:INFO:Defining folds
2023-06-14 14:23:38,953:INFO:Declaring metric variables
2023-06-14 14:23:38,959:INFO:Importing untrained model
2023-06-14 14:23:38,962:INFO:Least Angle Regression Imported successfully
2023-06-14 14:23:38,972:INFO:Starting cross validation
2023-06-14 14:23:38,973:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 14:23:39,442:INFO:Calculating mean and std
2023-06-14 14:23:39,444:INFO:Creating metrics dataframe
2023-06-14 14:23:39,631:INFO:Uploading results into container
2023-06-14 14:23:39,634:INFO:Uploading model into container now
2023-06-14 14:23:39,634:INFO:_master_model_container: 5
2023-06-14 14:23:39,635:INFO:_display_container: 2
2023-06-14 14:23:39,635:INFO:Lars(random_state=42)
2023-06-14 14:23:39,635:INFO:create_model() successfully completed......................................
2023-06-14 14:23:39,771:INFO:SubProcess create_model() end ==================================
2023-06-14 14:23:39,772:INFO:Creating metrics dataframe
2023-06-14 14:23:39,798:INFO:Initializing Lasso Least Angle Regression
2023-06-14 14:23:39,799:INFO:Total runtime is 0.18322468598683678 minutes
2023-06-14 14:23:39,803:INFO:SubProcess create_model() called ==================================
2023-06-14 14:23:39,803:INFO:Initializing create_model()
2023-06-14 14:23:39,803:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000233315760B0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 14:23:39,803:INFO:Checking exceptions
2023-06-14 14:23:39,803:INFO:Importing libraries
2023-06-14 14:23:39,804:INFO:Copying training dataset
2023-06-14 14:23:39,811:INFO:Defining folds
2023-06-14 14:23:39,812:INFO:Declaring metric variables
2023-06-14 14:23:39,815:INFO:Importing untrained model
2023-06-14 14:23:39,821:INFO:Lasso Least Angle Regression Imported successfully
2023-06-14 14:23:39,829:INFO:Starting cross validation
2023-06-14 14:23:39,830:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 14:23:40,298:INFO:Calculating mean and std
2023-06-14 14:23:40,300:INFO:Creating metrics dataframe
2023-06-14 14:23:40,432:INFO:Uploading results into container
2023-06-14 14:23:40,433:INFO:Uploading model into container now
2023-06-14 14:23:40,434:INFO:_master_model_container: 6
2023-06-14 14:23:40,434:INFO:_display_container: 2
2023-06-14 14:23:40,434:INFO:LassoLars(random_state=42)
2023-06-14 14:23:40,434:INFO:create_model() successfully completed......................................
2023-06-14 14:23:40,545:INFO:SubProcess create_model() end ==================================
2023-06-14 14:23:40,545:INFO:Creating metrics dataframe
2023-06-14 14:23:40,563:INFO:Initializing Orthogonal Matching Pursuit
2023-06-14 14:23:40,564:INFO:Total runtime is 0.19597146113713584 minutes
2023-06-14 14:23:40,570:INFO:SubProcess create_model() called ==================================
2023-06-14 14:23:40,570:INFO:Initializing create_model()
2023-06-14 14:23:40,570:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000233315760B0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 14:23:40,570:INFO:Checking exceptions
2023-06-14 14:23:40,571:INFO:Importing libraries
2023-06-14 14:23:40,571:INFO:Copying training dataset
2023-06-14 14:23:40,578:INFO:Defining folds
2023-06-14 14:23:40,579:INFO:Declaring metric variables
2023-06-14 14:23:40,585:INFO:Importing untrained model
2023-06-14 14:23:40,589:INFO:Orthogonal Matching Pursuit Imported successfully
2023-06-14 14:23:40,596:INFO:Starting cross validation
2023-06-14 14:23:40,597:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 14:23:41,086:INFO:Calculating mean and std
2023-06-14 14:23:41,087:INFO:Creating metrics dataframe
2023-06-14 14:23:41,224:INFO:Uploading results into container
2023-06-14 14:23:41,225:INFO:Uploading model into container now
2023-06-14 14:23:41,225:INFO:_master_model_container: 7
2023-06-14 14:23:41,225:INFO:_display_container: 2
2023-06-14 14:23:41,226:INFO:OrthogonalMatchingPursuit()
2023-06-14 14:23:41,226:INFO:create_model() successfully completed......................................
2023-06-14 14:23:41,362:INFO:SubProcess create_model() end ==================================
2023-06-14 14:23:41,362:INFO:Creating metrics dataframe
2023-06-14 14:23:41,387:INFO:Initializing Bayesian Ridge
2023-06-14 14:23:41,388:INFO:Total runtime is 0.20971511999766035 minutes
2023-06-14 14:23:41,398:INFO:SubProcess create_model() called ==================================
2023-06-14 14:23:41,400:INFO:Initializing create_model()
2023-06-14 14:23:41,400:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000233315760B0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 14:23:41,400:INFO:Checking exceptions
2023-06-14 14:23:41,400:INFO:Importing libraries
2023-06-14 14:23:41,401:INFO:Copying training dataset
2023-06-14 14:23:41,412:INFO:Defining folds
2023-06-14 14:23:41,413:INFO:Declaring metric variables
2023-06-14 14:23:41,417:INFO:Importing untrained model
2023-06-14 14:23:41,422:INFO:Bayesian Ridge Imported successfully
2023-06-14 14:23:41,428:INFO:Starting cross validation
2023-06-14 14:23:41,429:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 14:23:41,892:INFO:Calculating mean and std
2023-06-14 14:23:41,893:INFO:Creating metrics dataframe
2023-06-14 14:23:42,029:INFO:Uploading results into container
2023-06-14 14:23:42,030:INFO:Uploading model into container now
2023-06-14 14:23:42,030:INFO:_master_model_container: 8
2023-06-14 14:23:42,030:INFO:_display_container: 2
2023-06-14 14:23:42,031:INFO:BayesianRidge()
2023-06-14 14:23:42,031:INFO:create_model() successfully completed......................................
2023-06-14 14:23:42,149:INFO:SubProcess create_model() end ==================================
2023-06-14 14:23:42,149:INFO:Creating metrics dataframe
2023-06-14 14:23:42,161:INFO:Initializing Passive Aggressive Regressor
2023-06-14 14:23:42,162:INFO:Total runtime is 0.222613000869751 minutes
2023-06-14 14:23:42,166:INFO:SubProcess create_model() called ==================================
2023-06-14 14:23:42,166:INFO:Initializing create_model()
2023-06-14 14:23:42,166:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000233315760B0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 14:23:42,167:INFO:Checking exceptions
2023-06-14 14:23:42,167:INFO:Importing libraries
2023-06-14 14:23:42,167:INFO:Copying training dataset
2023-06-14 14:23:42,174:INFO:Defining folds
2023-06-14 14:23:42,174:INFO:Declaring metric variables
2023-06-14 14:23:42,178:INFO:Importing untrained model
2023-06-14 14:23:42,183:INFO:Passive Aggressive Regressor Imported successfully
2023-06-14 14:23:42,190:INFO:Starting cross validation
2023-06-14 14:23:42,191:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 14:23:42,681:INFO:Calculating mean and std
2023-06-14 14:23:42,682:INFO:Creating metrics dataframe
2023-06-14 14:23:42,825:INFO:Uploading results into container
2023-06-14 14:23:42,826:INFO:Uploading model into container now
2023-06-14 14:23:42,826:INFO:_master_model_container: 9
2023-06-14 14:23:42,826:INFO:_display_container: 2
2023-06-14 14:23:42,827:INFO:PassiveAggressiveRegressor(random_state=42)
2023-06-14 14:23:42,827:INFO:create_model() successfully completed......................................
2023-06-14 14:23:42,959:INFO:SubProcess create_model() end ==================================
2023-06-14 14:23:42,959:INFO:Creating metrics dataframe
2023-06-14 14:23:42,980:INFO:Initializing Huber Regressor
2023-06-14 14:23:42,980:INFO:Total runtime is 0.23624229828516644 minutes
2023-06-14 14:23:42,984:INFO:SubProcess create_model() called ==================================
2023-06-14 14:23:42,984:INFO:Initializing create_model()
2023-06-14 14:23:42,985:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000233315760B0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 14:23:42,985:INFO:Checking exceptions
2023-06-14 14:23:42,985:INFO:Importing libraries
2023-06-14 14:23:42,985:INFO:Copying training dataset
2023-06-14 14:23:42,996:INFO:Defining folds
2023-06-14 14:23:42,996:INFO:Declaring metric variables
2023-06-14 14:23:43,006:INFO:Importing untrained model
2023-06-14 14:23:43,013:INFO:Huber Regressor Imported successfully
2023-06-14 14:23:43,022:INFO:Starting cross validation
2023-06-14 14:23:43,023:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 14:23:43,161:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 14:23:43,162:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 14:23:43,165:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 14:23:43,215:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 14:23:43,238:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 14:23:43,636:INFO:Calculating mean and std
2023-06-14 14:23:43,637:INFO:Creating metrics dataframe
2023-06-14 14:23:43,868:INFO:Uploading results into container
2023-06-14 14:23:43,868:INFO:Uploading model into container now
2023-06-14 14:23:43,869:INFO:_master_model_container: 10
2023-06-14 14:23:43,870:INFO:_display_container: 2
2023-06-14 14:23:43,870:INFO:HuberRegressor()
2023-06-14 14:23:43,870:INFO:create_model() successfully completed......................................
2023-06-14 14:23:43,996:INFO:SubProcess create_model() end ==================================
2023-06-14 14:23:43,996:INFO:Creating metrics dataframe
2023-06-14 14:23:44,007:INFO:Initializing K Neighbors Regressor
2023-06-14 14:23:44,007:INFO:Total runtime is 0.2533673405647278 minutes
2023-06-14 14:23:44,011:INFO:SubProcess create_model() called ==================================
2023-06-14 14:23:44,012:INFO:Initializing create_model()
2023-06-14 14:23:44,012:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000233315760B0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 14:23:44,012:INFO:Checking exceptions
2023-06-14 14:23:44,012:INFO:Importing libraries
2023-06-14 14:23:44,012:INFO:Copying training dataset
2023-06-14 14:23:44,021:INFO:Defining folds
2023-06-14 14:23:44,021:INFO:Declaring metric variables
2023-06-14 14:23:44,025:INFO:Importing untrained model
2023-06-14 14:23:44,030:INFO:K Neighbors Regressor Imported successfully
2023-06-14 14:23:44,036:INFO:Starting cross validation
2023-06-14 14:23:44,038:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 14:23:44,616:INFO:Calculating mean and std
2023-06-14 14:23:44,618:INFO:Creating metrics dataframe
2023-06-14 14:23:44,819:INFO:Uploading results into container
2023-06-14 14:23:44,819:INFO:Uploading model into container now
2023-06-14 14:23:44,820:INFO:_master_model_container: 11
2023-06-14 14:23:44,820:INFO:_display_container: 2
2023-06-14 14:23:44,820:INFO:KNeighborsRegressor(n_jobs=-1)
2023-06-14 14:23:44,821:INFO:create_model() successfully completed......................................
2023-06-14 14:23:44,939:INFO:SubProcess create_model() end ==================================
2023-06-14 14:23:44,940:INFO:Creating metrics dataframe
2023-06-14 14:23:44,965:INFO:Initializing Decision Tree Regressor
2023-06-14 14:23:44,965:INFO:Total runtime is 0.2693195144335429 minutes
2023-06-14 14:23:44,971:INFO:SubProcess create_model() called ==================================
2023-06-14 14:23:44,971:INFO:Initializing create_model()
2023-06-14 14:23:44,971:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000233315760B0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 14:23:44,971:INFO:Checking exceptions
2023-06-14 14:23:44,972:INFO:Importing libraries
2023-06-14 14:23:44,972:INFO:Copying training dataset
2023-06-14 14:23:44,976:INFO:Defining folds
2023-06-14 14:23:44,976:INFO:Declaring metric variables
2023-06-14 14:23:44,981:INFO:Importing untrained model
2023-06-14 14:23:44,984:INFO:Decision Tree Regressor Imported successfully
2023-06-14 14:23:44,991:INFO:Starting cross validation
2023-06-14 14:23:44,992:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 14:23:45,523:INFO:Calculating mean and std
2023-06-14 14:23:45,525:INFO:Creating metrics dataframe
2023-06-14 14:23:45,703:INFO:Uploading results into container
2023-06-14 14:23:45,704:INFO:Uploading model into container now
2023-06-14 14:23:45,704:INFO:_master_model_container: 12
2023-06-14 14:23:45,705:INFO:_display_container: 2
2023-06-14 14:23:45,705:INFO:DecisionTreeRegressor(random_state=42)
2023-06-14 14:23:45,705:INFO:create_model() successfully completed......................................
2023-06-14 14:23:45,834:INFO:SubProcess create_model() end ==================================
2023-06-14 14:23:45,834:INFO:Creating metrics dataframe
2023-06-14 14:23:45,846:INFO:Initializing Random Forest Regressor
2023-06-14 14:23:45,846:INFO:Total runtime is 0.2840104142824809 minutes
2023-06-14 14:23:45,851:INFO:SubProcess create_model() called ==================================
2023-06-14 14:23:45,851:INFO:Initializing create_model()
2023-06-14 14:23:45,851:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000233315760B0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 14:23:45,851:INFO:Checking exceptions
2023-06-14 14:23:45,851:INFO:Importing libraries
2023-06-14 14:23:45,851:INFO:Copying training dataset
2023-06-14 14:23:45,857:INFO:Defining folds
2023-06-14 14:23:45,858:INFO:Declaring metric variables
2023-06-14 14:23:45,862:INFO:Importing untrained model
2023-06-14 14:23:45,867:INFO:Random Forest Regressor Imported successfully
2023-06-14 14:23:45,876:INFO:Starting cross validation
2023-06-14 14:23:45,877:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 14:23:46,482:INFO:Calculating mean and std
2023-06-14 14:23:46,484:INFO:Creating metrics dataframe
2023-06-14 14:23:46,628:INFO:Uploading results into container
2023-06-14 14:23:46,628:INFO:Uploading model into container now
2023-06-14 14:23:46,629:INFO:_master_model_container: 13
2023-06-14 14:23:46,629:INFO:_display_container: 2
2023-06-14 14:23:46,630:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-14 14:23:46,630:INFO:create_model() successfully completed......................................
2023-06-14 14:23:46,739:INFO:SubProcess create_model() end ==================================
2023-06-14 14:23:46,739:INFO:Creating metrics dataframe
2023-06-14 14:23:46,769:INFO:Initializing Extra Trees Regressor
2023-06-14 14:23:46,769:INFO:Total runtime is 0.29938781658808394 minutes
2023-06-14 14:23:46,778:INFO:SubProcess create_model() called ==================================
2023-06-14 14:23:46,779:INFO:Initializing create_model()
2023-06-14 14:23:46,779:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000233315760B0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 14:23:46,780:INFO:Checking exceptions
2023-06-14 14:23:46,780:INFO:Importing libraries
2023-06-14 14:23:46,780:INFO:Copying training dataset
2023-06-14 14:23:46,792:INFO:Defining folds
2023-06-14 14:23:46,792:INFO:Declaring metric variables
2023-06-14 14:23:46,801:INFO:Importing untrained model
2023-06-14 14:23:46,804:INFO:Extra Trees Regressor Imported successfully
2023-06-14 14:23:46,811:INFO:Starting cross validation
2023-06-14 14:23:46,812:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 14:23:47,514:INFO:Calculating mean and std
2023-06-14 14:23:47,516:INFO:Creating metrics dataframe
2023-06-14 14:23:47,686:INFO:Uploading results into container
2023-06-14 14:23:47,687:INFO:Uploading model into container now
2023-06-14 14:23:47,688:INFO:_master_model_container: 14
2023-06-14 14:23:47,689:INFO:_display_container: 2
2023-06-14 14:23:47,689:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2023-06-14 14:23:47,689:INFO:create_model() successfully completed......................................
2023-06-14 14:23:47,839:INFO:SubProcess create_model() end ==================================
2023-06-14 14:23:47,839:INFO:Creating metrics dataframe
2023-06-14 14:23:47,852:INFO:Initializing AdaBoost Regressor
2023-06-14 14:23:47,852:INFO:Total runtime is 0.31744143565495814 minutes
2023-06-14 14:23:47,857:INFO:SubProcess create_model() called ==================================
2023-06-14 14:23:47,858:INFO:Initializing create_model()
2023-06-14 14:23:47,858:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000233315760B0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 14:23:47,858:INFO:Checking exceptions
2023-06-14 14:23:47,858:INFO:Importing libraries
2023-06-14 14:23:47,859:INFO:Copying training dataset
2023-06-14 14:23:47,867:INFO:Defining folds
2023-06-14 14:23:47,868:INFO:Declaring metric variables
2023-06-14 14:23:47,874:INFO:Importing untrained model
2023-06-14 14:23:47,879:INFO:AdaBoost Regressor Imported successfully
2023-06-14 14:23:47,886:INFO:Starting cross validation
2023-06-14 14:23:47,887:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 14:23:48,421:INFO:Calculating mean and std
2023-06-14 14:23:48,423:INFO:Creating metrics dataframe
2023-06-14 14:23:48,617:INFO:Uploading results into container
2023-06-14 14:23:48,618:INFO:Uploading model into container now
2023-06-14 14:23:48,618:INFO:_master_model_container: 15
2023-06-14 14:23:48,618:INFO:_display_container: 2
2023-06-14 14:23:48,619:INFO:AdaBoostRegressor(random_state=42)
2023-06-14 14:23:48,619:INFO:create_model() successfully completed......................................
2023-06-14 14:23:48,730:INFO:SubProcess create_model() end ==================================
2023-06-14 14:23:48,730:INFO:Creating metrics dataframe
2023-06-14 14:23:48,749:INFO:Initializing Gradient Boosting Regressor
2023-06-14 14:23:48,749:INFO:Total runtime is 0.3323912421862285 minutes
2023-06-14 14:23:48,754:INFO:SubProcess create_model() called ==================================
2023-06-14 14:23:48,755:INFO:Initializing create_model()
2023-06-14 14:23:48,755:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000233315760B0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 14:23:48,756:INFO:Checking exceptions
2023-06-14 14:23:48,756:INFO:Importing libraries
2023-06-14 14:23:48,756:INFO:Copying training dataset
2023-06-14 14:23:48,767:INFO:Defining folds
2023-06-14 14:23:48,767:INFO:Declaring metric variables
2023-06-14 14:23:48,771:INFO:Importing untrained model
2023-06-14 14:23:48,776:INFO:Gradient Boosting Regressor Imported successfully
2023-06-14 14:23:48,784:INFO:Starting cross validation
2023-06-14 14:23:48,785:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 14:23:49,347:INFO:Calculating mean and std
2023-06-14 14:23:49,349:INFO:Creating metrics dataframe
2023-06-14 14:23:49,541:INFO:Uploading results into container
2023-06-14 14:23:49,542:INFO:Uploading model into container now
2023-06-14 14:23:49,543:INFO:_master_model_container: 16
2023-06-14 14:23:49,543:INFO:_display_container: 2
2023-06-14 14:23:49,543:INFO:GradientBoostingRegressor(random_state=42)
2023-06-14 14:23:49,543:INFO:create_model() successfully completed......................................
2023-06-14 14:23:49,673:INFO:SubProcess create_model() end ==================================
2023-06-14 14:23:49,673:INFO:Creating metrics dataframe
2023-06-14 14:23:49,687:INFO:Initializing Extreme Gradient Boosting
2023-06-14 14:23:49,687:INFO:Total runtime is 0.3480285326639812 minutes
2023-06-14 14:23:49,691:INFO:SubProcess create_model() called ==================================
2023-06-14 14:23:49,692:INFO:Initializing create_model()
2023-06-14 14:23:49,692:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000233315760B0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 14:23:49,692:INFO:Checking exceptions
2023-06-14 14:23:49,692:INFO:Importing libraries
2023-06-14 14:23:49,692:INFO:Copying training dataset
2023-06-14 14:23:49,697:INFO:Defining folds
2023-06-14 14:23:49,697:INFO:Declaring metric variables
2023-06-14 14:23:49,701:INFO:Importing untrained model
2023-06-14 14:23:49,708:INFO:Extreme Gradient Boosting Imported successfully
2023-06-14 14:23:49,716:INFO:Starting cross validation
2023-06-14 14:23:49,717:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 14:23:50,271:INFO:Calculating mean and std
2023-06-14 14:23:50,272:INFO:Creating metrics dataframe
2023-06-14 14:23:50,458:INFO:Uploading results into container
2023-06-14 14:23:50,459:INFO:Uploading model into container now
2023-06-14 14:23:50,460:INFO:_master_model_container: 17
2023-06-14 14:23:50,461:INFO:_display_container: 2
2023-06-14 14:23:50,463:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=42, ...)
2023-06-14 14:23:50,463:INFO:create_model() successfully completed......................................
2023-06-14 14:23:50,578:INFO:SubProcess create_model() end ==================================
2023-06-14 14:23:50,578:INFO:Creating metrics dataframe
2023-06-14 14:23:50,591:INFO:Initializing Light Gradient Boosting Machine
2023-06-14 14:23:50,591:INFO:Total runtime is 0.36310120820999153 minutes
2023-06-14 14:23:50,595:INFO:SubProcess create_model() called ==================================
2023-06-14 14:23:50,595:INFO:Initializing create_model()
2023-06-14 14:23:50,595:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000233315760B0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 14:23:50,595:INFO:Checking exceptions
2023-06-14 14:23:50,597:INFO:Importing libraries
2023-06-14 14:23:50,597:INFO:Copying training dataset
2023-06-14 14:23:50,602:INFO:Defining folds
2023-06-14 14:23:50,603:INFO:Declaring metric variables
2023-06-14 14:23:50,606:INFO:Importing untrained model
2023-06-14 14:23:50,611:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-14 14:23:50,619:INFO:Starting cross validation
2023-06-14 14:23:50,620:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 14:23:52,395:INFO:Calculating mean and std
2023-06-14 14:23:52,396:INFO:Creating metrics dataframe
2023-06-14 14:23:52,590:INFO:Uploading results into container
2023-06-14 14:23:52,591:INFO:Uploading model into container now
2023-06-14 14:23:52,593:INFO:_master_model_container: 18
2023-06-14 14:23:52,593:INFO:_display_container: 2
2023-06-14 14:23:52,593:INFO:LGBMRegressor(random_state=42)
2023-06-14 14:23:52,594:INFO:create_model() successfully completed......................................
2023-06-14 14:23:52,768:INFO:SubProcess create_model() end ==================================
2023-06-14 14:23:52,769:INFO:Creating metrics dataframe
2023-06-14 14:23:52,796:INFO:Initializing Dummy Regressor
2023-06-14 14:23:52,796:INFO:Total runtime is 0.3998507777849834 minutes
2023-06-14 14:23:52,801:INFO:SubProcess create_model() called ==================================
2023-06-14 14:23:52,802:INFO:Initializing create_model()
2023-06-14 14:23:52,803:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000233315760B0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 14:23:52,803:INFO:Checking exceptions
2023-06-14 14:23:52,803:INFO:Importing libraries
2023-06-14 14:23:52,803:INFO:Copying training dataset
2023-06-14 14:23:52,812:INFO:Defining folds
2023-06-14 14:23:52,812:INFO:Declaring metric variables
2023-06-14 14:23:52,818:INFO:Importing untrained model
2023-06-14 14:23:52,823:INFO:Dummy Regressor Imported successfully
2023-06-14 14:23:52,832:INFO:Starting cross validation
2023-06-14 14:23:52,834:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 14:23:53,473:INFO:Calculating mean and std
2023-06-14 14:23:53,475:INFO:Creating metrics dataframe
2023-06-14 14:23:53,677:INFO:Uploading results into container
2023-06-14 14:23:53,678:INFO:Uploading model into container now
2023-06-14 14:23:53,679:INFO:_master_model_container: 19
2023-06-14 14:23:53,679:INFO:_display_container: 2
2023-06-14 14:23:53,679:INFO:DummyRegressor()
2023-06-14 14:23:53,679:INFO:create_model() successfully completed......................................
2023-06-14 14:23:53,814:INFO:SubProcess create_model() end ==================================
2023-06-14 14:23:53,814:INFO:Creating metrics dataframe
2023-06-14 14:23:53,841:INFO:Initializing create_model()
2023-06-14 14:23:53,841:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-14 14:23:53,841:INFO:Checking exceptions
2023-06-14 14:23:53,843:INFO:Importing libraries
2023-06-14 14:23:53,843:INFO:Copying training dataset
2023-06-14 14:23:53,852:INFO:Defining folds
2023-06-14 14:23:53,852:INFO:Declaring metric variables
2023-06-14 14:23:53,853:INFO:Importing untrained model
2023-06-14 14:23:53,853:INFO:Declaring custom model
2023-06-14 14:23:53,854:INFO:Random Forest Regressor Imported successfully
2023-06-14 14:23:53,855:INFO:Cross validation set to False
2023-06-14 14:23:53,855:INFO:Fitting Model
2023-06-14 14:23:54,077:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-14 14:23:54,077:INFO:create_model() successfully completed......................................
2023-06-14 14:23:54,239:INFO:_master_model_container: 19
2023-06-14 14:23:54,240:INFO:_display_container: 2
2023-06-14 14:23:54,240:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-14 14:23:54,240:INFO:compare_models() successfully completed......................................
2023-06-14 14:23:54,266:INFO:Initializing create_model()
2023-06-14 14:23:54,266:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>, estimator=rf, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-14 14:23:54,266:INFO:Checking exceptions
2023-06-14 14:23:54,287:INFO:Importing libraries
2023-06-14 14:23:54,287:INFO:Copying training dataset
2023-06-14 14:23:54,297:INFO:Defining folds
2023-06-14 14:23:54,297:INFO:Declaring metric variables
2023-06-14 14:23:54,301:INFO:Importing untrained model
2023-06-14 14:23:54,305:INFO:Random Forest Regressor Imported successfully
2023-06-14 14:23:54,311:INFO:Starting cross validation
2023-06-14 14:23:54,312:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 14:23:54,949:INFO:Calculating mean and std
2023-06-14 14:23:54,950:INFO:Creating metrics dataframe
2023-06-14 14:23:54,955:INFO:Finalizing model
2023-06-14 14:23:55,196:INFO:Uploading results into container
2023-06-14 14:23:55,197:INFO:Uploading model into container now
2023-06-14 14:23:55,207:INFO:_master_model_container: 20
2023-06-14 14:23:55,207:INFO:_display_container: 3
2023-06-14 14:23:55,207:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-14 14:23:55,207:INFO:create_model() successfully completed......................................
2023-06-14 14:24:00,553:INFO:Initializing create_model()
2023-06-14 14:24:00,554:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>, estimator=rf, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-14 14:24:00,554:INFO:Checking exceptions
2023-06-14 14:24:00,574:INFO:Importing libraries
2023-06-14 14:24:00,575:INFO:Copying training dataset
2023-06-14 14:24:00,583:INFO:Defining folds
2023-06-14 14:24:00,583:INFO:Declaring metric variables
2023-06-14 14:24:00,587:INFO:Importing untrained model
2023-06-14 14:24:00,592:INFO:Random Forest Regressor Imported successfully
2023-06-14 14:24:00,601:INFO:Starting cross validation
2023-06-14 14:24:00,603:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 14:24:01,241:INFO:Calculating mean and std
2023-06-14 14:24:01,242:INFO:Creating metrics dataframe
2023-06-14 14:24:01,251:INFO:Finalizing model
2023-06-14 14:24:01,621:INFO:Uploading results into container
2023-06-14 14:24:01,622:INFO:Uploading model into container now
2023-06-14 14:24:01,631:INFO:_master_model_container: 21
2023-06-14 14:24:01,631:INFO:_display_container: 4
2023-06-14 14:24:01,631:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-14 14:24:01,631:INFO:create_model() successfully completed......................................
2023-06-14 14:24:03,525:INFO:Initializing tune_model()
2023-06-14 14:24:03,525:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=5, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>)
2023-06-14 14:24:03,525:INFO:Checking exceptions
2023-06-14 14:24:03,548:INFO:Copying training dataset
2023-06-14 14:24:03,553:INFO:Checking base model
2023-06-14 14:24:03,554:INFO:Base model : Random Forest Regressor
2023-06-14 14:24:03,558:INFO:Declaring metric variables
2023-06-14 14:24:03,564:INFO:Defining Hyperparameters
2023-06-14 14:24:03,699:INFO:Tuning with n_jobs=-1
2023-06-14 14:24:03,701:INFO:Initializing RandomizedSearchCV
2023-06-14 14:24:10,158:INFO:best_params: {'actual_estimator__n_estimators': 190, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 4, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': True}
2023-06-14 14:24:10,160:INFO:Hyperparameter search completed
2023-06-14 14:24:10,160:INFO:SubProcess create_model() called ==================================
2023-06-14 14:24:10,161:INFO:Initializing create_model()
2023-06-14 14:24:10,161:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023331A71510>, model_only=True, return_train_score=False, kwargs={'n_estimators': 190, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.3, 'max_features': 1.0, 'max_depth': 4, 'criterion': 'squared_error', 'bootstrap': True})
2023-06-14 14:24:10,162:INFO:Checking exceptions
2023-06-14 14:24:10,162:INFO:Importing libraries
2023-06-14 14:24:10,162:INFO:Copying training dataset
2023-06-14 14:24:10,171:INFO:Defining folds
2023-06-14 14:24:10,171:INFO:Declaring metric variables
2023-06-14 14:24:10,175:INFO:Importing untrained model
2023-06-14 14:24:10,175:INFO:Declaring custom model
2023-06-14 14:24:10,178:INFO:Random Forest Regressor Imported successfully
2023-06-14 14:24:10,184:INFO:Starting cross validation
2023-06-14 14:24:10,185:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 14:24:10,831:INFO:Calculating mean and std
2023-06-14 14:24:10,832:INFO:Creating metrics dataframe
2023-06-14 14:24:10,839:INFO:Finalizing model
2023-06-14 14:24:11,166:INFO:Uploading results into container
2023-06-14 14:24:11,168:INFO:Uploading model into container now
2023-06-14 14:24:11,169:INFO:_master_model_container: 22
2023-06-14 14:24:11,169:INFO:_display_container: 5
2023-06-14 14:24:11,170:INFO:RandomForestRegressor(max_depth=4, min_impurity_decrease=0.3,
                      min_samples_leaf=2, n_estimators=190, n_jobs=-1,
                      random_state=42)
2023-06-14 14:24:11,171:INFO:create_model() successfully completed......................................
2023-06-14 14:24:11,292:INFO:SubProcess create_model() end ==================================
2023-06-14 14:24:11,292:INFO:choose_better activated
2023-06-14 14:24:11,296:INFO:SubProcess create_model() called ==================================
2023-06-14 14:24:11,296:INFO:Initializing create_model()
2023-06-14 14:24:11,297:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-14 14:24:11,297:INFO:Checking exceptions
2023-06-14 14:24:11,299:INFO:Importing libraries
2023-06-14 14:24:11,299:INFO:Copying training dataset
2023-06-14 14:24:11,307:INFO:Defining folds
2023-06-14 14:24:11,307:INFO:Declaring metric variables
2023-06-14 14:24:11,308:INFO:Importing untrained model
2023-06-14 14:24:11,308:INFO:Declaring custom model
2023-06-14 14:24:11,308:INFO:Random Forest Regressor Imported successfully
2023-06-14 14:24:11,308:INFO:Starting cross validation
2023-06-14 14:24:11,310:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 14:24:11,937:INFO:Calculating mean and std
2023-06-14 14:24:11,938:INFO:Creating metrics dataframe
2023-06-14 14:24:11,940:INFO:Finalizing model
2023-06-14 14:24:12,249:INFO:Uploading results into container
2023-06-14 14:24:12,250:INFO:Uploading model into container now
2023-06-14 14:24:12,251:INFO:_master_model_container: 23
2023-06-14 14:24:12,251:INFO:_display_container: 6
2023-06-14 14:24:12,252:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-14 14:24:12,252:INFO:create_model() successfully completed......................................
2023-06-14 14:24:12,373:INFO:SubProcess create_model() end ==================================
2023-06-14 14:24:12,374:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) result for R2 is 0.9102
2023-06-14 14:24:12,375:INFO:RandomForestRegressor(max_depth=4, min_impurity_decrease=0.3,
                      min_samples_leaf=2, n_estimators=190, n_jobs=-1,
                      random_state=42) result for R2 is 0.8871
2023-06-14 14:24:12,375:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) is best model
2023-06-14 14:24:12,375:INFO:choose_better completed
2023-06-14 14:24:12,375:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-06-14 14:24:12,389:INFO:_master_model_container: 23
2023-06-14 14:24:12,389:INFO:_display_container: 5
2023-06-14 14:24:12,390:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-14 14:24:12,390:INFO:tune_model() successfully completed......................................
2023-06-14 14:24:14,692:INFO:Initializing plot_model()
2023-06-14 14:24:14,692:INFO:plot_model(plot=learning, fold=None, use_train_data=True, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>, system=True)
2023-06-14 14:24:14,692:INFO:Checking exceptions
2023-06-14 14:24:14,721:INFO:Preloading libraries
2023-06-14 14:24:14,752:INFO:Copying training dataset
2023-06-14 14:24:14,752:INFO:Plot type: learning
2023-06-14 14:24:14,880:INFO:Fitting Model
2023-06-14 14:25:30,770:INFO:Visual Rendered Successfully
2023-06-14 14:25:30,903:INFO:plot_model() successfully completed......................................
2023-06-14 14:25:30,925:INFO:Initializing plot_model()
2023-06-14 14:25:30,925:INFO:plot_model(plot=vc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>, system=True)
2023-06-14 14:25:30,926:INFO:Checking exceptions
2023-06-14 14:25:30,966:INFO:Preloading libraries
2023-06-14 14:25:31,030:INFO:Copying training dataset
2023-06-14 14:25:31,030:INFO:Plot type: vc
2023-06-14 14:25:31,031:INFO:Determining param_name
2023-06-14 14:25:31,031:INFO:param_name: max_depth
2023-06-14 14:25:31,134:INFO:Fitting Model
2023-06-14 14:26:15,937:INFO:Visual Rendered Successfully
2023-06-14 14:26:16,059:INFO:plot_model() successfully completed......................................
2023-06-14 14:26:16,088:INFO:Initializing plot_model()
2023-06-14 14:26:16,088:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>, system=True)
2023-06-14 14:26:16,088:INFO:Checking exceptions
2023-06-14 14:26:16,109:INFO:Preloading libraries
2023-06-14 14:26:16,145:INFO:Copying training dataset
2023-06-14 14:26:16,145:INFO:Plot type: error
2023-06-14 14:26:16,280:INFO:Fitting Model
2023-06-14 14:26:16,280:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2023-06-14 14:26:16,280:INFO:Scoring test/hold-out set
2023-06-14 14:26:16,763:INFO:Visual Rendered Successfully
2023-06-14 14:26:16,886:INFO:plot_model() successfully completed......................................
2023-06-14 14:28:05,574:INFO:Initializing plot_model()
2023-06-14 14:28:05,574:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>, system=True)
2023-06-14 14:28:05,575:INFO:Checking exceptions
2023-06-14 14:28:05,598:INFO:Preloading libraries
2023-06-14 14:28:05,638:INFO:Copying training dataset
2023-06-14 14:28:05,638:INFO:Plot type: feature
2023-06-14 14:28:05,639:WARNING:No coef_ found. Trying feature_importances_
2023-06-14 14:28:05,860:INFO:Visual Rendered Successfully
2023-06-14 14:28:05,969:INFO:plot_model() successfully completed......................................
2023-06-14 14:28:10,877:INFO:Initializing plot_model()
2023-06-14 14:28:10,878:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>, system=True)
2023-06-14 14:28:10,878:INFO:Checking exceptions
2023-06-14 14:28:10,906:INFO:Preloading libraries
2023-06-14 14:28:10,951:INFO:Copying training dataset
2023-06-14 14:28:10,952:INFO:Plot type: residuals
2023-06-14 14:28:11,122:INFO:Fitting Model
2023-06-14 14:28:11,122:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2023-06-14 14:28:11,218:INFO:Scoring test/hold-out set
2023-06-14 14:28:11,829:INFO:Visual Rendered Successfully
2023-06-14 14:28:11,982:INFO:plot_model() successfully completed......................................
2023-06-14 14:28:20,059:INFO:Initializing interpret_model()
2023-06-14 14:28:20,059:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>)
2023-06-14 14:28:20,059:INFO:Checking exceptions
2023-06-14 14:28:20,060:INFO:Soft dependency imported: shap: 0.41.0
2023-06-14 14:28:20,089:INFO:plot type: summary
2023-06-14 14:28:20,089:INFO:Creating TreeExplainer
2023-06-14 14:28:20,122:INFO:Compiling shap values
2023-06-14 14:30:12,514:WARNING:No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored

2023-06-14 14:30:13,179:INFO:Visual Rendered Successfully
2023-06-14 14:30:13,179:INFO:interpret_model() successfully completed......................................
2023-06-14 14:30:21,083:INFO:Initializing interpret_model()
2023-06-14 14:30:21,084:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>)
2023-06-14 14:30:21,084:INFO:Checking exceptions
2023-06-14 14:30:21,084:INFO:Soft dependency imported: shap: 0.41.0
2023-06-14 14:30:21,110:INFO:plot type: summary
2023-06-14 14:30:21,110:INFO:Creating TreeExplainer
2023-06-14 14:30:21,131:INFO:Compiling shap values
2023-06-14 14:32:11,867:WARNING:No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored

2023-06-14 14:32:12,559:INFO:Visual Rendered Successfully
2023-06-14 14:32:12,559:INFO:interpret_model() successfully completed......................................
2023-06-14 14:32:19,420:INFO:Initializing interpret_model()
2023-06-14 14:32:19,420:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=pop_total, kwargs={}, observation=None, plot=correlation, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>)
2023-06-14 14:32:19,420:INFO:Checking exceptions
2023-06-14 14:32:19,422:INFO:Soft dependency imported: shap: 0.41.0
2023-06-14 14:32:19,449:INFO:plot type: correlation
2023-06-14 14:32:19,449:WARNING:feature value passed. Feature used for correlation plot: pop_total
2023-06-14 14:32:19,449:INFO:Creating TreeExplainer
2023-06-14 14:32:19,467:INFO:Compiling shap values
2023-06-14 14:34:14,176:INFO:model type detected: type 2
2023-06-14 14:34:14,467:INFO:Visual Rendered Successfully
2023-06-14 14:34:14,468:INFO:interpret_model() successfully completed......................................
2023-06-14 14:34:18,725:INFO:Initializing plot_model()
2023-06-14 14:34:18,726:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=3, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>, system=True)
2023-06-14 14:34:18,726:INFO:Checking exceptions
2023-06-14 14:34:18,756:INFO:Preloading libraries
2023-06-14 14:34:18,794:INFO:Copying training dataset
2023-06-14 14:34:18,794:INFO:Plot type: residuals
2023-06-14 14:34:18,953:INFO:Fitting Model
2023-06-14 14:34:18,953:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2023-06-14 14:34:19,034:INFO:Scoring test/hold-out set
2023-06-14 14:34:19,766:INFO:Visual Rendered Successfully
2023-06-14 14:34:19,953:INFO:plot_model() successfully completed......................................
2023-06-14 14:38:14,427:INFO:Initializing plot_model()
2023-06-14 14:38:14,427:INFO:plot_model(plot=learning, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>, system=True)
2023-06-14 14:38:14,427:INFO:Checking exceptions
2023-06-14 14:38:14,455:INFO:Preloading libraries
2023-06-14 14:38:14,496:INFO:Copying training dataset
2023-06-14 14:38:14,496:INFO:Plot type: learning
2023-06-14 14:38:14,601:INFO:Fitting Model
2023-06-14 14:39:39,378:INFO:Visual Rendered Successfully
2023-06-14 14:39:39,517:INFO:plot_model() successfully completed......................................
2023-06-14 15:28:12,559:INFO:Initializing interpret_model()
2023-06-14 15:28:12,559:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=correlation, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>)
2023-06-14 15:28:12,559:INFO:Checking exceptions
2023-06-14 15:28:12,559:INFO:Soft dependency imported: shap: 0.41.0
2023-06-14 15:28:12,585:INFO:plot type: correlation
2023-06-14 15:28:12,585:WARNING:No feature passed. Default value of feature used for correlation plot: taxa_homicidio
2023-06-14 15:28:12,585:INFO:Creating TreeExplainer
2023-06-14 15:28:12,609:INFO:Compiling shap values
2023-06-14 15:30:05,256:INFO:model type detected: type 2
2023-06-14 15:30:05,601:INFO:Visual Rendered Successfully
2023-06-14 15:30:05,601:INFO:interpret_model() successfully completed......................................
2023-06-14 15:41:04,104:INFO:Initializing tune_model()
2023-06-14 15:41:04,104:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=None, round=4, n_iter=10, custom_grid={'max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'min_samples_leaf': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'n_jobs': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'n_estimators': [50, 100, 150]}, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>)
2023-06-14 15:41:04,104:INFO:Checking exceptions
2023-06-14 15:41:04,130:INFO:Copying training dataset
2023-06-14 15:41:04,135:INFO:Checking base model
2023-06-14 15:41:04,135:INFO:Base model : Random Forest Regressor
2023-06-14 15:41:04,138:INFO:Declaring metric variables
2023-06-14 15:41:04,141:INFO:Defining Hyperparameters
2023-06-14 15:41:04,271:INFO:custom_grid: {'actual_estimator__max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'actual_estimator__min_samples_leaf': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'actual_estimator__n_jobs': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'actual_estimator__n_estimators': [50, 100, 150]}
2023-06-14 15:41:04,271:INFO:Tuning with n_jobs=-1
2023-06-14 15:41:04,271:INFO:Initializing RandomizedSearchCV
2023-06-14 15:41:11,103:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-14 15:41:11,818:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:41:11,954:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:41:12,053:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:41:12,600:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:41:12,787:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:41:14,407:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:41:17,134:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:41:17,197:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:41:19,707:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:41:19,708:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:41:20,238:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:41:20,945:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:41:21,377:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:41:21,885:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:41:43,296:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:41:51,265:WARNING:
10 fits failed out of a total of 100.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\lapei\anaconda3\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py", line 340, in fit
    self._validate_params()
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\base.py", line 581, in _validate_params
    validate_parameter_constraints(
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 97, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_leaf' parameter of RandomForestRegressor must be an int in the range [1, inf) or a float in the range (0.0, 1.0). Got 0 instead.


2023-06-14 15:41:51,266:WARNING:One or more of the test scores are non-finite: [0.82663402 0.78503576        nan 0.80914816 0.88421587 0.78622057
 0.79079419 0.81344985 0.72585026 0.77764529]

2023-06-14 15:41:51,486:INFO:best_params: {'actual_estimator__n_jobs': 8, 'actual_estimator__n_estimators': 50, 'actual_estimator__min_samples_leaf': 1, 'actual_estimator__max_depth': 3}
2023-06-14 15:41:51,487:INFO:Hyperparameter search completed
2023-06-14 15:41:51,487:INFO:SubProcess create_model() called ==================================
2023-06-14 15:41:51,488:INFO:Initializing create_model()
2023-06-14 15:41:51,488:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023331AA2D10>, model_only=True, return_train_score=False, kwargs={'n_jobs': 8, 'n_estimators': 50, 'min_samples_leaf': 1, 'max_depth': 3})
2023-06-14 15:41:51,488:INFO:Checking exceptions
2023-06-14 15:41:51,489:INFO:Importing libraries
2023-06-14 15:41:51,489:INFO:Copying training dataset
2023-06-14 15:41:51,495:INFO:Defining folds
2023-06-14 15:41:51,495:INFO:Declaring metric variables
2023-06-14 15:41:51,500:INFO:Importing untrained model
2023-06-14 15:41:51,500:INFO:Declaring custom model
2023-06-14 15:41:51,505:INFO:Random Forest Regressor Imported successfully
2023-06-14 15:41:51,515:INFO:Starting cross validation
2023-06-14 15:41:51,516:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 15:41:53,249:INFO:Calculating mean and std
2023-06-14 15:41:53,250:INFO:Creating metrics dataframe
2023-06-14 15:41:53,259:INFO:Finalizing model
2023-06-14 15:41:53,738:INFO:Uploading results into container
2023-06-14 15:41:53,739:INFO:Uploading model into container now
2023-06-14 15:41:53,739:INFO:_master_model_container: 24
2023-06-14 15:41:53,740:INFO:_display_container: 6
2023-06-14 15:41:53,740:INFO:RandomForestRegressor(max_depth=3, n_estimators=50, n_jobs=8, random_state=42)
2023-06-14 15:41:53,741:INFO:create_model() successfully completed......................................
2023-06-14 15:41:53,852:INFO:SubProcess create_model() end ==================================
2023-06-14 15:41:53,852:INFO:choose_better activated
2023-06-14 15:41:53,855:INFO:SubProcess create_model() called ==================================
2023-06-14 15:41:53,856:INFO:Initializing create_model()
2023-06-14 15:41:53,856:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-14 15:41:53,856:INFO:Checking exceptions
2023-06-14 15:41:53,859:INFO:Importing libraries
2023-06-14 15:41:53,859:INFO:Copying training dataset
2023-06-14 15:41:53,864:INFO:Defining folds
2023-06-14 15:41:53,864:INFO:Declaring metric variables
2023-06-14 15:41:53,864:INFO:Importing untrained model
2023-06-14 15:41:53,864:INFO:Declaring custom model
2023-06-14 15:41:53,865:INFO:Random Forest Regressor Imported successfully
2023-06-14 15:41:53,865:INFO:Starting cross validation
2023-06-14 15:41:53,866:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 15:42:02,588:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:42:02,596:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:42:03,761:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:42:07,237:INFO:Calculating mean and std
2023-06-14 15:42:07,237:INFO:Creating metrics dataframe
2023-06-14 15:42:07,239:INFO:Finalizing model
2023-06-14 15:42:07,586:INFO:Uploading results into container
2023-06-14 15:42:07,586:INFO:Uploading model into container now
2023-06-14 15:42:07,587:INFO:_master_model_container: 25
2023-06-14 15:42:07,587:INFO:_display_container: 7
2023-06-14 15:42:07,587:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-14 15:42:07,587:INFO:create_model() successfully completed......................................
2023-06-14 15:42:07,715:INFO:SubProcess create_model() end ==================================
2023-06-14 15:42:07,716:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) result for R2 is 0.9117
2023-06-14 15:42:07,717:INFO:RandomForestRegressor(max_depth=3, n_estimators=50, n_jobs=8, random_state=42) result for R2 is 0.8842
2023-06-14 15:42:07,717:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) is best model
2023-06-14 15:42:07,717:INFO:choose_better completed
2023-06-14 15:42:07,717:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-06-14 15:42:07,735:INFO:_master_model_container: 25
2023-06-14 15:42:07,735:INFO:_display_container: 6
2023-06-14 15:42:07,735:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-14 15:42:07,736:INFO:tune_model() successfully completed......................................
2023-06-14 15:42:44,239:INFO:Initializing tune_model()
2023-06-14 15:42:44,239:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=None, round=4, n_iter=10, custom_grid={'max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'n_estimators': [50, 100, 150]}, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>)
2023-06-14 15:42:44,239:INFO:Checking exceptions
2023-06-14 15:42:44,268:INFO:Copying training dataset
2023-06-14 15:42:44,271:INFO:Checking base model
2023-06-14 15:42:44,271:INFO:Base model : Random Forest Regressor
2023-06-14 15:42:44,275:INFO:Declaring metric variables
2023-06-14 15:42:44,281:INFO:Defining Hyperparameters
2023-06-14 15:42:44,401:INFO:custom_grid: {'actual_estimator__max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'actual_estimator__n_estimators': [50, 100, 150]}
2023-06-14 15:42:44,403:INFO:Tuning with n_jobs=-1
2023-06-14 15:42:44,403:INFO:Initializing RandomizedSearchCV
2023-06-14 15:42:47,684:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:42:48,015:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:42:48,314:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:42:48,738:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:42:48,773:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:42:48,797:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:42:49,153:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:42:49,341:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:42:50,190:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-06-14 15:42:50,212:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:42:50,465:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:42:50,493:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-14 15:42:52,252:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:42:53,564:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:42:53,891:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:42:54,255:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:42:54,484:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:42:56,766:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:42:57,299:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:42:57,480:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:42:57,529:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:42:57,577:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:42:57,874:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-14 15:42:58,292:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:42:59,885:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:43:00,763:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-14 15:43:02,240:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.48s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:43:02,426:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.48s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:43:04,038:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:43:04,251:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:43:04,484:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:43:04,580:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:43:05,312:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:43:06,590:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:43:14,096:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:43:14,715:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:43:15,887:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:43:16,413:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:43:16,963:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:43:17,454:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:43:18,567:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:43:18,861:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:43:19,876:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:43:21,539:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:43:23,031:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:43:23,629:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:43:24,990:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:43:25,299:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:43:26,476:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-14 15:43:27,063:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:43:27,234:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-14 15:43:27,438:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:43:29,024:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-14 15:43:29,203:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-14 15:43:29,503:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:43:29,715:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:43:30,389:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:43:31,027:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:43:32,083:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:43:33,095:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:43:34,813:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:43:35,200:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:43:36,482:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:43:36,592:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:43:37,046:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:43:39,772:WARNING:
10 fits failed out of a total of 100.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\lapei\anaconda3\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py", line 340, in fit
    self._validate_params()
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\base.py", line 581, in _validate_params
    validate_parameter_constraints(
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 97, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestRegressor must be an int in the range [1, inf) or None. Got 0 instead.


2023-06-14 15:43:39,773:WARNING:One or more of the test scores are non-finite: [       nan 0.84304975 0.88352203 0.89080575 0.90989648 0.90657964
 0.90903751 0.9139807  0.91078924 0.9077926 ]

2023-06-14 15:43:40,026:INFO:best_params: {'actual_estimator__n_estimators': 100, 'actual_estimator__max_depth': 7}
2023-06-14 15:43:40,027:INFO:Hyperparameter search completed
2023-06-14 15:43:40,027:INFO:SubProcess create_model() called ==================================
2023-06-14 15:43:40,028:INFO:Initializing create_model()
2023-06-14 15:43:40,028:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000233323B8040>, model_only=True, return_train_score=False, kwargs={'n_estimators': 100, 'max_depth': 7})
2023-06-14 15:43:40,029:INFO:Checking exceptions
2023-06-14 15:43:40,029:INFO:Importing libraries
2023-06-14 15:43:40,029:INFO:Copying training dataset
2023-06-14 15:43:40,037:INFO:Defining folds
2023-06-14 15:43:40,037:INFO:Declaring metric variables
2023-06-14 15:43:40,041:INFO:Importing untrained model
2023-06-14 15:43:40,041:INFO:Declaring custom model
2023-06-14 15:43:40,046:INFO:Random Forest Regressor Imported successfully
2023-06-14 15:43:40,053:INFO:Starting cross validation
2023-06-14 15:43:40,054:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 15:43:42,095:INFO:Calculating mean and std
2023-06-14 15:43:42,096:INFO:Creating metrics dataframe
2023-06-14 15:43:42,101:INFO:Finalizing model
2023-06-14 15:43:43,138:INFO:Uploading results into container
2023-06-14 15:43:43,140:INFO:Uploading model into container now
2023-06-14 15:43:43,140:INFO:_master_model_container: 26
2023-06-14 15:43:43,141:INFO:_display_container: 7
2023-06-14 15:43:43,141:INFO:RandomForestRegressor(max_depth=7, n_jobs=-1, random_state=42)
2023-06-14 15:43:43,141:INFO:create_model() successfully completed......................................
2023-06-14 15:43:43,264:INFO:SubProcess create_model() end ==================================
2023-06-14 15:43:43,265:INFO:choose_better activated
2023-06-14 15:43:43,268:INFO:SubProcess create_model() called ==================================
2023-06-14 15:43:43,269:INFO:Initializing create_model()
2023-06-14 15:43:43,269:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-14 15:43:43,269:INFO:Checking exceptions
2023-06-14 15:43:43,272:INFO:Importing libraries
2023-06-14 15:43:43,273:INFO:Copying training dataset
2023-06-14 15:43:43,284:INFO:Defining folds
2023-06-14 15:43:43,284:INFO:Declaring metric variables
2023-06-14 15:43:43,285:INFO:Importing untrained model
2023-06-14 15:43:43,285:INFO:Declaring custom model
2023-06-14 15:43:43,286:INFO:Random Forest Regressor Imported successfully
2023-06-14 15:43:43,287:INFO:Starting cross validation
2023-06-14 15:43:43,289:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 15:43:45,743:INFO:Calculating mean and std
2023-06-14 15:43:45,743:INFO:Creating metrics dataframe
2023-06-14 15:43:45,746:INFO:Finalizing model
2023-06-14 15:43:46,146:INFO:Uploading results into container
2023-06-14 15:43:46,147:INFO:Uploading model into container now
2023-06-14 15:43:46,148:INFO:_master_model_container: 27
2023-06-14 15:43:46,148:INFO:_display_container: 8
2023-06-14 15:43:46,148:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-14 15:43:46,148:INFO:create_model() successfully completed......................................
2023-06-14 15:43:46,272:INFO:SubProcess create_model() end ==================================
2023-06-14 15:43:46,273:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) result for R2 is 0.9117
2023-06-14 15:43:46,273:INFO:RandomForestRegressor(max_depth=7, n_jobs=-1, random_state=42) result for R2 is 0.914
2023-06-14 15:43:46,273:INFO:RandomForestRegressor(max_depth=7, n_jobs=-1, random_state=42) is best model
2023-06-14 15:43:46,274:INFO:choose_better completed
2023-06-14 15:43:46,285:INFO:_master_model_container: 27
2023-06-14 15:43:46,286:INFO:_display_container: 7
2023-06-14 15:43:46,286:INFO:RandomForestRegressor(max_depth=7, n_jobs=-1, random_state=42)
2023-06-14 15:43:46,286:INFO:tune_model() successfully completed......................................
2023-06-14 15:45:07,219:INFO:Initializing tune_model()
2023-06-14 15:45:07,219:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=5, round=4, n_iter=10, custom_grid={'max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'n_estimators': [50, 100, 150]}, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>)
2023-06-14 15:45:07,219:INFO:Checking exceptions
2023-06-14 15:45:07,245:INFO:Copying training dataset
2023-06-14 15:45:07,252:INFO:Checking base model
2023-06-14 15:45:07,252:INFO:Base model : Random Forest Regressor
2023-06-14 15:45:07,256:INFO:Declaring metric variables
2023-06-14 15:45:07,261:INFO:Defining Hyperparameters
2023-06-14 15:45:07,385:INFO:custom_grid: {'actual_estimator__max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'actual_estimator__n_estimators': [50, 100, 150]}
2023-06-14 15:45:07,386:INFO:Tuning with n_jobs=-1
2023-06-14 15:45:07,386:INFO:Initializing RandomizedSearchCV
2023-06-14 15:45:08,712:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:45:08,780:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:45:09,076:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:45:09,287:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:45:10,829:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:45:10,889:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:45:12,031:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:45:12,086:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:45:13,841:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:45:14,988:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:45:15,322:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:45:15,788:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:45:15,909:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:45:16,957:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:45:18,772:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:45:20,493:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:45:20,875:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:45:21,862:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:45:21,920:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-14 15:45:22,590:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:45:22,931:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:45:23,740:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-14 15:45:25,556:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:45:26,160:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:45:28,188:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:45:28,389:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:45:31,831:WARNING:
5 fits failed out of a total of 50.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\lapei\anaconda3\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py", line 340, in fit
    self._validate_params()
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\base.py", line 581, in _validate_params
    validate_parameter_constraints(
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 97, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestRegressor must be an int in the range [1, inf) or None. Got 0 instead.


2023-06-14 15:45:31,831:WARNING:One or more of the test scores are non-finite: [       nan 0.84008985 0.88700297 0.89634997 0.90884864 0.90717856
 0.90883588 0.90843499 0.90638845 0.90995616]

2023-06-14 15:45:32,113:INFO:best_params: {'actual_estimator__n_estimators': 100, 'actual_estimator__max_depth': 9}
2023-06-14 15:45:32,114:INFO:Hyperparameter search completed
2023-06-14 15:45:32,114:INFO:SubProcess create_model() called ==================================
2023-06-14 15:45:32,115:INFO:Initializing create_model()
2023-06-14 15:45:32,115:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023331A71510>, model_only=True, return_train_score=False, kwargs={'n_estimators': 100, 'max_depth': 9})
2023-06-14 15:45:32,115:INFO:Checking exceptions
2023-06-14 15:45:32,115:INFO:Importing libraries
2023-06-14 15:45:32,115:INFO:Copying training dataset
2023-06-14 15:45:32,121:INFO:Defining folds
2023-06-14 15:45:32,121:INFO:Declaring metric variables
2023-06-14 15:45:32,124:INFO:Importing untrained model
2023-06-14 15:45:32,124:INFO:Declaring custom model
2023-06-14 15:45:32,128:INFO:Random Forest Regressor Imported successfully
2023-06-14 15:45:32,133:INFO:Starting cross validation
2023-06-14 15:45:32,135:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 15:45:33,205:INFO:Calculating mean and std
2023-06-14 15:45:33,207:INFO:Creating metrics dataframe
2023-06-14 15:45:33,215:INFO:Finalizing model
2023-06-14 15:45:34,302:INFO:Uploading results into container
2023-06-14 15:45:34,303:INFO:Uploading model into container now
2023-06-14 15:45:34,303:INFO:_master_model_container: 28
2023-06-14 15:45:34,303:INFO:_display_container: 8
2023-06-14 15:45:34,304:INFO:RandomForestRegressor(max_depth=9, n_jobs=-1, random_state=42)
2023-06-14 15:45:34,304:INFO:create_model() successfully completed......................................
2023-06-14 15:45:34,424:INFO:SubProcess create_model() end ==================================
2023-06-14 15:45:34,424:INFO:choose_better activated
2023-06-14 15:45:34,429:INFO:SubProcess create_model() called ==================================
2023-06-14 15:45:34,429:INFO:Initializing create_model()
2023-06-14 15:45:34,429:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-14 15:45:34,431:INFO:Checking exceptions
2023-06-14 15:45:34,432:INFO:Importing libraries
2023-06-14 15:45:34,432:INFO:Copying training dataset
2023-06-14 15:45:34,442:INFO:Defining folds
2023-06-14 15:45:34,443:INFO:Declaring metric variables
2023-06-14 15:45:34,443:INFO:Importing untrained model
2023-06-14 15:45:34,443:INFO:Declaring custom model
2023-06-14 15:45:34,444:INFO:Random Forest Regressor Imported successfully
2023-06-14 15:45:34,444:INFO:Starting cross validation
2023-06-14 15:45:34,446:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 15:45:35,454:INFO:Calculating mean and std
2023-06-14 15:45:35,454:INFO:Creating metrics dataframe
2023-06-14 15:45:35,457:INFO:Finalizing model
2023-06-14 15:45:35,951:INFO:Uploading results into container
2023-06-14 15:45:35,951:INFO:Uploading model into container now
2023-06-14 15:45:35,953:INFO:_master_model_container: 29
2023-06-14 15:45:35,953:INFO:_display_container: 9
2023-06-14 15:45:35,953:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-14 15:45:35,953:INFO:create_model() successfully completed......................................
2023-06-14 15:45:36,059:INFO:SubProcess create_model() end ==================================
2023-06-14 15:45:36,061:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) result for R2 is 0.9102
2023-06-14 15:45:36,062:INFO:RandomForestRegressor(max_depth=9, n_jobs=-1, random_state=42) result for R2 is 0.91
2023-06-14 15:45:36,063:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) is best model
2023-06-14 15:45:36,063:INFO:choose_better completed
2023-06-14 15:45:36,063:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-06-14 15:45:36,077:INFO:_master_model_container: 29
2023-06-14 15:45:36,077:INFO:_display_container: 8
2023-06-14 15:45:36,078:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-14 15:45:36,078:INFO:tune_model() successfully completed......................................
2023-06-14 15:46:51,482:INFO:Initializing tune_model()
2023-06-14 15:46:51,482:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=5, round=4, n_iter=10, custom_grid={'max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>)
2023-06-14 15:46:51,482:INFO:Checking exceptions
2023-06-14 15:46:51,506:INFO:Copying training dataset
2023-06-14 15:46:51,514:INFO:Checking base model
2023-06-14 15:46:51,514:INFO:Base model : Random Forest Regressor
2023-06-14 15:46:51,518:INFO:Declaring metric variables
2023-06-14 15:46:51,523:INFO:Defining Hyperparameters
2023-06-14 15:46:51,658:INFO:custom_grid: {'actual_estimator__max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}
2023-06-14 15:46:51,658:INFO:Tuning with n_jobs=-1
2023-06-14 15:46:51,658:INFO:Initializing RandomizedSearchCV
2023-06-14 15:46:54,973:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:46:55,565:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:46:56,669:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:46:57,353:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:46:57,944:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:46:58,443:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:46:58,993:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:47:03,505:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 15:47:08,760:WARNING:
5 fits failed out of a total of 50.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\lapei\anaconda3\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py", line 340, in fit
    self._validate_params()
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\base.py", line 581, in _validate_params
    validate_parameter_constraints(
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 97, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestRegressor must be an int in the range [1, inf) or None. Got 0 instead.


2023-06-14 15:47:08,761:WARNING:One or more of the test scores are non-finite: [       nan 0.48652662 0.84008985 0.88700297 0.89957066 0.90836024
 0.90866937 0.90843499 0.90995616 0.91114377]

2023-06-14 15:47:09,034:INFO:best_params: {'actual_estimator__max_depth': 10}
2023-06-14 15:47:09,035:INFO:Hyperparameter search completed
2023-06-14 15:47:09,035:INFO:SubProcess create_model() called ==================================
2023-06-14 15:47:09,037:INFO:Initializing create_model()
2023-06-14 15:47:09,037:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023331574B20>, model_only=True, return_train_score=False, kwargs={'max_depth': 10})
2023-06-14 15:47:09,037:INFO:Checking exceptions
2023-06-14 15:47:09,037:INFO:Importing libraries
2023-06-14 15:47:09,037:INFO:Copying training dataset
2023-06-14 15:47:09,041:INFO:Defining folds
2023-06-14 15:47:09,041:INFO:Declaring metric variables
2023-06-14 15:47:09,044:INFO:Importing untrained model
2023-06-14 15:47:09,044:INFO:Declaring custom model
2023-06-14 15:47:09,047:INFO:Random Forest Regressor Imported successfully
2023-06-14 15:47:09,053:INFO:Starting cross validation
2023-06-14 15:47:09,054:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 15:47:10,049:INFO:Calculating mean and std
2023-06-14 15:47:10,051:INFO:Creating metrics dataframe
2023-06-14 15:47:10,057:INFO:Finalizing model
2023-06-14 15:47:11,253:INFO:Uploading results into container
2023-06-14 15:47:11,254:INFO:Uploading model into container now
2023-06-14 15:47:11,255:INFO:_master_model_container: 30
2023-06-14 15:47:11,255:INFO:_display_container: 9
2023-06-14 15:47:11,257:INFO:RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42)
2023-06-14 15:47:11,257:INFO:create_model() successfully completed......................................
2023-06-14 15:47:11,379:INFO:SubProcess create_model() end ==================================
2023-06-14 15:47:11,379:INFO:choose_better activated
2023-06-14 15:47:11,384:INFO:SubProcess create_model() called ==================================
2023-06-14 15:47:11,384:INFO:Initializing create_model()
2023-06-14 15:47:11,384:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-14 15:47:11,384:INFO:Checking exceptions
2023-06-14 15:47:11,387:INFO:Importing libraries
2023-06-14 15:47:11,387:INFO:Copying training dataset
2023-06-14 15:47:11,396:INFO:Defining folds
2023-06-14 15:47:11,396:INFO:Declaring metric variables
2023-06-14 15:47:11,396:INFO:Importing untrained model
2023-06-14 15:47:11,396:INFO:Declaring custom model
2023-06-14 15:47:11,398:INFO:Random Forest Regressor Imported successfully
2023-06-14 15:47:11,398:INFO:Starting cross validation
2023-06-14 15:47:11,401:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 15:47:12,473:INFO:Calculating mean and std
2023-06-14 15:47:12,473:INFO:Creating metrics dataframe
2023-06-14 15:47:12,475:INFO:Finalizing model
2023-06-14 15:47:12,841:INFO:Uploading results into container
2023-06-14 15:47:12,842:INFO:Uploading model into container now
2023-06-14 15:47:12,843:INFO:_master_model_container: 31
2023-06-14 15:47:12,843:INFO:_display_container: 10
2023-06-14 15:47:12,843:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-14 15:47:12,843:INFO:create_model() successfully completed......................................
2023-06-14 15:47:12,958:INFO:SubProcess create_model() end ==================================
2023-06-14 15:47:12,958:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) result for R2 is 0.9102
2023-06-14 15:47:12,959:INFO:RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42) result for R2 is 0.9111
2023-06-14 15:47:12,959:INFO:RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42) is best model
2023-06-14 15:47:12,959:INFO:choose_better completed
2023-06-14 15:47:12,970:INFO:_master_model_container: 31
2023-06-14 15:47:12,970:INFO:_display_container: 9
2023-06-14 15:47:12,971:INFO:RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42)
2023-06-14 15:47:12,971:INFO:tune_model() successfully completed......................................
2023-06-14 15:53:26,989:INFO:Initializing tune_model()
2023-06-14 15:53:26,989:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=5, round=4, n_iter=10, custom_grid={'max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>)
2023-06-14 15:53:26,989:INFO:Checking exceptions
2023-06-14 15:53:27,012:INFO:Copying training dataset
2023-06-14 15:53:27,025:INFO:Checking base model
2023-06-14 15:53:27,025:INFO:Base model : Random Forest Regressor
2023-06-14 15:53:27,030:INFO:Declaring metric variables
2023-06-14 15:53:27,034:INFO:Defining Hyperparameters
2023-06-14 15:53:27,163:INFO:custom_grid: {'actual_estimator__max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}
2023-06-14 15:53:27,164:INFO:Tuning with n_jobs=-1
2023-06-14 15:53:27,164:INFO:Initializing RandomizedSearchCV
2023-06-14 15:53:43,763:WARNING:
5 fits failed out of a total of 50.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\lapei\anaconda3\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py", line 340, in fit
    self._validate_params()
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\base.py", line 581, in _validate_params
    validate_parameter_constraints(
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 97, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestRegressor must be an int in the range [1, inf) or None. Got 0 instead.


2023-06-14 15:53:43,764:WARNING:One or more of the test scores are non-finite: [       nan 0.48652662 0.84008985 0.88700297 0.89957066 0.90836024
 0.90866937 0.90843499 0.90995616 0.91114377]

2023-06-14 15:53:44,128:INFO:best_params: {'actual_estimator__max_depth': 10}
2023-06-14 15:53:44,129:INFO:Hyperparameter search completed
2023-06-14 15:53:44,129:INFO:SubProcess create_model() called ==================================
2023-06-14 15:53:44,130:INFO:Initializing create_model()
2023-06-14 15:53:44,130:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023331AA2D10>, model_only=True, return_train_score=False, kwargs={'max_depth': 10})
2023-06-14 15:53:44,130:INFO:Checking exceptions
2023-06-14 15:53:44,130:INFO:Importing libraries
2023-06-14 15:53:44,130:INFO:Copying training dataset
2023-06-14 15:53:44,138:INFO:Defining folds
2023-06-14 15:53:44,138:INFO:Declaring metric variables
2023-06-14 15:53:44,143:INFO:Importing untrained model
2023-06-14 15:53:44,143:INFO:Declaring custom model
2023-06-14 15:53:44,147:INFO:Random Forest Regressor Imported successfully
2023-06-14 15:53:44,153:INFO:Starting cross validation
2023-06-14 15:53:44,154:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 15:53:45,102:INFO:Calculating mean and std
2023-06-14 15:53:45,104:INFO:Creating metrics dataframe
2023-06-14 15:53:45,110:INFO:Finalizing model
2023-06-14 15:53:45,594:INFO:Uploading results into container
2023-06-14 15:53:45,596:INFO:Uploading model into container now
2023-06-14 15:53:45,596:INFO:_master_model_container: 32
2023-06-14 15:53:45,596:INFO:_display_container: 10
2023-06-14 15:53:45,597:INFO:RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42)
2023-06-14 15:53:45,597:INFO:create_model() successfully completed......................................
2023-06-14 15:53:45,725:INFO:SubProcess create_model() end ==================================
2023-06-14 15:53:45,726:INFO:choose_better activated
2023-06-14 15:53:45,736:INFO:SubProcess create_model() called ==================================
2023-06-14 15:53:45,738:INFO:Initializing create_model()
2023-06-14 15:53:45,739:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023331AE3490>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-14 15:53:45,739:INFO:Checking exceptions
2023-06-14 15:53:45,744:INFO:Importing libraries
2023-06-14 15:53:45,744:INFO:Copying training dataset
2023-06-14 15:53:45,753:INFO:Defining folds
2023-06-14 15:53:45,754:INFO:Declaring metric variables
2023-06-14 15:53:45,754:INFO:Importing untrained model
2023-06-14 15:53:45,754:INFO:Declaring custom model
2023-06-14 15:53:45,755:INFO:Random Forest Regressor Imported successfully
2023-06-14 15:53:45,755:INFO:Starting cross validation
2023-06-14 15:53:45,756:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 15:53:46,813:INFO:Calculating mean and std
2023-06-14 15:53:46,814:INFO:Creating metrics dataframe
2023-06-14 15:53:46,816:INFO:Finalizing model
2023-06-14 15:53:47,342:INFO:Uploading results into container
2023-06-14 15:53:47,343:INFO:Uploading model into container now
2023-06-14 15:53:47,343:INFO:_master_model_container: 33
2023-06-14 15:53:47,343:INFO:_display_container: 11
2023-06-14 15:53:47,344:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-14 15:53:47,344:INFO:create_model() successfully completed......................................
2023-06-14 15:53:47,484:INFO:SubProcess create_model() end ==================================
2023-06-14 15:53:47,485:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) result for R2 is 0.9102
2023-06-14 15:53:47,485:INFO:RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42) result for R2 is 0.9111
2023-06-14 15:53:47,486:INFO:RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42) is best model
2023-06-14 15:53:47,486:INFO:choose_better completed
2023-06-14 15:53:47,494:INFO:_master_model_container: 33
2023-06-14 15:53:47,494:INFO:_display_container: 10
2023-06-14 15:53:47,495:INFO:RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42)
2023-06-14 15:53:47,495:INFO:tune_model() successfully completed......................................
2023-06-15 08:31:08,748:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-15 08:31:08,749:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-15 08:31:08,749:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-15 08:31:08,749:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-15 08:31:09,844:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-15 08:31:29,726:INFO:PyCaret RegressionExperiment
2023-06-15 08:31:29,726:INFO:Logging name: reg-default-name
2023-06-15 08:31:29,727:INFO:ML Usecase: MLUsecase.REGRESSION
2023-06-15 08:31:29,727:INFO:version 3.0.2
2023-06-15 08:31:29,727:INFO:Initializing setup()
2023-06-15 08:31:29,727:INFO:self.USI: e8fa
2023-06-15 08:31:29,727:INFO:self._variable_keys: {'logging_param', 'gpu_n_jobs_param', 'y', 'n_jobs_param', 'gpu_param', 'fold_generator', 'fold_shuffle_param', 'seed', 'exp_id', 'html_param', 'exp_name_log', 'fold_groups_param', 'data', 'USI', 'transform_target_param', 'X_test', 'y_test', 'y_train', 'X_train', 'log_plots_param', '_ml_usecase', 'X', 'idx', 'memory', '_available_plots', 'pipeline', 'target_param'}
2023-06-15 08:31:29,727:INFO:Checking environment
2023-06-15 08:31:29,727:INFO:python_version: 3.10.9
2023-06-15 08:31:29,727:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-06-15 08:31:29,727:INFO:machine: AMD64
2023-06-15 08:31:29,727:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-15 08:31:29,727:INFO:Memory: svmem(total=16901767168, available=7314853888, percent=56.7, used=9586913280, free=7314853888)
2023-06-15 08:31:29,728:INFO:Physical Core: 4
2023-06-15 08:31:29,728:INFO:Logical Core: 8
2023-06-15 08:31:29,728:INFO:Checking libraries
2023-06-15 08:31:29,728:INFO:System:
2023-06-15 08:31:29,728:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-06-15 08:31:29,728:INFO:executable: C:\Users\lapei\anaconda3\python.exe
2023-06-15 08:31:29,728:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-15 08:31:29,728:INFO:PyCaret required dependencies:
2023-06-15 08:31:29,728:INFO:                 pip: 22.3.1
2023-06-15 08:31:29,728:INFO:          setuptools: 65.6.3
2023-06-15 08:31:29,729:INFO:             pycaret: 3.0.2
2023-06-15 08:31:29,729:INFO:             IPython: 8.10.0
2023-06-15 08:31:29,729:INFO:          ipywidgets: 7.6.5
2023-06-15 08:31:29,729:INFO:                tqdm: 4.64.1
2023-06-15 08:31:29,729:INFO:               numpy: 1.23.5
2023-06-15 08:31:29,729:INFO:              pandas: 1.5.3
2023-06-15 08:31:29,729:INFO:              jinja2: 3.1.2
2023-06-15 08:31:29,729:INFO:               scipy: 1.10.0
2023-06-15 08:31:29,729:INFO:              joblib: 1.2.0
2023-06-15 08:31:29,729:INFO:             sklearn: 1.2.1
2023-06-15 08:31:29,729:INFO:                pyod: 1.0.9
2023-06-15 08:31:29,729:INFO:            imblearn: 0.10.1
2023-06-15 08:31:29,729:INFO:   category_encoders: 2.6.1
2023-06-15 08:31:29,730:INFO:            lightgbm: 3.3.5
2023-06-15 08:31:29,730:INFO:               numba: 0.56.4
2023-06-15 08:31:29,730:INFO:            requests: 2.28.1
2023-06-15 08:31:29,730:INFO:          matplotlib: 3.7.0
2023-06-15 08:31:29,730:INFO:          scikitplot: 0.3.7
2023-06-15 08:31:29,730:INFO:         yellowbrick: 1.5
2023-06-15 08:31:29,730:INFO:              plotly: 5.9.0
2023-06-15 08:31:29,730:INFO:             kaleido: 0.2.1
2023-06-15 08:31:29,730:INFO:         statsmodels: 0.13.5
2023-06-15 08:31:29,730:INFO:              sktime: 0.17.0
2023-06-15 08:31:29,730:INFO:               tbats: 1.1.3
2023-06-15 08:31:29,731:INFO:            pmdarima: 2.0.3
2023-06-15 08:31:29,731:INFO:              psutil: 5.9.0
2023-06-15 08:31:29,731:INFO:PyCaret optional dependencies:
2023-06-15 08:31:29,844:INFO:                shap: 0.41.0
2023-06-15 08:31:29,844:INFO:           interpret: Not installed
2023-06-15 08:31:29,844:INFO:                umap: Not installed
2023-06-15 08:31:29,844:INFO:    pandas_profiling: Not installed
2023-06-15 08:31:29,844:INFO:  explainerdashboard: Not installed
2023-06-15 08:31:29,845:INFO:             autoviz: Not installed
2023-06-15 08:31:29,845:INFO:           fairlearn: Not installed
2023-06-15 08:31:29,845:INFO:             xgboost: 1.7.3
2023-06-15 08:31:29,845:INFO:            catboost: Not installed
2023-06-15 08:31:29,845:INFO:              kmodes: Not installed
2023-06-15 08:31:29,845:INFO:             mlxtend: Not installed
2023-06-15 08:31:29,845:INFO:       statsforecast: Not installed
2023-06-15 08:31:29,845:INFO:        tune_sklearn: Not installed
2023-06-15 08:31:29,845:INFO:                 ray: Not installed
2023-06-15 08:31:29,845:INFO:            hyperopt: Not installed
2023-06-15 08:31:29,845:INFO:              optuna: Not installed
2023-06-15 08:31:29,846:INFO:               skopt: 0.9.0
2023-06-15 08:31:29,846:INFO:              mlflow: Not installed
2023-06-15 08:31:29,846:INFO:              gradio: Not installed
2023-06-15 08:31:29,846:INFO:             fastapi: Not installed
2023-06-15 08:31:29,846:INFO:             uvicorn: Not installed
2023-06-15 08:31:29,846:INFO:              m2cgen: Not installed
2023-06-15 08:31:29,846:INFO:           evidently: Not installed
2023-06-15 08:31:29,846:INFO:               fugue: Not installed
2023-06-15 08:31:29,846:INFO:           streamlit: Not installed
2023-06-15 08:31:29,846:INFO:             prophet: Not installed
2023-06-15 08:31:29,846:INFO:None
2023-06-15 08:31:29,847:INFO:Set up data.
2023-06-15 08:31:29,865:INFO:Set up train/test split.
2023-06-15 08:31:29,876:INFO:Set up index.
2023-06-15 08:31:29,876:INFO:Set up folding strategy.
2023-06-15 08:31:29,876:INFO:Assigning column types.
2023-06-15 08:31:29,885:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-15 08:31:29,885:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-15 08:31:29,896:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-15 08:31:29,906:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-15 08:31:29,971:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-15 08:31:30,025:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-15 08:31:30,026:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-15 08:31:30,389:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-15 08:31:30,390:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-15 08:31:30,395:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-15 08:31:30,405:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-15 08:31:30,466:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-15 08:31:30,536:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-15 08:31:30,536:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-15 08:31:30,539:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-15 08:31:30,539:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-06-15 08:31:30,543:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-15 08:31:30,548:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-15 08:31:30,602:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-15 08:31:30,657:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-15 08:31:30,658:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-15 08:31:30,661:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-15 08:31:30,666:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-15 08:31:30,670:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-15 08:31:30,750:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-15 08:31:30,794:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-15 08:31:30,794:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-15 08:31:30,797:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-15 08:31:30,797:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-06-15 08:31:30,806:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-15 08:31:30,866:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-15 08:31:30,928:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-15 08:31:30,929:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-15 08:31:30,933:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-15 08:31:30,943:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-15 08:31:31,002:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-15 08:31:31,044:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-15 08:31:31,044:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-15 08:31:31,047:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-15 08:31:31,047:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-06-15 08:31:31,112:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-15 08:31:31,154:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-15 08:31:31,156:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-15 08:31:31,158:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-15 08:31:31,250:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-15 08:31:31,294:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-15 08:31:31,294:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-15 08:31:31,297:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-15 08:31:31,298:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-15 08:31:31,385:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-15 08:31:31,430:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-15 08:31:31,433:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-15 08:31:31,500:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-15 08:31:31,567:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-15 08:31:31,570:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-15 08:31:31,570:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-06-15 08:31:31,676:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-15 08:31:31,679:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-15 08:31:31,790:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-15 08:31:31,795:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-15 08:31:31,800:INFO:Preparing preprocessing pipeline...
2023-06-15 08:31:31,800:INFO:Set up simple imputation.
2023-06-15 08:31:31,802:INFO:Set up column name cleaning.
2023-06-15 08:31:31,845:INFO:Finished creating preprocessing pipeline.
2023-06-15 08:31:31,854:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\lapei\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['taxa_homicidio', 'RH_adm_dir',
                                             'densidade_banda_larga',
                                             'densidade_telefonia_movel',
                                             'qtd_cursos_engenharias',
                                             'qtd_cursos_negocios_direito',
                                             'media_notas_CN', 'media_notas_CH',
                                             'media_NU_NOTA_LC',
                                             'media_NU_NOTA_MT',
                                             'media_...
                                             'Isencao_ISSQN_Sim',
                                             'Isencao_Tx_Sim',
                                             'Cessao_terrenos_Sim',
                                             'Doacao_terrenos_Sim',
                                             'Outros_mecanismos_Sim',
                                             'ISH_Baixa', 'ISH_Máxima',
                                             'ISH_Média', 'ISH_Mínima'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-06-15 08:31:31,854:INFO:Creating final display dataframe.
2023-06-15 08:31:31,965:INFO:Setup _display_container:                     Description                              Value
0                    Session id                                 42
1                        Target  qtd_abertas_Empresario_Individual
2                   Target type                         Regression
3           Original data shape                         (4456, 30)
4        Transformed data shape                         (4456, 30)
5   Transformed train set shape                         (3119, 30)
6    Transformed test set shape                         (1337, 30)
7              Numeric features                                 29
8                    Preprocess                               True
9               Imputation type                             simple
10           Numeric imputation                               mean
11       Categorical imputation                               mode
12               Fold Generator                              KFold
13                  Fold Number                                 10
14                     CPU Jobs                                 -1
15                      Use GPU                              False
16               Log Experiment                              False
17              Experiment Name                   reg-default-name
18                          USI                               e8fa
2023-06-15 08:31:32,103:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-15 08:31:32,106:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-15 08:31:32,246:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-15 08:31:32,248:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-15 08:31:32,249:INFO:setup() successfully completed in 2.83s...............
2023-06-15 08:31:32,267:INFO:Initializing compare_models()
2023-06-15 08:31:32,268:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, include=None, fold=5, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, 'include': None, 'exclude': None, 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-06-15 08:31:32,268:INFO:Checking exceptions
2023-06-15 08:31:32,273:INFO:Preparing display monitor
2023-06-15 08:31:32,310:INFO:Initializing Linear Regression
2023-06-15 08:31:32,310:INFO:Total runtime is 0.0 minutes
2023-06-15 08:31:32,316:INFO:SubProcess create_model() called ==================================
2023-06-15 08:31:32,317:INFO:Initializing create_model()
2023-06-15 08:31:32,317:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6FA795570>, model_only=True, return_train_score=False, kwargs={})
2023-06-15 08:31:32,317:INFO:Checking exceptions
2023-06-15 08:31:32,317:INFO:Importing libraries
2023-06-15 08:31:32,317:INFO:Copying training dataset
2023-06-15 08:31:32,327:INFO:Defining folds
2023-06-15 08:31:32,327:INFO:Declaring metric variables
2023-06-15 08:31:32,332:INFO:Importing untrained model
2023-06-15 08:31:32,335:INFO:Linear Regression Imported successfully
2023-06-15 08:31:32,342:INFO:Starting cross validation
2023-06-15 08:31:32,352:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-15 08:31:37,613:INFO:Calculating mean and std
2023-06-15 08:31:37,614:INFO:Creating metrics dataframe
2023-06-15 08:31:37,903:INFO:Uploading results into container
2023-06-15 08:31:37,904:INFO:Uploading model into container now
2023-06-15 08:31:37,904:INFO:_master_model_container: 1
2023-06-15 08:31:37,904:INFO:_display_container: 2
2023-06-15 08:31:37,905:INFO:LinearRegression(n_jobs=-1)
2023-06-15 08:31:37,905:INFO:create_model() successfully completed......................................
2023-06-15 08:31:38,043:INFO:SubProcess create_model() end ==================================
2023-06-15 08:31:38,043:INFO:Creating metrics dataframe
2023-06-15 08:31:38,053:INFO:Initializing Lasso Regression
2023-06-15 08:31:38,053:INFO:Total runtime is 0.09571237166722615 minutes
2023-06-15 08:31:38,057:INFO:SubProcess create_model() called ==================================
2023-06-15 08:31:38,057:INFO:Initializing create_model()
2023-06-15 08:31:38,057:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6FA795570>, model_only=True, return_train_score=False, kwargs={})
2023-06-15 08:31:38,058:INFO:Checking exceptions
2023-06-15 08:31:38,058:INFO:Importing libraries
2023-06-15 08:31:38,058:INFO:Copying training dataset
2023-06-15 08:31:38,063:INFO:Defining folds
2023-06-15 08:31:38,064:INFO:Declaring metric variables
2023-06-15 08:31:38,071:INFO:Importing untrained model
2023-06-15 08:31:38,078:INFO:Lasso Regression Imported successfully
2023-06-15 08:31:38,086:INFO:Starting cross validation
2023-06-15 08:31:38,087:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-15 08:31:40,691:INFO:Calculating mean and std
2023-06-15 08:31:40,692:INFO:Creating metrics dataframe
2023-06-15 08:31:40,964:INFO:Uploading results into container
2023-06-15 08:31:40,965:INFO:Uploading model into container now
2023-06-15 08:31:40,965:INFO:_master_model_container: 2
2023-06-15 08:31:40,965:INFO:_display_container: 2
2023-06-15 08:31:40,966:INFO:Lasso(random_state=42)
2023-06-15 08:31:40,966:INFO:create_model() successfully completed......................................
2023-06-15 08:31:41,083:INFO:SubProcess create_model() end ==================================
2023-06-15 08:31:41,083:INFO:Creating metrics dataframe
2023-06-15 08:31:41,093:INFO:Initializing Ridge Regression
2023-06-15 08:31:41,093:INFO:Total runtime is 0.14638519684473672 minutes
2023-06-15 08:31:41,096:INFO:SubProcess create_model() called ==================================
2023-06-15 08:31:41,097:INFO:Initializing create_model()
2023-06-15 08:31:41,097:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6FA795570>, model_only=True, return_train_score=False, kwargs={})
2023-06-15 08:31:41,097:INFO:Checking exceptions
2023-06-15 08:31:41,097:INFO:Importing libraries
2023-06-15 08:31:41,097:INFO:Copying training dataset
2023-06-15 08:31:41,103:INFO:Defining folds
2023-06-15 08:31:41,103:INFO:Declaring metric variables
2023-06-15 08:31:41,107:INFO:Importing untrained model
2023-06-15 08:31:41,119:INFO:Ridge Regression Imported successfully
2023-06-15 08:31:41,131:INFO:Starting cross validation
2023-06-15 08:31:41,132:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-15 08:31:42,025:INFO:Calculating mean and std
2023-06-15 08:31:42,026:INFO:Creating metrics dataframe
2023-06-15 08:31:42,400:INFO:Uploading results into container
2023-06-15 08:31:42,401:INFO:Uploading model into container now
2023-06-15 08:31:42,402:INFO:_master_model_container: 3
2023-06-15 08:31:42,403:INFO:_display_container: 2
2023-06-15 08:31:42,403:INFO:Ridge(random_state=42)
2023-06-15 08:31:42,403:INFO:create_model() successfully completed......................................
2023-06-15 08:31:42,558:INFO:SubProcess create_model() end ==================================
2023-06-15 08:31:42,558:INFO:Creating metrics dataframe
2023-06-15 08:31:42,569:INFO:Initializing Elastic Net
2023-06-15 08:31:42,569:INFO:Total runtime is 0.1709825833638509 minutes
2023-06-15 08:31:42,573:INFO:SubProcess create_model() called ==================================
2023-06-15 08:31:42,573:INFO:Initializing create_model()
2023-06-15 08:31:42,573:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6FA795570>, model_only=True, return_train_score=False, kwargs={})
2023-06-15 08:31:42,573:INFO:Checking exceptions
2023-06-15 08:31:42,573:INFO:Importing libraries
2023-06-15 08:31:42,573:INFO:Copying training dataset
2023-06-15 08:31:42,578:INFO:Defining folds
2023-06-15 08:31:42,579:INFO:Declaring metric variables
2023-06-15 08:31:42,582:INFO:Importing untrained model
2023-06-15 08:31:42,586:INFO:Elastic Net Imported successfully
2023-06-15 08:31:42,594:INFO:Starting cross validation
2023-06-15 08:31:42,595:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-15 08:31:43,401:INFO:Calculating mean and std
2023-06-15 08:31:43,404:INFO:Creating metrics dataframe
2023-06-15 08:31:43,923:INFO:Uploading results into container
2023-06-15 08:31:43,924:INFO:Uploading model into container now
2023-06-15 08:31:43,925:INFO:_master_model_container: 4
2023-06-15 08:31:43,926:INFO:_display_container: 2
2023-06-15 08:31:43,926:INFO:ElasticNet(random_state=42)
2023-06-15 08:31:43,927:INFO:create_model() successfully completed......................................
2023-06-15 08:31:44,075:INFO:SubProcess create_model() end ==================================
2023-06-15 08:31:44,075:INFO:Creating metrics dataframe
2023-06-15 08:31:44,087:INFO:Initializing Least Angle Regression
2023-06-15 08:31:44,087:INFO:Total runtime is 0.1962852358818054 minutes
2023-06-15 08:31:44,094:INFO:SubProcess create_model() called ==================================
2023-06-15 08:31:44,094:INFO:Initializing create_model()
2023-06-15 08:31:44,094:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6FA795570>, model_only=True, return_train_score=False, kwargs={})
2023-06-15 08:31:44,094:INFO:Checking exceptions
2023-06-15 08:31:44,094:INFO:Importing libraries
2023-06-15 08:31:44,094:INFO:Copying training dataset
2023-06-15 08:31:44,112:INFO:Defining folds
2023-06-15 08:31:44,112:INFO:Declaring metric variables
2023-06-15 08:31:44,120:INFO:Importing untrained model
2023-06-15 08:31:44,125:INFO:Least Angle Regression Imported successfully
2023-06-15 08:31:44,135:INFO:Starting cross validation
2023-06-15 08:31:44,136:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-15 08:31:44,971:INFO:Calculating mean and std
2023-06-15 08:31:44,972:INFO:Creating metrics dataframe
2023-06-15 08:31:45,333:INFO:Uploading results into container
2023-06-15 08:31:45,334:INFO:Uploading model into container now
2023-06-15 08:31:45,335:INFO:_master_model_container: 5
2023-06-15 08:31:45,335:INFO:_display_container: 2
2023-06-15 08:31:45,335:INFO:Lars(random_state=42)
2023-06-15 08:31:45,335:INFO:create_model() successfully completed......................................
2023-06-15 08:31:45,474:INFO:SubProcess create_model() end ==================================
2023-06-15 08:31:45,474:INFO:Creating metrics dataframe
2023-06-15 08:31:45,498:INFO:Initializing Lasso Least Angle Regression
2023-06-15 08:31:45,499:INFO:Total runtime is 0.21981117328008015 minutes
2023-06-15 08:31:45,506:INFO:SubProcess create_model() called ==================================
2023-06-15 08:31:45,507:INFO:Initializing create_model()
2023-06-15 08:31:45,507:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6FA795570>, model_only=True, return_train_score=False, kwargs={})
2023-06-15 08:31:45,507:INFO:Checking exceptions
2023-06-15 08:31:45,507:INFO:Importing libraries
2023-06-15 08:31:45,507:INFO:Copying training dataset
2023-06-15 08:31:45,515:INFO:Defining folds
2023-06-15 08:31:45,515:INFO:Declaring metric variables
2023-06-15 08:31:45,520:INFO:Importing untrained model
2023-06-15 08:31:45,525:INFO:Lasso Least Angle Regression Imported successfully
2023-06-15 08:31:45,537:INFO:Starting cross validation
2023-06-15 08:31:45,538:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-15 08:31:46,393:INFO:Calculating mean and std
2023-06-15 08:31:46,394:INFO:Creating metrics dataframe
2023-06-15 08:31:46,771:INFO:Uploading results into container
2023-06-15 08:31:46,772:INFO:Uploading model into container now
2023-06-15 08:31:46,773:INFO:_master_model_container: 6
2023-06-15 08:31:46,773:INFO:_display_container: 2
2023-06-15 08:31:46,775:INFO:LassoLars(random_state=42)
2023-06-15 08:31:46,775:INFO:create_model() successfully completed......................................
2023-06-15 08:31:46,904:INFO:SubProcess create_model() end ==================================
2023-06-15 08:31:46,904:INFO:Creating metrics dataframe
2023-06-15 08:31:46,921:INFO:Initializing Orthogonal Matching Pursuit
2023-06-15 08:31:46,921:INFO:Total runtime is 0.24351096947987874 minutes
2023-06-15 08:31:46,926:INFO:SubProcess create_model() called ==================================
2023-06-15 08:31:46,926:INFO:Initializing create_model()
2023-06-15 08:31:46,926:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6FA795570>, model_only=True, return_train_score=False, kwargs={})
2023-06-15 08:31:46,926:INFO:Checking exceptions
2023-06-15 08:31:46,927:INFO:Importing libraries
2023-06-15 08:31:46,927:INFO:Copying training dataset
2023-06-15 08:31:46,932:INFO:Defining folds
2023-06-15 08:31:46,932:INFO:Declaring metric variables
2023-06-15 08:31:46,936:INFO:Importing untrained model
2023-06-15 08:31:46,941:INFO:Orthogonal Matching Pursuit Imported successfully
2023-06-15 08:31:46,955:INFO:Starting cross validation
2023-06-15 08:31:46,956:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-15 08:31:47,815:INFO:Calculating mean and std
2023-06-15 08:31:47,817:INFO:Creating metrics dataframe
2023-06-15 08:31:48,125:INFO:Uploading results into container
2023-06-15 08:31:48,127:INFO:Uploading model into container now
2023-06-15 08:31:48,127:INFO:_master_model_container: 7
2023-06-15 08:31:48,127:INFO:_display_container: 2
2023-06-15 08:31:48,127:INFO:OrthogonalMatchingPursuit()
2023-06-15 08:31:48,127:INFO:create_model() successfully completed......................................
2023-06-15 08:31:48,240:INFO:SubProcess create_model() end ==================================
2023-06-15 08:31:48,240:INFO:Creating metrics dataframe
2023-06-15 08:31:48,253:INFO:Initializing Bayesian Ridge
2023-06-15 08:31:48,254:INFO:Total runtime is 0.26573143402735394 minutes
2023-06-15 08:31:48,257:INFO:SubProcess create_model() called ==================================
2023-06-15 08:31:48,257:INFO:Initializing create_model()
2023-06-15 08:31:48,257:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6FA795570>, model_only=True, return_train_score=False, kwargs={})
2023-06-15 08:31:48,257:INFO:Checking exceptions
2023-06-15 08:31:48,257:INFO:Importing libraries
2023-06-15 08:31:48,257:INFO:Copying training dataset
2023-06-15 08:31:48,263:INFO:Defining folds
2023-06-15 08:31:48,263:INFO:Declaring metric variables
2023-06-15 08:31:48,269:INFO:Importing untrained model
2023-06-15 08:31:48,272:INFO:Bayesian Ridge Imported successfully
2023-06-15 08:31:48,279:INFO:Starting cross validation
2023-06-15 08:31:48,281:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-15 08:31:49,183:INFO:Calculating mean and std
2023-06-15 08:31:49,184:INFO:Creating metrics dataframe
2023-06-15 08:31:49,530:INFO:Uploading results into container
2023-06-15 08:31:49,531:INFO:Uploading model into container now
2023-06-15 08:31:49,532:INFO:_master_model_container: 8
2023-06-15 08:31:49,532:INFO:_display_container: 2
2023-06-15 08:31:49,532:INFO:BayesianRidge()
2023-06-15 08:31:49,532:INFO:create_model() successfully completed......................................
2023-06-15 08:31:49,661:INFO:SubProcess create_model() end ==================================
2023-06-15 08:31:49,661:INFO:Creating metrics dataframe
2023-06-15 08:31:49,675:INFO:Initializing Passive Aggressive Regressor
2023-06-15 08:31:49,675:INFO:Total runtime is 0.2894078850746155 minutes
2023-06-15 08:31:49,678:INFO:SubProcess create_model() called ==================================
2023-06-15 08:31:49,679:INFO:Initializing create_model()
2023-06-15 08:31:49,679:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6FA795570>, model_only=True, return_train_score=False, kwargs={})
2023-06-15 08:31:49,679:INFO:Checking exceptions
2023-06-15 08:31:49,680:INFO:Importing libraries
2023-06-15 08:31:49,680:INFO:Copying training dataset
2023-06-15 08:31:49,686:INFO:Defining folds
2023-06-15 08:31:49,686:INFO:Declaring metric variables
2023-06-15 08:31:49,690:INFO:Importing untrained model
2023-06-15 08:31:49,694:INFO:Passive Aggressive Regressor Imported successfully
2023-06-15 08:31:49,706:INFO:Starting cross validation
2023-06-15 08:31:49,707:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-15 08:31:50,559:INFO:Calculating mean and std
2023-06-15 08:31:50,560:INFO:Creating metrics dataframe
2023-06-15 08:31:50,794:INFO:Uploading results into container
2023-06-15 08:31:50,795:INFO:Uploading model into container now
2023-06-15 08:31:50,795:INFO:_master_model_container: 9
2023-06-15 08:31:50,795:INFO:_display_container: 2
2023-06-15 08:31:50,796:INFO:PassiveAggressiveRegressor(random_state=42)
2023-06-15 08:31:50,796:INFO:create_model() successfully completed......................................
2023-06-15 08:31:50,941:INFO:SubProcess create_model() end ==================================
2023-06-15 08:31:50,941:INFO:Creating metrics dataframe
2023-06-15 08:31:50,954:INFO:Initializing Huber Regressor
2023-06-15 08:31:50,955:INFO:Total runtime is 0.3107537468274435 minutes
2023-06-15 08:31:50,968:INFO:SubProcess create_model() called ==================================
2023-06-15 08:31:50,968:INFO:Initializing create_model()
2023-06-15 08:31:50,968:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6FA795570>, model_only=True, return_train_score=False, kwargs={})
2023-06-15 08:31:50,969:INFO:Checking exceptions
2023-06-15 08:31:50,969:INFO:Importing libraries
2023-06-15 08:31:50,970:INFO:Copying training dataset
2023-06-15 08:31:50,978:INFO:Defining folds
2023-06-15 08:31:50,978:INFO:Declaring metric variables
2023-06-15 08:31:50,984:INFO:Importing untrained model
2023-06-15 08:31:50,988:INFO:Huber Regressor Imported successfully
2023-06-15 08:31:50,998:INFO:Starting cross validation
2023-06-15 08:31:51,000:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-15 08:31:51,146:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-15 08:31:51,163:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-15 08:31:51,163:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-15 08:31:51,184:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-15 08:31:51,909:INFO:Calculating mean and std
2023-06-15 08:31:51,910:INFO:Creating metrics dataframe
2023-06-15 08:31:52,318:INFO:Uploading results into container
2023-06-15 08:31:52,319:INFO:Uploading model into container now
2023-06-15 08:31:52,320:INFO:_master_model_container: 10
2023-06-15 08:31:52,320:INFO:_display_container: 2
2023-06-15 08:31:52,320:INFO:HuberRegressor()
2023-06-15 08:31:52,320:INFO:create_model() successfully completed......................................
2023-06-15 08:31:52,471:INFO:SubProcess create_model() end ==================================
2023-06-15 08:31:52,473:INFO:Creating metrics dataframe
2023-06-15 08:31:52,499:INFO:Initializing K Neighbors Regressor
2023-06-15 08:31:52,499:INFO:Total runtime is 0.33648476600646976 minutes
2023-06-15 08:31:52,507:INFO:SubProcess create_model() called ==================================
2023-06-15 08:31:52,508:INFO:Initializing create_model()
2023-06-15 08:31:52,508:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6FA795570>, model_only=True, return_train_score=False, kwargs={})
2023-06-15 08:31:52,509:INFO:Checking exceptions
2023-06-15 08:31:52,509:INFO:Importing libraries
2023-06-15 08:31:52,509:INFO:Copying training dataset
2023-06-15 08:31:52,521:INFO:Defining folds
2023-06-15 08:31:52,522:INFO:Declaring metric variables
2023-06-15 08:31:52,527:INFO:Importing untrained model
2023-06-15 08:31:52,533:INFO:K Neighbors Regressor Imported successfully
2023-06-15 08:31:52,541:INFO:Starting cross validation
2023-06-15 08:31:52,542:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-15 08:31:53,518:INFO:Calculating mean and std
2023-06-15 08:31:53,519:INFO:Creating metrics dataframe
2023-06-15 08:31:53,965:INFO:Uploading results into container
2023-06-15 08:31:53,966:INFO:Uploading model into container now
2023-06-15 08:31:53,967:INFO:_master_model_container: 11
2023-06-15 08:31:53,967:INFO:_display_container: 2
2023-06-15 08:31:53,967:INFO:KNeighborsRegressor(n_jobs=-1)
2023-06-15 08:31:53,967:INFO:create_model() successfully completed......................................
2023-06-15 08:31:54,081:INFO:SubProcess create_model() end ==================================
2023-06-15 08:31:54,082:INFO:Creating metrics dataframe
2023-06-15 08:31:54,093:INFO:Initializing Decision Tree Regressor
2023-06-15 08:31:54,094:INFO:Total runtime is 0.363070027033488 minutes
2023-06-15 08:31:54,102:INFO:SubProcess create_model() called ==================================
2023-06-15 08:31:54,103:INFO:Initializing create_model()
2023-06-15 08:31:54,103:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6FA795570>, model_only=True, return_train_score=False, kwargs={})
2023-06-15 08:31:54,108:INFO:Checking exceptions
2023-06-15 08:31:54,109:INFO:Importing libraries
2023-06-15 08:31:54,109:INFO:Copying training dataset
2023-06-15 08:31:54,114:INFO:Defining folds
2023-06-15 08:31:54,114:INFO:Declaring metric variables
2023-06-15 08:31:54,120:INFO:Importing untrained model
2023-06-15 08:31:54,124:INFO:Decision Tree Regressor Imported successfully
2023-06-15 08:31:54,132:INFO:Starting cross validation
2023-06-15 08:31:54,133:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-15 08:31:54,965:INFO:Calculating mean and std
2023-06-15 08:31:54,966:INFO:Creating metrics dataframe
2023-06-15 08:31:55,522:INFO:Uploading results into container
2023-06-15 08:31:55,524:INFO:Uploading model into container now
2023-06-15 08:31:55,525:INFO:_master_model_container: 12
2023-06-15 08:31:55,525:INFO:_display_container: 2
2023-06-15 08:31:55,526:INFO:DecisionTreeRegressor(random_state=42)
2023-06-15 08:31:55,527:INFO:create_model() successfully completed......................................
2023-06-15 08:31:55,643:INFO:SubProcess create_model() end ==================================
2023-06-15 08:31:55,644:INFO:Creating metrics dataframe
2023-06-15 08:31:55,655:INFO:Initializing Random Forest Regressor
2023-06-15 08:31:55,655:INFO:Total runtime is 0.3890821695327759 minutes
2023-06-15 08:31:55,662:INFO:SubProcess create_model() called ==================================
2023-06-15 08:31:55,663:INFO:Initializing create_model()
2023-06-15 08:31:55,663:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6FA795570>, model_only=True, return_train_score=False, kwargs={})
2023-06-15 08:31:55,663:INFO:Checking exceptions
2023-06-15 08:31:55,663:INFO:Importing libraries
2023-06-15 08:31:55,664:INFO:Copying training dataset
2023-06-15 08:31:55,678:INFO:Defining folds
2023-06-15 08:31:55,679:INFO:Declaring metric variables
2023-06-15 08:31:55,687:INFO:Importing untrained model
2023-06-15 08:31:55,696:INFO:Random Forest Regressor Imported successfully
2023-06-15 08:31:55,704:INFO:Starting cross validation
2023-06-15 08:31:55,705:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-15 08:31:56,719:INFO:Calculating mean and std
2023-06-15 08:31:56,721:INFO:Creating metrics dataframe
2023-06-15 08:31:57,160:INFO:Uploading results into container
2023-06-15 08:31:57,160:INFO:Uploading model into container now
2023-06-15 08:31:57,160:INFO:_master_model_container: 13
2023-06-15 08:31:57,161:INFO:_display_container: 2
2023-06-15 08:31:57,161:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-15 08:31:57,161:INFO:create_model() successfully completed......................................
2023-06-15 08:31:57,300:INFO:SubProcess create_model() end ==================================
2023-06-15 08:31:57,300:INFO:Creating metrics dataframe
2023-06-15 08:31:57,324:INFO:Initializing Extra Trees Regressor
2023-06-15 08:31:57,324:INFO:Total runtime is 0.416891626516978 minutes
2023-06-15 08:31:57,331:INFO:SubProcess create_model() called ==================================
2023-06-15 08:31:57,332:INFO:Initializing create_model()
2023-06-15 08:31:57,332:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6FA795570>, model_only=True, return_train_score=False, kwargs={})
2023-06-15 08:31:57,332:INFO:Checking exceptions
2023-06-15 08:31:57,333:INFO:Importing libraries
2023-06-15 08:31:57,333:INFO:Copying training dataset
2023-06-15 08:31:57,343:INFO:Defining folds
2023-06-15 08:31:57,343:INFO:Declaring metric variables
2023-06-15 08:31:57,348:INFO:Importing untrained model
2023-06-15 08:31:57,358:INFO:Extra Trees Regressor Imported successfully
2023-06-15 08:31:57,366:INFO:Starting cross validation
2023-06-15 08:31:57,367:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-15 08:31:58,427:INFO:Calculating mean and std
2023-06-15 08:31:58,429:INFO:Creating metrics dataframe
2023-06-15 08:31:58,763:INFO:Uploading results into container
2023-06-15 08:31:58,764:INFO:Uploading model into container now
2023-06-15 08:31:58,765:INFO:_master_model_container: 14
2023-06-15 08:31:58,765:INFO:_display_container: 2
2023-06-15 08:31:58,766:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2023-06-15 08:31:58,766:INFO:create_model() successfully completed......................................
2023-06-15 08:31:58,910:INFO:SubProcess create_model() end ==================================
2023-06-15 08:31:58,911:INFO:Creating metrics dataframe
2023-06-15 08:31:58,928:INFO:Initializing AdaBoost Regressor
2023-06-15 08:31:58,929:INFO:Total runtime is 0.44365236759185794 minutes
2023-06-15 08:31:58,933:INFO:SubProcess create_model() called ==================================
2023-06-15 08:31:58,934:INFO:Initializing create_model()
2023-06-15 08:31:58,934:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6FA795570>, model_only=True, return_train_score=False, kwargs={})
2023-06-15 08:31:58,934:INFO:Checking exceptions
2023-06-15 08:31:58,934:INFO:Importing libraries
2023-06-15 08:31:58,934:INFO:Copying training dataset
2023-06-15 08:31:58,942:INFO:Defining folds
2023-06-15 08:31:58,943:INFO:Declaring metric variables
2023-06-15 08:31:58,946:INFO:Importing untrained model
2023-06-15 08:31:58,950:INFO:AdaBoost Regressor Imported successfully
2023-06-15 08:31:58,957:INFO:Starting cross validation
2023-06-15 08:31:58,959:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-15 08:31:59,772:INFO:Calculating mean and std
2023-06-15 08:31:59,773:INFO:Creating metrics dataframe
2023-06-15 08:32:00,094:INFO:Uploading results into container
2023-06-15 08:32:00,095:INFO:Uploading model into container now
2023-06-15 08:32:00,096:INFO:_master_model_container: 15
2023-06-15 08:32:00,096:INFO:_display_container: 2
2023-06-15 08:32:00,097:INFO:AdaBoostRegressor(random_state=42)
2023-06-15 08:32:00,097:INFO:create_model() successfully completed......................................
2023-06-15 08:32:00,229:INFO:SubProcess create_model() end ==================================
2023-06-15 08:32:00,230:INFO:Creating metrics dataframe
2023-06-15 08:32:00,242:INFO:Initializing Gradient Boosting Regressor
2023-06-15 08:32:00,242:INFO:Total runtime is 0.46553045511245733 minutes
2023-06-15 08:32:00,251:INFO:SubProcess create_model() called ==================================
2023-06-15 08:32:00,251:INFO:Initializing create_model()
2023-06-15 08:32:00,252:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6FA795570>, model_only=True, return_train_score=False, kwargs={})
2023-06-15 08:32:00,252:INFO:Checking exceptions
2023-06-15 08:32:00,252:INFO:Importing libraries
2023-06-15 08:32:00,252:INFO:Copying training dataset
2023-06-15 08:32:00,264:INFO:Defining folds
2023-06-15 08:32:00,264:INFO:Declaring metric variables
2023-06-15 08:32:00,271:INFO:Importing untrained model
2023-06-15 08:32:00,275:INFO:Gradient Boosting Regressor Imported successfully
2023-06-15 08:32:00,284:INFO:Starting cross validation
2023-06-15 08:32:00,285:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-15 08:32:01,141:INFO:Calculating mean and std
2023-06-15 08:32:01,143:INFO:Creating metrics dataframe
2023-06-15 08:32:01,606:INFO:Uploading results into container
2023-06-15 08:32:01,607:INFO:Uploading model into container now
2023-06-15 08:32:01,608:INFO:_master_model_container: 16
2023-06-15 08:32:01,608:INFO:_display_container: 2
2023-06-15 08:32:01,608:INFO:GradientBoostingRegressor(random_state=42)
2023-06-15 08:32:01,609:INFO:create_model() successfully completed......................................
2023-06-15 08:32:01,739:INFO:SubProcess create_model() end ==================================
2023-06-15 08:32:01,740:INFO:Creating metrics dataframe
2023-06-15 08:32:01,767:INFO:Initializing Extreme Gradient Boosting
2023-06-15 08:32:01,767:INFO:Total runtime is 0.4909521818161011 minutes
2023-06-15 08:32:01,771:INFO:SubProcess create_model() called ==================================
2023-06-15 08:32:01,771:INFO:Initializing create_model()
2023-06-15 08:32:01,771:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6FA795570>, model_only=True, return_train_score=False, kwargs={})
2023-06-15 08:32:01,772:INFO:Checking exceptions
2023-06-15 08:32:01,772:INFO:Importing libraries
2023-06-15 08:32:01,772:INFO:Copying training dataset
2023-06-15 08:32:01,782:INFO:Defining folds
2023-06-15 08:32:01,782:INFO:Declaring metric variables
2023-06-15 08:32:01,787:INFO:Importing untrained model
2023-06-15 08:32:01,794:INFO:Extreme Gradient Boosting Imported successfully
2023-06-15 08:32:01,803:INFO:Starting cross validation
2023-06-15 08:32:01,804:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-15 08:32:02,760:INFO:Calculating mean and std
2023-06-15 08:32:02,762:INFO:Creating metrics dataframe
2023-06-15 08:32:03,191:INFO:Uploading results into container
2023-06-15 08:32:03,192:INFO:Uploading model into container now
2023-06-15 08:32:03,193:INFO:_master_model_container: 17
2023-06-15 08:32:03,193:INFO:_display_container: 2
2023-06-15 08:32:03,195:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=42, ...)
2023-06-15 08:32:03,195:INFO:create_model() successfully completed......................................
2023-06-15 08:32:03,306:INFO:SubProcess create_model() end ==================================
2023-06-15 08:32:03,306:INFO:Creating metrics dataframe
2023-06-15 08:32:03,321:INFO:Initializing Light Gradient Boosting Machine
2023-06-15 08:32:03,321:INFO:Total runtime is 0.5168455998102824 minutes
2023-06-15 08:32:03,324:INFO:SubProcess create_model() called ==================================
2023-06-15 08:32:03,324:INFO:Initializing create_model()
2023-06-15 08:32:03,324:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6FA795570>, model_only=True, return_train_score=False, kwargs={})
2023-06-15 08:32:03,325:INFO:Checking exceptions
2023-06-15 08:32:03,325:INFO:Importing libraries
2023-06-15 08:32:03,325:INFO:Copying training dataset
2023-06-15 08:32:03,340:INFO:Defining folds
2023-06-15 08:32:03,341:INFO:Declaring metric variables
2023-06-15 08:32:03,349:INFO:Importing untrained model
2023-06-15 08:32:03,356:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-15 08:32:03,363:INFO:Starting cross validation
2023-06-15 08:32:03,365:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-15 08:32:05,231:INFO:Calculating mean and std
2023-06-15 08:32:05,233:INFO:Creating metrics dataframe
2023-06-15 08:32:05,713:INFO:Uploading results into container
2023-06-15 08:32:05,715:INFO:Uploading model into container now
2023-06-15 08:32:05,716:INFO:_master_model_container: 18
2023-06-15 08:32:05,716:INFO:_display_container: 2
2023-06-15 08:32:05,717:INFO:LGBMRegressor(random_state=42)
2023-06-15 08:32:05,718:INFO:create_model() successfully completed......................................
2023-06-15 08:32:05,858:INFO:SubProcess create_model() end ==================================
2023-06-15 08:32:05,858:INFO:Creating metrics dataframe
2023-06-15 08:32:05,871:INFO:Initializing Dummy Regressor
2023-06-15 08:32:05,871:INFO:Total runtime is 0.5593568682670593 minutes
2023-06-15 08:32:05,875:INFO:SubProcess create_model() called ==================================
2023-06-15 08:32:05,875:INFO:Initializing create_model()
2023-06-15 08:32:05,875:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6FA795570>, model_only=True, return_train_score=False, kwargs={})
2023-06-15 08:32:05,876:INFO:Checking exceptions
2023-06-15 08:32:05,876:INFO:Importing libraries
2023-06-15 08:32:05,876:INFO:Copying training dataset
2023-06-15 08:32:05,886:INFO:Defining folds
2023-06-15 08:32:05,886:INFO:Declaring metric variables
2023-06-15 08:32:05,893:INFO:Importing untrained model
2023-06-15 08:32:05,897:INFO:Dummy Regressor Imported successfully
2023-06-15 08:32:05,904:INFO:Starting cross validation
2023-06-15 08:32:05,905:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-15 08:32:06,752:INFO:Calculating mean and std
2023-06-15 08:32:06,754:INFO:Creating metrics dataframe
2023-06-15 08:32:07,137:INFO:Uploading results into container
2023-06-15 08:32:07,140:INFO:Uploading model into container now
2023-06-15 08:32:07,140:INFO:_master_model_container: 19
2023-06-15 08:32:07,140:INFO:_display_container: 2
2023-06-15 08:32:07,140:INFO:DummyRegressor()
2023-06-15 08:32:07,140:INFO:create_model() successfully completed......................................
2023-06-15 08:32:07,246:INFO:SubProcess create_model() end ==================================
2023-06-15 08:32:07,246:INFO:Creating metrics dataframe
2023-06-15 08:32:07,297:INFO:Initializing create_model()
2023-06-15 08:32:07,297:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-15 08:32:07,298:INFO:Checking exceptions
2023-06-15 08:32:07,299:INFO:Importing libraries
2023-06-15 08:32:07,299:INFO:Copying training dataset
2023-06-15 08:32:07,304:INFO:Defining folds
2023-06-15 08:32:07,304:INFO:Declaring metric variables
2023-06-15 08:32:07,304:INFO:Importing untrained model
2023-06-15 08:32:07,304:INFO:Declaring custom model
2023-06-15 08:32:07,305:INFO:Random Forest Regressor Imported successfully
2023-06-15 08:32:07,305:INFO:Cross validation set to False
2023-06-15 08:32:07,306:INFO:Fitting Model
2023-06-15 08:32:07,567:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-15 08:32:07,567:INFO:create_model() successfully completed......................................
2023-06-15 08:32:07,728:INFO:_master_model_container: 19
2023-06-15 08:32:07,728:INFO:_display_container: 2
2023-06-15 08:32:07,728:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-15 08:32:07,728:INFO:compare_models() successfully completed......................................
2023-06-15 08:32:13,186:INFO:Initializing create_model()
2023-06-15 08:32:13,187:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, estimator=rf, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-15 08:32:13,187:INFO:Checking exceptions
2023-06-15 08:32:13,212:INFO:Importing libraries
2023-06-15 08:32:13,212:INFO:Copying training dataset
2023-06-15 08:32:13,223:INFO:Defining folds
2023-06-15 08:32:13,223:INFO:Declaring metric variables
2023-06-15 08:32:13,229:INFO:Importing untrained model
2023-06-15 08:32:13,232:INFO:Random Forest Regressor Imported successfully
2023-06-15 08:32:13,241:INFO:Starting cross validation
2023-06-15 08:32:13,242:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-15 08:32:14,261:INFO:Calculating mean and std
2023-06-15 08:32:14,263:INFO:Creating metrics dataframe
2023-06-15 08:32:14,272:INFO:Finalizing model
2023-06-15 08:32:14,659:INFO:Uploading results into container
2023-06-15 08:32:14,659:INFO:Uploading model into container now
2023-06-15 08:32:14,672:INFO:_master_model_container: 20
2023-06-15 08:32:14,673:INFO:_display_container: 3
2023-06-15 08:32:14,673:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-15 08:32:14,673:INFO:create_model() successfully completed......................................
2023-06-15 08:32:23,884:INFO:Initializing plot_model()
2023-06-15 08:32:23,884:INFO:plot_model(plot=learning, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, system=True)
2023-06-15 08:32:23,884:INFO:Checking exceptions
2023-06-15 08:32:23,909:INFO:Preloading libraries
2023-06-15 08:32:23,941:INFO:Copying training dataset
2023-06-15 08:32:23,941:INFO:Plot type: learning
2023-06-15 08:32:24,054:INFO:Fitting Model
2023-06-15 08:33:41,481:INFO:Visual Rendered Successfully
2023-06-15 08:33:41,637:INFO:plot_model() successfully completed......................................
2023-06-15 08:33:41,651:INFO:Initializing plot_model()
2023-06-15 08:33:41,651:INFO:plot_model(plot=vc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, system=True)
2023-06-15 08:33:41,651:INFO:Checking exceptions
2023-06-15 08:33:41,682:INFO:Preloading libraries
2023-06-15 08:33:41,747:INFO:Copying training dataset
2023-06-15 08:33:41,747:INFO:Plot type: vc
2023-06-15 08:33:41,748:INFO:Determining param_name
2023-06-15 08:33:41,749:INFO:param_name: max_depth
2023-06-15 08:33:41,932:INFO:Fitting Model
2023-06-15 08:34:30,324:INFO:Visual Rendered Successfully
2023-06-15 08:34:30,489:INFO:plot_model() successfully completed......................................
2023-06-15 08:34:30,517:INFO:Initializing plot_model()
2023-06-15 08:34:30,517:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, system=True)
2023-06-15 08:34:30,517:INFO:Checking exceptions
2023-06-15 08:34:30,543:INFO:Preloading libraries
2023-06-15 08:34:30,579:INFO:Copying training dataset
2023-06-15 08:34:30,579:INFO:Plot type: error
2023-06-15 08:34:30,770:INFO:Fitting Model
2023-06-15 08:34:30,770:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2023-06-15 08:34:30,771:INFO:Scoring test/hold-out set
2023-06-15 08:34:31,369:INFO:Visual Rendered Successfully
2023-06-15 08:34:31,531:INFO:plot_model() successfully completed......................................
2023-06-15 08:34:31,543:INFO:Initializing plot_model()
2023-06-15 08:34:31,543:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, system=True)
2023-06-15 08:34:31,543:INFO:Checking exceptions
2023-06-15 08:34:31,565:INFO:Preloading libraries
2023-06-15 08:34:31,599:INFO:Copying training dataset
2023-06-15 08:34:31,599:INFO:Plot type: feature
2023-06-15 08:34:31,600:WARNING:No coef_ found. Trying feature_importances_
2023-06-15 08:34:31,912:INFO:Visual Rendered Successfully
2023-06-15 08:34:32,052:INFO:plot_model() successfully completed......................................
2023-06-15 08:34:32,066:INFO:Initializing plot_model()
2023-06-15 08:34:32,066:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=3, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, system=True)
2023-06-15 08:34:32,066:INFO:Checking exceptions
2023-06-15 08:34:32,088:INFO:Preloading libraries
2023-06-15 08:34:32,123:INFO:Copying training dataset
2023-06-15 08:34:32,123:INFO:Plot type: residuals
2023-06-15 08:34:32,296:INFO:Fitting Model
2023-06-15 08:34:32,296:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2023-06-15 08:34:32,398:INFO:Scoring test/hold-out set
2023-06-15 08:34:33,344:INFO:Visual Rendered Successfully
2023-06-15 08:34:33,490:INFO:plot_model() successfully completed......................................
2023-06-15 08:34:33,522:INFO:Initializing interpret_model()
2023-06-15 08:34:33,522:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>)
2023-06-15 08:34:33,523:INFO:Checking exceptions
2023-06-15 08:34:33,523:INFO:Soft dependency imported: shap: 0.41.0
2023-06-15 08:34:33,551:INFO:plot type: summary
2023-06-15 08:34:33,551:INFO:Creating TreeExplainer
2023-06-15 08:34:33,569:INFO:Compiling shap values
2023-06-15 08:36:17,546:WARNING:No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored

2023-06-15 08:36:18,192:INFO:Visual Rendered Successfully
2023-06-15 08:36:18,192:INFO:interpret_model() successfully completed......................................
2023-06-15 08:36:18,347:INFO:Initializing interpret_model()
2023-06-15 08:36:18,347:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=correlation, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>)
2023-06-15 08:36:18,348:INFO:Checking exceptions
2023-06-15 08:36:18,348:INFO:Soft dependency imported: shap: 0.41.0
2023-06-15 08:36:18,383:INFO:plot type: correlation
2023-06-15 08:36:18,383:WARNING:No feature passed. Default value of feature used for correlation plot: taxa_homicidio
2023-06-15 08:36:18,383:INFO:Creating TreeExplainer
2023-06-15 08:36:18,410:INFO:Compiling shap values
2023-06-15 08:38:06,859:INFO:model type detected: type 2
2023-06-15 08:38:07,107:INFO:Visual Rendered Successfully
2023-06-15 08:38:07,107:INFO:interpret_model() successfully completed......................................
2023-06-15 08:38:07,232:INFO:Initializing interpret_model()
2023-06-15 08:38:07,232:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=1, plot=reason, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>)
2023-06-15 08:38:07,232:INFO:Checking exceptions
2023-06-15 08:38:07,232:INFO:Soft dependency imported: shap: 0.41.0
2023-06-15 08:38:07,256:INFO:plot type: reason
2023-06-15 08:38:07,256:INFO:model type detected: type 2
2023-06-15 08:38:07,256:INFO:Creating TreeExplainer
2023-06-15 08:38:07,274:INFO:Compiling shap values
2023-06-15 08:40:04,099:INFO:Visual Rendered Successfully
2023-06-15 08:40:04,099:INFO:interpret_model() successfully completed......................................
2023-06-15 08:40:04,257:INFO:Initializing interpret_model()
2023-06-15 08:40:04,258:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=3, plot=reason, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>)
2023-06-15 08:40:04,258:INFO:Checking exceptions
2023-06-15 08:40:04,258:INFO:Soft dependency imported: shap: 0.41.0
2023-06-15 08:40:04,305:INFO:plot type: reason
2023-06-15 08:40:04,305:INFO:model type detected: type 2
2023-06-15 08:40:04,305:INFO:Creating TreeExplainer
2023-06-15 08:40:04,331:INFO:Compiling shap values
2023-06-15 08:41:58,878:INFO:Visual Rendered Successfully
2023-06-15 08:41:58,878:INFO:interpret_model() successfully completed......................................
2023-06-15 08:42:23,303:INFO:Initializing tune_model()
2023-06-15 08:42:23,304:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=5, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>)
2023-06-15 08:42:23,304:INFO:Checking exceptions
2023-06-15 08:42:23,330:INFO:Copying training dataset
2023-06-15 08:42:23,333:INFO:Checking base model
2023-06-15 08:42:23,333:INFO:Base model : Random Forest Regressor
2023-06-15 08:42:23,338:INFO:Declaring metric variables
2023-06-15 08:42:23,343:INFO:Defining Hyperparameters
2023-06-15 08:42:23,459:INFO:Tuning with n_jobs=-1
2023-06-15 08:42:23,459:INFO:Initializing RandomizedSearchCV
2023-06-15 08:42:40,302:INFO:best_params: {'actual_estimator__n_estimators': 190, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 4, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': True}
2023-06-15 08:42:40,303:INFO:Hyperparameter search completed
2023-06-15 08:42:40,304:INFO:SubProcess create_model() called ==================================
2023-06-15 08:42:40,304:INFO:Initializing create_model()
2023-06-15 08:42:40,305:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6EAD65720>, model_only=True, return_train_score=False, kwargs={'n_estimators': 190, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.3, 'max_features': 1.0, 'max_depth': 4, 'criterion': 'squared_error', 'bootstrap': True})
2023-06-15 08:42:40,305:INFO:Checking exceptions
2023-06-15 08:42:40,305:INFO:Importing libraries
2023-06-15 08:42:40,305:INFO:Copying training dataset
2023-06-15 08:42:40,313:INFO:Defining folds
2023-06-15 08:42:40,313:INFO:Declaring metric variables
2023-06-15 08:42:40,317:INFO:Importing untrained model
2023-06-15 08:42:40,317:INFO:Declaring custom model
2023-06-15 08:42:40,321:INFO:Random Forest Regressor Imported successfully
2023-06-15 08:42:40,329:INFO:Starting cross validation
2023-06-15 08:42:40,331:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-15 08:42:41,389:INFO:Calculating mean and std
2023-06-15 08:42:41,390:INFO:Creating metrics dataframe
2023-06-15 08:42:41,401:INFO:Finalizing model
2023-06-15 08:42:41,697:INFO:Uploading results into container
2023-06-15 08:42:41,698:INFO:Uploading model into container now
2023-06-15 08:42:41,699:INFO:_master_model_container: 21
2023-06-15 08:42:41,699:INFO:_display_container: 4
2023-06-15 08:42:41,701:INFO:RandomForestRegressor(max_depth=4, min_impurity_decrease=0.3,
                      min_samples_leaf=2, n_estimators=190, n_jobs=-1,
                      random_state=42)
2023-06-15 08:42:41,701:INFO:create_model() successfully completed......................................
2023-06-15 08:42:41,825:INFO:SubProcess create_model() end ==================================
2023-06-15 08:42:41,825:INFO:choose_better activated
2023-06-15 08:42:41,834:INFO:SubProcess create_model() called ==================================
2023-06-15 08:42:41,835:INFO:Initializing create_model()
2023-06-15 08:42:41,836:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-15 08:42:41,836:INFO:Checking exceptions
2023-06-15 08:42:41,839:INFO:Importing libraries
2023-06-15 08:42:41,839:INFO:Copying training dataset
2023-06-15 08:42:41,849:INFO:Defining folds
2023-06-15 08:42:41,851:INFO:Declaring metric variables
2023-06-15 08:42:41,851:INFO:Importing untrained model
2023-06-15 08:42:41,851:INFO:Declaring custom model
2023-06-15 08:42:41,852:INFO:Random Forest Regressor Imported successfully
2023-06-15 08:42:41,853:INFO:Starting cross validation
2023-06-15 08:42:41,854:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-15 08:42:42,886:INFO:Calculating mean and std
2023-06-15 08:42:42,887:INFO:Creating metrics dataframe
2023-06-15 08:42:42,891:INFO:Finalizing model
2023-06-15 08:42:43,207:INFO:Uploading results into container
2023-06-15 08:42:43,208:INFO:Uploading model into container now
2023-06-15 08:42:43,208:INFO:_master_model_container: 22
2023-06-15 08:42:43,208:INFO:_display_container: 5
2023-06-15 08:42:43,209:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-15 08:42:43,209:INFO:create_model() successfully completed......................................
2023-06-15 08:42:43,319:INFO:SubProcess create_model() end ==================================
2023-06-15 08:42:43,320:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) result for R2 is 0.9102
2023-06-15 08:42:43,321:INFO:RandomForestRegressor(max_depth=4, min_impurity_decrease=0.3,
                      min_samples_leaf=2, n_estimators=190, n_jobs=-1,
                      random_state=42) result for R2 is 0.8871
2023-06-15 08:42:43,321:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) is best model
2023-06-15 08:42:43,321:INFO:choose_better completed
2023-06-15 08:42:43,321:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-06-15 08:42:43,331:INFO:_master_model_container: 22
2023-06-15 08:42:43,331:INFO:_display_container: 4
2023-06-15 08:42:43,332:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-15 08:42:43,332:INFO:tune_model() successfully completed......................................
2023-06-15 08:43:17,937:INFO:Initializing plot_model()
2023-06-15 08:43:17,937:INFO:plot_model(plot=learning, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, system=True)
2023-06-15 08:43:17,937:INFO:Checking exceptions
2023-06-15 08:43:17,962:INFO:Preloading libraries
2023-06-15 08:43:17,997:INFO:Copying training dataset
2023-06-15 08:43:17,997:INFO:Plot type: learning
2023-06-15 08:43:18,110:INFO:Fitting Model
2023-06-15 08:44:36,568:INFO:Visual Rendered Successfully
2023-06-15 08:44:36,707:INFO:plot_model() successfully completed......................................
2023-06-15 08:44:36,738:INFO:Initializing plot_model()
2023-06-15 08:44:36,738:INFO:plot_model(plot=vc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, system=True)
2023-06-15 08:44:36,738:INFO:Checking exceptions
2023-06-15 08:44:36,766:INFO:Preloading libraries
2023-06-15 08:44:36,801:INFO:Copying training dataset
2023-06-15 08:44:36,801:INFO:Plot type: vc
2023-06-15 08:44:36,801:INFO:Determining param_name
2023-06-15 08:44:36,801:INFO:param_name: max_depth
2023-06-15 08:44:36,953:INFO:Fitting Model
2023-06-15 08:45:25,672:INFO:Visual Rendered Successfully
2023-06-15 08:45:25,822:INFO:plot_model() successfully completed......................................
2023-06-15 08:45:25,845:INFO:Initializing plot_model()
2023-06-15 08:45:25,846:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, system=True)
2023-06-15 08:45:25,846:INFO:Checking exceptions
2023-06-15 08:45:25,870:INFO:Preloading libraries
2023-06-15 08:45:25,913:INFO:Copying training dataset
2023-06-15 08:45:25,913:INFO:Plot type: error
2023-06-15 08:45:25,999:INFO:Fitting Model
2023-06-15 08:45:26,000:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2023-06-15 08:45:26,000:INFO:Scoring test/hold-out set
2023-06-15 08:45:26,327:INFO:Visual Rendered Successfully
2023-06-15 08:45:26,459:INFO:plot_model() successfully completed......................................
2023-06-15 08:45:26,480:INFO:Initializing plot_model()
2023-06-15 08:45:26,480:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, system=True)
2023-06-15 08:45:26,480:INFO:Checking exceptions
2023-06-15 08:45:26,518:INFO:Preloading libraries
2023-06-15 08:45:26,569:INFO:Copying training dataset
2023-06-15 08:45:26,569:INFO:Plot type: feature
2023-06-15 08:45:26,569:WARNING:No coef_ found. Trying feature_importances_
2023-06-15 08:45:26,760:INFO:Visual Rendered Successfully
2023-06-15 08:45:26,892:INFO:plot_model() successfully completed......................................
2023-06-15 08:45:26,919:INFO:Initializing plot_model()
2023-06-15 08:45:26,919:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=3, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, system=True)
2023-06-15 08:45:26,919:INFO:Checking exceptions
2023-06-15 08:45:26,941:INFO:Preloading libraries
2023-06-15 08:45:26,976:INFO:Copying training dataset
2023-06-15 08:45:26,976:INFO:Plot type: residuals
2023-06-15 08:45:27,109:INFO:Fitting Model
2023-06-15 08:45:27,109:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2023-06-15 08:45:27,229:INFO:Scoring test/hold-out set
2023-06-15 08:45:28,087:INFO:Visual Rendered Successfully
2023-06-15 08:45:28,244:INFO:plot_model() successfully completed......................................
2023-06-15 08:45:28,290:INFO:Initializing interpret_model()
2023-06-15 08:45:28,290:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>)
2023-06-15 08:45:28,291:INFO:Checking exceptions
2023-06-15 08:45:28,291:INFO:Soft dependency imported: shap: 0.41.0
2023-06-15 08:45:28,321:INFO:plot type: summary
2023-06-15 08:45:28,321:INFO:Creating TreeExplainer
2023-06-15 08:45:28,338:INFO:Compiling shap values
2023-06-15 08:47:19,923:WARNING:No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored

2023-06-15 08:47:20,576:INFO:Visual Rendered Successfully
2023-06-15 08:47:20,576:INFO:interpret_model() successfully completed......................................
2023-06-15 08:47:20,761:INFO:Initializing interpret_model()
2023-06-15 08:47:20,762:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=correlation, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>)
2023-06-15 08:47:20,762:INFO:Checking exceptions
2023-06-15 08:47:20,762:INFO:Soft dependency imported: shap: 0.41.0
2023-06-15 08:47:20,809:INFO:plot type: correlation
2023-06-15 08:47:20,809:WARNING:No feature passed. Default value of feature used for correlation plot: taxa_homicidio
2023-06-15 08:47:20,809:INFO:Creating TreeExplainer
2023-06-15 08:47:20,831:INFO:Compiling shap values
2023-06-15 08:49:17,517:INFO:model type detected: type 2
2023-06-15 08:49:17,785:INFO:Visual Rendered Successfully
2023-06-15 08:49:17,786:INFO:interpret_model() successfully completed......................................
2023-06-15 08:49:17,952:INFO:Initializing interpret_model()
2023-06-15 08:49:17,952:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=1, plot=reason, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>)
2023-06-15 08:49:17,952:INFO:Checking exceptions
2023-06-15 08:49:17,953:INFO:Soft dependency imported: shap: 0.41.0
2023-06-15 08:49:17,984:INFO:plot type: reason
2023-06-15 08:49:17,984:INFO:model type detected: type 2
2023-06-15 08:49:17,984:INFO:Creating TreeExplainer
2023-06-15 08:49:18,003:INFO:Compiling shap values
2023-06-15 08:51:16,025:INFO:Visual Rendered Successfully
2023-06-15 08:51:16,025:INFO:interpret_model() successfully completed......................................
2023-06-15 08:51:16,209:INFO:Initializing interpret_model()
2023-06-15 08:51:16,209:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=3, plot=reason, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>)
2023-06-15 08:51:16,209:INFO:Checking exceptions
2023-06-15 08:51:16,209:INFO:Soft dependency imported: shap: 0.41.0
2023-06-15 08:51:16,246:INFO:plot type: reason
2023-06-15 08:51:16,246:INFO:model type detected: type 2
2023-06-15 08:51:16,246:INFO:Creating TreeExplainer
2023-06-15 08:51:16,265:INFO:Compiling shap values
2023-06-15 08:53:11,880:INFO:Visual Rendered Successfully
2023-06-15 08:53:11,880:INFO:interpret_model() successfully completed......................................
2023-06-15 08:55:07,620:INFO:Initializing tune_model()
2023-06-15 08:55:07,620:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=5, round=4, n_iter=10, custom_grid={'max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>)
2023-06-15 08:55:07,620:INFO:Checking exceptions
2023-06-15 08:55:07,643:INFO:Copying training dataset
2023-06-15 08:55:07,651:INFO:Checking base model
2023-06-15 08:55:07,651:INFO:Base model : Random Forest Regressor
2023-06-15 08:55:07,657:INFO:Declaring metric variables
2023-06-15 08:55:07,661:INFO:Defining Hyperparameters
2023-06-15 08:55:07,779:INFO:custom_grid: {'actual_estimator__max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}
2023-06-15 08:55:07,779:INFO:Tuning with n_jobs=-1
2023-06-15 08:55:07,779:INFO:Initializing RandomizedSearchCV
2023-06-15 08:55:23,973:WARNING:
5 fits failed out of a total of 50.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\lapei\anaconda3\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py", line 340, in fit
    self._validate_params()
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\base.py", line 581, in _validate_params
    validate_parameter_constraints(
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 97, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestRegressor must be an int in the range [1, inf) or None. Got 0 instead.


2023-06-15 08:55:23,974:WARNING:One or more of the test scores are non-finite: [       nan 0.48652662 0.84008985 0.88700297 0.89957066 0.90836024
 0.90866937 0.90843499 0.90995616 0.91114377]

2023-06-15 08:55:24,221:INFO:best_params: {'actual_estimator__max_depth': 10}
2023-06-15 08:55:24,222:INFO:Hyperparameter search completed
2023-06-15 08:55:24,222:INFO:SubProcess create_model() called ==================================
2023-06-15 08:55:24,222:INFO:Initializing create_model()
2023-06-15 08:55:24,222:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6FCE21960>, model_only=True, return_train_score=False, kwargs={'max_depth': 10})
2023-06-15 08:55:24,222:INFO:Checking exceptions
2023-06-15 08:55:24,223:INFO:Importing libraries
2023-06-15 08:55:24,223:INFO:Copying training dataset
2023-06-15 08:55:24,229:INFO:Defining folds
2023-06-15 08:55:24,229:INFO:Declaring metric variables
2023-06-15 08:55:24,232:INFO:Importing untrained model
2023-06-15 08:55:24,232:INFO:Declaring custom model
2023-06-15 08:55:24,236:INFO:Random Forest Regressor Imported successfully
2023-06-15 08:55:24,243:INFO:Starting cross validation
2023-06-15 08:55:24,244:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-15 08:55:25,290:INFO:Calculating mean and std
2023-06-15 08:55:25,291:INFO:Creating metrics dataframe
2023-06-15 08:55:25,297:INFO:Finalizing model
2023-06-15 08:55:25,658:INFO:Uploading results into container
2023-06-15 08:55:25,659:INFO:Uploading model into container now
2023-06-15 08:55:25,659:INFO:_master_model_container: 23
2023-06-15 08:55:25,659:INFO:_display_container: 5
2023-06-15 08:55:25,661:INFO:RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42)
2023-06-15 08:55:25,661:INFO:create_model() successfully completed......................................
2023-06-15 08:55:25,780:INFO:SubProcess create_model() end ==================================
2023-06-15 08:55:25,780:INFO:choose_better activated
2023-06-15 08:55:25,784:INFO:SubProcess create_model() called ==================================
2023-06-15 08:55:25,784:INFO:Initializing create_model()
2023-06-15 08:55:25,784:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-15 08:55:25,784:INFO:Checking exceptions
2023-06-15 08:55:25,787:INFO:Importing libraries
2023-06-15 08:55:25,787:INFO:Copying training dataset
2023-06-15 08:55:25,799:INFO:Defining folds
2023-06-15 08:55:25,800:INFO:Declaring metric variables
2023-06-15 08:55:25,800:INFO:Importing untrained model
2023-06-15 08:55:25,800:INFO:Declaring custom model
2023-06-15 08:55:25,801:INFO:Random Forest Regressor Imported successfully
2023-06-15 08:55:25,802:INFO:Starting cross validation
2023-06-15 08:55:25,804:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-15 08:55:26,901:INFO:Calculating mean and std
2023-06-15 08:55:26,902:INFO:Creating metrics dataframe
2023-06-15 08:55:26,906:INFO:Finalizing model
2023-06-15 08:55:27,190:INFO:Uploading results into container
2023-06-15 08:55:27,191:INFO:Uploading model into container now
2023-06-15 08:55:27,191:INFO:_master_model_container: 24
2023-06-15 08:55:27,191:INFO:_display_container: 6
2023-06-15 08:55:27,192:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-15 08:55:27,192:INFO:create_model() successfully completed......................................
2023-06-15 08:55:27,303:INFO:SubProcess create_model() end ==================================
2023-06-15 08:55:27,303:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) result for R2 is 0.9102
2023-06-15 08:55:27,304:INFO:RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42) result for R2 is 0.9111
2023-06-15 08:55:27,304:INFO:RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42) is best model
2023-06-15 08:55:27,304:INFO:choose_better completed
2023-06-15 08:55:27,312:INFO:_master_model_container: 24
2023-06-15 08:55:27,313:INFO:_display_container: 5
2023-06-15 08:55:27,313:INFO:RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42)
2023-06-15 08:55:27,313:INFO:tune_model() successfully completed......................................
2023-06-15 08:56:23,200:INFO:Initializing plot_model()
2023-06-15 08:56:23,201:INFO:plot_model(plot=learning, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, system=True)
2023-06-15 08:56:23,201:INFO:Checking exceptions
2023-06-15 08:56:23,223:INFO:Preloading libraries
2023-06-15 08:56:23,232:INFO:Copying training dataset
2023-06-15 08:56:23,232:INFO:Plot type: learning
2023-06-15 08:56:23,335:INFO:Fitting Model
2023-06-15 08:57:13,623:INFO:Visual Rendered Successfully
2023-06-15 08:57:13,763:INFO:plot_model() successfully completed......................................
2023-06-15 08:57:13,773:INFO:Initializing plot_model()
2023-06-15 08:57:13,773:INFO:plot_model(plot=vc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, system=True)
2023-06-15 08:57:13,773:INFO:Checking exceptions
2023-06-15 08:57:13,796:INFO:Preloading libraries
2023-06-15 08:57:13,803:INFO:Copying training dataset
2023-06-15 08:57:13,804:INFO:Plot type: vc
2023-06-15 08:57:13,804:INFO:Determining param_name
2023-06-15 08:57:13,804:INFO:param_name: max_depth
2023-06-15 08:57:13,911:INFO:Fitting Model
2023-06-15 08:58:00,154:INFO:Visual Rendered Successfully
2023-06-15 08:58:00,269:INFO:plot_model() successfully completed......................................
2023-06-15 08:58:00,288:INFO:Initializing plot_model()
2023-06-15 08:58:00,288:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, system=True)
2023-06-15 08:58:00,288:INFO:Checking exceptions
2023-06-15 08:58:00,327:INFO:Preloading libraries
2023-06-15 08:58:00,350:INFO:Copying training dataset
2023-06-15 08:58:00,351:INFO:Plot type: error
2023-06-15 08:58:00,463:INFO:Fitting Model
2023-06-15 08:58:00,463:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2023-06-15 08:58:00,464:INFO:Scoring test/hold-out set
2023-06-15 08:58:00,805:INFO:Visual Rendered Successfully
2023-06-15 08:58:00,935:INFO:plot_model() successfully completed......................................
2023-06-15 08:58:00,953:INFO:Initializing plot_model()
2023-06-15 08:58:00,953:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, system=True)
2023-06-15 08:58:00,953:INFO:Checking exceptions
2023-06-15 08:58:00,970:INFO:Preloading libraries
2023-06-15 08:58:00,978:INFO:Copying training dataset
2023-06-15 08:58:00,979:INFO:Plot type: feature
2023-06-15 08:58:00,979:WARNING:No coef_ found. Trying feature_importances_
2023-06-15 08:58:01,160:INFO:Visual Rendered Successfully
2023-06-15 08:58:01,289:INFO:plot_model() successfully completed......................................
2023-06-15 08:58:01,308:INFO:Initializing plot_model()
2023-06-15 08:58:01,308:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=3, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, system=True)
2023-06-15 08:58:01,308:INFO:Checking exceptions
2023-06-15 08:58:01,327:INFO:Preloading libraries
2023-06-15 08:58:01,335:INFO:Copying training dataset
2023-06-15 08:58:01,335:INFO:Plot type: residuals
2023-06-15 08:58:01,484:INFO:Fitting Model
2023-06-15 08:58:01,484:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2023-06-15 08:58:01,591:INFO:Scoring test/hold-out set
2023-06-15 08:58:02,273:INFO:Visual Rendered Successfully
2023-06-15 08:58:02,434:INFO:plot_model() successfully completed......................................
2023-06-15 08:58:02,446:INFO:Initializing interpret_model()
2023-06-15 08:58:02,446:INFO:interpret_model(estimator=RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>)
2023-06-15 08:58:02,446:INFO:Checking exceptions
2023-06-15 08:58:02,446:INFO:Soft dependency imported: shap: 0.41.0
2023-06-15 08:58:02,469:INFO:plot type: summary
2023-06-15 08:58:02,469:INFO:Creating TreeExplainer
2023-06-15 08:58:02,473:INFO:Compiling shap values
2023-06-15 08:58:08,456:WARNING:No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored

2023-06-15 08:58:09,187:INFO:Visual Rendered Successfully
2023-06-15 08:58:09,187:INFO:interpret_model() successfully completed......................................
2023-06-15 08:58:09,346:INFO:Initializing interpret_model()
2023-06-15 08:58:09,346:INFO:interpret_model(estimator=RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=correlation, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>)
2023-06-15 08:58:09,347:INFO:Checking exceptions
2023-06-15 08:58:09,347:INFO:Soft dependency imported: shap: 0.41.0
2023-06-15 08:58:09,368:INFO:plot type: correlation
2023-06-15 08:58:09,368:WARNING:No feature passed. Default value of feature used for correlation plot: taxa_homicidio
2023-06-15 08:58:09,368:INFO:Creating TreeExplainer
2023-06-15 08:58:09,372:INFO:Compiling shap values
2023-06-15 08:58:15,283:INFO:model type detected: type 2
2023-06-15 08:58:15,621:INFO:Visual Rendered Successfully
2023-06-15 08:58:15,621:INFO:interpret_model() successfully completed......................................
2023-06-15 08:58:15,771:INFO:Initializing interpret_model()
2023-06-15 08:58:15,772:INFO:interpret_model(estimator=RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=1, plot=reason, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>)
2023-06-15 08:58:15,772:INFO:Checking exceptions
2023-06-15 08:58:15,772:INFO:Soft dependency imported: shap: 0.41.0
2023-06-15 08:58:15,805:INFO:plot type: reason
2023-06-15 08:58:15,805:INFO:model type detected: type 2
2023-06-15 08:58:15,805:INFO:Creating TreeExplainer
2023-06-15 08:58:15,809:INFO:Compiling shap values
2023-06-15 08:58:21,295:INFO:Visual Rendered Successfully
2023-06-15 08:58:21,295:INFO:interpret_model() successfully completed......................................
2023-06-15 08:58:21,445:INFO:Initializing interpret_model()
2023-06-15 08:58:21,445:INFO:interpret_model(estimator=RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=3, plot=reason, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>)
2023-06-15 08:58:21,446:INFO:Checking exceptions
2023-06-15 08:58:21,446:INFO:Soft dependency imported: shap: 0.41.0
2023-06-15 08:58:21,487:INFO:plot type: reason
2023-06-15 08:58:21,487:INFO:model type detected: type 2
2023-06-15 08:58:21,487:INFO:Creating TreeExplainer
2023-06-15 08:58:21,492:INFO:Compiling shap values
2023-06-15 08:58:27,171:INFO:Visual Rendered Successfully
2023-06-15 08:58:27,171:INFO:interpret_model() successfully completed......................................
2023-06-15 09:00:03,985:INFO:Initializing predict_model()
2023-06-15 09:00:03,985:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, estimator=RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B6FBC21120>)
2023-06-15 09:00:03,985:INFO:Checking exceptions
2023-06-15 09:00:03,986:INFO:Preloading libraries
2023-06-15 09:00:03,988:INFO:Set up data.
2023-06-15 09:00:04,002:INFO:Set up index.
2023-06-15 09:02:45,770:INFO:Initializing tune_model()
2023-06-15 09:02:45,770:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=5, round=4, n_iter=10, custom_grid={'max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'criterion': ['gini', 'entropy', 'log_loss']}, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>)
2023-06-15 09:02:45,771:INFO:Checking exceptions
2023-06-15 09:02:45,796:INFO:Copying training dataset
2023-06-15 09:02:45,802:INFO:Checking base model
2023-06-15 09:02:45,804:INFO:Base model : Random Forest Regressor
2023-06-15 09:02:45,807:INFO:Declaring metric variables
2023-06-15 09:02:45,814:INFO:Defining Hyperparameters
2023-06-15 09:02:45,930:INFO:custom_grid: {'actual_estimator__max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'actual_estimator__criterion': ['gini', 'entropy', 'log_loss']}
2023-06-15 09:02:45,930:INFO:Tuning with n_jobs=-1
2023-06-15 09:02:45,930:INFO:Initializing RandomizedSearchCV
2023-06-15 09:04:06,785:INFO:Initializing tune_model()
2023-06-15 09:04:06,786:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=5, round=4, n_iter=10, custom_grid={'max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'criterion': ['entropy']}, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>)
2023-06-15 09:04:06,786:INFO:Checking exceptions
2023-06-15 09:04:06,814:INFO:Copying training dataset
2023-06-15 09:04:06,818:INFO:Checking base model
2023-06-15 09:04:06,818:INFO:Base model : Random Forest Regressor
2023-06-15 09:04:06,822:INFO:Declaring metric variables
2023-06-15 09:04:06,826:INFO:Defining Hyperparameters
2023-06-15 09:04:07,027:INFO:custom_grid: {'actual_estimator__max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'actual_estimator__criterion': ['entropy']}
2023-06-15 09:04:07,027:INFO:Tuning with n_jobs=-1
2023-06-15 09:04:07,028:INFO:Initializing RandomizedSearchCV
2023-06-15 09:04:53,071:INFO:Initializing tune_model()
2023-06-15 09:04:53,071:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=5, round=4, n_iter=10, custom_grid={'max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'criterion': ['entropy']}, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>)
2023-06-15 09:04:53,072:INFO:Checking exceptions
2023-06-15 09:04:53,101:INFO:Copying training dataset
2023-06-15 09:04:53,108:INFO:Checking base model
2023-06-15 09:04:53,108:INFO:Base model : Random Forest Regressor
2023-06-15 09:04:53,115:INFO:Declaring metric variables
2023-06-15 09:04:53,118:INFO:Defining Hyperparameters
2023-06-15 09:04:53,792:INFO:custom_grid: {'actual_estimator__max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'actual_estimator__criterion': ['entropy']}
2023-06-15 09:04:53,792:INFO:Tuning with n_jobs=-1
2023-06-15 09:04:53,793:INFO:Initializing RandomizedSearchCV
2023-06-15 09:06:10,046:INFO:Initializing tune_model()
2023-06-15 09:06:10,047:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=5, round=4, n_iter=10, custom_grid={'max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'min_samples_leaf': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>)
2023-06-15 09:06:10,047:INFO:Checking exceptions
2023-06-15 09:06:10,074:INFO:Copying training dataset
2023-06-15 09:06:10,082:INFO:Checking base model
2023-06-15 09:06:10,082:INFO:Base model : Random Forest Regressor
2023-06-15 09:06:10,087:INFO:Declaring metric variables
2023-06-15 09:06:10,092:INFO:Defining Hyperparameters
2023-06-15 09:06:10,759:INFO:custom_grid: {'actual_estimator__max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'actual_estimator__min_samples_leaf': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}
2023-06-15 09:06:10,760:INFO:Tuning with n_jobs=-1
2023-06-15 09:06:10,760:INFO:Initializing RandomizedSearchCV
2023-06-15 09:06:14,392:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-15 09:06:14,699:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-15 09:06:14,721:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-15 09:06:17,153:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-15 09:06:18,689:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-15 09:06:18,866:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-15 09:06:18,871:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-15 09:06:20,340:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-15 09:06:20,966:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-15 09:06:20,970:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-15 09:06:21,008:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-15 09:06:24,164:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-15 09:06:34,151:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-15 09:06:38,695:INFO:best_params: {'actual_estimator__min_samples_leaf': 3, 'actual_estimator__max_depth': 9}
2023-06-15 09:06:38,696:INFO:Hyperparameter search completed
2023-06-15 09:06:38,696:INFO:SubProcess create_model() called ==================================
2023-06-15 09:06:38,697:INFO:Initializing create_model()
2023-06-15 09:06:38,697:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6FB727280>, model_only=True, return_train_score=False, kwargs={'min_samples_leaf': 3, 'max_depth': 9})
2023-06-15 09:06:38,697:INFO:Checking exceptions
2023-06-15 09:06:38,697:INFO:Importing libraries
2023-06-15 09:06:38,698:INFO:Copying training dataset
2023-06-15 09:06:38,704:INFO:Defining folds
2023-06-15 09:06:38,704:INFO:Declaring metric variables
2023-06-15 09:06:38,708:INFO:Importing untrained model
2023-06-15 09:06:38,708:INFO:Declaring custom model
2023-06-15 09:06:38,711:INFO:Random Forest Regressor Imported successfully
2023-06-15 09:06:38,727:INFO:Starting cross validation
2023-06-15 09:06:38,729:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-15 09:06:39,967:INFO:Calculating mean and std
2023-06-15 09:06:39,968:INFO:Creating metrics dataframe
2023-06-15 09:06:39,974:INFO:Finalizing model
2023-06-15 09:06:41,178:INFO:Uploading results into container
2023-06-15 09:06:41,179:INFO:Uploading model into container now
2023-06-15 09:06:41,179:INFO:_master_model_container: 25
2023-06-15 09:06:41,181:INFO:_display_container: 7
2023-06-15 09:06:41,182:INFO:RandomForestRegressor(max_depth=9, min_samples_leaf=3, n_jobs=-1,
                      random_state=42)
2023-06-15 09:06:41,182:INFO:create_model() successfully completed......................................
2023-06-15 09:06:41,395:INFO:SubProcess create_model() end ==================================
2023-06-15 09:06:41,396:INFO:choose_better activated
2023-06-15 09:06:41,400:INFO:SubProcess create_model() called ==================================
2023-06-15 09:06:41,401:INFO:Initializing create_model()
2023-06-15 09:06:41,401:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-15 09:06:41,401:INFO:Checking exceptions
2023-06-15 09:06:41,403:INFO:Importing libraries
2023-06-15 09:06:41,403:INFO:Copying training dataset
2023-06-15 09:06:41,411:INFO:Defining folds
2023-06-15 09:06:41,411:INFO:Declaring metric variables
2023-06-15 09:06:41,411:INFO:Importing untrained model
2023-06-15 09:06:41,411:INFO:Declaring custom model
2023-06-15 09:06:41,413:INFO:Random Forest Regressor Imported successfully
2023-06-15 09:06:41,413:INFO:Starting cross validation
2023-06-15 09:06:41,415:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-15 09:06:42,694:INFO:Calculating mean and std
2023-06-15 09:06:42,695:INFO:Creating metrics dataframe
2023-06-15 09:06:42,697:INFO:Finalizing model
2023-06-15 09:06:43,131:INFO:Uploading results into container
2023-06-15 09:06:43,131:INFO:Uploading model into container now
2023-06-15 09:06:43,133:INFO:_master_model_container: 26
2023-06-15 09:06:43,133:INFO:_display_container: 8
2023-06-15 09:06:43,133:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-15 09:06:43,133:INFO:create_model() successfully completed......................................
2023-06-15 09:06:43,296:INFO:SubProcess create_model() end ==================================
2023-06-15 09:06:43,297:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) result for R2 is 0.9102
2023-06-15 09:06:43,299:INFO:RandomForestRegressor(max_depth=9, min_samples_leaf=3, n_jobs=-1,
                      random_state=42) result for R2 is 0.8809
2023-06-15 09:06:43,300:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) is best model
2023-06-15 09:06:43,300:INFO:choose_better completed
2023-06-15 09:06:43,301:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-06-15 09:06:43,318:INFO:_master_model_container: 26
2023-06-15 09:06:43,318:INFO:_display_container: 7
2023-06-15 09:06:43,318:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-15 09:06:43,318:INFO:tune_model() successfully completed......................................
2023-06-15 09:07:26,014:INFO:Initializing tune_model()
2023-06-15 09:07:26,014:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=5, round=4, n_iter=10, custom_grid={'max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 30]}, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>)
2023-06-15 09:07:26,014:INFO:Checking exceptions
2023-06-15 09:07:26,041:INFO:Copying training dataset
2023-06-15 09:07:26,045:INFO:Checking base model
2023-06-15 09:07:26,045:INFO:Base model : Random Forest Regressor
2023-06-15 09:07:26,049:INFO:Declaring metric variables
2023-06-15 09:07:26,054:INFO:Defining Hyperparameters
2023-06-15 09:07:26,234:INFO:custom_grid: {'actual_estimator__max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 30]}
2023-06-15 09:07:26,234:INFO:Tuning with n_jobs=-1
2023-06-15 09:07:26,234:INFO:Initializing RandomizedSearchCV
2023-06-15 09:07:37,493:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-15 09:07:38,352:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-15 09:07:40,129:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-15 09:07:43,082:INFO:best_params: {'actual_estimator__max_depth': 10}
2023-06-15 09:07:43,083:INFO:Hyperparameter search completed
2023-06-15 09:07:43,084:INFO:SubProcess create_model() called ==================================
2023-06-15 09:07:43,084:INFO:Initializing create_model()
2023-06-15 09:07:43,084:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6FB592D10>, model_only=True, return_train_score=False, kwargs={'max_depth': 10})
2023-06-15 09:07:43,084:INFO:Checking exceptions
2023-06-15 09:07:43,084:INFO:Importing libraries
2023-06-15 09:07:43,085:INFO:Copying training dataset
2023-06-15 09:07:43,093:INFO:Defining folds
2023-06-15 09:07:43,094:INFO:Declaring metric variables
2023-06-15 09:07:43,099:INFO:Importing untrained model
2023-06-15 09:07:43,100:INFO:Declaring custom model
2023-06-15 09:07:43,105:INFO:Random Forest Regressor Imported successfully
2023-06-15 09:07:43,116:INFO:Starting cross validation
2023-06-15 09:07:43,117:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-15 09:07:44,269:INFO:Calculating mean and std
2023-06-15 09:07:44,271:INFO:Creating metrics dataframe
2023-06-15 09:07:44,279:INFO:Finalizing model
2023-06-15 09:07:44,681:INFO:Uploading results into container
2023-06-15 09:07:44,683:INFO:Uploading model into container now
2023-06-15 09:07:44,684:INFO:_master_model_container: 27
2023-06-15 09:07:44,684:INFO:_display_container: 8
2023-06-15 09:07:44,685:INFO:RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42)
2023-06-15 09:07:44,685:INFO:create_model() successfully completed......................................
2023-06-15 09:07:44,853:INFO:SubProcess create_model() end ==================================
2023-06-15 09:07:44,853:INFO:choose_better activated
2023-06-15 09:07:44,859:INFO:SubProcess create_model() called ==================================
2023-06-15 09:07:44,860:INFO:Initializing create_model()
2023-06-15 09:07:44,860:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-15 09:07:44,860:INFO:Checking exceptions
2023-06-15 09:07:44,862:INFO:Importing libraries
2023-06-15 09:07:44,862:INFO:Copying training dataset
2023-06-15 09:07:44,873:INFO:Defining folds
2023-06-15 09:07:44,875:INFO:Declaring metric variables
2023-06-15 09:07:44,875:INFO:Importing untrained model
2023-06-15 09:07:44,875:INFO:Declaring custom model
2023-06-15 09:07:44,877:INFO:Random Forest Regressor Imported successfully
2023-06-15 09:07:44,877:INFO:Starting cross validation
2023-06-15 09:07:44,879:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-15 09:07:46,136:INFO:Calculating mean and std
2023-06-15 09:07:46,136:INFO:Creating metrics dataframe
2023-06-15 09:07:46,139:INFO:Finalizing model
2023-06-15 09:07:46,548:INFO:Uploading results into container
2023-06-15 09:07:46,548:INFO:Uploading model into container now
2023-06-15 09:07:46,549:INFO:_master_model_container: 28
2023-06-15 09:07:46,549:INFO:_display_container: 9
2023-06-15 09:07:46,549:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-15 09:07:46,549:INFO:create_model() successfully completed......................................
2023-06-15 09:07:46,746:INFO:SubProcess create_model() end ==================================
2023-06-15 09:07:46,747:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) result for R2 is 0.9102
2023-06-15 09:07:46,748:INFO:RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42) result for R2 is 0.9111
2023-06-15 09:07:46,749:INFO:RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42) is best model
2023-06-15 09:07:46,749:INFO:choose_better completed
2023-06-15 09:07:46,762:INFO:_master_model_container: 28
2023-06-15 09:07:46,762:INFO:_display_container: 8
2023-06-15 09:07:46,763:INFO:RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42)
2023-06-15 09:07:46,763:INFO:tune_model() successfully completed......................................
2023-06-15 09:08:11,285:INFO:Initializing tune_model()
2023-06-15 09:08:11,286:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=5, round=4, n_iter=10, custom_grid={'max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>)
2023-06-15 09:08:11,286:INFO:Checking exceptions
2023-06-15 09:08:11,319:INFO:Copying training dataset
2023-06-15 09:08:11,325:INFO:Checking base model
2023-06-15 09:08:11,326:INFO:Base model : Random Forest Regressor
2023-06-15 09:08:11,330:INFO:Declaring metric variables
2023-06-15 09:08:11,334:INFO:Defining Hyperparameters
2023-06-15 09:08:11,518:INFO:custom_grid: {'actual_estimator__max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}
2023-06-15 09:08:11,519:INFO:Tuning with n_jobs=-1
2023-06-15 09:08:11,519:INFO:Initializing RandomizedSearchCV
2023-06-15 09:08:24,420:WARNING:
5 fits failed out of a total of 50.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\lapei\anaconda3\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py", line 340, in fit
    self._validate_params()
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\base.py", line 581, in _validate_params
    validate_parameter_constraints(
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 97, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestRegressor must be an int in the range [1, inf) or None. Got 0 instead.


2023-06-15 09:08:24,421:WARNING:One or more of the test scores are non-finite: [       nan 0.48652662 0.84008985 0.88700297 0.89957066 0.90836024
 0.90866937 0.90843499 0.90995616 0.91114377]

2023-06-15 09:08:24,696:INFO:best_params: {'actual_estimator__max_depth': 10}
2023-06-15 09:08:24,697:INFO:Hyperparameter search completed
2023-06-15 09:08:24,697:INFO:SubProcess create_model() called ==================================
2023-06-15 09:08:24,698:INFO:Initializing create_model()
2023-06-15 09:08:24,698:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6FB6E7A90>, model_only=True, return_train_score=False, kwargs={'max_depth': 10})
2023-06-15 09:08:24,698:INFO:Checking exceptions
2023-06-15 09:08:24,698:INFO:Importing libraries
2023-06-15 09:08:24,698:INFO:Copying training dataset
2023-06-15 09:08:24,705:INFO:Defining folds
2023-06-15 09:08:24,705:INFO:Declaring metric variables
2023-06-15 09:08:24,708:INFO:Importing untrained model
2023-06-15 09:08:24,709:INFO:Declaring custom model
2023-06-15 09:08:24,712:INFO:Random Forest Regressor Imported successfully
2023-06-15 09:08:24,723:INFO:Starting cross validation
2023-06-15 09:08:24,724:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-15 09:08:25,976:INFO:Calculating mean and std
2023-06-15 09:08:25,977:INFO:Creating metrics dataframe
2023-06-15 09:08:25,985:INFO:Finalizing model
2023-06-15 09:08:26,548:INFO:Uploading results into container
2023-06-15 09:08:26,550:INFO:Uploading model into container now
2023-06-15 09:08:26,550:INFO:_master_model_container: 29
2023-06-15 09:08:26,551:INFO:_display_container: 9
2023-06-15 09:08:26,551:INFO:RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42)
2023-06-15 09:08:26,551:INFO:create_model() successfully completed......................................
2023-06-15 09:08:26,736:INFO:SubProcess create_model() end ==================================
2023-06-15 09:08:26,736:INFO:choose_better activated
2023-06-15 09:08:26,740:INFO:SubProcess create_model() called ==================================
2023-06-15 09:08:26,742:INFO:Initializing create_model()
2023-06-15 09:08:26,742:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-15 09:08:26,742:INFO:Checking exceptions
2023-06-15 09:08:26,744:INFO:Importing libraries
2023-06-15 09:08:26,744:INFO:Copying training dataset
2023-06-15 09:08:26,751:INFO:Defining folds
2023-06-15 09:08:26,751:INFO:Declaring metric variables
2023-06-15 09:08:26,752:INFO:Importing untrained model
2023-06-15 09:08:26,752:INFO:Declaring custom model
2023-06-15 09:08:26,754:INFO:Random Forest Regressor Imported successfully
2023-06-15 09:08:26,755:INFO:Starting cross validation
2023-06-15 09:08:26,756:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-15 09:08:28,001:INFO:Calculating mean and std
2023-06-15 09:08:28,001:INFO:Creating metrics dataframe
2023-06-15 09:08:28,003:INFO:Finalizing model
2023-06-15 09:08:28,486:INFO:Uploading results into container
2023-06-15 09:08:28,487:INFO:Uploading model into container now
2023-06-15 09:08:28,487:INFO:_master_model_container: 30
2023-06-15 09:08:28,487:INFO:_display_container: 10
2023-06-15 09:08:28,488:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-15 09:08:28,488:INFO:create_model() successfully completed......................................
2023-06-15 09:08:28,682:INFO:SubProcess create_model() end ==================================
2023-06-15 09:08:28,683:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) result for R2 is 0.9102
2023-06-15 09:08:28,683:INFO:RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42) result for R2 is 0.9111
2023-06-15 09:08:28,683:INFO:RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42) is best model
2023-06-15 09:08:28,683:INFO:choose_better completed
2023-06-15 09:08:28,698:INFO:_master_model_container: 30
2023-06-15 09:08:28,698:INFO:_display_container: 9
2023-06-15 09:08:28,699:INFO:RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42)
2023-06-15 09:08:28,699:INFO:tune_model() successfully completed......................................
2023-06-15 09:09:58,781:INFO:Initializing tune_model()
2023-06-15 09:09:58,782:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=5, round=4, n_iter=10, custom_grid={'max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'n_jobs': [-5, -4, -3, -2, -1, 1, 2, 3, 4, 5]}, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>)
2023-06-15 09:09:58,782:INFO:Checking exceptions
2023-06-15 09:09:58,806:INFO:Copying training dataset
2023-06-15 09:09:58,813:INFO:Checking base model
2023-06-15 09:09:58,814:INFO:Base model : Random Forest Regressor
2023-06-15 09:09:58,821:INFO:Declaring metric variables
2023-06-15 09:09:58,825:INFO:Defining Hyperparameters
2023-06-15 09:09:59,002:INFO:custom_grid: {'actual_estimator__max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'actual_estimator__n_jobs': [-5, -4, -3, -2, -1, 1, 2, 3, 4, 5]}
2023-06-15 09:09:59,002:INFO:Tuning with n_jobs=-1
2023-06-15 09:09:59,002:INFO:Initializing RandomizedSearchCV
2023-06-15 09:10:03,209:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-15 09:10:03,224:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-15 09:10:05,741:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-15 09:10:06,158:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-15 09:10:09,435:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-15 09:10:10,946:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-15 09:10:11,411:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-15 09:10:11,818:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-15 09:10:13,663:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-15 09:10:14,006:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-15 09:10:15,485:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-15 09:10:15,944:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-15 09:10:16,120:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-15 09:10:22,491:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-15 09:10:22,975:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-15 09:10:23,312:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-15 09:10:24,219:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-15 09:10:24,894:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-15 09:10:29,576:INFO:best_params: {'actual_estimator__n_jobs': -3, 'actual_estimator__max_depth': 10}
2023-06-15 09:10:29,578:INFO:Hyperparameter search completed
2023-06-15 09:10:29,578:INFO:SubProcess create_model() called ==================================
2023-06-15 09:10:29,578:INFO:Initializing create_model()
2023-06-15 09:10:29,579:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6FB5D68C0>, model_only=True, return_train_score=False, kwargs={'n_jobs': -3, 'max_depth': 10})
2023-06-15 09:10:29,579:INFO:Checking exceptions
2023-06-15 09:10:29,579:INFO:Importing libraries
2023-06-15 09:10:29,579:INFO:Copying training dataset
2023-06-15 09:10:29,587:INFO:Defining folds
2023-06-15 09:10:29,587:INFO:Declaring metric variables
2023-06-15 09:10:29,594:INFO:Importing untrained model
2023-06-15 09:10:29,595:INFO:Declaring custom model
2023-06-15 09:10:29,605:INFO:Random Forest Regressor Imported successfully
2023-06-15 09:10:29,620:INFO:Starting cross validation
2023-06-15 09:10:29,622:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-15 09:10:31,111:INFO:Calculating mean and std
2023-06-15 09:10:31,111:INFO:Creating metrics dataframe
2023-06-15 09:10:31,118:INFO:Finalizing model
2023-06-15 09:10:32,705:INFO:Uploading results into container
2023-06-15 09:10:32,706:INFO:Uploading model into container now
2023-06-15 09:10:32,707:INFO:_master_model_container: 31
2023-06-15 09:10:32,707:INFO:_display_container: 10
2023-06-15 09:10:32,708:INFO:RandomForestRegressor(max_depth=10, n_jobs=-3, random_state=42)
2023-06-15 09:10:32,708:INFO:create_model() successfully completed......................................
2023-06-15 09:10:32,907:INFO:SubProcess create_model() end ==================================
2023-06-15 09:10:32,907:INFO:choose_better activated
2023-06-15 09:10:32,912:INFO:SubProcess create_model() called ==================================
2023-06-15 09:10:32,912:INFO:Initializing create_model()
2023-06-15 09:10:32,912:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-15 09:10:32,912:INFO:Checking exceptions
2023-06-15 09:10:32,914:INFO:Importing libraries
2023-06-15 09:10:32,914:INFO:Copying training dataset
2023-06-15 09:10:32,919:INFO:Defining folds
2023-06-15 09:10:32,919:INFO:Declaring metric variables
2023-06-15 09:10:32,920:INFO:Importing untrained model
2023-06-15 09:10:32,920:INFO:Declaring custom model
2023-06-15 09:10:32,920:INFO:Random Forest Regressor Imported successfully
2023-06-15 09:10:32,920:INFO:Starting cross validation
2023-06-15 09:10:32,921:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-15 09:10:34,361:INFO:Calculating mean and std
2023-06-15 09:10:34,361:INFO:Creating metrics dataframe
2023-06-15 09:10:34,364:INFO:Finalizing model
2023-06-15 09:10:34,784:INFO:Uploading results into container
2023-06-15 09:10:34,785:INFO:Uploading model into container now
2023-06-15 09:10:34,786:INFO:_master_model_container: 32
2023-06-15 09:10:34,786:INFO:_display_container: 11
2023-06-15 09:10:34,786:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-15 09:10:34,786:INFO:create_model() successfully completed......................................
2023-06-15 09:10:34,976:INFO:SubProcess create_model() end ==================================
2023-06-15 09:10:34,977:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) result for R2 is 0.9102
2023-06-15 09:10:34,977:INFO:RandomForestRegressor(max_depth=10, n_jobs=-3, random_state=42) result for R2 is 0.9111
2023-06-15 09:10:34,978:INFO:RandomForestRegressor(max_depth=10, n_jobs=-3, random_state=42) is best model
2023-06-15 09:10:34,978:INFO:choose_better completed
2023-06-15 09:10:34,991:INFO:_master_model_container: 32
2023-06-15 09:10:34,992:INFO:_display_container: 10
2023-06-15 09:10:34,992:INFO:RandomForestRegressor(max_depth=10, n_jobs=-3, random_state=42)
2023-06-15 09:10:34,994:INFO:tune_model() successfully completed......................................
2023-06-15 09:14:25,684:INFO:Initializing tune_model()
2023-06-15 09:14:25,684:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=5, round=4, n_iter=10, custom_grid={'max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'num_leaves': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000001B685DE7250>, 'min_child_samples': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000001B6FCD4AEF0>, 'min_child_weight': [1e-05, 0.001, 0.01, 0.1, 1, 10.0, 100.0, 1000.0, 10000.0], 'subsample': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001B6FB7270D0>, 'colsample_bytree': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001B6FB727130>, 'reg_alpha': [0, 0.1, 1, 2, 5, 7, 10, 50, 100], 'reg_lambda': [0, 0.1, 1, 5, 10, 20, 50, 100]}, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>)
2023-06-15 09:14:25,684:INFO:Checking exceptions
2023-06-15 09:14:25,712:INFO:Copying training dataset
2023-06-15 09:14:25,719:INFO:Checking base model
2023-06-15 09:14:25,719:INFO:Base model : Random Forest Regressor
2023-06-15 09:14:25,722:INFO:Declaring metric variables
2023-06-15 09:14:25,726:INFO:Defining Hyperparameters
2023-06-15 09:14:25,911:INFO:custom_grid: {'actual_estimator__max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'actual_estimator__num_leaves': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000001B685DE7250>, 'actual_estimator__min_child_samples': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000001B6FCD4AEF0>, 'actual_estimator__min_child_weight': [1e-05, 0.001, 0.01, 0.1, 1, 10.0, 100.0, 1000.0, 10000.0], 'actual_estimator__subsample': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001B6FB7270D0>, 'actual_estimator__colsample_bytree': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001B6FB727130>, 'actual_estimator__reg_alpha': [0, 0.1, 1, 2, 5, 7, 10, 50, 100], 'actual_estimator__reg_lambda': [0, 0.1, 1, 5, 10, 20, 50, 100]}
2023-06-15 09:14:25,911:INFO:Tuning with n_jobs=-1
2023-06-15 09:14:25,911:INFO:Initializing RandomizedSearchCV
2023-06-15 09:14:59,014:INFO:Initializing tune_model()
2023-06-15 09:14:59,014:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=5, round=4, n_iter=10, custom_grid={'max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'num_leaves': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000001B68D3EFFA0>, 'min_child_samples': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000001B6841F1CC0>, 'min_child_weight': [1e-05, 0.001, 0.01, 0.1, 1, 10.0, 100.0, 1000.0, 10000.0], 'subsample': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001B68D3EFB80>, 'colsample_bytree': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001B685DE4A00>, 'reg_alpha': [0, 0.1, 1, 2, 5, 7, 10, 50, 100], 'reg_lambda': [0, 0.1, 1, 5, 10, 20, 50, 100]}, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>)
2023-06-15 09:14:59,014:INFO:Checking exceptions
2023-06-15 09:14:59,037:INFO:Copying training dataset
2023-06-15 09:14:59,043:INFO:Checking base model
2023-06-15 09:14:59,044:INFO:Base model : Random Forest Regressor
2023-06-15 09:14:59,048:INFO:Declaring metric variables
2023-06-15 09:14:59,054:INFO:Defining Hyperparameters
2023-06-15 09:14:59,741:INFO:custom_grid: {'actual_estimator__max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'actual_estimator__num_leaves': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000001B68D3EFFA0>, 'actual_estimator__min_child_samples': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000001B6841F1CC0>, 'actual_estimator__min_child_weight': [1e-05, 0.001, 0.01, 0.1, 1, 10.0, 100.0, 1000.0, 10000.0], 'actual_estimator__subsample': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001B68D3EFB80>, 'actual_estimator__colsample_bytree': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001B685DE4A00>, 'actual_estimator__reg_alpha': [0, 0.1, 1, 2, 5, 7, 10, 50, 100], 'actual_estimator__reg_lambda': [0, 0.1, 1, 5, 10, 20, 50, 100]}
2023-06-15 09:14:59,742:INFO:Tuning with n_jobs=-1
2023-06-15 09:14:59,742:INFO:Initializing RandomizedSearchCV
2023-06-15 09:20:04,850:INFO:Initializing tune_model()
2023-06-15 09:20:04,850:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=5, round=4, n_iter=10, custom_grid={'max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'min_samples_split': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'min_samples_leaf': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'min_child_weight': [1e-05, 0.001, 0.01, 0.1, 1, 10.0, 100.0, 1000.0, 10000.0], 'ccp_alpha': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.9]}, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>)
2023-06-15 09:20:04,850:INFO:Checking exceptions
2023-06-15 09:20:04,872:INFO:Copying training dataset
2023-06-15 09:20:04,877:INFO:Checking base model
2023-06-15 09:20:04,877:INFO:Base model : Random Forest Regressor
2023-06-15 09:20:04,883:INFO:Declaring metric variables
2023-06-15 09:20:04,887:INFO:Defining Hyperparameters
2023-06-15 09:20:05,378:INFO:custom_grid: {'actual_estimator__max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'actual_estimator__min_samples_split': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'actual_estimator__min_samples_leaf': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'actual_estimator__min_child_weight': [1e-05, 0.001, 0.01, 0.1, 1, 10.0, 100.0, 1000.0, 10000.0], 'actual_estimator__ccp_alpha': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.9]}
2023-06-15 09:20:05,378:INFO:Tuning with n_jobs=-1
2023-06-15 09:20:05,378:INFO:Initializing RandomizedSearchCV
2023-06-15 09:26:30,258:INFO:Initializing tune_model()
2023-06-15 09:26:30,258:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=5, round=4, n_iter=10, custom_grid={'max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'min_samples_split': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'min_samples_leaf': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'ccp_alpha': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.9]}, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>)
2023-06-15 09:26:30,258:INFO:Checking exceptions
2023-06-15 09:26:30,288:INFO:Copying training dataset
2023-06-15 09:26:30,294:INFO:Checking base model
2023-06-15 09:26:30,294:INFO:Base model : Random Forest Regressor
2023-06-15 09:26:30,297:INFO:Declaring metric variables
2023-06-15 09:26:30,301:INFO:Defining Hyperparameters
2023-06-15 09:26:30,711:INFO:custom_grid: {'actual_estimator__max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'actual_estimator__min_samples_split': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'actual_estimator__min_samples_leaf': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'actual_estimator__ccp_alpha': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.9]}
2023-06-15 09:26:30,712:INFO:Tuning with n_jobs=-1
2023-06-15 09:26:30,712:INFO:Initializing RandomizedSearchCV
2023-06-15 09:26:38,730:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-15 09:26:39,090:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-15 09:26:39,480:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-15 09:26:41,528:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-15 09:26:42,385:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-15 09:26:43,248:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-15 09:26:43,926:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-15 09:26:45,853:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-15 09:26:46,092:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-15 09:26:55,404:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-15 09:26:59,956:WARNING:
10 fits failed out of a total of 50.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\lapei\anaconda3\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py", line 340, in fit
    self._validate_params()
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\base.py", line 581, in _validate_params
    validate_parameter_constraints(
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 97, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_leaf' parameter of RandomForestRegressor must be an int in the range [1, inf) or a float in the range (0.0, 1.0). Got 0 instead.

--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\lapei\anaconda3\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py", line 340, in fit
    self._validate_params()
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\base.py", line 581, in _validate_params
    validate_parameter_constraints(
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 97, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestRegressor must be an int in the range [1, inf) or None. Got 0 instead.


2023-06-15 09:26:59,957:WARNING:One or more of the test scores are non-finite: [0.71688307 0.8282534  0.7137073         nan 0.78077576 0.84008985
        nan 0.70168477 0.74884873 0.90843499]

2023-06-15 09:27:00,414:INFO:best_params: {'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 1, 'actual_estimator__max_depth': 7, 'actual_estimator__ccp_alpha': 0.0}
2023-06-15 09:27:00,415:INFO:Hyperparameter search completed
2023-06-15 09:27:00,416:INFO:SubProcess create_model() called ==================================
2023-06-15 09:27:00,417:INFO:Initializing create_model()
2023-06-15 09:27:00,417:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B683DD69B0>, model_only=True, return_train_score=False, kwargs={'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'ccp_alpha': 0.0})
2023-06-15 09:27:00,417:INFO:Checking exceptions
2023-06-15 09:27:00,417:INFO:Importing libraries
2023-06-15 09:27:00,417:INFO:Copying training dataset
2023-06-15 09:27:00,427:INFO:Defining folds
2023-06-15 09:27:00,427:INFO:Declaring metric variables
2023-06-15 09:27:00,430:INFO:Importing untrained model
2023-06-15 09:27:00,431:INFO:Declaring custom model
2023-06-15 09:27:00,436:INFO:Random Forest Regressor Imported successfully
2023-06-15 09:27:00,446:INFO:Starting cross validation
2023-06-15 09:27:00,447:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-15 09:27:01,717:INFO:Calculating mean and std
2023-06-15 09:27:01,719:INFO:Creating metrics dataframe
2023-06-15 09:27:01,726:INFO:Finalizing model
2023-06-15 09:27:02,176:INFO:Uploading results into container
2023-06-15 09:27:02,177:INFO:Uploading model into container now
2023-06-15 09:27:02,178:INFO:_master_model_container: 33
2023-06-15 09:27:02,178:INFO:_display_container: 11
2023-06-15 09:27:02,179:INFO:RandomForestRegressor(max_depth=7, n_jobs=-1, random_state=42)
2023-06-15 09:27:02,179:INFO:create_model() successfully completed......................................
2023-06-15 09:27:02,364:INFO:SubProcess create_model() end ==================================
2023-06-15 09:27:02,365:INFO:choose_better activated
2023-06-15 09:27:02,368:INFO:SubProcess create_model() called ==================================
2023-06-15 09:27:02,369:INFO:Initializing create_model()
2023-06-15 09:27:02,369:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-15 09:27:02,369:INFO:Checking exceptions
2023-06-15 09:27:02,371:INFO:Importing libraries
2023-06-15 09:27:02,371:INFO:Copying training dataset
2023-06-15 09:27:02,379:INFO:Defining folds
2023-06-15 09:27:02,379:INFO:Declaring metric variables
2023-06-15 09:27:02,380:INFO:Importing untrained model
2023-06-15 09:27:02,380:INFO:Declaring custom model
2023-06-15 09:27:02,381:INFO:Random Forest Regressor Imported successfully
2023-06-15 09:27:02,381:INFO:Starting cross validation
2023-06-15 09:27:02,382:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-15 09:27:03,753:INFO:Calculating mean and std
2023-06-15 09:27:03,754:INFO:Creating metrics dataframe
2023-06-15 09:27:03,756:INFO:Finalizing model
2023-06-15 09:27:04,190:INFO:Uploading results into container
2023-06-15 09:27:04,191:INFO:Uploading model into container now
2023-06-15 09:27:04,192:INFO:_master_model_container: 34
2023-06-15 09:27:04,192:INFO:_display_container: 12
2023-06-15 09:27:04,192:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-15 09:27:04,192:INFO:create_model() successfully completed......................................
2023-06-15 09:27:04,356:INFO:SubProcess create_model() end ==================================
2023-06-15 09:27:04,357:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) result for R2 is 0.9102
2023-06-15 09:27:04,357:INFO:RandomForestRegressor(max_depth=7, n_jobs=-1, random_state=42) result for R2 is 0.9084
2023-06-15 09:27:04,357:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) is best model
2023-06-15 09:27:04,357:INFO:choose_better completed
2023-06-15 09:27:04,357:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-06-15 09:27:04,368:INFO:_master_model_container: 34
2023-06-15 09:27:04,369:INFO:_display_container: 11
2023-06-15 09:27:04,369:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-15 09:27:04,369:INFO:tune_model() successfully completed......................................
2023-06-15 12:19:27,051:INFO:Initializing tune_model()
2023-06-15 12:19:27,053:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=5, round=4, n_iter=10, custom_grid={'max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'min_samples_split': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'min_samples_leaf': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'ccp_alpha': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.9]}, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>)
2023-06-15 12:19:27,053:INFO:Checking exceptions
2023-06-15 12:19:27,170:INFO:Copying training dataset
2023-06-15 12:19:27,175:INFO:Checking base model
2023-06-15 12:19:27,177:INFO:Base model : Random Forest Regressor
2023-06-15 12:19:27,182:INFO:Declaring metric variables
2023-06-15 12:19:27,185:INFO:Defining Hyperparameters
2023-06-15 12:19:27,725:INFO:custom_grid: {'actual_estimator__max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'actual_estimator__min_samples_split': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'actual_estimator__min_samples_leaf': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'actual_estimator__ccp_alpha': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.9]}
2023-06-15 12:19:27,725:INFO:Tuning with n_jobs=-1
2023-06-15 12:19:27,726:INFO:Initializing RandomizedSearchCV
2023-06-15 12:19:46,916:WARNING:
10 fits failed out of a total of 50.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\lapei\anaconda3\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py", line 340, in fit
    self._validate_params()
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\base.py", line 581, in _validate_params
    validate_parameter_constraints(
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 97, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_leaf' parameter of RandomForestRegressor must be an int in the range [1, inf) or a float in the range (0.0, 1.0). Got 0 instead.

--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\lapei\anaconda3\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py", line 340, in fit
    self._validate_params()
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\base.py", line 581, in _validate_params
    validate_parameter_constraints(
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 97, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestRegressor must be an int in the range [1, inf) or None. Got 0 instead.


2023-06-15 12:19:46,919:WARNING:One or more of the test scores are non-finite: [0.71688307 0.8282534  0.7137073         nan 0.78077576 0.84008985
        nan 0.70168477 0.74884873 0.90843499]

2023-06-15 12:19:47,322:INFO:best_params: {'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 1, 'actual_estimator__max_depth': 7, 'actual_estimator__ccp_alpha': 0.0}
2023-06-15 12:19:47,324:INFO:Hyperparameter search completed
2023-06-15 12:19:47,324:INFO:SubProcess create_model() called ==================================
2023-06-15 12:19:47,325:INFO:Initializing create_model()
2023-06-15 12:19:47,326:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6FB7270D0>, model_only=True, return_train_score=False, kwargs={'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'ccp_alpha': 0.0})
2023-06-15 12:19:47,326:INFO:Checking exceptions
2023-06-15 12:19:47,326:INFO:Importing libraries
2023-06-15 12:19:47,327:INFO:Copying training dataset
2023-06-15 12:19:47,336:INFO:Defining folds
2023-06-15 12:19:47,336:INFO:Declaring metric variables
2023-06-15 12:19:47,343:INFO:Importing untrained model
2023-06-15 12:19:47,343:INFO:Declaring custom model
2023-06-15 12:19:47,353:INFO:Random Forest Regressor Imported successfully
2023-06-15 12:19:47,367:INFO:Starting cross validation
2023-06-15 12:19:47,370:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-15 12:19:48,594:INFO:Calculating mean and std
2023-06-15 12:19:48,596:INFO:Creating metrics dataframe
2023-06-15 12:19:48,605:INFO:Finalizing model
2023-06-15 12:19:49,024:INFO:Uploading results into container
2023-06-15 12:19:49,026:INFO:Uploading model into container now
2023-06-15 12:19:49,027:INFO:_master_model_container: 35
2023-06-15 12:19:49,027:INFO:_display_container: 12
2023-06-15 12:19:49,028:INFO:RandomForestRegressor(max_depth=7, n_jobs=-1, random_state=42)
2023-06-15 12:19:49,028:INFO:create_model() successfully completed......................................
2023-06-15 12:19:49,193:INFO:SubProcess create_model() end ==================================
2023-06-15 12:19:49,193:INFO:choose_better activated
2023-06-15 12:19:49,201:INFO:SubProcess create_model() called ==================================
2023-06-15 12:19:49,201:INFO:Initializing create_model()
2023-06-15 12:19:49,202:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-15 12:19:49,202:INFO:Checking exceptions
2023-06-15 12:19:49,204:INFO:Importing libraries
2023-06-15 12:19:49,204:INFO:Copying training dataset
2023-06-15 12:19:49,214:INFO:Defining folds
2023-06-15 12:19:49,214:INFO:Declaring metric variables
2023-06-15 12:19:49,215:INFO:Importing untrained model
2023-06-15 12:19:49,215:INFO:Declaring custom model
2023-06-15 12:19:49,216:INFO:Random Forest Regressor Imported successfully
2023-06-15 12:19:49,217:INFO:Starting cross validation
2023-06-15 12:19:49,219:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-15 12:19:50,343:INFO:Calculating mean and std
2023-06-15 12:19:50,344:INFO:Creating metrics dataframe
2023-06-15 12:19:50,346:INFO:Finalizing model
2023-06-15 12:19:50,891:INFO:Uploading results into container
2023-06-15 12:19:50,892:INFO:Uploading model into container now
2023-06-15 12:19:50,892:INFO:_master_model_container: 36
2023-06-15 12:19:50,893:INFO:_display_container: 13
2023-06-15 12:19:50,893:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-15 12:19:50,893:INFO:create_model() successfully completed......................................
2023-06-15 12:19:51,047:INFO:SubProcess create_model() end ==================================
2023-06-15 12:19:51,047:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) result for R2 is 0.9102
2023-06-15 12:19:51,048:INFO:RandomForestRegressor(max_depth=7, n_jobs=-1, random_state=42) result for R2 is 0.9084
2023-06-15 12:19:51,049:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) is best model
2023-06-15 12:19:51,049:INFO:choose_better completed
2023-06-15 12:19:51,049:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-06-15 12:19:51,064:INFO:_master_model_container: 36
2023-06-15 12:19:51,064:INFO:_display_container: 12
2023-06-15 12:19:51,065:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-15 12:19:51,065:INFO:tune_model() successfully completed......................................
2023-06-15 12:21:43,457:INFO:Initializing plot_model()
2023-06-15 12:21:43,457:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, system=True)
2023-06-15 12:21:43,458:INFO:Checking exceptions
2023-06-15 12:21:43,488:INFO:Preloading libraries
2023-06-15 12:21:43,515:INFO:Copying training dataset
2023-06-15 12:21:43,516:INFO:Plot type: error
2023-06-15 12:21:43,627:INFO:Fitting Model
2023-06-15 12:21:43,627:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2023-06-15 12:21:43,627:INFO:Scoring test/hold-out set
2023-06-15 12:21:43,913:INFO:Visual Rendered Successfully
2023-06-15 12:21:44,091:INFO:plot_model() successfully completed......................................
2023-06-15 12:21:53,497:INFO:Initializing plot_model()
2023-06-15 12:21:53,497:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, system=True)
2023-06-15 12:21:53,497:INFO:Checking exceptions
2023-06-15 12:21:53,526:INFO:Preloading libraries
2023-06-15 12:21:53,573:INFO:Copying training dataset
2023-06-15 12:21:53,573:INFO:Plot type: error
2023-06-15 12:21:53,674:INFO:Fitting Model
2023-06-15 12:21:53,674:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2023-06-15 12:21:53,674:INFO:Scoring test/hold-out set
2023-06-15 12:21:53,964:INFO:Visual Rendered Successfully
2023-06-15 12:21:54,145:INFO:plot_model() successfully completed......................................
2023-06-15 12:22:06,204:INFO:Initializing tune_model()
2023-06-15 12:22:06,204:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=5, round=4, n_iter=10, custom_grid={'max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>)
2023-06-15 12:22:06,204:INFO:Checking exceptions
2023-06-15 12:22:06,237:INFO:Copying training dataset
2023-06-15 12:22:06,244:INFO:Checking base model
2023-06-15 12:22:06,244:INFO:Base model : Random Forest Regressor
2023-06-15 12:22:06,248:INFO:Declaring metric variables
2023-06-15 12:22:06,252:INFO:Defining Hyperparameters
2023-06-15 12:22:06,415:INFO:custom_grid: {'actual_estimator__max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}
2023-06-15 12:22:06,416:INFO:Tuning with n_jobs=-1
2023-06-15 12:22:06,416:INFO:Initializing RandomizedSearchCV
2023-06-15 12:22:18,751:WARNING:
5 fits failed out of a total of 50.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\lapei\anaconda3\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py", line 340, in fit
    self._validate_params()
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\base.py", line 581, in _validate_params
    validate_parameter_constraints(
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 97, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestRegressor must be an int in the range [1, inf) or None. Got 0 instead.


2023-06-15 12:22:18,752:WARNING:One or more of the test scores are non-finite: [       nan 0.48652662 0.84008985 0.88700297 0.89957066 0.90836024
 0.90866937 0.90843499 0.90995616 0.91114377]

2023-06-15 12:22:19,094:INFO:best_params: {'actual_estimator__max_depth': 10}
2023-06-15 12:22:19,095:INFO:Hyperparameter search completed
2023-06-15 12:22:19,096:INFO:SubProcess create_model() called ==================================
2023-06-15 12:22:19,097:INFO:Initializing create_model()
2023-06-15 12:22:19,097:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6FCE21540>, model_only=True, return_train_score=False, kwargs={'max_depth': 10})
2023-06-15 12:22:19,097:INFO:Checking exceptions
2023-06-15 12:22:19,097:INFO:Importing libraries
2023-06-15 12:22:19,097:INFO:Copying training dataset
2023-06-15 12:22:19,103:INFO:Defining folds
2023-06-15 12:22:19,104:INFO:Declaring metric variables
2023-06-15 12:22:19,107:INFO:Importing untrained model
2023-06-15 12:22:19,108:INFO:Declaring custom model
2023-06-15 12:22:19,111:INFO:Random Forest Regressor Imported successfully
2023-06-15 12:22:19,118:INFO:Starting cross validation
2023-06-15 12:22:19,119:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-15 12:22:20,252:INFO:Calculating mean and std
2023-06-15 12:22:20,253:INFO:Creating metrics dataframe
2023-06-15 12:22:20,259:INFO:Finalizing model
2023-06-15 12:22:20,894:INFO:Uploading results into container
2023-06-15 12:22:20,895:INFO:Uploading model into container now
2023-06-15 12:22:20,896:INFO:_master_model_container: 37
2023-06-15 12:22:20,896:INFO:_display_container: 13
2023-06-15 12:22:20,896:INFO:RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42)
2023-06-15 12:22:20,896:INFO:create_model() successfully completed......................................
2023-06-15 12:22:21,072:INFO:SubProcess create_model() end ==================================
2023-06-15 12:22:21,073:INFO:choose_better activated
2023-06-15 12:22:21,076:INFO:SubProcess create_model() called ==================================
2023-06-15 12:22:21,076:INFO:Initializing create_model()
2023-06-15 12:22:21,077:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-15 12:22:21,077:INFO:Checking exceptions
2023-06-15 12:22:21,079:INFO:Importing libraries
2023-06-15 12:22:21,079:INFO:Copying training dataset
2023-06-15 12:22:21,084:INFO:Defining folds
2023-06-15 12:22:21,084:INFO:Declaring metric variables
2023-06-15 12:22:21,084:INFO:Importing untrained model
2023-06-15 12:22:21,084:INFO:Declaring custom model
2023-06-15 12:22:21,085:INFO:Random Forest Regressor Imported successfully
2023-06-15 12:22:21,085:INFO:Starting cross validation
2023-06-15 12:22:21,086:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-15 12:22:22,256:INFO:Calculating mean and std
2023-06-15 12:22:22,257:INFO:Creating metrics dataframe
2023-06-15 12:22:22,259:INFO:Finalizing model
2023-06-15 12:22:22,670:INFO:Uploading results into container
2023-06-15 12:22:22,671:INFO:Uploading model into container now
2023-06-15 12:22:22,671:INFO:_master_model_container: 38
2023-06-15 12:22:22,671:INFO:_display_container: 14
2023-06-15 12:22:22,672:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-15 12:22:22,672:INFO:create_model() successfully completed......................................
2023-06-15 12:22:22,834:INFO:SubProcess create_model() end ==================================
2023-06-15 12:22:22,835:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) result for R2 is 0.9102
2023-06-15 12:22:22,835:INFO:RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42) result for R2 is 0.9111
2023-06-15 12:22:22,836:INFO:RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42) is best model
2023-06-15 12:22:22,836:INFO:choose_better completed
2023-06-15 12:22:22,853:INFO:_master_model_container: 38
2023-06-15 12:22:22,853:INFO:_display_container: 13
2023-06-15 12:22:22,853:INFO:RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42)
2023-06-15 12:22:22,853:INFO:tune_model() successfully completed......................................
2023-06-15 12:22:27,015:INFO:Initializing plot_model()
2023-06-15 12:22:27,016:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAD06B00>, system=True)
2023-06-15 12:22:27,016:INFO:Checking exceptions
2023-06-15 12:22:27,038:INFO:Preloading libraries
2023-06-15 12:22:27,046:INFO:Copying training dataset
2023-06-15 12:22:27,046:INFO:Plot type: error
2023-06-15 12:22:27,128:INFO:Fitting Model
2023-06-15 12:22:27,128:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2023-06-15 12:22:27,129:INFO:Scoring test/hold-out set
2023-06-15 12:22:27,457:INFO:Visual Rendered Successfully
2023-06-15 12:22:27,628:INFO:plot_model() successfully completed......................................
2023-06-16 09:02:23,567:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-16 09:02:23,567:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-16 09:02:23,567:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-16 09:02:23,567:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-16 09:02:24,707:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-16 10:26:49,026:INFO:PyCaret RegressionExperiment
2023-06-16 10:26:49,026:INFO:Logging name: reg-default-name
2023-06-16 10:26:49,026:INFO:ML Usecase: MLUsecase.REGRESSION
2023-06-16 10:26:49,026:INFO:version 3.0.2
2023-06-16 10:26:49,026:INFO:Initializing setup()
2023-06-16 10:26:49,026:INFO:self.USI: 5aee
2023-06-16 10:26:49,026:INFO:self._variable_keys: {'log_plots_param', 'memory', 'html_param', 'n_jobs_param', 'idx', 'seed', 'data', 'gpu_param', 'exp_name_log', 'fold_generator', 'y_test', 'target_param', 'X', 'USI', 'pipeline', 'logging_param', 'y_train', 'fold_groups_param', 'X_test', 'gpu_n_jobs_param', 'transform_target_param', '_ml_usecase', 'X_train', 'exp_id', 'fold_shuffle_param', 'y', '_available_plots'}
2023-06-16 10:26:49,026:INFO:Checking environment
2023-06-16 10:26:49,026:INFO:python_version: 3.10.9
2023-06-16 10:26:49,026:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-06-16 10:26:49,026:INFO:machine: AMD64
2023-06-16 10:26:49,026:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-16 10:26:49,026:INFO:Memory: svmem(total=16901767168, available=7137898496, percent=57.8, used=9763868672, free=7137898496)
2023-06-16 10:26:49,027:INFO:Physical Core: 4
2023-06-16 10:26:49,027:INFO:Logical Core: 8
2023-06-16 10:26:49,027:INFO:Checking libraries
2023-06-16 10:26:49,027:INFO:System:
2023-06-16 10:26:49,027:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-06-16 10:26:49,027:INFO:executable: C:\Users\lapei\anaconda3\python.exe
2023-06-16 10:26:49,027:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-16 10:26:49,027:INFO:PyCaret required dependencies:
2023-06-16 10:26:49,027:INFO:                 pip: 22.3.1
2023-06-16 10:26:49,027:INFO:          setuptools: 65.6.3
2023-06-16 10:26:49,027:INFO:             pycaret: 3.0.2
2023-06-16 10:26:49,027:INFO:             IPython: 8.10.0
2023-06-16 10:26:49,027:INFO:          ipywidgets: 7.6.5
2023-06-16 10:26:49,027:INFO:                tqdm: 4.64.1
2023-06-16 10:26:49,027:INFO:               numpy: 1.23.5
2023-06-16 10:26:49,027:INFO:              pandas: 1.5.3
2023-06-16 10:26:49,027:INFO:              jinja2: 3.1.2
2023-06-16 10:26:49,027:INFO:               scipy: 1.10.0
2023-06-16 10:26:49,027:INFO:              joblib: 1.2.0
2023-06-16 10:26:49,027:INFO:             sklearn: 1.2.1
2023-06-16 10:26:49,027:INFO:                pyod: 1.0.9
2023-06-16 10:26:49,027:INFO:            imblearn: 0.10.1
2023-06-16 10:26:49,028:INFO:   category_encoders: 2.6.1
2023-06-16 10:26:49,028:INFO:            lightgbm: 3.3.5
2023-06-16 10:26:49,028:INFO:               numba: 0.56.4
2023-06-16 10:26:49,028:INFO:            requests: 2.28.1
2023-06-16 10:26:49,028:INFO:          matplotlib: 3.7.0
2023-06-16 10:26:49,028:INFO:          scikitplot: 0.3.7
2023-06-16 10:26:49,028:INFO:         yellowbrick: 1.5
2023-06-16 10:26:49,028:INFO:              plotly: 5.9.0
2023-06-16 10:26:49,028:INFO:             kaleido: 0.2.1
2023-06-16 10:26:49,028:INFO:         statsmodels: 0.13.5
2023-06-16 10:26:49,028:INFO:              sktime: 0.17.0
2023-06-16 10:26:49,028:INFO:               tbats: 1.1.3
2023-06-16 10:26:49,028:INFO:            pmdarima: 2.0.3
2023-06-16 10:26:49,028:INFO:              psutil: 5.9.0
2023-06-16 10:26:49,028:INFO:PyCaret optional dependencies:
2023-06-16 10:26:49,089:INFO:                shap: 0.41.0
2023-06-16 10:26:49,089:INFO:           interpret: Not installed
2023-06-16 10:26:49,089:INFO:                umap: Not installed
2023-06-16 10:26:49,090:INFO:    pandas_profiling: Not installed
2023-06-16 10:26:49,090:INFO:  explainerdashboard: Not installed
2023-06-16 10:26:49,090:INFO:             autoviz: Not installed
2023-06-16 10:26:49,090:INFO:           fairlearn: Not installed
2023-06-16 10:26:49,090:INFO:             xgboost: 1.7.3
2023-06-16 10:26:49,090:INFO:            catboost: Not installed
2023-06-16 10:26:49,090:INFO:              kmodes: Not installed
2023-06-16 10:26:49,090:INFO:             mlxtend: Not installed
2023-06-16 10:26:49,090:INFO:       statsforecast: Not installed
2023-06-16 10:26:49,090:INFO:        tune_sklearn: Not installed
2023-06-16 10:26:49,090:INFO:                 ray: Not installed
2023-06-16 10:26:49,090:INFO:            hyperopt: Not installed
2023-06-16 10:26:49,090:INFO:              optuna: Not installed
2023-06-16 10:26:49,090:INFO:               skopt: 0.9.0
2023-06-16 10:26:49,090:INFO:              mlflow: Not installed
2023-06-16 10:26:49,090:INFO:              gradio: Not installed
2023-06-16 10:26:49,091:INFO:             fastapi: Not installed
2023-06-16 10:26:49,091:INFO:             uvicorn: Not installed
2023-06-16 10:26:49,091:INFO:              m2cgen: Not installed
2023-06-16 10:26:49,091:INFO:           evidently: Not installed
2023-06-16 10:26:49,091:INFO:               fugue: Not installed
2023-06-16 10:26:49,091:INFO:           streamlit: Not installed
2023-06-16 10:26:49,091:INFO:             prophet: Not installed
2023-06-16 10:26:49,091:INFO:None
2023-06-16 10:26:49,091:INFO:Set up data.
2023-06-16 10:26:49,105:INFO:Set up train/test split.
2023-06-16 10:26:49,114:INFO:Set up index.
2023-06-16 10:26:49,114:INFO:Set up folding strategy.
2023-06-16 10:26:49,115:INFO:Assigning column types.
2023-06-16 10:26:49,120:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-16 10:26:49,120:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-16 10:26:49,125:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-16 10:26:49,134:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-16 10:26:49,204:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-16 10:26:49,268:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-16 10:26:49,269:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 10:26:49,642:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 10:26:49,643:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-16 10:26:49,654:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-16 10:26:49,664:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-16 10:26:49,723:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-16 10:26:49,766:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-16 10:26:49,767:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 10:26:49,769:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 10:26:49,770:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-06-16 10:26:49,774:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-16 10:26:49,778:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-16 10:26:49,864:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-16 10:26:49,906:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-16 10:26:49,907:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 10:26:49,909:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 10:26:49,914:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-16 10:26:49,918:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-16 10:26:50,002:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-16 10:26:50,044:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-16 10:26:50,045:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 10:26:50,047:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 10:26:50,048:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-06-16 10:26:50,059:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-16 10:26:50,136:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-16 10:26:50,177:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-16 10:26:50,178:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 10:26:50,181:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 10:26:50,189:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-16 10:26:50,248:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-16 10:26:50,290:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-16 10:26:50,291:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 10:26:50,294:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 10:26:50,294:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-06-16 10:26:50,358:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-16 10:26:50,400:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-16 10:26:50,400:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 10:26:50,403:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 10:26:50,467:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-16 10:26:50,536:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-16 10:26:50,537:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 10:26:50,539:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 10:26:50,540:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-16 10:26:50,605:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-16 10:26:50,676:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 10:26:50,678:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 10:26:50,774:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-16 10:26:50,819:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 10:26:50,822:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 10:26:50,823:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-06-16 10:26:50,944:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 10:26:50,946:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 10:26:51,072:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 10:26:51,077:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 10:26:51,085:INFO:Preparing preprocessing pipeline...
2023-06-16 10:26:51,085:INFO:Set up simple imputation.
2023-06-16 10:26:51,087:INFO:Set up column name cleaning.
2023-06-16 10:26:51,146:INFO:Finished creating preprocessing pipeline.
2023-06-16 10:26:51,154:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\lapei\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['taxa_homicidio', 'RH_adm_dir',
                                             'densidade_banda_larga',
                                             'densidade_telefonia_movel',
                                             'qtd_cursos_engenharias',
                                             'qtd_cursos_negocios_direito',
                                             'media_notas_CN', 'media_notas_CH',
                                             'media_NU_NOTA_LC',
                                             'media_NU_NOTA_MT',
                                             'media_...
                                             'Isencao_ISSQN_Sim',
                                             'Isencao_Tx_Sim',
                                             'Cessao_terrenos_Sim',
                                             'Doacao_terrenos_Sim',
                                             'Outros_mecanismos_Sim',
                                             'ISH_Baixa', 'ISH_Máxima',
                                             'ISH_Média', 'ISH_Mínima'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-06-16 10:26:51,154:INFO:Creating final display dataframe.
2023-06-16 10:26:51,301:INFO:Setup _display_container:                     Description                              Value
0                    Session id                                 42
1                        Target  qtd_abertas_Empresario_Individual
2                   Target type                         Regression
3           Original data shape                         (4456, 31)
4        Transformed data shape                         (4456, 31)
5   Transformed train set shape                         (3119, 31)
6    Transformed test set shape                         (1337, 31)
7              Numeric features                                 30
8                    Preprocess                               True
9               Imputation type                             simple
10           Numeric imputation                               mean
11       Categorical imputation                               mode
12               Fold Generator                              KFold
13                  Fold Number                                 10
14                     CPU Jobs                                 -1
15                      Use GPU                              False
16               Log Experiment                              False
17              Experiment Name                   reg-default-name
18                          USI                               5aee
2023-06-16 10:26:51,440:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 10:26:51,443:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 10:26:51,564:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 10:26:51,566:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 10:26:51,567:INFO:setup() successfully completed in 3.07s...............
2023-06-16 10:26:54,917:INFO:Initializing compare_models()
2023-06-16 10:26:54,917:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, include=None, fold=5, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, 'include': None, 'exclude': None, 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-06-16 10:26:54,918:INFO:Checking exceptions
2023-06-16 10:26:54,924:INFO:Preparing display monitor
2023-06-16 10:26:54,964:INFO:Initializing Linear Regression
2023-06-16 10:26:54,964:INFO:Total runtime is 0.0 minutes
2023-06-16 10:26:54,970:INFO:SubProcess create_model() called ==================================
2023-06-16 10:26:54,971:INFO:Initializing create_model()
2023-06-16 10:26:54,971:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196D5704280>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:26:54,971:INFO:Checking exceptions
2023-06-16 10:26:54,971:INFO:Importing libraries
2023-06-16 10:26:54,971:INFO:Copying training dataset
2023-06-16 10:26:54,978:INFO:Defining folds
2023-06-16 10:26:54,979:INFO:Declaring metric variables
2023-06-16 10:26:54,984:INFO:Importing untrained model
2023-06-16 10:26:54,989:INFO:Linear Regression Imported successfully
2023-06-16 10:26:55,002:INFO:Starting cross validation
2023-06-16 10:26:55,016:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:27:00,597:INFO:Calculating mean and std
2023-06-16 10:27:00,598:INFO:Creating metrics dataframe
2023-06-16 10:27:01,009:INFO:Uploading results into container
2023-06-16 10:27:01,009:INFO:Uploading model into container now
2023-06-16 10:27:01,010:INFO:_master_model_container: 1
2023-06-16 10:27:01,010:INFO:_display_container: 2
2023-06-16 10:27:01,010:INFO:LinearRegression(n_jobs=-1)
2023-06-16 10:27:01,010:INFO:create_model() successfully completed......................................
2023-06-16 10:27:01,226:INFO:SubProcess create_model() end ==================================
2023-06-16 10:27:01,226:INFO:Creating metrics dataframe
2023-06-16 10:27:01,236:INFO:Initializing Lasso Regression
2023-06-16 10:27:01,236:INFO:Total runtime is 0.10454188187917074 minutes
2023-06-16 10:27:01,242:INFO:SubProcess create_model() called ==================================
2023-06-16 10:27:01,242:INFO:Initializing create_model()
2023-06-16 10:27:01,242:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196D5704280>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:27:01,242:INFO:Checking exceptions
2023-06-16 10:27:01,242:INFO:Importing libraries
2023-06-16 10:27:01,242:INFO:Copying training dataset
2023-06-16 10:27:01,249:INFO:Defining folds
2023-06-16 10:27:01,249:INFO:Declaring metric variables
2023-06-16 10:27:01,254:INFO:Importing untrained model
2023-06-16 10:27:01,258:INFO:Lasso Regression Imported successfully
2023-06-16 10:27:01,268:INFO:Starting cross validation
2023-06-16 10:27:01,269:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:27:04,238:INFO:Calculating mean and std
2023-06-16 10:27:04,241:INFO:Creating metrics dataframe
2023-06-16 10:27:04,953:INFO:Uploading results into container
2023-06-16 10:27:04,954:INFO:Uploading model into container now
2023-06-16 10:27:04,954:INFO:_master_model_container: 2
2023-06-16 10:27:04,954:INFO:_display_container: 2
2023-06-16 10:27:04,955:INFO:Lasso(random_state=42)
2023-06-16 10:27:04,955:INFO:create_model() successfully completed......................................
2023-06-16 10:27:05,141:INFO:SubProcess create_model() end ==================================
2023-06-16 10:27:05,141:INFO:Creating metrics dataframe
2023-06-16 10:27:05,151:INFO:Initializing Ridge Regression
2023-06-16 10:27:05,151:INFO:Total runtime is 0.16979297399520876 minutes
2023-06-16 10:27:05,158:INFO:SubProcess create_model() called ==================================
2023-06-16 10:27:05,159:INFO:Initializing create_model()
2023-06-16 10:27:05,159:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196D5704280>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:27:05,159:INFO:Checking exceptions
2023-06-16 10:27:05,160:INFO:Importing libraries
2023-06-16 10:27:05,160:INFO:Copying training dataset
2023-06-16 10:27:05,175:INFO:Defining folds
2023-06-16 10:27:05,175:INFO:Declaring metric variables
2023-06-16 10:27:05,185:INFO:Importing untrained model
2023-06-16 10:27:05,195:INFO:Ridge Regression Imported successfully
2023-06-16 10:27:05,210:INFO:Starting cross validation
2023-06-16 10:27:05,212:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:27:06,235:INFO:Calculating mean and std
2023-06-16 10:27:06,236:INFO:Creating metrics dataframe
2023-06-16 10:27:06,746:INFO:Uploading results into container
2023-06-16 10:27:06,748:INFO:Uploading model into container now
2023-06-16 10:27:06,749:INFO:_master_model_container: 3
2023-06-16 10:27:06,749:INFO:_display_container: 2
2023-06-16 10:27:06,750:INFO:Ridge(random_state=42)
2023-06-16 10:27:06,750:INFO:create_model() successfully completed......................................
2023-06-16 10:27:06,905:INFO:SubProcess create_model() end ==================================
2023-06-16 10:27:06,906:INFO:Creating metrics dataframe
2023-06-16 10:27:06,915:INFO:Initializing Elastic Net
2023-06-16 10:27:06,915:INFO:Total runtime is 0.19918773174285892 minutes
2023-06-16 10:27:06,919:INFO:SubProcess create_model() called ==================================
2023-06-16 10:27:06,920:INFO:Initializing create_model()
2023-06-16 10:27:06,920:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196D5704280>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:27:06,920:INFO:Checking exceptions
2023-06-16 10:27:06,921:INFO:Importing libraries
2023-06-16 10:27:06,921:INFO:Copying training dataset
2023-06-16 10:27:06,928:INFO:Defining folds
2023-06-16 10:27:06,928:INFO:Declaring metric variables
2023-06-16 10:27:06,933:INFO:Importing untrained model
2023-06-16 10:27:06,937:INFO:Elastic Net Imported successfully
2023-06-16 10:27:06,950:INFO:Starting cross validation
2023-06-16 10:27:06,951:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:27:08,034:INFO:Calculating mean and std
2023-06-16 10:27:08,035:INFO:Creating metrics dataframe
2023-06-16 10:27:08,434:INFO:Uploading results into container
2023-06-16 10:27:08,434:INFO:Uploading model into container now
2023-06-16 10:27:08,435:INFO:_master_model_container: 4
2023-06-16 10:27:08,435:INFO:_display_container: 2
2023-06-16 10:27:08,435:INFO:ElasticNet(random_state=42)
2023-06-16 10:27:08,435:INFO:create_model() successfully completed......................................
2023-06-16 10:27:08,616:INFO:SubProcess create_model() end ==================================
2023-06-16 10:27:08,617:INFO:Creating metrics dataframe
2023-06-16 10:27:08,628:INFO:Initializing Least Angle Regression
2023-06-16 10:27:08,628:INFO:Total runtime is 0.22773890495300297 minutes
2023-06-16 10:27:08,631:INFO:SubProcess create_model() called ==================================
2023-06-16 10:27:08,633:INFO:Initializing create_model()
2023-06-16 10:27:08,634:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196D5704280>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:27:08,634:INFO:Checking exceptions
2023-06-16 10:27:08,634:INFO:Importing libraries
2023-06-16 10:27:08,635:INFO:Copying training dataset
2023-06-16 10:27:08,646:INFO:Defining folds
2023-06-16 10:27:08,647:INFO:Declaring metric variables
2023-06-16 10:27:08,652:INFO:Importing untrained model
2023-06-16 10:27:08,657:INFO:Least Angle Regression Imported successfully
2023-06-16 10:27:08,664:INFO:Starting cross validation
2023-06-16 10:27:08,666:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:27:09,738:INFO:Calculating mean and std
2023-06-16 10:27:09,739:INFO:Creating metrics dataframe
2023-06-16 10:27:10,245:INFO:Uploading results into container
2023-06-16 10:27:10,246:INFO:Uploading model into container now
2023-06-16 10:27:10,247:INFO:_master_model_container: 5
2023-06-16 10:27:10,247:INFO:_display_container: 2
2023-06-16 10:27:10,248:INFO:Lars(random_state=42)
2023-06-16 10:27:10,248:INFO:create_model() successfully completed......................................
2023-06-16 10:27:10,419:INFO:SubProcess create_model() end ==================================
2023-06-16 10:27:10,419:INFO:Creating metrics dataframe
2023-06-16 10:27:10,439:INFO:Initializing Lasso Least Angle Regression
2023-06-16 10:27:10,439:INFO:Total runtime is 0.2579163034756979 minutes
2023-06-16 10:27:10,443:INFO:SubProcess create_model() called ==================================
2023-06-16 10:27:10,444:INFO:Initializing create_model()
2023-06-16 10:27:10,445:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196D5704280>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:27:10,445:INFO:Checking exceptions
2023-06-16 10:27:10,445:INFO:Importing libraries
2023-06-16 10:27:10,445:INFO:Copying training dataset
2023-06-16 10:27:10,460:INFO:Defining folds
2023-06-16 10:27:10,460:INFO:Declaring metric variables
2023-06-16 10:27:10,469:INFO:Importing untrained model
2023-06-16 10:27:10,479:INFO:Lasso Least Angle Regression Imported successfully
2023-06-16 10:27:10,496:INFO:Starting cross validation
2023-06-16 10:27:10,500:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:27:11,516:INFO:Calculating mean and std
2023-06-16 10:27:11,517:INFO:Creating metrics dataframe
2023-06-16 10:27:11,966:INFO:Uploading results into container
2023-06-16 10:27:11,967:INFO:Uploading model into container now
2023-06-16 10:27:11,967:INFO:_master_model_container: 6
2023-06-16 10:27:11,967:INFO:_display_container: 2
2023-06-16 10:27:11,968:INFO:LassoLars(random_state=42)
2023-06-16 10:27:11,968:INFO:create_model() successfully completed......................................
2023-06-16 10:27:12,121:INFO:SubProcess create_model() end ==================================
2023-06-16 10:27:12,121:INFO:Creating metrics dataframe
2023-06-16 10:27:12,133:INFO:Initializing Orthogonal Matching Pursuit
2023-06-16 10:27:12,133:INFO:Total runtime is 0.28614765008290616 minutes
2023-06-16 10:27:12,136:INFO:SubProcess create_model() called ==================================
2023-06-16 10:27:12,137:INFO:Initializing create_model()
2023-06-16 10:27:12,137:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196D5704280>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:27:12,137:INFO:Checking exceptions
2023-06-16 10:27:12,137:INFO:Importing libraries
2023-06-16 10:27:12,137:INFO:Copying training dataset
2023-06-16 10:27:12,143:INFO:Defining folds
2023-06-16 10:27:12,143:INFO:Declaring metric variables
2023-06-16 10:27:12,147:INFO:Importing untrained model
2023-06-16 10:27:12,155:INFO:Orthogonal Matching Pursuit Imported successfully
2023-06-16 10:27:12,172:INFO:Starting cross validation
2023-06-16 10:27:12,175:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:27:13,197:INFO:Calculating mean and std
2023-06-16 10:27:13,199:INFO:Creating metrics dataframe
2023-06-16 10:27:13,630:INFO:Uploading results into container
2023-06-16 10:27:13,630:INFO:Uploading model into container now
2023-06-16 10:27:13,631:INFO:_master_model_container: 7
2023-06-16 10:27:13,631:INFO:_display_container: 2
2023-06-16 10:27:13,631:INFO:OrthogonalMatchingPursuit()
2023-06-16 10:27:13,631:INFO:create_model() successfully completed......................................
2023-06-16 10:27:13,808:INFO:SubProcess create_model() end ==================================
2023-06-16 10:27:13,808:INFO:Creating metrics dataframe
2023-06-16 10:27:13,819:INFO:Initializing Bayesian Ridge
2023-06-16 10:27:13,820:INFO:Total runtime is 0.31426754792531336 minutes
2023-06-16 10:27:13,825:INFO:SubProcess create_model() called ==================================
2023-06-16 10:27:13,826:INFO:Initializing create_model()
2023-06-16 10:27:13,826:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196D5704280>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:27:13,826:INFO:Checking exceptions
2023-06-16 10:27:13,826:INFO:Importing libraries
2023-06-16 10:27:13,826:INFO:Copying training dataset
2023-06-16 10:27:13,833:INFO:Defining folds
2023-06-16 10:27:13,833:INFO:Declaring metric variables
2023-06-16 10:27:13,837:INFO:Importing untrained model
2023-06-16 10:27:13,848:INFO:Bayesian Ridge Imported successfully
2023-06-16 10:27:13,858:INFO:Starting cross validation
2023-06-16 10:27:13,859:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:27:14,967:INFO:Calculating mean and std
2023-06-16 10:27:14,968:INFO:Creating metrics dataframe
2023-06-16 10:27:15,398:INFO:Uploading results into container
2023-06-16 10:27:15,398:INFO:Uploading model into container now
2023-06-16 10:27:15,400:INFO:_master_model_container: 8
2023-06-16 10:27:15,400:INFO:_display_container: 2
2023-06-16 10:27:15,400:INFO:BayesianRidge()
2023-06-16 10:27:15,400:INFO:create_model() successfully completed......................................
2023-06-16 10:27:15,550:INFO:SubProcess create_model() end ==================================
2023-06-16 10:27:15,550:INFO:Creating metrics dataframe
2023-06-16 10:27:15,563:INFO:Initializing Passive Aggressive Regressor
2023-06-16 10:27:15,563:INFO:Total runtime is 0.3433136185010275 minutes
2023-06-16 10:27:15,567:INFO:SubProcess create_model() called ==================================
2023-06-16 10:27:15,567:INFO:Initializing create_model()
2023-06-16 10:27:15,567:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196D5704280>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:27:15,567:INFO:Checking exceptions
2023-06-16 10:27:15,567:INFO:Importing libraries
2023-06-16 10:27:15,567:INFO:Copying training dataset
2023-06-16 10:27:15,574:INFO:Defining folds
2023-06-16 10:27:15,574:INFO:Declaring metric variables
2023-06-16 10:27:15,578:INFO:Importing untrained model
2023-06-16 10:27:15,587:INFO:Passive Aggressive Regressor Imported successfully
2023-06-16 10:27:15,603:INFO:Starting cross validation
2023-06-16 10:27:15,607:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:27:16,647:INFO:Calculating mean and std
2023-06-16 10:27:16,649:INFO:Creating metrics dataframe
2023-06-16 10:27:17,163:INFO:Uploading results into container
2023-06-16 10:27:17,165:INFO:Uploading model into container now
2023-06-16 10:27:17,165:INFO:_master_model_container: 9
2023-06-16 10:27:17,166:INFO:_display_container: 2
2023-06-16 10:27:17,167:INFO:PassiveAggressiveRegressor(random_state=42)
2023-06-16 10:27:17,167:INFO:create_model() successfully completed......................................
2023-06-16 10:27:17,333:INFO:SubProcess create_model() end ==================================
2023-06-16 10:27:17,333:INFO:Creating metrics dataframe
2023-06-16 10:27:17,344:INFO:Initializing Huber Regressor
2023-06-16 10:27:17,344:INFO:Total runtime is 0.37300845384597786 minutes
2023-06-16 10:27:17,347:INFO:SubProcess create_model() called ==================================
2023-06-16 10:27:17,348:INFO:Initializing create_model()
2023-06-16 10:27:17,348:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196D5704280>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:27:17,348:INFO:Checking exceptions
2023-06-16 10:27:17,348:INFO:Importing libraries
2023-06-16 10:27:17,348:INFO:Copying training dataset
2023-06-16 10:27:17,358:INFO:Defining folds
2023-06-16 10:27:17,358:INFO:Declaring metric variables
2023-06-16 10:27:17,367:INFO:Importing untrained model
2023-06-16 10:27:17,373:INFO:Huber Regressor Imported successfully
2023-06-16 10:27:17,386:INFO:Starting cross validation
2023-06-16 10:27:17,388:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:27:17,541:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:27:17,545:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:27:17,578:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:27:17,593:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:27:17,609:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:27:18,525:INFO:Calculating mean and std
2023-06-16 10:27:18,526:INFO:Creating metrics dataframe
2023-06-16 10:27:19,024:INFO:Uploading results into container
2023-06-16 10:27:19,025:INFO:Uploading model into container now
2023-06-16 10:27:19,026:INFO:_master_model_container: 10
2023-06-16 10:27:19,026:INFO:_display_container: 2
2023-06-16 10:27:19,026:INFO:HuberRegressor()
2023-06-16 10:27:19,026:INFO:create_model() successfully completed......................................
2023-06-16 10:27:19,220:INFO:SubProcess create_model() end ==================================
2023-06-16 10:27:19,220:INFO:Creating metrics dataframe
2023-06-16 10:27:19,234:INFO:Initializing K Neighbors Regressor
2023-06-16 10:27:19,234:INFO:Total runtime is 0.40449880758921314 minutes
2023-06-16 10:27:19,239:INFO:SubProcess create_model() called ==================================
2023-06-16 10:27:19,239:INFO:Initializing create_model()
2023-06-16 10:27:19,239:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196D5704280>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:27:19,239:INFO:Checking exceptions
2023-06-16 10:27:19,239:INFO:Importing libraries
2023-06-16 10:27:19,239:INFO:Copying training dataset
2023-06-16 10:27:19,248:INFO:Defining folds
2023-06-16 10:27:19,248:INFO:Declaring metric variables
2023-06-16 10:27:19,252:INFO:Importing untrained model
2023-06-16 10:27:19,256:INFO:K Neighbors Regressor Imported successfully
2023-06-16 10:27:19,268:INFO:Starting cross validation
2023-06-16 10:27:19,271:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:27:20,388:INFO:Calculating mean and std
2023-06-16 10:27:20,389:INFO:Creating metrics dataframe
2023-06-16 10:27:20,914:INFO:Uploading results into container
2023-06-16 10:27:20,915:INFO:Uploading model into container now
2023-06-16 10:27:20,915:INFO:_master_model_container: 11
2023-06-16 10:27:20,915:INFO:_display_container: 2
2023-06-16 10:27:20,916:INFO:KNeighborsRegressor(n_jobs=-1)
2023-06-16 10:27:20,916:INFO:create_model() successfully completed......................................
2023-06-16 10:27:21,107:INFO:SubProcess create_model() end ==================================
2023-06-16 10:27:21,107:INFO:Creating metrics dataframe
2023-06-16 10:27:21,121:INFO:Initializing Decision Tree Regressor
2023-06-16 10:27:21,122:INFO:Total runtime is 0.4359675685564678 minutes
2023-06-16 10:27:21,126:INFO:SubProcess create_model() called ==================================
2023-06-16 10:27:21,126:INFO:Initializing create_model()
2023-06-16 10:27:21,127:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196D5704280>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:27:21,127:INFO:Checking exceptions
2023-06-16 10:27:21,127:INFO:Importing libraries
2023-06-16 10:27:21,127:INFO:Copying training dataset
2023-06-16 10:27:21,143:INFO:Defining folds
2023-06-16 10:27:21,144:INFO:Declaring metric variables
2023-06-16 10:27:21,153:INFO:Importing untrained model
2023-06-16 10:27:21,163:INFO:Decision Tree Regressor Imported successfully
2023-06-16 10:27:21,176:INFO:Starting cross validation
2023-06-16 10:27:21,177:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:27:22,268:INFO:Calculating mean and std
2023-06-16 10:27:22,269:INFO:Creating metrics dataframe
2023-06-16 10:27:22,804:INFO:Uploading results into container
2023-06-16 10:27:22,805:INFO:Uploading model into container now
2023-06-16 10:27:22,806:INFO:_master_model_container: 12
2023-06-16 10:27:22,807:INFO:_display_container: 2
2023-06-16 10:27:22,808:INFO:DecisionTreeRegressor(random_state=42)
2023-06-16 10:27:22,808:INFO:create_model() successfully completed......................................
2023-06-16 10:27:22,960:INFO:SubProcess create_model() end ==================================
2023-06-16 10:27:22,960:INFO:Creating metrics dataframe
2023-06-16 10:27:22,973:INFO:Initializing Random Forest Regressor
2023-06-16 10:27:22,973:INFO:Total runtime is 0.46682524283727017 minutes
2023-06-16 10:27:22,978:INFO:SubProcess create_model() called ==================================
2023-06-16 10:27:22,978:INFO:Initializing create_model()
2023-06-16 10:27:22,978:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196D5704280>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:27:22,978:INFO:Checking exceptions
2023-06-16 10:27:22,978:INFO:Importing libraries
2023-06-16 10:27:22,979:INFO:Copying training dataset
2023-06-16 10:27:22,994:INFO:Defining folds
2023-06-16 10:27:22,994:INFO:Declaring metric variables
2023-06-16 10:27:23,002:INFO:Importing untrained model
2023-06-16 10:27:23,013:INFO:Random Forest Regressor Imported successfully
2023-06-16 10:27:23,026:INFO:Starting cross validation
2023-06-16 10:27:23,028:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:27:26,972:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:27:27,317:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:27:28,903:INFO:Calculating mean and std
2023-06-16 10:27:28,905:INFO:Creating metrics dataframe
2023-06-16 10:27:29,383:INFO:Uploading results into container
2023-06-16 10:27:29,384:INFO:Uploading model into container now
2023-06-16 10:27:29,385:INFO:_master_model_container: 13
2023-06-16 10:27:29,385:INFO:_display_container: 2
2023-06-16 10:27:29,385:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 10:27:29,386:INFO:create_model() successfully completed......................................
2023-06-16 10:27:29,534:INFO:SubProcess create_model() end ==================================
2023-06-16 10:27:29,534:INFO:Creating metrics dataframe
2023-06-16 10:27:29,546:INFO:Initializing Extra Trees Regressor
2023-06-16 10:27:29,547:INFO:Total runtime is 0.5763922452926636 minutes
2023-06-16 10:27:29,550:INFO:SubProcess create_model() called ==================================
2023-06-16 10:27:29,550:INFO:Initializing create_model()
2023-06-16 10:27:29,551:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196D5704280>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:27:29,551:INFO:Checking exceptions
2023-06-16 10:27:29,551:INFO:Importing libraries
2023-06-16 10:27:29,551:INFO:Copying training dataset
2023-06-16 10:27:29,560:INFO:Defining folds
2023-06-16 10:27:29,560:INFO:Declaring metric variables
2023-06-16 10:27:29,564:INFO:Importing untrained model
2023-06-16 10:27:29,577:INFO:Extra Trees Regressor Imported successfully
2023-06-16 10:27:29,591:INFO:Starting cross validation
2023-06-16 10:27:29,592:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:27:31,348:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:27:31,375:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:27:32,473:INFO:Calculating mean and std
2023-06-16 10:27:32,475:INFO:Creating metrics dataframe
2023-06-16 10:27:32,963:INFO:Uploading results into container
2023-06-16 10:27:32,965:INFO:Uploading model into container now
2023-06-16 10:27:32,965:INFO:_master_model_container: 14
2023-06-16 10:27:32,966:INFO:_display_container: 2
2023-06-16 10:27:32,967:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2023-06-16 10:27:32,967:INFO:create_model() successfully completed......................................
2023-06-16 10:27:33,140:INFO:SubProcess create_model() end ==================================
2023-06-16 10:27:33,141:INFO:Creating metrics dataframe
2023-06-16 10:27:33,172:INFO:Initializing AdaBoost Regressor
2023-06-16 10:27:33,173:INFO:Total runtime is 0.6368058284123739 minutes
2023-06-16 10:27:33,178:INFO:SubProcess create_model() called ==================================
2023-06-16 10:27:33,179:INFO:Initializing create_model()
2023-06-16 10:27:33,179:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196D5704280>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:27:33,179:INFO:Checking exceptions
2023-06-16 10:27:33,179:INFO:Importing libraries
2023-06-16 10:27:33,179:INFO:Copying training dataset
2023-06-16 10:27:33,186:INFO:Defining folds
2023-06-16 10:27:33,186:INFO:Declaring metric variables
2023-06-16 10:27:33,191:INFO:Importing untrained model
2023-06-16 10:27:33,195:INFO:AdaBoost Regressor Imported successfully
2023-06-16 10:27:33,203:INFO:Starting cross validation
2023-06-16 10:27:33,205:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:27:34,575:INFO:Calculating mean and std
2023-06-16 10:27:34,577:INFO:Creating metrics dataframe
2023-06-16 10:27:35,019:INFO:Uploading results into container
2023-06-16 10:27:35,020:INFO:Uploading model into container now
2023-06-16 10:27:35,020:INFO:_master_model_container: 15
2023-06-16 10:27:35,020:INFO:_display_container: 2
2023-06-16 10:27:35,020:INFO:AdaBoostRegressor(random_state=42)
2023-06-16 10:27:35,021:INFO:create_model() successfully completed......................................
2023-06-16 10:27:35,220:INFO:SubProcess create_model() end ==================================
2023-06-16 10:27:35,221:INFO:Creating metrics dataframe
2023-06-16 10:27:35,249:INFO:Initializing Gradient Boosting Regressor
2023-06-16 10:27:35,249:INFO:Total runtime is 0.671422561009725 minutes
2023-06-16 10:27:35,255:INFO:SubProcess create_model() called ==================================
2023-06-16 10:27:35,255:INFO:Initializing create_model()
2023-06-16 10:27:35,255:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196D5704280>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:27:35,255:INFO:Checking exceptions
2023-06-16 10:27:35,256:INFO:Importing libraries
2023-06-16 10:27:35,256:INFO:Copying training dataset
2023-06-16 10:27:35,269:INFO:Defining folds
2023-06-16 10:27:35,271:INFO:Declaring metric variables
2023-06-16 10:27:35,277:INFO:Importing untrained model
2023-06-16 10:27:35,281:INFO:Gradient Boosting Regressor Imported successfully
2023-06-16 10:27:35,289:INFO:Starting cross validation
2023-06-16 10:27:35,291:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:27:38,491:INFO:Calculating mean and std
2023-06-16 10:27:38,493:INFO:Creating metrics dataframe
2023-06-16 10:27:39,070:INFO:Uploading results into container
2023-06-16 10:27:39,071:INFO:Uploading model into container now
2023-06-16 10:27:39,071:INFO:_master_model_container: 16
2023-06-16 10:27:39,071:INFO:_display_container: 2
2023-06-16 10:27:39,072:INFO:GradientBoostingRegressor(random_state=42)
2023-06-16 10:27:39,072:INFO:create_model() successfully completed......................................
2023-06-16 10:27:39,236:INFO:SubProcess create_model() end ==================================
2023-06-16 10:27:39,236:INFO:Creating metrics dataframe
2023-06-16 10:27:39,267:INFO:Initializing Extreme Gradient Boosting
2023-06-16 10:27:39,267:INFO:Total runtime is 0.7383933901786804 minutes
2023-06-16 10:27:39,277:INFO:SubProcess create_model() called ==================================
2023-06-16 10:27:39,278:INFO:Initializing create_model()
2023-06-16 10:27:39,278:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196D5704280>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:27:39,278:INFO:Checking exceptions
2023-06-16 10:27:39,278:INFO:Importing libraries
2023-06-16 10:27:39,278:INFO:Copying training dataset
2023-06-16 10:27:39,286:INFO:Defining folds
2023-06-16 10:27:39,287:INFO:Declaring metric variables
2023-06-16 10:27:39,291:INFO:Importing untrained model
2023-06-16 10:27:39,304:INFO:Extreme Gradient Boosting Imported successfully
2023-06-16 10:27:39,318:INFO:Starting cross validation
2023-06-16 10:27:39,319:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:27:41,562:INFO:Calculating mean and std
2023-06-16 10:27:41,563:INFO:Creating metrics dataframe
2023-06-16 10:27:42,084:INFO:Uploading results into container
2023-06-16 10:27:42,085:INFO:Uploading model into container now
2023-06-16 10:27:42,086:INFO:_master_model_container: 17
2023-06-16 10:27:42,087:INFO:_display_container: 2
2023-06-16 10:27:42,088:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=42, ...)
2023-06-16 10:27:42,089:INFO:create_model() successfully completed......................................
2023-06-16 10:27:42,251:INFO:SubProcess create_model() end ==================================
2023-06-16 10:27:42,251:INFO:Creating metrics dataframe
2023-06-16 10:27:42,262:INFO:Initializing Light Gradient Boosting Machine
2023-06-16 10:27:42,262:INFO:Total runtime is 0.7883100708325704 minutes
2023-06-16 10:27:42,266:INFO:SubProcess create_model() called ==================================
2023-06-16 10:27:42,266:INFO:Initializing create_model()
2023-06-16 10:27:42,266:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196D5704280>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:27:42,266:INFO:Checking exceptions
2023-06-16 10:27:42,266:INFO:Importing libraries
2023-06-16 10:27:42,266:INFO:Copying training dataset
2023-06-16 10:27:42,282:INFO:Defining folds
2023-06-16 10:27:42,282:INFO:Declaring metric variables
2023-06-16 10:27:42,291:INFO:Importing untrained model
2023-06-16 10:27:42,299:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-16 10:27:42,312:INFO:Starting cross validation
2023-06-16 10:27:42,314:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:27:44,801:INFO:Calculating mean and std
2023-06-16 10:27:44,802:INFO:Creating metrics dataframe
2023-06-16 10:27:45,310:INFO:Uploading results into container
2023-06-16 10:27:45,312:INFO:Uploading model into container now
2023-06-16 10:27:45,313:INFO:_master_model_container: 18
2023-06-16 10:27:45,313:INFO:_display_container: 2
2023-06-16 10:27:45,314:INFO:LGBMRegressor(random_state=42)
2023-06-16 10:27:45,314:INFO:create_model() successfully completed......................................
2023-06-16 10:27:45,482:INFO:SubProcess create_model() end ==================================
2023-06-16 10:27:45,483:INFO:Creating metrics dataframe
2023-06-16 10:27:45,524:INFO:Initializing Dummy Regressor
2023-06-16 10:27:45,524:INFO:Total runtime is 0.8426633795102437 minutes
2023-06-16 10:27:45,530:INFO:SubProcess create_model() called ==================================
2023-06-16 10:27:45,532:INFO:Initializing create_model()
2023-06-16 10:27:45,532:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196D5704280>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:27:45,532:INFO:Checking exceptions
2023-06-16 10:27:45,532:INFO:Importing libraries
2023-06-16 10:27:45,532:INFO:Copying training dataset
2023-06-16 10:27:45,544:INFO:Defining folds
2023-06-16 10:27:45,544:INFO:Declaring metric variables
2023-06-16 10:27:45,549:INFO:Importing untrained model
2023-06-16 10:27:45,556:INFO:Dummy Regressor Imported successfully
2023-06-16 10:27:45,569:INFO:Starting cross validation
2023-06-16 10:27:45,569:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:27:46,601:INFO:Calculating mean and std
2023-06-16 10:27:46,604:INFO:Creating metrics dataframe
2023-06-16 10:27:47,052:INFO:Uploading results into container
2023-06-16 10:27:47,053:INFO:Uploading model into container now
2023-06-16 10:27:47,053:INFO:_master_model_container: 19
2023-06-16 10:27:47,053:INFO:_display_container: 2
2023-06-16 10:27:47,054:INFO:DummyRegressor()
2023-06-16 10:27:47,054:INFO:create_model() successfully completed......................................
2023-06-16 10:27:47,202:INFO:SubProcess create_model() end ==================================
2023-06-16 10:27:47,202:INFO:Creating metrics dataframe
2023-06-16 10:27:47,226:INFO:Initializing create_model()
2023-06-16 10:27:47,226:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:27:47,226:INFO:Checking exceptions
2023-06-16 10:27:47,228:INFO:Importing libraries
2023-06-16 10:27:47,228:INFO:Copying training dataset
2023-06-16 10:27:47,234:INFO:Defining folds
2023-06-16 10:27:47,234:INFO:Declaring metric variables
2023-06-16 10:27:47,234:INFO:Importing untrained model
2023-06-16 10:27:47,234:INFO:Declaring custom model
2023-06-16 10:27:47,235:INFO:Random Forest Regressor Imported successfully
2023-06-16 10:27:47,236:INFO:Cross validation set to False
2023-06-16 10:27:47,236:INFO:Fitting Model
2023-06-16 10:27:48,971:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 10:27:48,971:INFO:create_model() successfully completed......................................
2023-06-16 10:27:49,205:INFO:_master_model_container: 19
2023-06-16 10:27:49,205:INFO:_display_container: 2
2023-06-16 10:27:49,206:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 10:27:49,206:INFO:compare_models() successfully completed......................................
2023-06-16 10:33:05,572:INFO:Initializing compare_models()
2023-06-16 10:33:05,572:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, include=None, fold=5, round=4, cross_validation=True, sort=MAPE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, 'include': None, 'exclude': None, 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'MAPE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-06-16 10:33:05,572:INFO:Checking exceptions
2023-06-16 10:33:05,576:INFO:Preparing display monitor
2023-06-16 10:33:05,607:INFO:Initializing Linear Regression
2023-06-16 10:33:05,608:INFO:Total runtime is 1.662572224934896e-05 minutes
2023-06-16 10:33:05,611:INFO:SubProcess create_model() called ==================================
2023-06-16 10:33:05,611:INFO:Initializing create_model()
2023-06-16 10:33:05,611:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196D373AE60>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:33:05,612:INFO:Checking exceptions
2023-06-16 10:33:05,612:INFO:Importing libraries
2023-06-16 10:33:05,612:INFO:Copying training dataset
2023-06-16 10:33:05,620:INFO:Defining folds
2023-06-16 10:33:05,620:INFO:Declaring metric variables
2023-06-16 10:33:05,623:INFO:Importing untrained model
2023-06-16 10:33:05,626:INFO:Linear Regression Imported successfully
2023-06-16 10:33:05,633:INFO:Starting cross validation
2023-06-16 10:33:05,635:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:33:10,796:INFO:Calculating mean and std
2023-06-16 10:33:10,797:INFO:Creating metrics dataframe
2023-06-16 10:33:11,289:INFO:Uploading results into container
2023-06-16 10:33:11,291:INFO:Uploading model into container now
2023-06-16 10:33:11,292:INFO:_master_model_container: 20
2023-06-16 10:33:11,292:INFO:_display_container: 3
2023-06-16 10:33:11,292:INFO:LinearRegression(n_jobs=-1)
2023-06-16 10:33:11,292:INFO:create_model() successfully completed......................................
2023-06-16 10:33:11,452:INFO:SubProcess create_model() end ==================================
2023-06-16 10:33:11,452:INFO:Creating metrics dataframe
2023-06-16 10:33:11,461:INFO:Initializing Lasso Regression
2023-06-16 10:33:11,461:INFO:Total runtime is 0.09755584796269735 minutes
2023-06-16 10:33:11,463:INFO:SubProcess create_model() called ==================================
2023-06-16 10:33:11,464:INFO:Initializing create_model()
2023-06-16 10:33:11,465:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196D373AE60>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:33:11,465:INFO:Checking exceptions
2023-06-16 10:33:11,465:INFO:Importing libraries
2023-06-16 10:33:11,465:INFO:Copying training dataset
2023-06-16 10:33:11,473:INFO:Defining folds
2023-06-16 10:33:11,473:INFO:Declaring metric variables
2023-06-16 10:33:11,477:INFO:Importing untrained model
2023-06-16 10:33:11,483:INFO:Lasso Regression Imported successfully
2023-06-16 10:33:11,489:INFO:Starting cross validation
2023-06-16 10:33:11,491:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:33:14,108:INFO:Calculating mean and std
2023-06-16 10:33:14,110:INFO:Creating metrics dataframe
2023-06-16 10:33:14,569:INFO:Uploading results into container
2023-06-16 10:33:14,570:INFO:Uploading model into container now
2023-06-16 10:33:14,570:INFO:_master_model_container: 21
2023-06-16 10:33:14,570:INFO:_display_container: 3
2023-06-16 10:33:14,571:INFO:Lasso(random_state=42)
2023-06-16 10:33:14,571:INFO:create_model() successfully completed......................................
2023-06-16 10:33:14,769:INFO:SubProcess create_model() end ==================================
2023-06-16 10:33:14,769:INFO:Creating metrics dataframe
2023-06-16 10:33:14,777:INFO:Initializing Ridge Regression
2023-06-16 10:33:14,777:INFO:Total runtime is 0.1528385082880656 minutes
2023-06-16 10:33:14,786:INFO:SubProcess create_model() called ==================================
2023-06-16 10:33:14,787:INFO:Initializing create_model()
2023-06-16 10:33:14,787:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196D373AE60>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:33:14,787:INFO:Checking exceptions
2023-06-16 10:33:14,787:INFO:Importing libraries
2023-06-16 10:33:14,788:INFO:Copying training dataset
2023-06-16 10:33:14,796:INFO:Defining folds
2023-06-16 10:33:14,796:INFO:Declaring metric variables
2023-06-16 10:33:14,799:INFO:Importing untrained model
2023-06-16 10:33:14,804:INFO:Ridge Regression Imported successfully
2023-06-16 10:33:14,813:INFO:Starting cross validation
2023-06-16 10:33:14,814:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:33:15,914:INFO:Calculating mean and std
2023-06-16 10:33:15,915:INFO:Creating metrics dataframe
2023-06-16 10:33:16,308:INFO:Uploading results into container
2023-06-16 10:33:16,309:INFO:Uploading model into container now
2023-06-16 10:33:16,310:INFO:_master_model_container: 22
2023-06-16 10:33:16,310:INFO:_display_container: 3
2023-06-16 10:33:16,310:INFO:Ridge(random_state=42)
2023-06-16 10:33:16,311:INFO:create_model() successfully completed......................................
2023-06-16 10:33:16,475:INFO:SubProcess create_model() end ==================================
2023-06-16 10:33:16,475:INFO:Creating metrics dataframe
2023-06-16 10:33:16,484:INFO:Initializing Elastic Net
2023-06-16 10:33:16,484:INFO:Total runtime is 0.18127992153167727 minutes
2023-06-16 10:33:16,487:INFO:SubProcess create_model() called ==================================
2023-06-16 10:33:16,488:INFO:Initializing create_model()
2023-06-16 10:33:16,488:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196D373AE60>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:33:16,488:INFO:Checking exceptions
2023-06-16 10:33:16,488:INFO:Importing libraries
2023-06-16 10:33:16,488:INFO:Copying training dataset
2023-06-16 10:33:16,498:INFO:Defining folds
2023-06-16 10:33:16,499:INFO:Declaring metric variables
2023-06-16 10:33:16,504:INFO:Importing untrained model
2023-06-16 10:33:16,507:INFO:Elastic Net Imported successfully
2023-06-16 10:33:16,516:INFO:Starting cross validation
2023-06-16 10:33:16,517:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:33:17,654:INFO:Calculating mean and std
2023-06-16 10:33:17,657:INFO:Creating metrics dataframe
2023-06-16 10:33:18,122:INFO:Uploading results into container
2023-06-16 10:33:18,124:INFO:Uploading model into container now
2023-06-16 10:33:18,124:INFO:_master_model_container: 23
2023-06-16 10:33:18,124:INFO:_display_container: 3
2023-06-16 10:33:18,125:INFO:ElasticNet(random_state=42)
2023-06-16 10:33:18,125:INFO:create_model() successfully completed......................................
2023-06-16 10:33:18,306:INFO:SubProcess create_model() end ==================================
2023-06-16 10:33:18,306:INFO:Creating metrics dataframe
2023-06-16 10:33:18,316:INFO:Initializing Least Angle Regression
2023-06-16 10:33:18,316:INFO:Total runtime is 0.21181039810180666 minutes
2023-06-16 10:33:18,319:INFO:SubProcess create_model() called ==================================
2023-06-16 10:33:18,320:INFO:Initializing create_model()
2023-06-16 10:33:18,320:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196D373AE60>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:33:18,320:INFO:Checking exceptions
2023-06-16 10:33:18,320:INFO:Importing libraries
2023-06-16 10:33:18,320:INFO:Copying training dataset
2023-06-16 10:33:18,326:INFO:Defining folds
2023-06-16 10:33:18,326:INFO:Declaring metric variables
2023-06-16 10:33:18,330:INFO:Importing untrained model
2023-06-16 10:33:18,334:INFO:Least Angle Regression Imported successfully
2023-06-16 10:33:18,343:INFO:Starting cross validation
2023-06-16 10:33:18,347:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:33:19,390:INFO:Calculating mean and std
2023-06-16 10:33:19,391:INFO:Creating metrics dataframe
2023-06-16 10:33:20,028:INFO:Uploading results into container
2023-06-16 10:33:20,029:INFO:Uploading model into container now
2023-06-16 10:33:20,030:INFO:_master_model_container: 24
2023-06-16 10:33:20,030:INFO:_display_container: 3
2023-06-16 10:33:20,030:INFO:Lars(random_state=42)
2023-06-16 10:33:20,030:INFO:create_model() successfully completed......................................
2023-06-16 10:33:20,208:INFO:SubProcess create_model() end ==================================
2023-06-16 10:33:20,208:INFO:Creating metrics dataframe
2023-06-16 10:33:20,220:INFO:Initializing Lasso Least Angle Regression
2023-06-16 10:33:20,221:INFO:Total runtime is 0.24356960455576582 minutes
2023-06-16 10:33:20,224:INFO:SubProcess create_model() called ==================================
2023-06-16 10:33:20,225:INFO:Initializing create_model()
2023-06-16 10:33:20,225:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196D373AE60>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:33:20,225:INFO:Checking exceptions
2023-06-16 10:33:20,225:INFO:Importing libraries
2023-06-16 10:33:20,225:INFO:Copying training dataset
2023-06-16 10:33:20,234:INFO:Defining folds
2023-06-16 10:33:20,234:INFO:Declaring metric variables
2023-06-16 10:33:20,239:INFO:Importing untrained model
2023-06-16 10:33:20,244:INFO:Lasso Least Angle Regression Imported successfully
2023-06-16 10:33:20,256:INFO:Starting cross validation
2023-06-16 10:33:20,258:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:33:21,326:INFO:Calculating mean and std
2023-06-16 10:33:21,327:INFO:Creating metrics dataframe
2023-06-16 10:33:21,907:INFO:Uploading results into container
2023-06-16 10:33:21,909:INFO:Uploading model into container now
2023-06-16 10:33:21,910:INFO:_master_model_container: 25
2023-06-16 10:33:21,910:INFO:_display_container: 3
2023-06-16 10:33:21,911:INFO:LassoLars(random_state=42)
2023-06-16 10:33:21,911:INFO:create_model() successfully completed......................................
2023-06-16 10:33:22,109:INFO:SubProcess create_model() end ==================================
2023-06-16 10:33:22,109:INFO:Creating metrics dataframe
2023-06-16 10:33:22,119:INFO:Initializing Orthogonal Matching Pursuit
2023-06-16 10:33:22,120:INFO:Total runtime is 0.27521879275639854 minutes
2023-06-16 10:33:22,123:INFO:SubProcess create_model() called ==================================
2023-06-16 10:33:22,123:INFO:Initializing create_model()
2023-06-16 10:33:22,123:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196D373AE60>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:33:22,123:INFO:Checking exceptions
2023-06-16 10:33:22,123:INFO:Importing libraries
2023-06-16 10:33:22,124:INFO:Copying training dataset
2023-06-16 10:33:22,129:INFO:Defining folds
2023-06-16 10:33:22,129:INFO:Declaring metric variables
2023-06-16 10:33:22,133:INFO:Importing untrained model
2023-06-16 10:33:22,140:INFO:Orthogonal Matching Pursuit Imported successfully
2023-06-16 10:33:22,155:INFO:Starting cross validation
2023-06-16 10:33:22,157:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:33:23,261:INFO:Calculating mean and std
2023-06-16 10:33:23,263:INFO:Creating metrics dataframe
2023-06-16 10:33:23,626:INFO:Uploading results into container
2023-06-16 10:33:23,627:INFO:Uploading model into container now
2023-06-16 10:33:23,628:INFO:_master_model_container: 26
2023-06-16 10:33:23,628:INFO:_display_container: 3
2023-06-16 10:33:23,629:INFO:OrthogonalMatchingPursuit()
2023-06-16 10:33:23,629:INFO:create_model() successfully completed......................................
2023-06-16 10:33:23,800:INFO:SubProcess create_model() end ==================================
2023-06-16 10:33:23,800:INFO:Creating metrics dataframe
2023-06-16 10:33:23,815:INFO:Initializing Bayesian Ridge
2023-06-16 10:33:23,815:INFO:Total runtime is 0.30346323649088547 minutes
2023-06-16 10:33:23,819:INFO:SubProcess create_model() called ==================================
2023-06-16 10:33:23,819:INFO:Initializing create_model()
2023-06-16 10:33:23,820:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196D373AE60>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:33:23,820:INFO:Checking exceptions
2023-06-16 10:33:23,820:INFO:Importing libraries
2023-06-16 10:33:23,820:INFO:Copying training dataset
2023-06-16 10:33:23,829:INFO:Defining folds
2023-06-16 10:33:23,829:INFO:Declaring metric variables
2023-06-16 10:33:23,834:INFO:Importing untrained model
2023-06-16 10:33:23,839:INFO:Bayesian Ridge Imported successfully
2023-06-16 10:33:23,847:INFO:Starting cross validation
2023-06-16 10:33:23,848:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:33:24,909:INFO:Calculating mean and std
2023-06-16 10:33:24,911:INFO:Creating metrics dataframe
2023-06-16 10:33:25,268:INFO:Uploading results into container
2023-06-16 10:33:25,269:INFO:Uploading model into container now
2023-06-16 10:33:25,269:INFO:_master_model_container: 27
2023-06-16 10:33:25,269:INFO:_display_container: 3
2023-06-16 10:33:25,270:INFO:BayesianRidge()
2023-06-16 10:33:25,270:INFO:create_model() successfully completed......................................
2023-06-16 10:33:25,466:INFO:SubProcess create_model() end ==================================
2023-06-16 10:33:25,466:INFO:Creating metrics dataframe
2023-06-16 10:33:25,492:INFO:Initializing Passive Aggressive Regressor
2023-06-16 10:33:25,493:INFO:Total runtime is 0.3314358750979106 minutes
2023-06-16 10:33:25,502:INFO:SubProcess create_model() called ==================================
2023-06-16 10:33:25,503:INFO:Initializing create_model()
2023-06-16 10:33:25,503:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196D373AE60>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:33:25,504:INFO:Checking exceptions
2023-06-16 10:33:25,504:INFO:Importing libraries
2023-06-16 10:33:25,504:INFO:Copying training dataset
2023-06-16 10:33:25,514:INFO:Defining folds
2023-06-16 10:33:25,515:INFO:Declaring metric variables
2023-06-16 10:33:25,519:INFO:Importing untrained model
2023-06-16 10:33:25,527:INFO:Passive Aggressive Regressor Imported successfully
2023-06-16 10:33:25,539:INFO:Starting cross validation
2023-06-16 10:33:25,541:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:33:26,599:INFO:Calculating mean and std
2023-06-16 10:33:26,600:INFO:Creating metrics dataframe
2023-06-16 10:33:27,079:INFO:Uploading results into container
2023-06-16 10:33:27,080:INFO:Uploading model into container now
2023-06-16 10:33:27,081:INFO:_master_model_container: 28
2023-06-16 10:33:27,081:INFO:_display_container: 3
2023-06-16 10:33:27,081:INFO:PassiveAggressiveRegressor(random_state=42)
2023-06-16 10:33:27,081:INFO:create_model() successfully completed......................................
2023-06-16 10:33:27,257:INFO:SubProcess create_model() end ==================================
2023-06-16 10:33:27,257:INFO:Creating metrics dataframe
2023-06-16 10:33:27,286:INFO:Initializing Huber Regressor
2023-06-16 10:33:27,287:INFO:Total runtime is 0.36133252382278447 minutes
2023-06-16 10:33:27,295:INFO:SubProcess create_model() called ==================================
2023-06-16 10:33:27,296:INFO:Initializing create_model()
2023-06-16 10:33:27,296:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196D373AE60>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:33:27,296:INFO:Checking exceptions
2023-06-16 10:33:27,297:INFO:Importing libraries
2023-06-16 10:33:27,297:INFO:Copying training dataset
2023-06-16 10:33:27,313:INFO:Defining folds
2023-06-16 10:33:27,313:INFO:Declaring metric variables
2023-06-16 10:33:27,321:INFO:Importing untrained model
2023-06-16 10:33:27,332:INFO:Huber Regressor Imported successfully
2023-06-16 10:33:27,347:INFO:Starting cross validation
2023-06-16 10:33:27,348:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:33:27,468:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:33:27,490:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:33:27,501:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:33:27,511:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:33:27,536:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:33:28,512:INFO:Calculating mean and std
2023-06-16 10:33:28,514:INFO:Creating metrics dataframe
2023-06-16 10:33:28,907:INFO:Uploading results into container
2023-06-16 10:33:28,908:INFO:Uploading model into container now
2023-06-16 10:33:28,908:INFO:_master_model_container: 29
2023-06-16 10:33:28,909:INFO:_display_container: 3
2023-06-16 10:33:28,909:INFO:HuberRegressor()
2023-06-16 10:33:28,909:INFO:create_model() successfully completed......................................
2023-06-16 10:33:29,083:INFO:SubProcess create_model() end ==================================
2023-06-16 10:33:29,083:INFO:Creating metrics dataframe
2023-06-16 10:33:29,111:INFO:Initializing K Neighbors Regressor
2023-06-16 10:33:29,112:INFO:Total runtime is 0.3917430679003398 minutes
2023-06-16 10:33:29,118:INFO:SubProcess create_model() called ==================================
2023-06-16 10:33:29,118:INFO:Initializing create_model()
2023-06-16 10:33:29,119:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196D373AE60>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:33:29,119:INFO:Checking exceptions
2023-06-16 10:33:29,119:INFO:Importing libraries
2023-06-16 10:33:29,119:INFO:Copying training dataset
2023-06-16 10:33:29,131:INFO:Defining folds
2023-06-16 10:33:29,132:INFO:Declaring metric variables
2023-06-16 10:33:29,137:INFO:Importing untrained model
2023-06-16 10:33:29,140:INFO:K Neighbors Regressor Imported successfully
2023-06-16 10:33:29,149:INFO:Starting cross validation
2023-06-16 10:33:29,150:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:33:30,568:INFO:Calculating mean and std
2023-06-16 10:33:30,569:INFO:Creating metrics dataframe
2023-06-16 10:33:30,935:INFO:Uploading results into container
2023-06-16 10:33:30,936:INFO:Uploading model into container now
2023-06-16 10:33:30,936:INFO:_master_model_container: 30
2023-06-16 10:33:30,936:INFO:_display_container: 3
2023-06-16 10:33:30,937:INFO:KNeighborsRegressor(n_jobs=-1)
2023-06-16 10:33:30,937:INFO:create_model() successfully completed......................................
2023-06-16 10:33:31,091:INFO:SubProcess create_model() end ==================================
2023-06-16 10:33:31,092:INFO:Creating metrics dataframe
2023-06-16 10:33:31,115:INFO:Initializing Decision Tree Regressor
2023-06-16 10:33:31,116:INFO:Total runtime is 0.42515170971552535 minutes
2023-06-16 10:33:31,122:INFO:SubProcess create_model() called ==================================
2023-06-16 10:33:31,123:INFO:Initializing create_model()
2023-06-16 10:33:31,123:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196D373AE60>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:33:31,124:INFO:Checking exceptions
2023-06-16 10:33:31,124:INFO:Importing libraries
2023-06-16 10:33:31,124:INFO:Copying training dataset
2023-06-16 10:33:31,131:INFO:Defining folds
2023-06-16 10:33:31,132:INFO:Declaring metric variables
2023-06-16 10:33:31,135:INFO:Importing untrained model
2023-06-16 10:33:31,148:INFO:Decision Tree Regressor Imported successfully
2023-06-16 10:33:31,163:INFO:Starting cross validation
2023-06-16 10:33:31,164:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:33:32,457:INFO:Calculating mean and std
2023-06-16 10:33:32,459:INFO:Creating metrics dataframe
2023-06-16 10:33:32,857:INFO:Uploading results into container
2023-06-16 10:33:32,859:INFO:Uploading model into container now
2023-06-16 10:33:32,860:INFO:_master_model_container: 31
2023-06-16 10:33:32,861:INFO:_display_container: 3
2023-06-16 10:33:32,862:INFO:DecisionTreeRegressor(random_state=42)
2023-06-16 10:33:32,862:INFO:create_model() successfully completed......................................
2023-06-16 10:33:33,032:INFO:SubProcess create_model() end ==================================
2023-06-16 10:33:33,032:INFO:Creating metrics dataframe
2023-06-16 10:33:33,059:INFO:Initializing Random Forest Regressor
2023-06-16 10:33:33,060:INFO:Total runtime is 0.4575337131818136 minutes
2023-06-16 10:33:33,069:INFO:SubProcess create_model() called ==================================
2023-06-16 10:33:33,069:INFO:Initializing create_model()
2023-06-16 10:33:33,070:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196D373AE60>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:33:33,071:INFO:Checking exceptions
2023-06-16 10:33:33,071:INFO:Importing libraries
2023-06-16 10:33:33,071:INFO:Copying training dataset
2023-06-16 10:33:33,087:INFO:Defining folds
2023-06-16 10:33:33,087:INFO:Declaring metric variables
2023-06-16 10:33:33,096:INFO:Importing untrained model
2023-06-16 10:33:33,101:INFO:Random Forest Regressor Imported successfully
2023-06-16 10:33:33,116:INFO:Starting cross validation
2023-06-16 10:33:33,117:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:33:34,471:INFO:Calculating mean and std
2023-06-16 10:33:34,472:INFO:Creating metrics dataframe
2023-06-16 10:33:34,828:INFO:Uploading results into container
2023-06-16 10:33:34,829:INFO:Uploading model into container now
2023-06-16 10:33:34,830:INFO:_master_model_container: 32
2023-06-16 10:33:34,830:INFO:_display_container: 3
2023-06-16 10:33:34,830:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 10:33:34,830:INFO:create_model() successfully completed......................................
2023-06-16 10:33:35,012:INFO:SubProcess create_model() end ==================================
2023-06-16 10:33:35,013:INFO:Creating metrics dataframe
2023-06-16 10:33:35,029:INFO:Initializing Extra Trees Regressor
2023-06-16 10:33:35,030:INFO:Total runtime is 0.490386700630188 minutes
2023-06-16 10:33:35,032:INFO:SubProcess create_model() called ==================================
2023-06-16 10:33:35,034:INFO:Initializing create_model()
2023-06-16 10:33:35,034:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196D373AE60>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:33:35,034:INFO:Checking exceptions
2023-06-16 10:33:35,034:INFO:Importing libraries
2023-06-16 10:33:35,034:INFO:Copying training dataset
2023-06-16 10:33:35,040:INFO:Defining folds
2023-06-16 10:33:35,040:INFO:Declaring metric variables
2023-06-16 10:33:35,044:INFO:Importing untrained model
2023-06-16 10:33:35,049:INFO:Extra Trees Regressor Imported successfully
2023-06-16 10:33:35,065:INFO:Starting cross validation
2023-06-16 10:33:35,066:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:33:36,484:INFO:Calculating mean and std
2023-06-16 10:33:36,485:INFO:Creating metrics dataframe
2023-06-16 10:33:36,772:INFO:Uploading results into container
2023-06-16 10:33:36,773:INFO:Uploading model into container now
2023-06-16 10:33:36,774:INFO:_master_model_container: 33
2023-06-16 10:33:36,774:INFO:_display_container: 3
2023-06-16 10:33:36,774:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2023-06-16 10:33:36,774:INFO:create_model() successfully completed......................................
2023-06-16 10:33:36,933:INFO:SubProcess create_model() end ==================================
2023-06-16 10:33:36,933:INFO:Creating metrics dataframe
2023-06-16 10:33:36,944:INFO:Initializing AdaBoost Regressor
2023-06-16 10:33:36,944:INFO:Total runtime is 0.5222838679949443 minutes
2023-06-16 10:33:36,949:INFO:SubProcess create_model() called ==================================
2023-06-16 10:33:36,950:INFO:Initializing create_model()
2023-06-16 10:33:36,950:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196D373AE60>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:33:36,950:INFO:Checking exceptions
2023-06-16 10:33:36,951:INFO:Importing libraries
2023-06-16 10:33:36,951:INFO:Copying training dataset
2023-06-16 10:33:36,961:INFO:Defining folds
2023-06-16 10:33:36,961:INFO:Declaring metric variables
2023-06-16 10:33:36,965:INFO:Importing untrained model
2023-06-16 10:33:36,974:INFO:AdaBoost Regressor Imported successfully
2023-06-16 10:33:36,986:INFO:Starting cross validation
2023-06-16 10:33:36,990:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:33:38,227:INFO:Calculating mean and std
2023-06-16 10:33:38,228:INFO:Creating metrics dataframe
2023-06-16 10:33:38,715:INFO:Uploading results into container
2023-06-16 10:33:38,716:INFO:Uploading model into container now
2023-06-16 10:33:38,716:INFO:_master_model_container: 34
2023-06-16 10:33:38,716:INFO:_display_container: 3
2023-06-16 10:33:38,716:INFO:AdaBoostRegressor(random_state=42)
2023-06-16 10:33:38,717:INFO:create_model() successfully completed......................................
2023-06-16 10:33:38,875:INFO:SubProcess create_model() end ==================================
2023-06-16 10:33:38,875:INFO:Creating metrics dataframe
2023-06-16 10:33:38,888:INFO:Initializing Gradient Boosting Regressor
2023-06-16 10:33:38,889:INFO:Total runtime is 0.5546940644582113 minutes
2023-06-16 10:33:38,892:INFO:SubProcess create_model() called ==================================
2023-06-16 10:33:38,893:INFO:Initializing create_model()
2023-06-16 10:33:38,893:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196D373AE60>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:33:38,893:INFO:Checking exceptions
2023-06-16 10:33:38,893:INFO:Importing libraries
2023-06-16 10:33:38,893:INFO:Copying training dataset
2023-06-16 10:33:38,906:INFO:Defining folds
2023-06-16 10:33:38,906:INFO:Declaring metric variables
2023-06-16 10:33:38,913:INFO:Importing untrained model
2023-06-16 10:33:38,921:INFO:Gradient Boosting Regressor Imported successfully
2023-06-16 10:33:38,933:INFO:Starting cross validation
2023-06-16 10:33:38,935:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:33:40,142:INFO:Calculating mean and std
2023-06-16 10:33:40,143:INFO:Creating metrics dataframe
2023-06-16 10:33:40,457:INFO:Uploading results into container
2023-06-16 10:33:40,458:INFO:Uploading model into container now
2023-06-16 10:33:40,459:INFO:_master_model_container: 35
2023-06-16 10:33:40,459:INFO:_display_container: 3
2023-06-16 10:33:40,460:INFO:GradientBoostingRegressor(random_state=42)
2023-06-16 10:33:40,460:INFO:create_model() successfully completed......................................
2023-06-16 10:33:40,628:INFO:SubProcess create_model() end ==================================
2023-06-16 10:33:40,628:INFO:Creating metrics dataframe
2023-06-16 10:33:40,642:INFO:Initializing Extreme Gradient Boosting
2023-06-16 10:33:40,642:INFO:Total runtime is 0.5839157183965048 minutes
2023-06-16 10:33:40,648:INFO:SubProcess create_model() called ==================================
2023-06-16 10:33:40,648:INFO:Initializing create_model()
2023-06-16 10:33:40,649:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196D373AE60>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:33:40,649:INFO:Checking exceptions
2023-06-16 10:33:40,649:INFO:Importing libraries
2023-06-16 10:33:40,649:INFO:Copying training dataset
2023-06-16 10:33:40,663:INFO:Defining folds
2023-06-16 10:33:40,663:INFO:Declaring metric variables
2023-06-16 10:33:40,673:INFO:Importing untrained model
2023-06-16 10:33:40,683:INFO:Extreme Gradient Boosting Imported successfully
2023-06-16 10:33:40,698:INFO:Starting cross validation
2023-06-16 10:33:40,700:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:33:42,006:INFO:Calculating mean and std
2023-06-16 10:33:42,008:INFO:Creating metrics dataframe
2023-06-16 10:33:42,325:INFO:Uploading results into container
2023-06-16 10:33:42,326:INFO:Uploading model into container now
2023-06-16 10:33:42,326:INFO:_master_model_container: 36
2023-06-16 10:33:42,326:INFO:_display_container: 3
2023-06-16 10:33:42,327:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=42, ...)
2023-06-16 10:33:42,327:INFO:create_model() successfully completed......................................
2023-06-16 10:33:42,504:INFO:SubProcess create_model() end ==================================
2023-06-16 10:33:42,505:INFO:Creating metrics dataframe
2023-06-16 10:33:42,531:INFO:Initializing Light Gradient Boosting Machine
2023-06-16 10:33:42,532:INFO:Total runtime is 0.6154095093409221 minutes
2023-06-16 10:33:42,535:INFO:SubProcess create_model() called ==================================
2023-06-16 10:33:42,536:INFO:Initializing create_model()
2023-06-16 10:33:42,536:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196D373AE60>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:33:42,536:INFO:Checking exceptions
2023-06-16 10:33:42,536:INFO:Importing libraries
2023-06-16 10:33:42,536:INFO:Copying training dataset
2023-06-16 10:33:42,551:INFO:Defining folds
2023-06-16 10:33:42,551:INFO:Declaring metric variables
2023-06-16 10:33:42,558:INFO:Importing untrained model
2023-06-16 10:33:42,561:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-16 10:33:42,570:INFO:Starting cross validation
2023-06-16 10:33:42,571:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:33:44,855:INFO:Calculating mean and std
2023-06-16 10:33:44,857:INFO:Creating metrics dataframe
2023-06-16 10:33:45,238:INFO:Uploading results into container
2023-06-16 10:33:45,239:INFO:Uploading model into container now
2023-06-16 10:33:45,239:INFO:_master_model_container: 37
2023-06-16 10:33:45,239:INFO:_display_container: 3
2023-06-16 10:33:45,240:INFO:LGBMRegressor(random_state=42)
2023-06-16 10:33:45,240:INFO:create_model() successfully completed......................................
2023-06-16 10:33:45,427:INFO:SubProcess create_model() end ==================================
2023-06-16 10:33:45,427:INFO:Creating metrics dataframe
2023-06-16 10:33:45,442:INFO:Initializing Dummy Regressor
2023-06-16 10:33:45,442:INFO:Total runtime is 0.663920557498932 minutes
2023-06-16 10:33:45,446:INFO:SubProcess create_model() called ==================================
2023-06-16 10:33:45,446:INFO:Initializing create_model()
2023-06-16 10:33:45,446:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196D373AE60>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:33:45,446:INFO:Checking exceptions
2023-06-16 10:33:45,446:INFO:Importing libraries
2023-06-16 10:33:45,446:INFO:Copying training dataset
2023-06-16 10:33:45,462:INFO:Defining folds
2023-06-16 10:33:45,462:INFO:Declaring metric variables
2023-06-16 10:33:45,468:INFO:Importing untrained model
2023-06-16 10:33:45,476:INFO:Dummy Regressor Imported successfully
2023-06-16 10:33:45,488:INFO:Starting cross validation
2023-06-16 10:33:45,489:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:33:46,694:INFO:Calculating mean and std
2023-06-16 10:33:46,695:INFO:Creating metrics dataframe
2023-06-16 10:33:47,057:INFO:Uploading results into container
2023-06-16 10:33:47,059:INFO:Uploading model into container now
2023-06-16 10:33:47,060:INFO:_master_model_container: 38
2023-06-16 10:33:47,060:INFO:_display_container: 3
2023-06-16 10:33:47,060:INFO:DummyRegressor()
2023-06-16 10:33:47,061:INFO:create_model() successfully completed......................................
2023-06-16 10:33:47,236:INFO:SubProcess create_model() end ==================================
2023-06-16 10:33:47,236:INFO:Creating metrics dataframe
2023-06-16 10:33:47,266:INFO:Initializing create_model()
2023-06-16 10:33:47,267:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:33:47,267:INFO:Checking exceptions
2023-06-16 10:33:47,272:INFO:Importing libraries
2023-06-16 10:33:47,272:INFO:Copying training dataset
2023-06-16 10:33:47,281:INFO:Defining folds
2023-06-16 10:33:47,281:INFO:Declaring metric variables
2023-06-16 10:33:47,281:INFO:Importing untrained model
2023-06-16 10:33:47,281:INFO:Declaring custom model
2023-06-16 10:33:47,282:INFO:Random Forest Regressor Imported successfully
2023-06-16 10:33:47,283:INFO:Cross validation set to False
2023-06-16 10:33:47,283:INFO:Fitting Model
2023-06-16 10:33:47,596:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 10:33:47,596:INFO:create_model() successfully completed......................................
2023-06-16 10:33:47,804:INFO:_master_model_container: 38
2023-06-16 10:33:47,804:INFO:_display_container: 3
2023-06-16 10:33:47,805:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 10:33:47,806:INFO:compare_models() successfully completed......................................
2023-06-16 10:37:44,484:INFO:Initializing create_model()
2023-06-16 10:37:44,484:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=rf, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:37:44,485:INFO:Checking exceptions
2023-06-16 10:37:44,510:INFO:Importing libraries
2023-06-16 10:37:44,510:INFO:Copying training dataset
2023-06-16 10:37:44,518:INFO:Defining folds
2023-06-16 10:37:44,518:INFO:Declaring metric variables
2023-06-16 10:37:44,523:INFO:Importing untrained model
2023-06-16 10:37:44,526:INFO:Random Forest Regressor Imported successfully
2023-06-16 10:37:44,534:INFO:Starting cross validation
2023-06-16 10:37:44,535:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:37:45,790:INFO:Calculating mean and std
2023-06-16 10:37:45,792:INFO:Creating metrics dataframe
2023-06-16 10:37:45,797:INFO:Finalizing model
2023-06-16 10:37:46,360:INFO:Uploading results into container
2023-06-16 10:37:46,361:INFO:Uploading model into container now
2023-06-16 10:37:46,375:INFO:_master_model_container: 39
2023-06-16 10:37:46,375:INFO:_display_container: 4
2023-06-16 10:37:46,376:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 10:37:46,376:INFO:create_model() successfully completed......................................
2023-06-16 10:37:52,295:INFO:Initializing plot_model()
2023-06-16 10:37:52,295:INFO:plot_model(plot=learning, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, system=True)
2023-06-16 10:37:52,295:INFO:Checking exceptions
2023-06-16 10:37:52,325:INFO:Preloading libraries
2023-06-16 10:37:52,362:INFO:Copying training dataset
2023-06-16 10:37:52,362:INFO:Plot type: learning
2023-06-16 10:37:52,458:INFO:Fitting Model
2023-06-16 10:39:05,554:INFO:Visual Rendered Successfully
2023-06-16 10:39:05,713:INFO:plot_model() successfully completed......................................
2023-06-16 10:39:39,589:INFO:Initializing plot_model()
2023-06-16 10:39:39,589:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, system=True)
2023-06-16 10:39:39,589:INFO:Checking exceptions
2023-06-16 10:39:39,617:INFO:Preloading libraries
2023-06-16 10:39:39,651:INFO:Copying training dataset
2023-06-16 10:39:39,651:INFO:Plot type: error
2023-06-16 10:39:39,771:INFO:Fitting Model
2023-06-16 10:39:39,771:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2023-06-16 10:39:39,771:INFO:Scoring test/hold-out set
2023-06-16 10:39:40,235:INFO:Visual Rendered Successfully
2023-06-16 10:39:40,398:INFO:plot_model() successfully completed......................................
2023-06-16 10:40:15,158:INFO:Initializing tune_model()
2023-06-16 10:40:15,159:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=5, round=4, n_iter=10, custom_grid={'max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>)
2023-06-16 10:40:15,159:INFO:Checking exceptions
2023-06-16 10:40:15,189:INFO:Copying training dataset
2023-06-16 10:40:15,193:INFO:Checking base model
2023-06-16 10:40:15,193:INFO:Base model : Random Forest Regressor
2023-06-16 10:40:15,197:INFO:Declaring metric variables
2023-06-16 10:40:15,200:INFO:Defining Hyperparameters
2023-06-16 10:40:15,373:INFO:custom_grid: {'actual_estimator__max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}
2023-06-16 10:40:15,373:INFO:Tuning with n_jobs=-1
2023-06-16 10:40:15,374:INFO:Initializing RandomizedSearchCV
2023-06-16 10:40:18,668:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:40:19,640:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:40:20,081:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:40:20,753:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:40:20,937:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-16 10:40:20,982:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:40:21,213:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:40:21,687:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:40:22,179:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:40:22,225:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:40:22,765:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:40:24,592:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:40:25,709:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:40:27,413:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:40:28,067:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:40:29,375:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.31s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:40:29,587:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-16 10:40:31,404:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:40:32,326:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:40:33,445:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:40:34,051:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:40:34,438:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:40:40,469:WARNING:
5 fits failed out of a total of 50.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\lapei\anaconda3\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py", line 340, in fit
    self._validate_params()
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\base.py", line 581, in _validate_params
    validate_parameter_constraints(
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 97, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestRegressor must be an int in the range [1, inf) or None. Got 0 instead.


2023-06-16 10:40:40,471:WARNING:One or more of the test scores are non-finite: [       nan 0.49419939 0.84058494 0.88612187 0.89725281 0.90282624
 0.90641901 0.90529087 0.90911226 0.90600098]

2023-06-16 10:40:40,934:INFO:best_params: {'actual_estimator__max_depth': 9}
2023-06-16 10:40:40,935:INFO:Hyperparameter search completed
2023-06-16 10:40:40,935:INFO:SubProcess create_model() called ==================================
2023-06-16 10:40:40,936:INFO:Initializing create_model()
2023-06-16 10:40:40,936:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196DB8988B0>, model_only=True, return_train_score=False, kwargs={'max_depth': 9})
2023-06-16 10:40:40,936:INFO:Checking exceptions
2023-06-16 10:40:40,936:INFO:Importing libraries
2023-06-16 10:40:40,937:INFO:Copying training dataset
2023-06-16 10:40:40,943:INFO:Defining folds
2023-06-16 10:40:40,943:INFO:Declaring metric variables
2023-06-16 10:40:40,947:INFO:Importing untrained model
2023-06-16 10:40:40,947:INFO:Declaring custom model
2023-06-16 10:40:40,956:INFO:Random Forest Regressor Imported successfully
2023-06-16 10:40:40,968:INFO:Starting cross validation
2023-06-16 10:40:40,969:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:40:42,470:INFO:Calculating mean and std
2023-06-16 10:40:42,473:INFO:Creating metrics dataframe
2023-06-16 10:40:42,483:INFO:Finalizing model
2023-06-16 10:40:43,670:INFO:Uploading results into container
2023-06-16 10:40:43,671:INFO:Uploading model into container now
2023-06-16 10:40:43,672:INFO:_master_model_container: 40
2023-06-16 10:40:43,672:INFO:_display_container: 5
2023-06-16 10:40:43,672:INFO:RandomForestRegressor(max_depth=9, n_jobs=-1, random_state=42)
2023-06-16 10:40:43,672:INFO:create_model() successfully completed......................................
2023-06-16 10:40:43,835:INFO:SubProcess create_model() end ==================================
2023-06-16 10:40:43,835:INFO:choose_better activated
2023-06-16 10:40:43,839:INFO:SubProcess create_model() called ==================================
2023-06-16 10:40:43,839:INFO:Initializing create_model()
2023-06-16 10:40:43,839:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:40:43,839:INFO:Checking exceptions
2023-06-16 10:40:43,843:INFO:Importing libraries
2023-06-16 10:40:43,844:INFO:Copying training dataset
2023-06-16 10:40:43,851:INFO:Defining folds
2023-06-16 10:40:43,852:INFO:Declaring metric variables
2023-06-16 10:40:43,852:INFO:Importing untrained model
2023-06-16 10:40:43,852:INFO:Declaring custom model
2023-06-16 10:40:43,854:INFO:Random Forest Regressor Imported successfully
2023-06-16 10:40:43,854:INFO:Starting cross validation
2023-06-16 10:40:43,856:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:40:45,220:INFO:Calculating mean and std
2023-06-16 10:40:45,221:INFO:Creating metrics dataframe
2023-06-16 10:40:45,223:INFO:Finalizing model
2023-06-16 10:40:45,854:INFO:Uploading results into container
2023-06-16 10:40:45,855:INFO:Uploading model into container now
2023-06-16 10:40:45,855:INFO:_master_model_container: 41
2023-06-16 10:40:45,856:INFO:_display_container: 6
2023-06-16 10:40:45,856:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 10:40:45,856:INFO:create_model() successfully completed......................................
2023-06-16 10:40:46,003:INFO:SubProcess create_model() end ==================================
2023-06-16 10:40:46,004:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) result for R2 is 0.9092
2023-06-16 10:40:46,005:INFO:RandomForestRegressor(max_depth=9, n_jobs=-1, random_state=42) result for R2 is 0.9091
2023-06-16 10:40:46,005:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) is best model
2023-06-16 10:40:46,005:INFO:choose_better completed
2023-06-16 10:40:46,005:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-06-16 10:40:46,015:INFO:_master_model_container: 41
2023-06-16 10:40:46,015:INFO:_display_container: 5
2023-06-16 10:40:46,015:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 10:40:46,015:INFO:tune_model() successfully completed......................................
2023-06-16 10:41:10,554:INFO:Initializing tune_model()
2023-06-16 10:41:10,554:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=5, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>)
2023-06-16 10:41:10,555:INFO:Checking exceptions
2023-06-16 10:41:10,579:INFO:Copying training dataset
2023-06-16 10:41:10,583:INFO:Checking base model
2023-06-16 10:41:10,583:INFO:Base model : Random Forest Regressor
2023-06-16 10:41:10,586:INFO:Declaring metric variables
2023-06-16 10:41:10,589:INFO:Defining Hyperparameters
2023-06-16 10:41:10,761:INFO:Tuning with n_jobs=-1
2023-06-16 10:41:10,762:INFO:Initializing RandomizedSearchCV
2023-06-16 10:41:12,139:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:41:12,174:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:41:12,277:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:41:13,399:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-16 10:41:13,455:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:41:13,540:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:41:22,664:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:41:24,391:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:41:24,789:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:41:25,510:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:41:25,610:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:41:27,223:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:41:33,648:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-16 10:41:35,664:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:41:37,351:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-16 10:41:39,490:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:41:41,315:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-16 10:41:45,667:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:41:46,915:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:41:46,971:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-16 10:41:48,761:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:41:49,096:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:41:50,427:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:41:50,605:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-16 10:41:51,296:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:41:52,405:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-16 10:41:52,918:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:41:54,819:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:41:54,931:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:41:55,665:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:41:56,191:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 10:42:00,201:INFO:best_params: {'actual_estimator__n_estimators': 190, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 4, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': True}
2023-06-16 10:42:00,202:INFO:Hyperparameter search completed
2023-06-16 10:42:00,202:INFO:SubProcess create_model() called ==================================
2023-06-16 10:42:00,203:INFO:Initializing create_model()
2023-06-16 10:42:00,203:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196D4AE5300>, model_only=True, return_train_score=False, kwargs={'n_estimators': 190, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.3, 'max_features': 1.0, 'max_depth': 4, 'criterion': 'squared_error', 'bootstrap': True})
2023-06-16 10:42:00,203:INFO:Checking exceptions
2023-06-16 10:42:00,203:INFO:Importing libraries
2023-06-16 10:42:00,203:INFO:Copying training dataset
2023-06-16 10:42:00,209:INFO:Defining folds
2023-06-16 10:42:00,209:INFO:Declaring metric variables
2023-06-16 10:42:00,212:INFO:Importing untrained model
2023-06-16 10:42:00,212:INFO:Declaring custom model
2023-06-16 10:42:00,216:INFO:Random Forest Regressor Imported successfully
2023-06-16 10:42:00,223:INFO:Starting cross validation
2023-06-16 10:42:00,226:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:42:01,719:INFO:Calculating mean and std
2023-06-16 10:42:01,721:INFO:Creating metrics dataframe
2023-06-16 10:42:01,727:INFO:Finalizing model
2023-06-16 10:42:03,067:INFO:Uploading results into container
2023-06-16 10:42:03,068:INFO:Uploading model into container now
2023-06-16 10:42:03,069:INFO:_master_model_container: 42
2023-06-16 10:42:03,069:INFO:_display_container: 6
2023-06-16 10:42:03,069:INFO:RandomForestRegressor(max_depth=4, min_impurity_decrease=0.3,
                      min_samples_leaf=2, n_estimators=190, n_jobs=-1,
                      random_state=42)
2023-06-16 10:42:03,069:INFO:create_model() successfully completed......................................
2023-06-16 10:42:03,231:INFO:SubProcess create_model() end ==================================
2023-06-16 10:42:03,231:INFO:choose_better activated
2023-06-16 10:42:03,235:INFO:SubProcess create_model() called ==================================
2023-06-16 10:42:03,236:INFO:Initializing create_model()
2023-06-16 10:42:03,236:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:42:03,236:INFO:Checking exceptions
2023-06-16 10:42:03,238:INFO:Importing libraries
2023-06-16 10:42:03,238:INFO:Copying training dataset
2023-06-16 10:42:03,250:INFO:Defining folds
2023-06-16 10:42:03,250:INFO:Declaring metric variables
2023-06-16 10:42:03,250:INFO:Importing untrained model
2023-06-16 10:42:03,251:INFO:Declaring custom model
2023-06-16 10:42:03,252:INFO:Random Forest Regressor Imported successfully
2023-06-16 10:42:03,253:INFO:Starting cross validation
2023-06-16 10:42:03,254:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:42:04,646:INFO:Calculating mean and std
2023-06-16 10:42:04,647:INFO:Creating metrics dataframe
2023-06-16 10:42:04,651:INFO:Finalizing model
2023-06-16 10:42:05,184:INFO:Uploading results into container
2023-06-16 10:42:05,185:INFO:Uploading model into container now
2023-06-16 10:42:05,185:INFO:_master_model_container: 43
2023-06-16 10:42:05,186:INFO:_display_container: 7
2023-06-16 10:42:05,186:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 10:42:05,186:INFO:create_model() successfully completed......................................
2023-06-16 10:42:05,335:INFO:SubProcess create_model() end ==================================
2023-06-16 10:42:05,336:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) result for R2 is 0.9092
2023-06-16 10:42:05,337:INFO:RandomForestRegressor(max_depth=4, min_impurity_decrease=0.3,
                      min_samples_leaf=2, n_estimators=190, n_jobs=-1,
                      random_state=42) result for R2 is 0.8853
2023-06-16 10:42:05,337:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) is best model
2023-06-16 10:42:05,337:INFO:choose_better completed
2023-06-16 10:42:05,338:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-06-16 10:42:05,345:INFO:_master_model_container: 43
2023-06-16 10:42:05,346:INFO:_display_container: 6
2023-06-16 10:42:05,346:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 10:42:05,346:INFO:tune_model() successfully completed......................................
2023-06-16 10:42:34,151:INFO:Initializing compare_models()
2023-06-16 10:42:34,151:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, include=None, fold=5, round=4, cross_validation=True, sort=RMSE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, 'include': None, 'exclude': None, 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'RMSE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-06-16 10:42:34,151:INFO:Checking exceptions
2023-06-16 10:42:34,156:INFO:Preparing display monitor
2023-06-16 10:42:34,194:INFO:Initializing Linear Regression
2023-06-16 10:42:34,194:INFO:Total runtime is 0.0 minutes
2023-06-16 10:42:34,197:INFO:SubProcess create_model() called ==================================
2023-06-16 10:42:34,197:INFO:Initializing create_model()
2023-06-16 10:42:34,197:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196DA8B0880>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:42:34,198:INFO:Checking exceptions
2023-06-16 10:42:34,198:INFO:Importing libraries
2023-06-16 10:42:34,198:INFO:Copying training dataset
2023-06-16 10:42:34,203:INFO:Defining folds
2023-06-16 10:42:34,203:INFO:Declaring metric variables
2023-06-16 10:42:34,207:INFO:Importing untrained model
2023-06-16 10:42:34,210:INFO:Linear Regression Imported successfully
2023-06-16 10:42:34,216:INFO:Starting cross validation
2023-06-16 10:42:34,218:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:42:35,386:INFO:Calculating mean and std
2023-06-16 10:42:35,389:INFO:Creating metrics dataframe
2023-06-16 10:42:35,735:INFO:Uploading results into container
2023-06-16 10:42:35,736:INFO:Uploading model into container now
2023-06-16 10:42:35,736:INFO:_master_model_container: 44
2023-06-16 10:42:35,736:INFO:_display_container: 7
2023-06-16 10:42:35,736:INFO:LinearRegression(n_jobs=-1)
2023-06-16 10:42:35,736:INFO:create_model() successfully completed......................................
2023-06-16 10:42:35,898:INFO:SubProcess create_model() end ==================================
2023-06-16 10:42:35,898:INFO:Creating metrics dataframe
2023-06-16 10:42:35,916:INFO:Initializing Lasso Regression
2023-06-16 10:42:35,916:INFO:Total runtime is 0.028699890772501627 minutes
2023-06-16 10:42:35,922:INFO:SubProcess create_model() called ==================================
2023-06-16 10:42:35,922:INFO:Initializing create_model()
2023-06-16 10:42:35,922:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196DA8B0880>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:42:35,922:INFO:Checking exceptions
2023-06-16 10:42:35,922:INFO:Importing libraries
2023-06-16 10:42:35,922:INFO:Copying training dataset
2023-06-16 10:42:35,936:INFO:Defining folds
2023-06-16 10:42:35,936:INFO:Declaring metric variables
2023-06-16 10:42:35,943:INFO:Importing untrained model
2023-06-16 10:42:35,951:INFO:Lasso Regression Imported successfully
2023-06-16 10:42:35,959:INFO:Starting cross validation
2023-06-16 10:42:35,960:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:42:37,102:INFO:Calculating mean and std
2023-06-16 10:42:37,103:INFO:Creating metrics dataframe
2023-06-16 10:42:37,479:INFO:Uploading results into container
2023-06-16 10:42:37,480:INFO:Uploading model into container now
2023-06-16 10:42:37,481:INFO:_master_model_container: 45
2023-06-16 10:42:37,481:INFO:_display_container: 7
2023-06-16 10:42:37,482:INFO:Lasso(random_state=42)
2023-06-16 10:42:37,482:INFO:create_model() successfully completed......................................
2023-06-16 10:42:37,641:INFO:SubProcess create_model() end ==================================
2023-06-16 10:42:37,641:INFO:Creating metrics dataframe
2023-06-16 10:42:37,650:INFO:Initializing Ridge Regression
2023-06-16 10:42:37,650:INFO:Total runtime is 0.05759787559509277 minutes
2023-06-16 10:42:37,654:INFO:SubProcess create_model() called ==================================
2023-06-16 10:42:37,655:INFO:Initializing create_model()
2023-06-16 10:42:37,655:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196DA8B0880>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:42:37,655:INFO:Checking exceptions
2023-06-16 10:42:37,655:INFO:Importing libraries
2023-06-16 10:42:37,655:INFO:Copying training dataset
2023-06-16 10:42:37,662:INFO:Defining folds
2023-06-16 10:42:37,662:INFO:Declaring metric variables
2023-06-16 10:42:37,667:INFO:Importing untrained model
2023-06-16 10:42:37,673:INFO:Ridge Regression Imported successfully
2023-06-16 10:42:37,680:INFO:Starting cross validation
2023-06-16 10:42:37,681:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:42:38,884:INFO:Calculating mean and std
2023-06-16 10:42:38,885:INFO:Creating metrics dataframe
2023-06-16 10:42:39,281:INFO:Uploading results into container
2023-06-16 10:42:39,282:INFO:Uploading model into container now
2023-06-16 10:42:39,282:INFO:_master_model_container: 46
2023-06-16 10:42:39,283:INFO:_display_container: 7
2023-06-16 10:42:39,283:INFO:Ridge(random_state=42)
2023-06-16 10:42:39,283:INFO:create_model() successfully completed......................................
2023-06-16 10:42:39,460:INFO:SubProcess create_model() end ==================================
2023-06-16 10:42:39,460:INFO:Creating metrics dataframe
2023-06-16 10:42:39,470:INFO:Initializing Elastic Net
2023-06-16 10:42:39,470:INFO:Total runtime is 0.08792615334192912 minutes
2023-06-16 10:42:39,474:INFO:SubProcess create_model() called ==================================
2023-06-16 10:42:39,475:INFO:Initializing create_model()
2023-06-16 10:42:39,475:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196DA8B0880>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:42:39,476:INFO:Checking exceptions
2023-06-16 10:42:39,476:INFO:Importing libraries
2023-06-16 10:42:39,476:INFO:Copying training dataset
2023-06-16 10:42:39,482:INFO:Defining folds
2023-06-16 10:42:39,482:INFO:Declaring metric variables
2023-06-16 10:42:39,488:INFO:Importing untrained model
2023-06-16 10:42:39,495:INFO:Elastic Net Imported successfully
2023-06-16 10:42:39,502:INFO:Starting cross validation
2023-06-16 10:42:39,504:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:42:40,682:INFO:Calculating mean and std
2023-06-16 10:42:40,683:INFO:Creating metrics dataframe
2023-06-16 10:42:41,191:INFO:Uploading results into container
2023-06-16 10:42:41,192:INFO:Uploading model into container now
2023-06-16 10:42:41,192:INFO:_master_model_container: 47
2023-06-16 10:42:41,192:INFO:_display_container: 7
2023-06-16 10:42:41,193:INFO:ElasticNet(random_state=42)
2023-06-16 10:42:41,193:INFO:create_model() successfully completed......................................
2023-06-16 10:42:41,346:INFO:SubProcess create_model() end ==================================
2023-06-16 10:42:41,346:INFO:Creating metrics dataframe
2023-06-16 10:42:41,356:INFO:Initializing Least Angle Regression
2023-06-16 10:42:41,356:INFO:Total runtime is 0.11936968167622884 minutes
2023-06-16 10:42:41,359:INFO:SubProcess create_model() called ==================================
2023-06-16 10:42:41,360:INFO:Initializing create_model()
2023-06-16 10:42:41,360:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196DA8B0880>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:42:41,360:INFO:Checking exceptions
2023-06-16 10:42:41,360:INFO:Importing libraries
2023-06-16 10:42:41,360:INFO:Copying training dataset
2023-06-16 10:42:41,366:INFO:Defining folds
2023-06-16 10:42:41,366:INFO:Declaring metric variables
2023-06-16 10:42:41,370:INFO:Importing untrained model
2023-06-16 10:42:41,374:INFO:Least Angle Regression Imported successfully
2023-06-16 10:42:41,385:INFO:Starting cross validation
2023-06-16 10:42:41,387:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:42:42,529:INFO:Calculating mean and std
2023-06-16 10:42:42,530:INFO:Creating metrics dataframe
2023-06-16 10:42:43,062:INFO:Uploading results into container
2023-06-16 10:42:43,064:INFO:Uploading model into container now
2023-06-16 10:42:43,064:INFO:_master_model_container: 48
2023-06-16 10:42:43,065:INFO:_display_container: 7
2023-06-16 10:42:43,066:INFO:Lars(random_state=42)
2023-06-16 10:42:43,066:INFO:create_model() successfully completed......................................
2023-06-16 10:42:43,219:INFO:SubProcess create_model() end ==================================
2023-06-16 10:42:43,220:INFO:Creating metrics dataframe
2023-06-16 10:42:43,229:INFO:Initializing Lasso Least Angle Regression
2023-06-16 10:42:43,230:INFO:Total runtime is 0.1506001591682434 minutes
2023-06-16 10:42:43,234:INFO:SubProcess create_model() called ==================================
2023-06-16 10:42:43,234:INFO:Initializing create_model()
2023-06-16 10:42:43,235:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196DA8B0880>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:42:43,235:INFO:Checking exceptions
2023-06-16 10:42:43,235:INFO:Importing libraries
2023-06-16 10:42:43,235:INFO:Copying training dataset
2023-06-16 10:42:43,245:INFO:Defining folds
2023-06-16 10:42:43,245:INFO:Declaring metric variables
2023-06-16 10:42:43,252:INFO:Importing untrained model
2023-06-16 10:42:43,256:INFO:Lasso Least Angle Regression Imported successfully
2023-06-16 10:42:43,264:INFO:Starting cross validation
2023-06-16 10:42:43,266:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:42:44,402:INFO:Calculating mean and std
2023-06-16 10:42:44,404:INFO:Creating metrics dataframe
2023-06-16 10:42:44,801:INFO:Uploading results into container
2023-06-16 10:42:44,802:INFO:Uploading model into container now
2023-06-16 10:42:44,802:INFO:_master_model_container: 49
2023-06-16 10:42:44,802:INFO:_display_container: 7
2023-06-16 10:42:44,802:INFO:LassoLars(random_state=42)
2023-06-16 10:42:44,802:INFO:create_model() successfully completed......................................
2023-06-16 10:42:44,960:INFO:SubProcess create_model() end ==================================
2023-06-16 10:42:44,960:INFO:Creating metrics dataframe
2023-06-16 10:42:44,978:INFO:Initializing Orthogonal Matching Pursuit
2023-06-16 10:42:44,979:INFO:Total runtime is 0.17975470622380574 minutes
2023-06-16 10:42:44,983:INFO:SubProcess create_model() called ==================================
2023-06-16 10:42:44,984:INFO:Initializing create_model()
2023-06-16 10:42:44,984:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196DA8B0880>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:42:44,984:INFO:Checking exceptions
2023-06-16 10:42:44,984:INFO:Importing libraries
2023-06-16 10:42:44,984:INFO:Copying training dataset
2023-06-16 10:42:44,991:INFO:Defining folds
2023-06-16 10:42:44,991:INFO:Declaring metric variables
2023-06-16 10:42:44,995:INFO:Importing untrained model
2023-06-16 10:42:45,000:INFO:Orthogonal Matching Pursuit Imported successfully
2023-06-16 10:42:45,006:INFO:Starting cross validation
2023-06-16 10:42:45,007:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:42:46,157:INFO:Calculating mean and std
2023-06-16 10:42:46,158:INFO:Creating metrics dataframe
2023-06-16 10:42:46,581:INFO:Uploading results into container
2023-06-16 10:42:46,583:INFO:Uploading model into container now
2023-06-16 10:42:46,583:INFO:_master_model_container: 50
2023-06-16 10:42:46,583:INFO:_display_container: 7
2023-06-16 10:42:46,584:INFO:OrthogonalMatchingPursuit()
2023-06-16 10:42:46,584:INFO:create_model() successfully completed......................................
2023-06-16 10:42:46,750:INFO:SubProcess create_model() end ==================================
2023-06-16 10:42:46,750:INFO:Creating metrics dataframe
2023-06-16 10:42:46,761:INFO:Initializing Bayesian Ridge
2023-06-16 10:42:46,762:INFO:Total runtime is 0.20946929454803465 minutes
2023-06-16 10:42:46,765:INFO:SubProcess create_model() called ==================================
2023-06-16 10:42:46,765:INFO:Initializing create_model()
2023-06-16 10:42:46,765:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196DA8B0880>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:42:46,765:INFO:Checking exceptions
2023-06-16 10:42:46,765:INFO:Importing libraries
2023-06-16 10:42:46,765:INFO:Copying training dataset
2023-06-16 10:42:46,773:INFO:Defining folds
2023-06-16 10:42:46,773:INFO:Declaring metric variables
2023-06-16 10:42:46,783:INFO:Importing untrained model
2023-06-16 10:42:46,793:INFO:Bayesian Ridge Imported successfully
2023-06-16 10:42:46,804:INFO:Starting cross validation
2023-06-16 10:42:46,805:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:42:47,983:INFO:Calculating mean and std
2023-06-16 10:42:47,984:INFO:Creating metrics dataframe
2023-06-16 10:42:48,363:INFO:Uploading results into container
2023-06-16 10:42:48,364:INFO:Uploading model into container now
2023-06-16 10:42:48,365:INFO:_master_model_container: 51
2023-06-16 10:42:48,365:INFO:_display_container: 7
2023-06-16 10:42:48,365:INFO:BayesianRidge()
2023-06-16 10:42:48,365:INFO:create_model() successfully completed......................................
2023-06-16 10:42:48,536:INFO:SubProcess create_model() end ==================================
2023-06-16 10:42:48,536:INFO:Creating metrics dataframe
2023-06-16 10:42:48,552:INFO:Initializing Passive Aggressive Regressor
2023-06-16 10:42:48,552:INFO:Total runtime is 0.23929253816604612 minutes
2023-06-16 10:42:48,556:INFO:SubProcess create_model() called ==================================
2023-06-16 10:42:48,556:INFO:Initializing create_model()
2023-06-16 10:42:48,557:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196DA8B0880>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:42:48,557:INFO:Checking exceptions
2023-06-16 10:42:48,557:INFO:Importing libraries
2023-06-16 10:42:48,557:INFO:Copying training dataset
2023-06-16 10:42:48,570:INFO:Defining folds
2023-06-16 10:42:48,571:INFO:Declaring metric variables
2023-06-16 10:42:48,578:INFO:Importing untrained model
2023-06-16 10:42:48,585:INFO:Passive Aggressive Regressor Imported successfully
2023-06-16 10:42:48,594:INFO:Starting cross validation
2023-06-16 10:42:48,595:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:42:49,833:INFO:Calculating mean and std
2023-06-16 10:42:49,834:INFO:Creating metrics dataframe
2023-06-16 10:42:50,316:INFO:Uploading results into container
2023-06-16 10:42:50,317:INFO:Uploading model into container now
2023-06-16 10:42:50,318:INFO:_master_model_container: 52
2023-06-16 10:42:50,318:INFO:_display_container: 7
2023-06-16 10:42:50,319:INFO:PassiveAggressiveRegressor(random_state=42)
2023-06-16 10:42:50,319:INFO:create_model() successfully completed......................................
2023-06-16 10:42:50,467:INFO:SubProcess create_model() end ==================================
2023-06-16 10:42:50,467:INFO:Creating metrics dataframe
2023-06-16 10:42:50,478:INFO:Initializing Huber Regressor
2023-06-16 10:42:50,478:INFO:Total runtime is 0.2713985522588094 minutes
2023-06-16 10:42:50,481:INFO:SubProcess create_model() called ==================================
2023-06-16 10:42:50,483:INFO:Initializing create_model()
2023-06-16 10:42:50,483:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196DA8B0880>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:42:50,483:INFO:Checking exceptions
2023-06-16 10:42:50,483:INFO:Importing libraries
2023-06-16 10:42:50,483:INFO:Copying training dataset
2023-06-16 10:42:50,498:INFO:Defining folds
2023-06-16 10:42:50,498:INFO:Declaring metric variables
2023-06-16 10:42:50,504:INFO:Importing untrained model
2023-06-16 10:42:50,509:INFO:Huber Regressor Imported successfully
2023-06-16 10:42:50,515:INFO:Starting cross validation
2023-06-16 10:42:50,516:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:42:50,640:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:42:50,660:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:42:50,682:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:42:50,686:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:42:50,702:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:42:51,796:INFO:Calculating mean and std
2023-06-16 10:42:51,798:INFO:Creating metrics dataframe
2023-06-16 10:42:52,292:INFO:Uploading results into container
2023-06-16 10:42:52,294:INFO:Uploading model into container now
2023-06-16 10:42:52,295:INFO:_master_model_container: 53
2023-06-16 10:42:52,295:INFO:_display_container: 7
2023-06-16 10:42:52,295:INFO:HuberRegressor()
2023-06-16 10:42:52,295:INFO:create_model() successfully completed......................................
2023-06-16 10:42:52,473:INFO:SubProcess create_model() end ==================================
2023-06-16 10:42:52,473:INFO:Creating metrics dataframe
2023-06-16 10:42:52,484:INFO:Initializing K Neighbors Regressor
2023-06-16 10:42:52,484:INFO:Total runtime is 0.30483213663101194 minutes
2023-06-16 10:42:52,488:INFO:SubProcess create_model() called ==================================
2023-06-16 10:42:52,489:INFO:Initializing create_model()
2023-06-16 10:42:52,489:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196DA8B0880>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:42:52,489:INFO:Checking exceptions
2023-06-16 10:42:52,489:INFO:Importing libraries
2023-06-16 10:42:52,489:INFO:Copying training dataset
2023-06-16 10:42:52,495:INFO:Defining folds
2023-06-16 10:42:52,495:INFO:Declaring metric variables
2023-06-16 10:42:52,498:INFO:Importing untrained model
2023-06-16 10:42:52,502:INFO:K Neighbors Regressor Imported successfully
2023-06-16 10:42:52,509:INFO:Starting cross validation
2023-06-16 10:42:52,511:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:42:53,730:INFO:Calculating mean and std
2023-06-16 10:42:53,732:INFO:Creating metrics dataframe
2023-06-16 10:42:54,087:INFO:Uploading results into container
2023-06-16 10:42:54,088:INFO:Uploading model into container now
2023-06-16 10:42:54,088:INFO:_master_model_container: 54
2023-06-16 10:42:54,088:INFO:_display_container: 7
2023-06-16 10:42:54,089:INFO:KNeighborsRegressor(n_jobs=-1)
2023-06-16 10:42:54,089:INFO:create_model() successfully completed......................................
2023-06-16 10:42:54,247:INFO:SubProcess create_model() end ==================================
2023-06-16 10:42:54,247:INFO:Creating metrics dataframe
2023-06-16 10:42:54,261:INFO:Initializing Decision Tree Regressor
2023-06-16 10:42:54,261:INFO:Total runtime is 0.3344472010930379 minutes
2023-06-16 10:42:54,273:INFO:SubProcess create_model() called ==================================
2023-06-16 10:42:54,274:INFO:Initializing create_model()
2023-06-16 10:42:54,274:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196DA8B0880>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:42:54,274:INFO:Checking exceptions
2023-06-16 10:42:54,275:INFO:Importing libraries
2023-06-16 10:42:54,275:INFO:Copying training dataset
2023-06-16 10:42:54,286:INFO:Defining folds
2023-06-16 10:42:54,287:INFO:Declaring metric variables
2023-06-16 10:42:54,293:INFO:Importing untrained model
2023-06-16 10:42:54,299:INFO:Decision Tree Regressor Imported successfully
2023-06-16 10:42:54,314:INFO:Starting cross validation
2023-06-16 10:42:54,316:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:42:55,535:INFO:Calculating mean and std
2023-06-16 10:42:55,537:INFO:Creating metrics dataframe
2023-06-16 10:42:56,037:INFO:Uploading results into container
2023-06-16 10:42:56,038:INFO:Uploading model into container now
2023-06-16 10:42:56,038:INFO:_master_model_container: 55
2023-06-16 10:42:56,038:INFO:_display_container: 7
2023-06-16 10:42:56,038:INFO:DecisionTreeRegressor(random_state=42)
2023-06-16 10:42:56,039:INFO:create_model() successfully completed......................................
2023-06-16 10:42:56,194:INFO:SubProcess create_model() end ==================================
2023-06-16 10:42:56,194:INFO:Creating metrics dataframe
2023-06-16 10:42:56,207:INFO:Initializing Random Forest Regressor
2023-06-16 10:42:56,207:INFO:Total runtime is 0.3668740272521972 minutes
2023-06-16 10:42:56,213:INFO:SubProcess create_model() called ==================================
2023-06-16 10:42:56,213:INFO:Initializing create_model()
2023-06-16 10:42:56,214:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196DA8B0880>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:42:56,214:INFO:Checking exceptions
2023-06-16 10:42:56,214:INFO:Importing libraries
2023-06-16 10:42:56,214:INFO:Copying training dataset
2023-06-16 10:42:56,223:INFO:Defining folds
2023-06-16 10:42:56,223:INFO:Declaring metric variables
2023-06-16 10:42:56,229:INFO:Importing untrained model
2023-06-16 10:42:56,241:INFO:Random Forest Regressor Imported successfully
2023-06-16 10:42:56,254:INFO:Starting cross validation
2023-06-16 10:42:56,256:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:42:57,574:INFO:Calculating mean and std
2023-06-16 10:42:57,575:INFO:Creating metrics dataframe
2023-06-16 10:42:57,974:INFO:Uploading results into container
2023-06-16 10:42:57,975:INFO:Uploading model into container now
2023-06-16 10:42:57,976:INFO:_master_model_container: 56
2023-06-16 10:42:57,977:INFO:_display_container: 7
2023-06-16 10:42:57,977:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 10:42:57,977:INFO:create_model() successfully completed......................................
2023-06-16 10:42:58,163:INFO:SubProcess create_model() end ==================================
2023-06-16 10:42:58,163:INFO:Creating metrics dataframe
2023-06-16 10:42:58,175:INFO:Initializing Extra Trees Regressor
2023-06-16 10:42:58,176:INFO:Total runtime is 0.3996952056884765 minutes
2023-06-16 10:42:58,179:INFO:SubProcess create_model() called ==================================
2023-06-16 10:42:58,180:INFO:Initializing create_model()
2023-06-16 10:42:58,180:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196DA8B0880>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:42:58,180:INFO:Checking exceptions
2023-06-16 10:42:58,180:INFO:Importing libraries
2023-06-16 10:42:58,180:INFO:Copying training dataset
2023-06-16 10:42:58,186:INFO:Defining folds
2023-06-16 10:42:58,186:INFO:Declaring metric variables
2023-06-16 10:42:58,189:INFO:Importing untrained model
2023-06-16 10:42:58,194:INFO:Extra Trees Regressor Imported successfully
2023-06-16 10:42:58,204:INFO:Starting cross validation
2023-06-16 10:42:58,205:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:42:59,589:INFO:Calculating mean and std
2023-06-16 10:42:59,590:INFO:Creating metrics dataframe
2023-06-16 10:42:59,977:INFO:Uploading results into container
2023-06-16 10:42:59,978:INFO:Uploading model into container now
2023-06-16 10:42:59,978:INFO:_master_model_container: 57
2023-06-16 10:42:59,979:INFO:_display_container: 7
2023-06-16 10:42:59,979:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2023-06-16 10:42:59,979:INFO:create_model() successfully completed......................................
2023-06-16 10:43:00,156:INFO:SubProcess create_model() end ==================================
2023-06-16 10:43:00,156:INFO:Creating metrics dataframe
2023-06-16 10:43:00,169:INFO:Initializing AdaBoost Regressor
2023-06-16 10:43:00,169:INFO:Total runtime is 0.43291505575180045 minutes
2023-06-16 10:43:00,172:INFO:SubProcess create_model() called ==================================
2023-06-16 10:43:00,172:INFO:Initializing create_model()
2023-06-16 10:43:00,172:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196DA8B0880>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:43:00,172:INFO:Checking exceptions
2023-06-16 10:43:00,172:INFO:Importing libraries
2023-06-16 10:43:00,172:INFO:Copying training dataset
2023-06-16 10:43:00,180:INFO:Defining folds
2023-06-16 10:43:00,181:INFO:Declaring metric variables
2023-06-16 10:43:00,186:INFO:Importing untrained model
2023-06-16 10:43:00,195:INFO:AdaBoost Regressor Imported successfully
2023-06-16 10:43:00,207:INFO:Starting cross validation
2023-06-16 10:43:00,209:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:43:01,430:INFO:Calculating mean and std
2023-06-16 10:43:01,432:INFO:Creating metrics dataframe
2023-06-16 10:43:01,880:INFO:Uploading results into container
2023-06-16 10:43:01,881:INFO:Uploading model into container now
2023-06-16 10:43:01,881:INFO:_master_model_container: 58
2023-06-16 10:43:01,882:INFO:_display_container: 7
2023-06-16 10:43:01,882:INFO:AdaBoostRegressor(random_state=42)
2023-06-16 10:43:01,882:INFO:create_model() successfully completed......................................
2023-06-16 10:43:02,056:INFO:SubProcess create_model() end ==================================
2023-06-16 10:43:02,056:INFO:Creating metrics dataframe
2023-06-16 10:43:02,089:INFO:Initializing Gradient Boosting Regressor
2023-06-16 10:43:02,089:INFO:Total runtime is 0.4649123986562092 minutes
2023-06-16 10:43:02,096:INFO:SubProcess create_model() called ==================================
2023-06-16 10:43:02,096:INFO:Initializing create_model()
2023-06-16 10:43:02,096:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196DA8B0880>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:43:02,096:INFO:Checking exceptions
2023-06-16 10:43:02,096:INFO:Importing libraries
2023-06-16 10:43:02,096:INFO:Copying training dataset
2023-06-16 10:43:02,111:INFO:Defining folds
2023-06-16 10:43:02,112:INFO:Declaring metric variables
2023-06-16 10:43:02,117:INFO:Importing untrained model
2023-06-16 10:43:02,123:INFO:Gradient Boosting Regressor Imported successfully
2023-06-16 10:43:02,131:INFO:Starting cross validation
2023-06-16 10:43:02,133:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:43:03,363:INFO:Calculating mean and std
2023-06-16 10:43:03,364:INFO:Creating metrics dataframe
2023-06-16 10:43:03,914:INFO:Uploading results into container
2023-06-16 10:43:03,915:INFO:Uploading model into container now
2023-06-16 10:43:03,915:INFO:_master_model_container: 59
2023-06-16 10:43:03,915:INFO:_display_container: 7
2023-06-16 10:43:03,916:INFO:GradientBoostingRegressor(random_state=42)
2023-06-16 10:43:03,916:INFO:create_model() successfully completed......................................
2023-06-16 10:43:04,099:INFO:SubProcess create_model() end ==================================
2023-06-16 10:43:04,099:INFO:Creating metrics dataframe
2023-06-16 10:43:04,127:INFO:Initializing Extreme Gradient Boosting
2023-06-16 10:43:04,128:INFO:Total runtime is 0.498901335398356 minutes
2023-06-16 10:43:04,133:INFO:SubProcess create_model() called ==================================
2023-06-16 10:43:04,133:INFO:Initializing create_model()
2023-06-16 10:43:04,133:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196DA8B0880>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:43:04,133:INFO:Checking exceptions
2023-06-16 10:43:04,133:INFO:Importing libraries
2023-06-16 10:43:04,133:INFO:Copying training dataset
2023-06-16 10:43:04,141:INFO:Defining folds
2023-06-16 10:43:04,141:INFO:Declaring metric variables
2023-06-16 10:43:04,146:INFO:Importing untrained model
2023-06-16 10:43:04,160:INFO:Extreme Gradient Boosting Imported successfully
2023-06-16 10:43:04,171:INFO:Starting cross validation
2023-06-16 10:43:04,173:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:43:05,332:INFO:Calculating mean and std
2023-06-16 10:43:05,333:INFO:Creating metrics dataframe
2023-06-16 10:43:05,642:INFO:Uploading results into container
2023-06-16 10:43:05,643:INFO:Uploading model into container now
2023-06-16 10:43:05,643:INFO:_master_model_container: 60
2023-06-16 10:43:05,643:INFO:_display_container: 7
2023-06-16 10:43:05,644:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=42, ...)
2023-06-16 10:43:05,644:INFO:create_model() successfully completed......................................
2023-06-16 10:43:05,820:INFO:SubProcess create_model() end ==================================
2023-06-16 10:43:05,820:INFO:Creating metrics dataframe
2023-06-16 10:43:05,860:INFO:Initializing Light Gradient Boosting Machine
2023-06-16 10:43:05,860:INFO:Total runtime is 0.5277559280395506 minutes
2023-06-16 10:43:05,868:INFO:SubProcess create_model() called ==================================
2023-06-16 10:43:05,869:INFO:Initializing create_model()
2023-06-16 10:43:05,869:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196DA8B0880>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:43:05,869:INFO:Checking exceptions
2023-06-16 10:43:05,869:INFO:Importing libraries
2023-06-16 10:43:05,869:INFO:Copying training dataset
2023-06-16 10:43:05,878:INFO:Defining folds
2023-06-16 10:43:05,879:INFO:Declaring metric variables
2023-06-16 10:43:05,887:INFO:Importing untrained model
2023-06-16 10:43:05,892:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-16 10:43:05,904:INFO:Starting cross validation
2023-06-16 10:43:05,906:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:43:07,415:INFO:Calculating mean and std
2023-06-16 10:43:07,417:INFO:Creating metrics dataframe
2023-06-16 10:43:07,766:INFO:Uploading results into container
2023-06-16 10:43:07,767:INFO:Uploading model into container now
2023-06-16 10:43:07,767:INFO:_master_model_container: 61
2023-06-16 10:43:07,767:INFO:_display_container: 7
2023-06-16 10:43:07,768:INFO:LGBMRegressor(random_state=42)
2023-06-16 10:43:07,768:INFO:create_model() successfully completed......................................
2023-06-16 10:43:07,921:INFO:SubProcess create_model() end ==================================
2023-06-16 10:43:07,922:INFO:Creating metrics dataframe
2023-06-16 10:43:07,952:INFO:Initializing Dummy Regressor
2023-06-16 10:43:07,952:INFO:Total runtime is 0.5626347223917642 minutes
2023-06-16 10:43:07,958:INFO:SubProcess create_model() called ==================================
2023-06-16 10:43:07,958:INFO:Initializing create_model()
2023-06-16 10:43:07,958:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196DA8B0880>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:43:07,959:INFO:Checking exceptions
2023-06-16 10:43:07,959:INFO:Importing libraries
2023-06-16 10:43:07,959:INFO:Copying training dataset
2023-06-16 10:43:07,969:INFO:Defining folds
2023-06-16 10:43:07,969:INFO:Declaring metric variables
2023-06-16 10:43:07,974:INFO:Importing untrained model
2023-06-16 10:43:07,981:INFO:Dummy Regressor Imported successfully
2023-06-16 10:43:07,996:INFO:Starting cross validation
2023-06-16 10:43:07,998:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:43:09,264:INFO:Calculating mean and std
2023-06-16 10:43:09,266:INFO:Creating metrics dataframe
2023-06-16 10:43:09,746:INFO:Uploading results into container
2023-06-16 10:43:09,746:INFO:Uploading model into container now
2023-06-16 10:43:09,747:INFO:_master_model_container: 62
2023-06-16 10:43:09,747:INFO:_display_container: 7
2023-06-16 10:43:09,747:INFO:DummyRegressor()
2023-06-16 10:43:09,747:INFO:create_model() successfully completed......................................
2023-06-16 10:43:09,936:INFO:SubProcess create_model() end ==================================
2023-06-16 10:43:09,937:INFO:Creating metrics dataframe
2023-06-16 10:43:09,985:INFO:Initializing create_model()
2023-06-16 10:43:09,986:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=HuberRegressor(), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:43:09,986:INFO:Checking exceptions
2023-06-16 10:43:09,987:INFO:Importing libraries
2023-06-16 10:43:09,988:INFO:Copying training dataset
2023-06-16 10:43:09,996:INFO:Defining folds
2023-06-16 10:43:09,996:INFO:Declaring metric variables
2023-06-16 10:43:09,996:INFO:Importing untrained model
2023-06-16 10:43:09,997:INFO:Declaring custom model
2023-06-16 10:43:09,997:INFO:Huber Regressor Imported successfully
2023-06-16 10:43:09,998:INFO:Cross validation set to False
2023-06-16 10:43:09,998:INFO:Fitting Model
2023-06-16 10:43:10,124:WARNING:lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html

2023-06-16 10:43:10,383:INFO:HuberRegressor()
2023-06-16 10:43:10,383:INFO:create_model() successfully completed......................................
2023-06-16 10:43:10,593:INFO:_master_model_container: 62
2023-06-16 10:43:10,594:INFO:_display_container: 7
2023-06-16 10:43:10,594:INFO:HuberRegressor()
2023-06-16 10:43:10,594:INFO:compare_models() successfully completed......................................
2023-06-16 10:44:07,162:INFO:Initializing create_model()
2023-06-16 10:44:07,162:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=rf, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:44:07,162:INFO:Checking exceptions
2023-06-16 10:44:07,185:INFO:Importing libraries
2023-06-16 10:44:07,185:INFO:Copying training dataset
2023-06-16 10:44:07,192:INFO:Defining folds
2023-06-16 10:44:07,192:INFO:Declaring metric variables
2023-06-16 10:44:07,196:INFO:Importing untrained model
2023-06-16 10:44:07,199:INFO:Random Forest Regressor Imported successfully
2023-06-16 10:44:07,214:INFO:Starting cross validation
2023-06-16 10:44:07,215:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:44:08,583:INFO:Calculating mean and std
2023-06-16 10:44:08,584:INFO:Creating metrics dataframe
2023-06-16 10:44:08,590:INFO:Finalizing model
2023-06-16 10:44:09,248:INFO:Uploading results into container
2023-06-16 10:44:09,250:INFO:Uploading model into container now
2023-06-16 10:44:09,265:INFO:_master_model_container: 63
2023-06-16 10:44:09,266:INFO:_display_container: 8
2023-06-16 10:44:09,267:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 10:44:09,267:INFO:create_model() successfully completed......................................
2023-06-16 10:44:19,485:INFO:Initializing create_model()
2023-06-16 10:44:19,485:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=hr, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:44:19,485:INFO:Checking exceptions
2023-06-16 10:45:01,657:INFO:Initializing create_model()
2023-06-16 10:45:01,657:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=huber, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:45:01,657:INFO:Checking exceptions
2023-06-16 10:45:01,683:INFO:Importing libraries
2023-06-16 10:45:01,683:INFO:Copying training dataset
2023-06-16 10:45:01,689:INFO:Defining folds
2023-06-16 10:45:01,689:INFO:Declaring metric variables
2023-06-16 10:45:01,692:INFO:Importing untrained model
2023-06-16 10:45:01,695:INFO:Huber Regressor Imported successfully
2023-06-16 10:45:01,701:INFO:Starting cross validation
2023-06-16 10:45:01,702:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:45:01,835:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:01,847:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:01,850:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:01,861:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:01,886:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:02,978:INFO:Calculating mean and std
2023-06-16 10:45:02,979:INFO:Creating metrics dataframe
2023-06-16 10:45:02,985:INFO:Finalizing model
2023-06-16 10:45:03,130:WARNING:lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html

2023-06-16 10:45:03,483:INFO:Uploading results into container
2023-06-16 10:45:03,483:INFO:Uploading model into container now
2023-06-16 10:45:03,491:INFO:_master_model_container: 64
2023-06-16 10:45:03,491:INFO:_display_container: 9
2023-06-16 10:45:03,491:INFO:HuberRegressor()
2023-06-16 10:45:03,491:INFO:create_model() successfully completed......................................
2023-06-16 10:45:09,865:INFO:Initializing plot_model()
2023-06-16 10:45:09,865:INFO:plot_model(plot=learning, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, system=True)
2023-06-16 10:45:09,866:INFO:Checking exceptions
2023-06-16 10:45:09,874:INFO:Preloading libraries
2023-06-16 10:45:09,874:INFO:Copying training dataset
2023-06-16 10:45:09,874:INFO:Plot type: learning
2023-06-16 10:45:09,976:INFO:Fitting Model
2023-06-16 10:45:10,080:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,083:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,083:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,093:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,108:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,109:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,128:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,129:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,168:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,174:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,190:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,191:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,195:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,227:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,231:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,262:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,264:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,269:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,270:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,291:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,311:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,313:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,338:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,344:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,357:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,360:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,384:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,388:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,390:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,411:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,424:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,425:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,470:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,475:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,481:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,482:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,497:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,510:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,514:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,528:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,558:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,559:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,564:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,576:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,608:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,615:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,628:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,635:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,639:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,644:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,687:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,706:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,707:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,724:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,726:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,735:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,742:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,761:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,782:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,796:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,807:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,825:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,844:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,847:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,857:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,857:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,859:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,879:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,890:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,927:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,937:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,942:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,947:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,949:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,956:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,958:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,975:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:10,995:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:11,012:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:11,017:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:11,042:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:11,045:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:11,055:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:11,059:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:11,067:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:11,078:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:11,083:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:11,103:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:11,124:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:11,127:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:11,148:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:11,156:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:11,162:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:11,171:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:11,174:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:11,429:INFO:Visual Rendered Successfully
2023-06-16 10:45:11,597:INFO:plot_model() successfully completed......................................
2023-06-16 10:45:22,092:INFO:Initializing plot_model()
2023-06-16 10:45:22,093:INFO:plot_model(plot=vc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, system=True)
2023-06-16 10:45:22,093:INFO:Checking exceptions
2023-06-16 10:45:22,100:INFO:Preloading libraries
2023-06-16 10:45:22,100:INFO:Copying training dataset
2023-06-16 10:45:22,100:INFO:Plot type: vc
2023-06-16 10:45:22,100:INFO:Determining param_name
2023-06-16 10:45:22,101:INFO:param_name: alpha
2023-06-16 10:45:22,189:INFO:Fitting Model
2023-06-16 10:45:22,313:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,318:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,331:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,333:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,334:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,335:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,344:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,345:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,413:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,426:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,435:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,443:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,448:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,455:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,460:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,465:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,538:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,551:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,555:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,561:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,562:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,566:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,567:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,570:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,649:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,665:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,669:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,671:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,687:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,690:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,691:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,764:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,776:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,786:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,788:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,796:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,803:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,805:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,813:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,887:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,891:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,903:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,904:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,919:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,922:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,923:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,924:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:22,995:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,003:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,017:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,018:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,033:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,042:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,049:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,049:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,117:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,130:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,145:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,152:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,158:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,160:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,174:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,176:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,238:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,242:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,254:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,263:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,265:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,273:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,277:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,280:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,355:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,361:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,366:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,370:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,374:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,388:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,391:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,392:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,455:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,467:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,469:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,482:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,490:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,494:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,510:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,511:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,566:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,580:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,595:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,598:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,599:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,616:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,618:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,636:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,658:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,670:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,676:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,677:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:45:23,932:INFO:Visual Rendered Successfully
2023-06-16 10:45:24,109:INFO:plot_model() successfully completed......................................
2023-06-16 10:45:29,184:INFO:Initializing plot_model()
2023-06-16 10:45:29,184:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, system=True)
2023-06-16 10:45:29,184:INFO:Checking exceptions
2023-06-16 10:45:29,190:INFO:Preloading libraries
2023-06-16 10:45:29,190:INFO:Copying training dataset
2023-06-16 10:45:29,190:INFO:Plot type: error
2023-06-16 10:45:29,285:INFO:Fitting Model
2023-06-16 10:45:29,286:WARNING:X does not have valid feature names, but HuberRegressor was fitted with feature names

2023-06-16 10:45:29,286:INFO:Scoring test/hold-out set
2023-06-16 10:45:29,555:INFO:Visual Rendered Successfully
2023-06-16 10:45:29,816:INFO:plot_model() successfully completed......................................
2023-06-16 10:45:44,747:INFO:Initializing plot_model()
2023-06-16 10:45:44,747:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, system=True)
2023-06-16 10:45:44,747:INFO:Checking exceptions
2023-06-16 10:45:44,755:INFO:Preloading libraries
2023-06-16 10:45:44,756:INFO:Copying training dataset
2023-06-16 10:45:44,756:INFO:Plot type: feature
2023-06-16 10:45:44,968:INFO:Visual Rendered Successfully
2023-06-16 10:45:45,185:INFO:plot_model() successfully completed......................................
2023-06-16 10:46:00,829:INFO:Initializing plot_model()
2023-06-16 10:46:00,829:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=3, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, system=True)
2023-06-16 10:46:00,829:INFO:Checking exceptions
2023-06-16 10:46:00,835:INFO:Preloading libraries
2023-06-16 10:46:00,835:INFO:Copying training dataset
2023-06-16 10:46:00,835:INFO:Plot type: residuals
2023-06-16 10:46:00,980:INFO:Fitting Model
2023-06-16 10:46:00,980:WARNING:X does not have valid feature names, but HuberRegressor was fitted with feature names

2023-06-16 10:46:01,026:INFO:Scoring test/hold-out set
2023-06-16 10:46:01,713:INFO:Visual Rendered Successfully
2023-06-16 10:46:01,890:INFO:plot_model() successfully completed......................................
2023-06-16 10:46:07,716:INFO:Initializing interpret_model()
2023-06-16 10:46:07,716:INFO:interpret_model(estimator=HuberRegressor(), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>)
2023-06-16 10:46:07,716:INFO:Checking exceptions
2023-06-16 10:46:07,716:INFO:Soft dependency imported: shap: 0.41.0
2023-06-16 10:46:11,573:INFO:Initializing interpret_model()
2023-06-16 10:46:11,573:INFO:interpret_model(estimator=HuberRegressor(), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>)
2023-06-16 10:46:11,573:INFO:Checking exceptions
2023-06-16 10:46:11,573:INFO:Soft dependency imported: shap: 0.41.0
2023-06-16 10:46:22,804:INFO:Initializing tune_model()
2023-06-16 10:46:22,804:INFO:tune_model(estimator=HuberRegressor(), fold=5, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>)
2023-06-16 10:46:22,804:INFO:Checking exceptions
2023-06-16 10:46:22,831:INFO:Copying training dataset
2023-06-16 10:46:22,837:INFO:Checking base model
2023-06-16 10:46:22,837:INFO:Base model : Huber Regressor
2023-06-16 10:46:22,842:INFO:Declaring metric variables
2023-06-16 10:46:22,845:INFO:Defining Hyperparameters
2023-06-16 10:46:23,034:INFO:Tuning with n_jobs=-1
2023-06-16 10:46:23,034:INFO:Initializing RandomizedSearchCV
2023-06-16 10:46:23,203:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:23,219:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:23,224:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:23,236:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:23,239:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:23,240:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:23,257:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:23,277:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:23,896:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:23,938:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:23,958:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:23,969:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:24,001:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:24,035:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:24,037:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:24,588:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:24,616:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:24,698:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:24,701:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:24,732:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:24,839:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:25,041:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:25,162:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:25,400:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:25,533:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:25,792:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:25,920:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:26,201:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:26,309:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:26,508:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:26,676:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:26,884:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:27,017:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:27,254:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:27,427:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:27,561:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:27,684:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:27,906:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:28,041:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:28,234:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:28,366:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:28,529:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:28,678:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:28,829:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:28,988:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:29,242:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:29,376:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:29,926:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:30,611:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:38,203:INFO:best_params: {'actual_estimator__fit_intercept': False, 'actual_estimator__epsilon': 1, 'actual_estimator__alpha': 0.0005}
2023-06-16 10:46:38,205:INFO:Hyperparameter search completed
2023-06-16 10:46:38,205:INFO:SubProcess create_model() called ==================================
2023-06-16 10:46:38,206:INFO:Initializing create_model()
2023-06-16 10:46:38,206:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=HuberRegressor(), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196DB188970>, model_only=True, return_train_score=False, kwargs={'fit_intercept': False, 'epsilon': 1, 'alpha': 0.0005})
2023-06-16 10:46:38,207:INFO:Checking exceptions
2023-06-16 10:46:38,207:INFO:Importing libraries
2023-06-16 10:46:38,208:INFO:Copying training dataset
2023-06-16 10:46:38,222:INFO:Defining folds
2023-06-16 10:46:38,222:INFO:Declaring metric variables
2023-06-16 10:46:38,230:INFO:Importing untrained model
2023-06-16 10:46:38,230:INFO:Declaring custom model
2023-06-16 10:46:38,237:INFO:Huber Regressor Imported successfully
2023-06-16 10:46:38,251:INFO:Starting cross validation
2023-06-16 10:46:38,253:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:46:38,383:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:38,394:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:38,397:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:38,464:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:38,466:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:39,549:INFO:Calculating mean and std
2023-06-16 10:46:39,550:INFO:Creating metrics dataframe
2023-06-16 10:46:39,556:INFO:Finalizing model
2023-06-16 10:46:39,695:WARNING:lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html

2023-06-16 10:46:40,331:INFO:Uploading results into container
2023-06-16 10:46:40,332:INFO:Uploading model into container now
2023-06-16 10:46:40,332:INFO:_master_model_container: 65
2023-06-16 10:46:40,332:INFO:_display_container: 10
2023-06-16 10:46:40,333:INFO:HuberRegressor(alpha=0.0005, epsilon=1, fit_intercept=False)
2023-06-16 10:46:40,333:INFO:create_model() successfully completed......................................
2023-06-16 10:46:40,551:INFO:SubProcess create_model() end ==================================
2023-06-16 10:46:40,551:INFO:choose_better activated
2023-06-16 10:46:40,558:INFO:SubProcess create_model() called ==================================
2023-06-16 10:46:40,559:INFO:Initializing create_model()
2023-06-16 10:46:40,559:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=HuberRegressor(), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-16 10:46:40,560:INFO:Checking exceptions
2023-06-16 10:46:40,563:INFO:Importing libraries
2023-06-16 10:46:40,563:INFO:Copying training dataset
2023-06-16 10:46:40,575:INFO:Defining folds
2023-06-16 10:46:40,575:INFO:Declaring metric variables
2023-06-16 10:46:40,575:INFO:Importing untrained model
2023-06-16 10:46:40,575:INFO:Declaring custom model
2023-06-16 10:46:40,576:INFO:Huber Regressor Imported successfully
2023-06-16 10:46:40,577:INFO:Starting cross validation
2023-06-16 10:46:40,579:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 10:46:40,725:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:40,742:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:40,744:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:40,786:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:40,799:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 10:46:41,941:INFO:Calculating mean and std
2023-06-16 10:46:41,941:INFO:Creating metrics dataframe
2023-06-16 10:46:41,942:INFO:Finalizing model
2023-06-16 10:46:42,489:INFO:Uploading results into container
2023-06-16 10:46:42,490:INFO:Uploading model into container now
2023-06-16 10:46:42,490:INFO:_master_model_container: 66
2023-06-16 10:46:42,490:INFO:_display_container: 11
2023-06-16 10:46:42,490:INFO:HuberRegressor()
2023-06-16 10:46:42,490:INFO:create_model() successfully completed......................................
2023-06-16 10:46:42,682:INFO:SubProcess create_model() end ==================================
2023-06-16 10:46:42,682:INFO:HuberRegressor() result for R2 is 0.946
2023-06-16 10:46:42,683:INFO:HuberRegressor(alpha=0.0005, epsilon=1, fit_intercept=False) result for R2 is 0.947
2023-06-16 10:46:42,683:INFO:HuberRegressor(alpha=0.0005, epsilon=1, fit_intercept=False) is best model
2023-06-16 10:46:42,683:INFO:choose_better completed
2023-06-16 10:46:42,697:INFO:_master_model_container: 66
2023-06-16 10:46:42,697:INFO:_display_container: 10
2023-06-16 10:46:42,698:INFO:HuberRegressor(alpha=0.0005, epsilon=1, fit_intercept=False)
2023-06-16 10:46:42,698:INFO:tune_model() successfully completed......................................
2023-06-16 10:47:09,724:INFO:Initializing plot_model()
2023-06-16 10:47:09,725:INFO:plot_model(plot=learning, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, system=True)
2023-06-16 10:47:09,725:INFO:Checking exceptions
2023-06-16 10:47:09,750:INFO:Preloading libraries
2023-06-16 10:47:09,782:INFO:Copying training dataset
2023-06-16 10:47:09,782:INFO:Plot type: learning
2023-06-16 10:47:09,894:INFO:Fitting Model
2023-06-16 10:48:22,018:INFO:Visual Rendered Successfully
2023-06-16 10:48:22,216:INFO:plot_model() successfully completed......................................
2023-06-16 11:01:50,051:INFO:Initializing compare_models()
2023-06-16 11:01:50,051:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, include=None, fold=5, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, 'include': None, 'exclude': None, 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-06-16 11:01:50,051:INFO:Checking exceptions
2023-06-16 11:01:50,054:INFO:Preparing display monitor
2023-06-16 11:01:50,089:INFO:Initializing Linear Regression
2023-06-16 11:01:50,089:INFO:Total runtime is 0.0 minutes
2023-06-16 11:01:50,094:INFO:SubProcess create_model() called ==================================
2023-06-16 11:01:50,095:INFO:Initializing create_model()
2023-06-16 11:01:50,095:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196E4077EE0>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:01:50,095:INFO:Checking exceptions
2023-06-16 11:01:50,095:INFO:Importing libraries
2023-06-16 11:01:50,095:INFO:Copying training dataset
2023-06-16 11:01:50,101:INFO:Defining folds
2023-06-16 11:01:50,101:INFO:Declaring metric variables
2023-06-16 11:01:50,105:INFO:Importing untrained model
2023-06-16 11:01:50,108:INFO:Linear Regression Imported successfully
2023-06-16 11:01:50,115:INFO:Starting cross validation
2023-06-16 11:01:50,117:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:01:55,634:INFO:Calculating mean and std
2023-06-16 11:01:55,635:INFO:Creating metrics dataframe
2023-06-16 11:01:56,373:INFO:Uploading results into container
2023-06-16 11:01:56,375:INFO:Uploading model into container now
2023-06-16 11:01:56,376:INFO:_master_model_container: 67
2023-06-16 11:01:56,376:INFO:_display_container: 11
2023-06-16 11:01:56,376:INFO:LinearRegression(n_jobs=-1)
2023-06-16 11:01:56,377:INFO:create_model() successfully completed......................................
2023-06-16 11:01:56,644:INFO:SubProcess create_model() end ==================================
2023-06-16 11:01:56,644:INFO:Creating metrics dataframe
2023-06-16 11:01:56,654:INFO:Initializing Lasso Regression
2023-06-16 11:01:56,654:INFO:Total runtime is 0.10941778818766276 minutes
2023-06-16 11:01:56,659:INFO:SubProcess create_model() called ==================================
2023-06-16 11:01:56,659:INFO:Initializing create_model()
2023-06-16 11:01:56,659:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196E4077EE0>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:01:56,659:INFO:Checking exceptions
2023-06-16 11:01:56,659:INFO:Importing libraries
2023-06-16 11:01:56,659:INFO:Copying training dataset
2023-06-16 11:01:56,665:INFO:Defining folds
2023-06-16 11:01:56,665:INFO:Declaring metric variables
2023-06-16 11:01:56,669:INFO:Importing untrained model
2023-06-16 11:01:56,674:INFO:Lasso Regression Imported successfully
2023-06-16 11:01:56,684:INFO:Starting cross validation
2023-06-16 11:01:56,685:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:01:59,702:INFO:Calculating mean and std
2023-06-16 11:01:59,703:INFO:Creating metrics dataframe
2023-06-16 11:02:00,280:INFO:Uploading results into container
2023-06-16 11:02:00,281:INFO:Uploading model into container now
2023-06-16 11:02:00,281:INFO:_master_model_container: 68
2023-06-16 11:02:00,281:INFO:_display_container: 11
2023-06-16 11:02:00,282:INFO:Lasso(random_state=42)
2023-06-16 11:02:00,282:INFO:create_model() successfully completed......................................
2023-06-16 11:02:00,483:INFO:SubProcess create_model() end ==================================
2023-06-16 11:02:00,483:INFO:Creating metrics dataframe
2023-06-16 11:02:00,494:INFO:Initializing Ridge Regression
2023-06-16 11:02:00,494:INFO:Total runtime is 0.17341546614964803 minutes
2023-06-16 11:02:00,499:INFO:SubProcess create_model() called ==================================
2023-06-16 11:02:00,499:INFO:Initializing create_model()
2023-06-16 11:02:00,499:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196E4077EE0>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:02:00,500:INFO:Checking exceptions
2023-06-16 11:02:00,500:INFO:Importing libraries
2023-06-16 11:02:00,500:INFO:Copying training dataset
2023-06-16 11:02:00,508:INFO:Defining folds
2023-06-16 11:02:00,508:INFO:Declaring metric variables
2023-06-16 11:02:00,513:INFO:Importing untrained model
2023-06-16 11:02:00,516:INFO:Ridge Regression Imported successfully
2023-06-16 11:02:00,526:INFO:Starting cross validation
2023-06-16 11:02:00,527:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:02:01,792:INFO:Calculating mean and std
2023-06-16 11:02:01,793:INFO:Creating metrics dataframe
2023-06-16 11:02:02,481:INFO:Uploading results into container
2023-06-16 11:02:02,482:INFO:Uploading model into container now
2023-06-16 11:02:02,482:INFO:_master_model_container: 69
2023-06-16 11:02:02,482:INFO:_display_container: 11
2023-06-16 11:02:02,483:INFO:Ridge(random_state=42)
2023-06-16 11:02:02,483:INFO:create_model() successfully completed......................................
2023-06-16 11:02:02,671:INFO:SubProcess create_model() end ==================================
2023-06-16 11:02:02,671:INFO:Creating metrics dataframe
2023-06-16 11:02:02,695:INFO:Initializing Elastic Net
2023-06-16 11:02:02,695:INFO:Total runtime is 0.21009860038757325 minutes
2023-06-16 11:02:02,702:INFO:SubProcess create_model() called ==================================
2023-06-16 11:02:02,702:INFO:Initializing create_model()
2023-06-16 11:02:02,702:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196E4077EE0>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:02:02,703:INFO:Checking exceptions
2023-06-16 11:02:02,703:INFO:Importing libraries
2023-06-16 11:02:02,703:INFO:Copying training dataset
2023-06-16 11:02:02,712:INFO:Defining folds
2023-06-16 11:02:02,712:INFO:Declaring metric variables
2023-06-16 11:02:02,720:INFO:Importing untrained model
2023-06-16 11:02:02,725:INFO:Elastic Net Imported successfully
2023-06-16 11:02:02,734:INFO:Starting cross validation
2023-06-16 11:02:02,735:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:02:03,982:INFO:Calculating mean and std
2023-06-16 11:02:03,984:INFO:Creating metrics dataframe
2023-06-16 11:02:04,444:INFO:Uploading results into container
2023-06-16 11:02:04,445:INFO:Uploading model into container now
2023-06-16 11:02:04,446:INFO:_master_model_container: 70
2023-06-16 11:02:04,446:INFO:_display_container: 11
2023-06-16 11:02:04,447:INFO:ElasticNet(random_state=42)
2023-06-16 11:02:04,447:INFO:create_model() successfully completed......................................
2023-06-16 11:02:04,630:INFO:SubProcess create_model() end ==================================
2023-06-16 11:02:04,630:INFO:Creating metrics dataframe
2023-06-16 11:02:04,641:INFO:Initializing Least Angle Regression
2023-06-16 11:02:04,641:INFO:Total runtime is 0.24253528118133544 minutes
2023-06-16 11:02:04,645:INFO:SubProcess create_model() called ==================================
2023-06-16 11:02:04,645:INFO:Initializing create_model()
2023-06-16 11:02:04,645:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196E4077EE0>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:02:04,645:INFO:Checking exceptions
2023-06-16 11:02:04,645:INFO:Importing libraries
2023-06-16 11:02:04,645:INFO:Copying training dataset
2023-06-16 11:02:04,653:INFO:Defining folds
2023-06-16 11:02:04,653:INFO:Declaring metric variables
2023-06-16 11:02:04,657:INFO:Importing untrained model
2023-06-16 11:02:04,664:INFO:Least Angle Regression Imported successfully
2023-06-16 11:02:04,677:INFO:Starting cross validation
2023-06-16 11:02:04,678:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:02:05,892:INFO:Calculating mean and std
2023-06-16 11:02:05,893:INFO:Creating metrics dataframe
2023-06-16 11:02:06,477:INFO:Uploading results into container
2023-06-16 11:02:06,479:INFO:Uploading model into container now
2023-06-16 11:02:06,480:INFO:_master_model_container: 71
2023-06-16 11:02:06,480:INFO:_display_container: 11
2023-06-16 11:02:06,481:INFO:Lars(random_state=42)
2023-06-16 11:02:06,481:INFO:create_model() successfully completed......................................
2023-06-16 11:02:06,697:INFO:SubProcess create_model() end ==================================
2023-06-16 11:02:06,697:INFO:Creating metrics dataframe
2023-06-16 11:02:06,707:INFO:Initializing Lasso Least Angle Regression
2023-06-16 11:02:06,707:INFO:Total runtime is 0.27697122891743975 minutes
2023-06-16 11:02:06,711:INFO:SubProcess create_model() called ==================================
2023-06-16 11:02:06,711:INFO:Initializing create_model()
2023-06-16 11:02:06,711:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196E4077EE0>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:02:06,712:INFO:Checking exceptions
2023-06-16 11:02:06,712:INFO:Importing libraries
2023-06-16 11:02:06,712:INFO:Copying training dataset
2023-06-16 11:02:06,718:INFO:Defining folds
2023-06-16 11:02:06,718:INFO:Declaring metric variables
2023-06-16 11:02:06,722:INFO:Importing untrained model
2023-06-16 11:02:06,727:INFO:Lasso Least Angle Regression Imported successfully
2023-06-16 11:02:06,734:INFO:Starting cross validation
2023-06-16 11:02:06,735:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:02:07,965:INFO:Calculating mean and std
2023-06-16 11:02:07,967:INFO:Creating metrics dataframe
2023-06-16 11:02:08,593:INFO:Uploading results into container
2023-06-16 11:02:08,595:INFO:Uploading model into container now
2023-06-16 11:02:08,595:INFO:_master_model_container: 72
2023-06-16 11:02:08,596:INFO:_display_container: 11
2023-06-16 11:02:08,596:INFO:LassoLars(random_state=42)
2023-06-16 11:02:08,597:INFO:create_model() successfully completed......................................
2023-06-16 11:02:08,781:INFO:SubProcess create_model() end ==================================
2023-06-16 11:02:08,781:INFO:Creating metrics dataframe
2023-06-16 11:02:08,791:INFO:Initializing Orthogonal Matching Pursuit
2023-06-16 11:02:08,792:INFO:Total runtime is 0.3117238759994507 minutes
2023-06-16 11:02:08,797:INFO:SubProcess create_model() called ==================================
2023-06-16 11:02:08,798:INFO:Initializing create_model()
2023-06-16 11:02:08,798:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196E4077EE0>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:02:08,798:INFO:Checking exceptions
2023-06-16 11:02:08,799:INFO:Importing libraries
2023-06-16 11:02:08,799:INFO:Copying training dataset
2023-06-16 11:02:08,813:INFO:Defining folds
2023-06-16 11:02:08,813:INFO:Declaring metric variables
2023-06-16 11:02:08,822:INFO:Importing untrained model
2023-06-16 11:02:08,827:INFO:Orthogonal Matching Pursuit Imported successfully
2023-06-16 11:02:08,834:INFO:Starting cross validation
2023-06-16 11:02:08,835:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:02:10,090:INFO:Calculating mean and std
2023-06-16 11:02:10,092:INFO:Creating metrics dataframe
2023-06-16 11:02:10,812:INFO:Uploading results into container
2023-06-16 11:02:10,813:INFO:Uploading model into container now
2023-06-16 11:02:10,813:INFO:_master_model_container: 73
2023-06-16 11:02:10,814:INFO:_display_container: 11
2023-06-16 11:02:10,814:INFO:OrthogonalMatchingPursuit()
2023-06-16 11:02:10,814:INFO:create_model() successfully completed......................................
2023-06-16 11:02:11,005:INFO:SubProcess create_model() end ==================================
2023-06-16 11:02:11,006:INFO:Creating metrics dataframe
2023-06-16 11:02:11,017:INFO:Initializing Bayesian Ridge
2023-06-16 11:02:11,017:INFO:Total runtime is 0.34880196253458656 minutes
2023-06-16 11:02:11,021:INFO:SubProcess create_model() called ==================================
2023-06-16 11:02:11,021:INFO:Initializing create_model()
2023-06-16 11:02:11,021:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196E4077EE0>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:02:11,021:INFO:Checking exceptions
2023-06-16 11:02:11,021:INFO:Importing libraries
2023-06-16 11:02:11,021:INFO:Copying training dataset
2023-06-16 11:02:11,027:INFO:Defining folds
2023-06-16 11:02:11,027:INFO:Declaring metric variables
2023-06-16 11:02:11,030:INFO:Importing untrained model
2023-06-16 11:02:11,033:INFO:Bayesian Ridge Imported successfully
2023-06-16 11:02:11,040:INFO:Starting cross validation
2023-06-16 11:02:11,041:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:02:12,277:INFO:Calculating mean and std
2023-06-16 11:02:12,278:INFO:Creating metrics dataframe
2023-06-16 11:02:12,724:INFO:Uploading results into container
2023-06-16 11:02:12,725:INFO:Uploading model into container now
2023-06-16 11:02:12,725:INFO:_master_model_container: 74
2023-06-16 11:02:12,725:INFO:_display_container: 11
2023-06-16 11:02:12,726:INFO:BayesianRidge()
2023-06-16 11:02:12,726:INFO:create_model() successfully completed......................................
2023-06-16 11:02:12,897:INFO:SubProcess create_model() end ==================================
2023-06-16 11:02:12,897:INFO:Creating metrics dataframe
2023-06-16 11:02:12,908:INFO:Initializing Passive Aggressive Regressor
2023-06-16 11:02:12,908:INFO:Total runtime is 0.3803222099939982 minutes
2023-06-16 11:02:12,911:INFO:SubProcess create_model() called ==================================
2023-06-16 11:02:12,911:INFO:Initializing create_model()
2023-06-16 11:02:12,911:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196E4077EE0>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:02:12,912:INFO:Checking exceptions
2023-06-16 11:02:12,912:INFO:Importing libraries
2023-06-16 11:02:12,912:INFO:Copying training dataset
2023-06-16 11:02:12,921:INFO:Defining folds
2023-06-16 11:02:12,922:INFO:Declaring metric variables
2023-06-16 11:02:12,927:INFO:Importing untrained model
2023-06-16 11:02:12,933:INFO:Passive Aggressive Regressor Imported successfully
2023-06-16 11:02:12,950:INFO:Starting cross validation
2023-06-16 11:02:12,952:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:02:14,128:INFO:Calculating mean and std
2023-06-16 11:02:14,129:INFO:Creating metrics dataframe
2023-06-16 11:02:14,723:INFO:Uploading results into container
2023-06-16 11:02:14,724:INFO:Uploading model into container now
2023-06-16 11:02:14,725:INFO:_master_model_container: 75
2023-06-16 11:02:14,725:INFO:_display_container: 11
2023-06-16 11:02:14,726:INFO:PassiveAggressiveRegressor(random_state=42)
2023-06-16 11:02:14,726:INFO:create_model() successfully completed......................................
2023-06-16 11:02:14,919:INFO:SubProcess create_model() end ==================================
2023-06-16 11:02:14,919:INFO:Creating metrics dataframe
2023-06-16 11:02:14,931:INFO:Initializing Huber Regressor
2023-06-16 11:02:14,931:INFO:Total runtime is 0.4140459060668945 minutes
2023-06-16 11:02:14,935:INFO:SubProcess create_model() called ==================================
2023-06-16 11:02:14,936:INFO:Initializing create_model()
2023-06-16 11:02:14,936:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196E4077EE0>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:02:14,936:INFO:Checking exceptions
2023-06-16 11:02:14,936:INFO:Importing libraries
2023-06-16 11:02:14,936:INFO:Copying training dataset
2023-06-16 11:02:14,953:INFO:Defining folds
2023-06-16 11:02:14,954:INFO:Declaring metric variables
2023-06-16 11:02:14,962:INFO:Importing untrained model
2023-06-16 11:02:14,968:INFO:Huber Regressor Imported successfully
2023-06-16 11:02:14,977:INFO:Starting cross validation
2023-06-16 11:02:14,979:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:02:15,132:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:02:15,139:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:02:15,154:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:02:15,173:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:02:15,177:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:02:16,190:INFO:Calculating mean and std
2023-06-16 11:02:16,191:INFO:Creating metrics dataframe
2023-06-16 11:02:16,717:INFO:Uploading results into container
2023-06-16 11:02:16,719:INFO:Uploading model into container now
2023-06-16 11:02:16,720:INFO:_master_model_container: 76
2023-06-16 11:02:16,720:INFO:_display_container: 11
2023-06-16 11:02:16,720:INFO:HuberRegressor()
2023-06-16 11:02:16,721:INFO:create_model() successfully completed......................................
2023-06-16 11:02:16,916:INFO:SubProcess create_model() end ==================================
2023-06-16 11:02:16,916:INFO:Creating metrics dataframe
2023-06-16 11:02:16,927:INFO:Initializing K Neighbors Regressor
2023-06-16 11:02:16,928:INFO:Total runtime is 0.4473292589187622 minutes
2023-06-16 11:02:16,933:INFO:SubProcess create_model() called ==================================
2023-06-16 11:02:16,933:INFO:Initializing create_model()
2023-06-16 11:02:16,934:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196E4077EE0>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:02:16,934:INFO:Checking exceptions
2023-06-16 11:02:16,934:INFO:Importing libraries
2023-06-16 11:02:16,934:INFO:Copying training dataset
2023-06-16 11:02:16,946:INFO:Defining folds
2023-06-16 11:02:16,946:INFO:Declaring metric variables
2023-06-16 11:02:16,950:INFO:Importing untrained model
2023-06-16 11:02:16,958:INFO:K Neighbors Regressor Imported successfully
2023-06-16 11:02:16,965:INFO:Starting cross validation
2023-06-16 11:02:16,967:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:02:18,263:INFO:Calculating mean and std
2023-06-16 11:02:18,264:INFO:Creating metrics dataframe
2023-06-16 11:02:18,816:INFO:Uploading results into container
2023-06-16 11:02:18,817:INFO:Uploading model into container now
2023-06-16 11:02:18,818:INFO:_master_model_container: 77
2023-06-16 11:02:18,818:INFO:_display_container: 11
2023-06-16 11:02:18,818:INFO:KNeighborsRegressor(n_jobs=-1)
2023-06-16 11:02:18,819:INFO:create_model() successfully completed......................................
2023-06-16 11:02:18,992:INFO:SubProcess create_model() end ==================================
2023-06-16 11:02:18,993:INFO:Creating metrics dataframe
2023-06-16 11:02:19,018:INFO:Initializing Decision Tree Regressor
2023-06-16 11:02:19,019:INFO:Total runtime is 0.48216951290766397 minutes
2023-06-16 11:02:19,022:INFO:SubProcess create_model() called ==================================
2023-06-16 11:02:19,022:INFO:Initializing create_model()
2023-06-16 11:02:19,022:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196E4077EE0>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:02:19,022:INFO:Checking exceptions
2023-06-16 11:02:19,022:INFO:Importing libraries
2023-06-16 11:02:19,022:INFO:Copying training dataset
2023-06-16 11:02:19,032:INFO:Defining folds
2023-06-16 11:02:19,032:INFO:Declaring metric variables
2023-06-16 11:02:19,040:INFO:Importing untrained model
2023-06-16 11:02:19,046:INFO:Decision Tree Regressor Imported successfully
2023-06-16 11:02:19,057:INFO:Starting cross validation
2023-06-16 11:02:19,059:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:02:20,258:INFO:Calculating mean and std
2023-06-16 11:02:20,261:INFO:Creating metrics dataframe
2023-06-16 11:02:20,824:INFO:Uploading results into container
2023-06-16 11:02:20,825:INFO:Uploading model into container now
2023-06-16 11:02:20,825:INFO:_master_model_container: 78
2023-06-16 11:02:20,825:INFO:_display_container: 11
2023-06-16 11:02:20,826:INFO:DecisionTreeRegressor(random_state=42)
2023-06-16 11:02:20,826:INFO:create_model() successfully completed......................................
2023-06-16 11:02:21,020:INFO:SubProcess create_model() end ==================================
2023-06-16 11:02:21,020:INFO:Creating metrics dataframe
2023-06-16 11:02:21,031:INFO:Initializing Random Forest Regressor
2023-06-16 11:02:21,032:INFO:Total runtime is 0.5157218138376871 minutes
2023-06-16 11:02:21,035:INFO:SubProcess create_model() called ==================================
2023-06-16 11:02:21,035:INFO:Initializing create_model()
2023-06-16 11:02:21,035:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196E4077EE0>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:02:21,035:INFO:Checking exceptions
2023-06-16 11:02:21,036:INFO:Importing libraries
2023-06-16 11:02:21,036:INFO:Copying training dataset
2023-06-16 11:02:21,041:INFO:Defining folds
2023-06-16 11:02:21,041:INFO:Declaring metric variables
2023-06-16 11:02:21,045:INFO:Importing untrained model
2023-06-16 11:02:21,050:INFO:Random Forest Regressor Imported successfully
2023-06-16 11:02:21,061:INFO:Starting cross validation
2023-06-16 11:02:21,062:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:02:22,463:INFO:Calculating mean and std
2023-06-16 11:02:22,464:INFO:Creating metrics dataframe
2023-06-16 11:02:23,140:INFO:Uploading results into container
2023-06-16 11:02:23,140:INFO:Uploading model into container now
2023-06-16 11:02:23,141:INFO:_master_model_container: 79
2023-06-16 11:02:23,141:INFO:_display_container: 11
2023-06-16 11:02:23,141:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 11:02:23,141:INFO:create_model() successfully completed......................................
2023-06-16 11:02:23,318:INFO:SubProcess create_model() end ==================================
2023-06-16 11:02:23,319:INFO:Creating metrics dataframe
2023-06-16 11:02:23,331:INFO:Initializing Extra Trees Regressor
2023-06-16 11:02:23,331:INFO:Total runtime is 0.5540479024251301 minutes
2023-06-16 11:02:23,334:INFO:SubProcess create_model() called ==================================
2023-06-16 11:02:23,334:INFO:Initializing create_model()
2023-06-16 11:02:23,334:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196E4077EE0>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:02:23,335:INFO:Checking exceptions
2023-06-16 11:02:23,335:INFO:Importing libraries
2023-06-16 11:02:23,335:INFO:Copying training dataset
2023-06-16 11:02:23,343:INFO:Defining folds
2023-06-16 11:02:23,343:INFO:Declaring metric variables
2023-06-16 11:02:23,346:INFO:Importing untrained model
2023-06-16 11:02:23,351:INFO:Extra Trees Regressor Imported successfully
2023-06-16 11:02:23,359:INFO:Starting cross validation
2023-06-16 11:02:23,361:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:02:24,776:INFO:Calculating mean and std
2023-06-16 11:02:24,777:INFO:Creating metrics dataframe
2023-06-16 11:02:25,406:INFO:Uploading results into container
2023-06-16 11:02:25,407:INFO:Uploading model into container now
2023-06-16 11:02:25,408:INFO:_master_model_container: 80
2023-06-16 11:02:25,408:INFO:_display_container: 11
2023-06-16 11:02:25,408:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2023-06-16 11:02:25,408:INFO:create_model() successfully completed......................................
2023-06-16 11:02:25,613:INFO:SubProcess create_model() end ==================================
2023-06-16 11:02:25,613:INFO:Creating metrics dataframe
2023-06-16 11:02:25,626:INFO:Initializing AdaBoost Regressor
2023-06-16 11:02:25,626:INFO:Total runtime is 0.5922858874003092 minutes
2023-06-16 11:02:25,630:INFO:SubProcess create_model() called ==================================
2023-06-16 11:02:25,631:INFO:Initializing create_model()
2023-06-16 11:02:25,631:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196E4077EE0>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:02:25,631:INFO:Checking exceptions
2023-06-16 11:02:25,632:INFO:Importing libraries
2023-06-16 11:02:25,632:INFO:Copying training dataset
2023-06-16 11:02:25,646:INFO:Defining folds
2023-06-16 11:02:25,647:INFO:Declaring metric variables
2023-06-16 11:02:25,651:INFO:Importing untrained model
2023-06-16 11:02:25,663:INFO:AdaBoost Regressor Imported successfully
2023-06-16 11:02:25,676:INFO:Starting cross validation
2023-06-16 11:02:25,679:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:02:26,889:INFO:Calculating mean and std
2023-06-16 11:02:26,891:INFO:Creating metrics dataframe
2023-06-16 11:02:27,494:INFO:Uploading results into container
2023-06-16 11:02:27,495:INFO:Uploading model into container now
2023-06-16 11:02:27,495:INFO:_master_model_container: 81
2023-06-16 11:02:27,495:INFO:_display_container: 11
2023-06-16 11:02:27,495:INFO:AdaBoostRegressor(random_state=42)
2023-06-16 11:02:27,496:INFO:create_model() successfully completed......................................
2023-06-16 11:02:27,669:INFO:SubProcess create_model() end ==================================
2023-06-16 11:02:27,669:INFO:Creating metrics dataframe
2023-06-16 11:02:27,682:INFO:Initializing Gradient Boosting Regressor
2023-06-16 11:02:27,682:INFO:Total runtime is 0.6265646855036417 minutes
2023-06-16 11:02:27,685:INFO:SubProcess create_model() called ==================================
2023-06-16 11:02:27,685:INFO:Initializing create_model()
2023-06-16 11:02:27,685:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196E4077EE0>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:02:27,686:INFO:Checking exceptions
2023-06-16 11:02:27,686:INFO:Importing libraries
2023-06-16 11:02:27,686:INFO:Copying training dataset
2023-06-16 11:02:27,695:INFO:Defining folds
2023-06-16 11:02:27,695:INFO:Declaring metric variables
2023-06-16 11:02:27,699:INFO:Importing untrained model
2023-06-16 11:02:27,703:INFO:Gradient Boosting Regressor Imported successfully
2023-06-16 11:02:27,720:INFO:Starting cross validation
2023-06-16 11:02:27,722:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:02:28,999:INFO:Calculating mean and std
2023-06-16 11:02:29,000:INFO:Creating metrics dataframe
2023-06-16 11:02:29,620:INFO:Uploading results into container
2023-06-16 11:02:29,622:INFO:Uploading model into container now
2023-06-16 11:02:29,623:INFO:_master_model_container: 82
2023-06-16 11:02:29,626:INFO:_display_container: 11
2023-06-16 11:02:29,628:INFO:GradientBoostingRegressor(random_state=42)
2023-06-16 11:02:29,628:INFO:create_model() successfully completed......................................
2023-06-16 11:02:29,825:INFO:SubProcess create_model() end ==================================
2023-06-16 11:02:29,826:INFO:Creating metrics dataframe
2023-06-16 11:02:29,838:INFO:Initializing Extreme Gradient Boosting
2023-06-16 11:02:29,838:INFO:Total runtime is 0.6624952753384908 minutes
2023-06-16 11:02:29,843:INFO:SubProcess create_model() called ==================================
2023-06-16 11:02:29,843:INFO:Initializing create_model()
2023-06-16 11:02:29,843:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196E4077EE0>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:02:29,843:INFO:Checking exceptions
2023-06-16 11:02:29,843:INFO:Importing libraries
2023-06-16 11:02:29,843:INFO:Copying training dataset
2023-06-16 11:02:29,856:INFO:Defining folds
2023-06-16 11:02:29,857:INFO:Declaring metric variables
2023-06-16 11:02:29,860:INFO:Importing untrained model
2023-06-16 11:02:29,866:INFO:Extreme Gradient Boosting Imported successfully
2023-06-16 11:02:29,873:INFO:Starting cross validation
2023-06-16 11:02:29,874:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:02:31,237:INFO:Calculating mean and std
2023-06-16 11:02:31,239:INFO:Creating metrics dataframe
2023-06-16 11:02:31,973:INFO:Uploading results into container
2023-06-16 11:02:31,974:INFO:Uploading model into container now
2023-06-16 11:02:31,976:INFO:_master_model_container: 83
2023-06-16 11:02:31,976:INFO:_display_container: 11
2023-06-16 11:02:31,979:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=42, ...)
2023-06-16 11:02:31,979:INFO:create_model() successfully completed......................................
2023-06-16 11:02:32,182:INFO:SubProcess create_model() end ==================================
2023-06-16 11:02:32,182:INFO:Creating metrics dataframe
2023-06-16 11:02:32,196:INFO:Initializing Light Gradient Boosting Machine
2023-06-16 11:02:32,197:INFO:Total runtime is 0.7018043120702108 minutes
2023-06-16 11:02:32,200:INFO:SubProcess create_model() called ==================================
2023-06-16 11:02:32,200:INFO:Initializing create_model()
2023-06-16 11:02:32,200:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196E4077EE0>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:02:32,200:INFO:Checking exceptions
2023-06-16 11:02:32,201:INFO:Importing libraries
2023-06-16 11:02:32,201:INFO:Copying training dataset
2023-06-16 11:02:32,207:INFO:Defining folds
2023-06-16 11:02:32,207:INFO:Declaring metric variables
2023-06-16 11:02:32,211:INFO:Importing untrained model
2023-06-16 11:02:32,214:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-16 11:02:32,224:INFO:Starting cross validation
2023-06-16 11:02:32,225:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:02:34,452:INFO:Calculating mean and std
2023-06-16 11:02:34,454:INFO:Creating metrics dataframe
2023-06-16 11:02:35,122:INFO:Uploading results into container
2023-06-16 11:02:35,123:INFO:Uploading model into container now
2023-06-16 11:02:35,123:INFO:_master_model_container: 84
2023-06-16 11:02:35,123:INFO:_display_container: 11
2023-06-16 11:02:35,124:INFO:LGBMRegressor(random_state=42)
2023-06-16 11:02:35,124:INFO:create_model() successfully completed......................................
2023-06-16 11:02:35,314:INFO:SubProcess create_model() end ==================================
2023-06-16 11:02:35,314:INFO:Creating metrics dataframe
2023-06-16 11:02:35,327:INFO:Initializing Dummy Regressor
2023-06-16 11:02:35,327:INFO:Total runtime is 0.7539791941642762 minutes
2023-06-16 11:02:35,330:INFO:SubProcess create_model() called ==================================
2023-06-16 11:02:35,330:INFO:Initializing create_model()
2023-06-16 11:02:35,332:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196E4077EE0>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:02:35,332:INFO:Checking exceptions
2023-06-16 11:02:35,332:INFO:Importing libraries
2023-06-16 11:02:35,332:INFO:Copying training dataset
2023-06-16 11:02:35,346:INFO:Defining folds
2023-06-16 11:02:35,352:INFO:Declaring metric variables
2023-06-16 11:02:35,357:INFO:Importing untrained model
2023-06-16 11:02:35,362:INFO:Dummy Regressor Imported successfully
2023-06-16 11:02:35,369:INFO:Starting cross validation
2023-06-16 11:02:35,370:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:02:36,498:INFO:Calculating mean and std
2023-06-16 11:02:36,499:INFO:Creating metrics dataframe
2023-06-16 11:02:37,065:INFO:Uploading results into container
2023-06-16 11:02:37,065:INFO:Uploading model into container now
2023-06-16 11:02:37,065:INFO:_master_model_container: 85
2023-06-16 11:02:37,065:INFO:_display_container: 11
2023-06-16 11:02:37,069:INFO:DummyRegressor()
2023-06-16 11:02:37,069:INFO:create_model() successfully completed......................................
2023-06-16 11:02:37,257:INFO:SubProcess create_model() end ==================================
2023-06-16 11:02:37,257:INFO:Creating metrics dataframe
2023-06-16 11:02:37,288:INFO:Initializing create_model()
2023-06-16 11:02:37,288:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:02:37,288:INFO:Checking exceptions
2023-06-16 11:02:37,290:INFO:Importing libraries
2023-06-16 11:02:37,290:INFO:Copying training dataset
2023-06-16 11:02:37,298:INFO:Defining folds
2023-06-16 11:02:37,298:INFO:Declaring metric variables
2023-06-16 11:02:37,299:INFO:Importing untrained model
2023-06-16 11:02:37,299:INFO:Declaring custom model
2023-06-16 11:02:37,300:INFO:Random Forest Regressor Imported successfully
2023-06-16 11:02:37,302:INFO:Cross validation set to False
2023-06-16 11:02:37,302:INFO:Fitting Model
2023-06-16 11:02:37,608:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 11:02:37,608:INFO:create_model() successfully completed......................................
2023-06-16 11:02:37,879:INFO:_master_model_container: 85
2023-06-16 11:02:37,879:INFO:_display_container: 11
2023-06-16 11:02:37,879:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 11:02:37,879:INFO:compare_models() successfully completed......................................
2023-06-16 11:02:49,976:INFO:Initializing create_model()
2023-06-16 11:02:49,976:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=rf, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:02:49,977:INFO:Checking exceptions
2023-06-16 11:02:50,003:INFO:Importing libraries
2023-06-16 11:02:50,003:INFO:Copying training dataset
2023-06-16 11:02:50,010:INFO:Defining folds
2023-06-16 11:02:50,010:INFO:Declaring metric variables
2023-06-16 11:02:50,013:INFO:Importing untrained model
2023-06-16 11:02:50,016:INFO:Random Forest Regressor Imported successfully
2023-06-16 11:02:50,026:INFO:Starting cross validation
2023-06-16 11:02:50,028:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:02:51,330:INFO:Calculating mean and std
2023-06-16 11:02:51,331:INFO:Creating metrics dataframe
2023-06-16 11:02:51,337:INFO:Finalizing model
2023-06-16 11:02:51,820:INFO:Uploading results into container
2023-06-16 11:02:51,823:INFO:Uploading model into container now
2023-06-16 11:02:51,835:INFO:_master_model_container: 86
2023-06-16 11:02:51,835:INFO:_display_container: 12
2023-06-16 11:02:51,836:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 11:02:51,836:INFO:create_model() successfully completed......................................
2023-06-16 11:03:02,511:INFO:Initializing plot_model()
2023-06-16 11:03:02,511:INFO:plot_model(plot=learning, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, system=True)
2023-06-16 11:03:02,511:INFO:Checking exceptions
2023-06-16 11:03:02,538:INFO:Preloading libraries
2023-06-16 11:03:02,569:INFO:Copying training dataset
2023-06-16 11:03:02,569:INFO:Plot type: learning
2023-06-16 11:03:02,654:INFO:Fitting Model
2023-06-16 11:04:24,837:INFO:Visual Rendered Successfully
2023-06-16 11:04:25,095:INFO:plot_model() successfully completed......................................
2023-06-16 11:04:25,114:INFO:Initializing plot_model()
2023-06-16 11:04:25,114:INFO:plot_model(plot=vc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, system=True)
2023-06-16 11:04:25,114:INFO:Checking exceptions
2023-06-16 11:04:25,147:INFO:Preloading libraries
2023-06-16 11:04:25,212:INFO:Copying training dataset
2023-06-16 11:04:25,213:INFO:Plot type: vc
2023-06-16 11:04:25,214:INFO:Determining param_name
2023-06-16 11:04:25,214:INFO:param_name: max_depth
2023-06-16 11:04:25,398:INFO:Fitting Model
2023-06-16 11:05:19,690:INFO:Visual Rendered Successfully
2023-06-16 11:05:20,003:INFO:plot_model() successfully completed......................................
2023-06-16 11:06:30,078:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-16 11:06:30,078:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-16 11:06:30,078:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-16 11:06:30,078:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-16 11:06:31,110:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-16 11:06:53,695:INFO:PyCaret RegressionExperiment
2023-06-16 11:06:53,695:INFO:Logging name: reg-default-name
2023-06-16 11:06:53,695:INFO:ML Usecase: MLUsecase.REGRESSION
2023-06-16 11:06:53,695:INFO:version 3.0.2
2023-06-16 11:06:53,696:INFO:Initializing setup()
2023-06-16 11:06:53,696:INFO:self.USI: 716a
2023-06-16 11:06:53,696:INFO:self._variable_keys: {'gpu_param', 'y_train', 'X', '_ml_usecase', 'log_plots_param', 'exp_name_log', 'n_jobs_param', 'y', 'pipeline', 'idx', 'fold_shuffle_param', '_available_plots', 'seed', 'X_test', 'gpu_n_jobs_param', 'logging_param', 'data', 'target_param', 'X_train', 'exp_id', 'transform_target_param', 'USI', 'memory', 'html_param', 'fold_groups_param', 'y_test', 'fold_generator'}
2023-06-16 11:06:53,696:INFO:Checking environment
2023-06-16 11:06:53,696:INFO:python_version: 3.10.9
2023-06-16 11:06:53,696:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-06-16 11:06:53,696:INFO:machine: AMD64
2023-06-16 11:06:53,696:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-16 11:06:53,696:INFO:Memory: svmem(total=16901767168, available=5983035392, percent=64.6, used=10918731776, free=5983035392)
2023-06-16 11:06:53,696:INFO:Physical Core: 4
2023-06-16 11:06:53,697:INFO:Logical Core: 8
2023-06-16 11:06:53,697:INFO:Checking libraries
2023-06-16 11:06:53,697:INFO:System:
2023-06-16 11:06:53,697:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-06-16 11:06:53,697:INFO:executable: C:\Users\lapei\anaconda3\python.exe
2023-06-16 11:06:53,697:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-16 11:06:53,697:INFO:PyCaret required dependencies:
2023-06-16 11:06:53,697:INFO:                 pip: 22.3.1
2023-06-16 11:06:53,697:INFO:          setuptools: 65.6.3
2023-06-16 11:06:53,697:INFO:             pycaret: 3.0.2
2023-06-16 11:06:53,698:INFO:             IPython: 8.10.0
2023-06-16 11:06:53,698:INFO:          ipywidgets: 7.6.5
2023-06-16 11:06:53,698:INFO:                tqdm: 4.64.1
2023-06-16 11:06:53,698:INFO:               numpy: 1.23.5
2023-06-16 11:06:53,698:INFO:              pandas: 1.5.3
2023-06-16 11:06:53,698:INFO:              jinja2: 3.1.2
2023-06-16 11:06:53,698:INFO:               scipy: 1.10.0
2023-06-16 11:06:53,698:INFO:              joblib: 1.2.0
2023-06-16 11:06:53,698:INFO:             sklearn: 1.2.1
2023-06-16 11:06:53,698:INFO:                pyod: 1.0.9
2023-06-16 11:06:53,698:INFO:            imblearn: 0.10.1
2023-06-16 11:06:53,699:INFO:   category_encoders: 2.6.1
2023-06-16 11:06:53,699:INFO:            lightgbm: 3.3.5
2023-06-16 11:06:53,699:INFO:               numba: 0.56.4
2023-06-16 11:06:53,699:INFO:            requests: 2.28.1
2023-06-16 11:06:53,699:INFO:          matplotlib: 3.7.0
2023-06-16 11:06:53,699:INFO:          scikitplot: 0.3.7
2023-06-16 11:06:53,699:INFO:         yellowbrick: 1.5
2023-06-16 11:06:53,699:INFO:              plotly: 5.9.0
2023-06-16 11:06:53,699:INFO:             kaleido: 0.2.1
2023-06-16 11:06:53,699:INFO:         statsmodels: 0.13.5
2023-06-16 11:06:53,699:INFO:              sktime: 0.17.0
2023-06-16 11:06:53,699:INFO:               tbats: 1.1.3
2023-06-16 11:06:53,700:INFO:            pmdarima: 2.0.3
2023-06-16 11:06:53,700:INFO:              psutil: 5.9.0
2023-06-16 11:06:53,700:INFO:PyCaret optional dependencies:
2023-06-16 11:06:53,748:INFO:                shap: 0.41.0
2023-06-16 11:06:53,748:INFO:           interpret: Not installed
2023-06-16 11:06:53,748:INFO:                umap: Not installed
2023-06-16 11:06:53,748:INFO:    pandas_profiling: Not installed
2023-06-16 11:06:53,748:INFO:  explainerdashboard: Not installed
2023-06-16 11:06:53,748:INFO:             autoviz: Not installed
2023-06-16 11:06:53,748:INFO:           fairlearn: Not installed
2023-06-16 11:06:53,748:INFO:             xgboost: 1.7.3
2023-06-16 11:06:53,748:INFO:            catboost: Not installed
2023-06-16 11:06:53,748:INFO:              kmodes: Not installed
2023-06-16 11:06:53,749:INFO:             mlxtend: Not installed
2023-06-16 11:06:53,749:INFO:       statsforecast: Not installed
2023-06-16 11:06:53,749:INFO:        tune_sklearn: Not installed
2023-06-16 11:06:53,749:INFO:                 ray: Not installed
2023-06-16 11:06:53,749:INFO:            hyperopt: Not installed
2023-06-16 11:06:53,749:INFO:              optuna: Not installed
2023-06-16 11:06:53,749:INFO:               skopt: 0.9.0
2023-06-16 11:06:53,749:INFO:              mlflow: Not installed
2023-06-16 11:06:53,749:INFO:              gradio: Not installed
2023-06-16 11:06:53,749:INFO:             fastapi: Not installed
2023-06-16 11:06:53,749:INFO:             uvicorn: Not installed
2023-06-16 11:06:53,749:INFO:              m2cgen: Not installed
2023-06-16 11:06:53,749:INFO:           evidently: Not installed
2023-06-16 11:06:53,749:INFO:               fugue: Not installed
2023-06-16 11:06:53,749:INFO:           streamlit: Not installed
2023-06-16 11:06:53,749:INFO:             prophet: Not installed
2023-06-16 11:06:53,749:INFO:None
2023-06-16 11:06:53,749:INFO:Set up data.
2023-06-16 11:06:53,759:INFO:Set up train/test split.
2023-06-16 11:06:53,763:INFO:Set up index.
2023-06-16 11:06:53,764:INFO:Set up folding strategy.
2023-06-16 11:06:53,764:INFO:Assigning column types.
2023-06-16 11:06:53,767:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-16 11:06:53,768:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-16 11:06:53,772:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-16 11:06:53,778:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-16 11:06:53,862:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-16 11:06:53,926:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-16 11:06:53,927:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 11:06:54,167:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 11:06:54,167:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-16 11:06:54,174:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-16 11:06:54,181:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-16 11:06:54,236:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-16 11:06:54,278:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-16 11:06:54,279:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 11:06:54,281:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 11:06:54,281:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-06-16 11:06:54,286:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-16 11:06:54,290:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-16 11:06:54,365:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-16 11:06:54,407:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-16 11:06:54,407:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 11:06:54,410:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 11:06:54,415:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-16 11:06:54,419:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-16 11:06:54,474:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-16 11:06:54,516:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-16 11:06:54,517:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 11:06:54,519:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 11:06:54,520:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-06-16 11:06:54,528:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-16 11:06:54,584:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-16 11:06:54,630:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-16 11:06:54,630:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 11:06:54,633:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 11:06:54,642:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-16 11:06:54,716:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-16 11:06:54,757:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-16 11:06:54,758:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 11:06:54,761:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 11:06:54,761:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-06-16 11:06:54,853:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-16 11:06:54,895:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-16 11:06:54,898:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 11:06:54,900:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 11:06:54,965:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-16 11:06:55,047:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-16 11:06:55,048:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 11:06:55,055:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 11:06:55,056:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-16 11:06:55,121:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-16 11:06:55,173:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 11:06:55,176:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 11:06:55,273:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-16 11:06:55,316:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 11:06:55,319:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 11:06:55,319:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-06-16 11:06:55,429:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 11:06:55,431:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 11:06:55,541:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 11:06:55,543:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 11:06:55,546:INFO:Preparing preprocessing pipeline...
2023-06-16 11:06:55,546:INFO:Set up simple imputation.
2023-06-16 11:06:55,547:INFO:Set up column name cleaning.
2023-06-16 11:06:55,598:INFO:Finished creating preprocessing pipeline.
2023-06-16 11:06:55,612:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\lapei\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['taxa_homicidio', 'RH_adm_dir',
                                             'densidade_banda_larga',
                                             'densidade_telefonia_movel',
                                             'qtd_cursos_engenharias',
                                             'qtd_cursos_negocios_direito',
                                             'media_notas_CN', 'media_notas_CH',
                                             'media_NU_NOTA_LC',
                                             'media_NU_NOTA_MT',
                                             'media_...
                                             'Isencao_ISSQN_Sim',
                                             'Isencao_Tx_Sim',
                                             'Cessao_terrenos_Sim',
                                             'Doacao_terrenos_Sim',
                                             'Outros_mecanismos_Sim',
                                             'ISH_Baixa', 'ISH_Máxima',
                                             'ISH_Média', 'ISH_Mínima'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-06-16 11:06:55,613:INFO:Creating final display dataframe.
2023-06-16 11:06:55,737:INFO:Setup _display_container:                     Description                              Value
0                    Session id                                 42
1                        Target  qtd_abertas_Empresario_Individual
2                   Target type                         Regression
3           Original data shape                         (4456, 30)
4        Transformed data shape                         (4456, 30)
5   Transformed train set shape                         (3119, 30)
6    Transformed test set shape                         (1337, 30)
7              Numeric features                                 29
8                    Preprocess                               True
9               Imputation type                             simple
10           Numeric imputation                               mean
11       Categorical imputation                               mode
12               Fold Generator                              KFold
13                  Fold Number                                 10
14                     CPU Jobs                                 -1
15                      Use GPU                              False
16               Log Experiment                              False
17              Experiment Name                   reg-default-name
18                          USI                               716a
2023-06-16 11:06:55,883:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 11:06:55,887:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 11:06:55,998:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 11:06:56,000:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 11:06:56,001:INFO:setup() successfully completed in 2.59s...............
2023-06-16 11:07:04,495:INFO:Initializing compare_models()
2023-06-16 11:07:04,495:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, include=None, fold=5, round=4, cross_validation=True, sort=RMSE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, 'include': None, 'exclude': None, 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'RMSE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-06-16 11:07:04,496:INFO:Checking exceptions
2023-06-16 11:07:04,500:INFO:Preparing display monitor
2023-06-16 11:07:04,539:INFO:Initializing Linear Regression
2023-06-16 11:07:04,540:INFO:Total runtime is 1.6717116038004556e-05 minutes
2023-06-16 11:07:04,544:INFO:SubProcess create_model() called ==================================
2023-06-16 11:07:04,544:INFO:Initializing create_model()
2023-06-16 11:07:04,544:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023066344AF0>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:07:04,545:INFO:Checking exceptions
2023-06-16 11:07:04,545:INFO:Importing libraries
2023-06-16 11:07:04,545:INFO:Copying training dataset
2023-06-16 11:07:04,550:INFO:Defining folds
2023-06-16 11:07:04,550:INFO:Declaring metric variables
2023-06-16 11:07:04,554:INFO:Importing untrained model
2023-06-16 11:07:04,560:INFO:Linear Regression Imported successfully
2023-06-16 11:07:04,565:INFO:Starting cross validation
2023-06-16 11:07:04,572:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:07:10,175:INFO:Calculating mean and std
2023-06-16 11:07:10,177:INFO:Creating metrics dataframe
2023-06-16 11:07:10,660:INFO:Uploading results into container
2023-06-16 11:07:10,661:INFO:Uploading model into container now
2023-06-16 11:07:10,661:INFO:_master_model_container: 1
2023-06-16 11:07:10,661:INFO:_display_container: 2
2023-06-16 11:07:10,661:INFO:LinearRegression(n_jobs=-1)
2023-06-16 11:07:10,661:INFO:create_model() successfully completed......................................
2023-06-16 11:07:10,811:INFO:SubProcess create_model() end ==================================
2023-06-16 11:07:10,811:INFO:Creating metrics dataframe
2023-06-16 11:07:10,821:INFO:Initializing Lasso Regression
2023-06-16 11:07:10,821:INFO:Total runtime is 0.10469270547231038 minutes
2023-06-16 11:07:10,826:INFO:SubProcess create_model() called ==================================
2023-06-16 11:07:10,826:INFO:Initializing create_model()
2023-06-16 11:07:10,826:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023066344AF0>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:07:10,826:INFO:Checking exceptions
2023-06-16 11:07:10,826:INFO:Importing libraries
2023-06-16 11:07:10,826:INFO:Copying training dataset
2023-06-16 11:07:10,841:INFO:Defining folds
2023-06-16 11:07:10,841:INFO:Declaring metric variables
2023-06-16 11:07:10,846:INFO:Importing untrained model
2023-06-16 11:07:10,851:INFO:Lasso Regression Imported successfully
2023-06-16 11:07:10,860:INFO:Starting cross validation
2023-06-16 11:07:10,861:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:07:13,728:INFO:Calculating mean and std
2023-06-16 11:07:13,730:INFO:Creating metrics dataframe
2023-06-16 11:07:14,170:INFO:Uploading results into container
2023-06-16 11:07:14,171:INFO:Uploading model into container now
2023-06-16 11:07:14,172:INFO:_master_model_container: 2
2023-06-16 11:07:14,172:INFO:_display_container: 2
2023-06-16 11:07:14,173:INFO:Lasso(random_state=42)
2023-06-16 11:07:14,173:INFO:create_model() successfully completed......................................
2023-06-16 11:07:14,295:INFO:SubProcess create_model() end ==================================
2023-06-16 11:07:14,295:INFO:Creating metrics dataframe
2023-06-16 11:07:14,308:INFO:Initializing Ridge Regression
2023-06-16 11:07:14,308:INFO:Total runtime is 0.16280727386474608 minutes
2023-06-16 11:07:14,325:INFO:SubProcess create_model() called ==================================
2023-06-16 11:07:14,326:INFO:Initializing create_model()
2023-06-16 11:07:14,326:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023066344AF0>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:07:14,326:INFO:Checking exceptions
2023-06-16 11:07:14,326:INFO:Importing libraries
2023-06-16 11:07:14,326:INFO:Copying training dataset
2023-06-16 11:07:14,335:INFO:Defining folds
2023-06-16 11:07:14,335:INFO:Declaring metric variables
2023-06-16 11:07:14,339:INFO:Importing untrained model
2023-06-16 11:07:14,342:INFO:Ridge Regression Imported successfully
2023-06-16 11:07:14,351:INFO:Starting cross validation
2023-06-16 11:07:14,353:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:07:15,611:INFO:Calculating mean and std
2023-06-16 11:07:15,613:INFO:Creating metrics dataframe
2023-06-16 11:07:15,984:INFO:Uploading results into container
2023-06-16 11:07:15,986:INFO:Uploading model into container now
2023-06-16 11:07:15,987:INFO:_master_model_container: 3
2023-06-16 11:07:15,987:INFO:_display_container: 2
2023-06-16 11:07:15,987:INFO:Ridge(random_state=42)
2023-06-16 11:07:15,987:INFO:create_model() successfully completed......................................
2023-06-16 11:07:16,124:INFO:SubProcess create_model() end ==================================
2023-06-16 11:07:16,125:INFO:Creating metrics dataframe
2023-06-16 11:07:16,149:INFO:Initializing Elastic Net
2023-06-16 11:07:16,150:INFO:Total runtime is 0.19351067940394082 minutes
2023-06-16 11:07:16,156:INFO:SubProcess create_model() called ==================================
2023-06-16 11:07:16,156:INFO:Initializing create_model()
2023-06-16 11:07:16,157:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023066344AF0>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:07:16,157:INFO:Checking exceptions
2023-06-16 11:07:16,157:INFO:Importing libraries
2023-06-16 11:07:16,157:INFO:Copying training dataset
2023-06-16 11:07:16,166:INFO:Defining folds
2023-06-16 11:07:16,166:INFO:Declaring metric variables
2023-06-16 11:07:16,174:INFO:Importing untrained model
2023-06-16 11:07:16,179:INFO:Elastic Net Imported successfully
2023-06-16 11:07:16,187:INFO:Starting cross validation
2023-06-16 11:07:16,188:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:07:17,450:INFO:Calculating mean and std
2023-06-16 11:07:17,451:INFO:Creating metrics dataframe
2023-06-16 11:07:17,847:INFO:Uploading results into container
2023-06-16 11:07:17,851:INFO:Uploading model into container now
2023-06-16 11:07:17,853:INFO:_master_model_container: 4
2023-06-16 11:07:17,853:INFO:_display_container: 2
2023-06-16 11:07:17,854:INFO:ElasticNet(random_state=42)
2023-06-16 11:07:17,854:INFO:create_model() successfully completed......................................
2023-06-16 11:07:18,064:INFO:SubProcess create_model() end ==================================
2023-06-16 11:07:18,064:INFO:Creating metrics dataframe
2023-06-16 11:07:18,082:INFO:Initializing Least Angle Regression
2023-06-16 11:07:18,083:INFO:Total runtime is 0.22572522163391112 minutes
2023-06-16 11:07:18,090:INFO:SubProcess create_model() called ==================================
2023-06-16 11:07:18,090:INFO:Initializing create_model()
2023-06-16 11:07:18,091:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023066344AF0>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:07:18,091:INFO:Checking exceptions
2023-06-16 11:07:18,092:INFO:Importing libraries
2023-06-16 11:07:18,092:INFO:Copying training dataset
2023-06-16 11:07:18,108:INFO:Defining folds
2023-06-16 11:07:18,108:INFO:Declaring metric variables
2023-06-16 11:07:18,114:INFO:Importing untrained model
2023-06-16 11:07:18,118:INFO:Least Angle Regression Imported successfully
2023-06-16 11:07:18,137:INFO:Starting cross validation
2023-06-16 11:07:18,139:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:07:19,754:INFO:Calculating mean and std
2023-06-16 11:07:19,756:INFO:Creating metrics dataframe
2023-06-16 11:07:20,180:INFO:Uploading results into container
2023-06-16 11:07:20,181:INFO:Uploading model into container now
2023-06-16 11:07:20,181:INFO:_master_model_container: 5
2023-06-16 11:07:20,181:INFO:_display_container: 2
2023-06-16 11:07:20,181:INFO:Lars(random_state=42)
2023-06-16 11:07:20,182:INFO:create_model() successfully completed......................................
2023-06-16 11:07:20,313:INFO:SubProcess create_model() end ==================================
2023-06-16 11:07:20,313:INFO:Creating metrics dataframe
2023-06-16 11:07:20,337:INFO:Initializing Lasso Least Angle Regression
2023-06-16 11:07:20,338:INFO:Total runtime is 0.2633046150207519 minutes
2023-06-16 11:07:20,343:INFO:SubProcess create_model() called ==================================
2023-06-16 11:07:20,343:INFO:Initializing create_model()
2023-06-16 11:07:20,343:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023066344AF0>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:07:20,343:INFO:Checking exceptions
2023-06-16 11:07:20,343:INFO:Importing libraries
2023-06-16 11:07:20,343:INFO:Copying training dataset
2023-06-16 11:07:20,351:INFO:Defining folds
2023-06-16 11:07:20,352:INFO:Declaring metric variables
2023-06-16 11:07:20,360:INFO:Importing untrained model
2023-06-16 11:07:20,369:INFO:Lasso Least Angle Regression Imported successfully
2023-06-16 11:07:20,376:INFO:Starting cross validation
2023-06-16 11:07:20,377:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:07:21,640:INFO:Calculating mean and std
2023-06-16 11:07:21,641:INFO:Creating metrics dataframe
2023-06-16 11:07:22,160:INFO:Uploading results into container
2023-06-16 11:07:22,160:INFO:Uploading model into container now
2023-06-16 11:07:22,161:INFO:_master_model_container: 6
2023-06-16 11:07:22,161:INFO:_display_container: 2
2023-06-16 11:07:22,162:INFO:LassoLars(random_state=42)
2023-06-16 11:07:22,162:INFO:create_model() successfully completed......................................
2023-06-16 11:07:22,300:INFO:SubProcess create_model() end ==================================
2023-06-16 11:07:22,301:INFO:Creating metrics dataframe
2023-06-16 11:07:22,319:INFO:Initializing Orthogonal Matching Pursuit
2023-06-16 11:07:22,320:INFO:Total runtime is 0.29633672634760533 minutes
2023-06-16 11:07:22,329:INFO:SubProcess create_model() called ==================================
2023-06-16 11:07:22,329:INFO:Initializing create_model()
2023-06-16 11:07:22,329:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023066344AF0>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:07:22,329:INFO:Checking exceptions
2023-06-16 11:07:22,329:INFO:Importing libraries
2023-06-16 11:07:22,329:INFO:Copying training dataset
2023-06-16 11:07:22,338:INFO:Defining folds
2023-06-16 11:07:22,339:INFO:Declaring metric variables
2023-06-16 11:07:22,343:INFO:Importing untrained model
2023-06-16 11:07:22,350:INFO:Orthogonal Matching Pursuit Imported successfully
2023-06-16 11:07:22,359:INFO:Starting cross validation
2023-06-16 11:07:22,360:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:07:23,686:INFO:Calculating mean and std
2023-06-16 11:07:23,687:INFO:Creating metrics dataframe
2023-06-16 11:07:24,177:INFO:Uploading results into container
2023-06-16 11:07:24,178:INFO:Uploading model into container now
2023-06-16 11:07:24,180:INFO:_master_model_container: 7
2023-06-16 11:07:24,181:INFO:_display_container: 2
2023-06-16 11:07:24,181:INFO:OrthogonalMatchingPursuit()
2023-06-16 11:07:24,182:INFO:create_model() successfully completed......................................
2023-06-16 11:07:24,324:INFO:SubProcess create_model() end ==================================
2023-06-16 11:07:24,324:INFO:Creating metrics dataframe
2023-06-16 11:07:24,335:INFO:Initializing Bayesian Ridge
2023-06-16 11:07:24,335:INFO:Total runtime is 0.3299318313598632 minutes
2023-06-16 11:07:24,338:INFO:SubProcess create_model() called ==================================
2023-06-16 11:07:24,339:INFO:Initializing create_model()
2023-06-16 11:07:24,339:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023066344AF0>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:07:24,339:INFO:Checking exceptions
2023-06-16 11:07:24,339:INFO:Importing libraries
2023-06-16 11:07:24,339:INFO:Copying training dataset
2023-06-16 11:07:24,347:INFO:Defining folds
2023-06-16 11:07:24,347:INFO:Declaring metric variables
2023-06-16 11:07:24,351:INFO:Importing untrained model
2023-06-16 11:07:24,358:INFO:Bayesian Ridge Imported successfully
2023-06-16 11:07:24,367:INFO:Starting cross validation
2023-06-16 11:07:24,370:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:07:25,554:INFO:Calculating mean and std
2023-06-16 11:07:25,556:INFO:Creating metrics dataframe
2023-06-16 11:07:26,047:INFO:Uploading results into container
2023-06-16 11:07:26,048:INFO:Uploading model into container now
2023-06-16 11:07:26,049:INFO:_master_model_container: 8
2023-06-16 11:07:26,049:INFO:_display_container: 2
2023-06-16 11:07:26,049:INFO:BayesianRidge()
2023-06-16 11:07:26,049:INFO:create_model() successfully completed......................................
2023-06-16 11:07:26,176:INFO:SubProcess create_model() end ==================================
2023-06-16 11:07:26,177:INFO:Creating metrics dataframe
2023-06-16 11:07:26,203:INFO:Initializing Passive Aggressive Regressor
2023-06-16 11:07:26,204:INFO:Total runtime is 0.3610669255256652 minutes
2023-06-16 11:07:26,207:INFO:SubProcess create_model() called ==================================
2023-06-16 11:07:26,207:INFO:Initializing create_model()
2023-06-16 11:07:26,207:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023066344AF0>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:07:26,207:INFO:Checking exceptions
2023-06-16 11:07:26,208:INFO:Importing libraries
2023-06-16 11:07:26,208:INFO:Copying training dataset
2023-06-16 11:07:26,216:INFO:Defining folds
2023-06-16 11:07:26,216:INFO:Declaring metric variables
2023-06-16 11:07:26,222:INFO:Importing untrained model
2023-06-16 11:07:26,227:INFO:Passive Aggressive Regressor Imported successfully
2023-06-16 11:07:26,233:INFO:Starting cross validation
2023-06-16 11:07:26,236:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:07:27,480:INFO:Calculating mean and std
2023-06-16 11:07:27,483:INFO:Creating metrics dataframe
2023-06-16 11:07:28,025:INFO:Uploading results into container
2023-06-16 11:07:28,025:INFO:Uploading model into container now
2023-06-16 11:07:28,026:INFO:_master_model_container: 9
2023-06-16 11:07:28,026:INFO:_display_container: 2
2023-06-16 11:07:28,026:INFO:PassiveAggressiveRegressor(random_state=42)
2023-06-16 11:07:28,026:INFO:create_model() successfully completed......................................
2023-06-16 11:07:28,138:INFO:SubProcess create_model() end ==================================
2023-06-16 11:07:28,138:INFO:Creating metrics dataframe
2023-06-16 11:07:28,154:INFO:Initializing Huber Regressor
2023-06-16 11:07:28,154:INFO:Total runtime is 0.39357941548029574 minutes
2023-06-16 11:07:28,165:INFO:SubProcess create_model() called ==================================
2023-06-16 11:07:28,166:INFO:Initializing create_model()
2023-06-16 11:07:28,166:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023066344AF0>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:07:28,166:INFO:Checking exceptions
2023-06-16 11:07:28,167:INFO:Importing libraries
2023-06-16 11:07:28,167:INFO:Copying training dataset
2023-06-16 11:07:28,185:INFO:Defining folds
2023-06-16 11:07:28,186:INFO:Declaring metric variables
2023-06-16 11:07:28,195:INFO:Importing untrained model
2023-06-16 11:07:28,202:INFO:Huber Regressor Imported successfully
2023-06-16 11:07:28,211:INFO:Starting cross validation
2023-06-16 11:07:28,213:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:07:28,345:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:07:28,350:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:07:28,360:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:07:28,402:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:07:29,529:INFO:Calculating mean and std
2023-06-16 11:07:29,530:INFO:Creating metrics dataframe
2023-06-16 11:07:29,911:INFO:Uploading results into container
2023-06-16 11:07:29,912:INFO:Uploading model into container now
2023-06-16 11:07:29,913:INFO:_master_model_container: 10
2023-06-16 11:07:29,913:INFO:_display_container: 2
2023-06-16 11:07:29,914:INFO:HuberRegressor()
2023-06-16 11:07:29,914:INFO:create_model() successfully completed......................................
2023-06-16 11:07:30,034:INFO:SubProcess create_model() end ==================================
2023-06-16 11:07:30,034:INFO:Creating metrics dataframe
2023-06-16 11:07:30,046:INFO:Initializing K Neighbors Regressor
2023-06-16 11:07:30,046:INFO:Total runtime is 0.42511529525121045 minutes
2023-06-16 11:07:30,054:INFO:SubProcess create_model() called ==================================
2023-06-16 11:07:30,055:INFO:Initializing create_model()
2023-06-16 11:07:30,055:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023066344AF0>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:07:30,056:INFO:Checking exceptions
2023-06-16 11:07:30,056:INFO:Importing libraries
2023-06-16 11:07:30,056:INFO:Copying training dataset
2023-06-16 11:07:30,066:INFO:Defining folds
2023-06-16 11:07:30,066:INFO:Declaring metric variables
2023-06-16 11:07:30,073:INFO:Importing untrained model
2023-06-16 11:07:30,080:INFO:K Neighbors Regressor Imported successfully
2023-06-16 11:07:30,088:INFO:Starting cross validation
2023-06-16 11:07:30,093:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:07:31,421:INFO:Calculating mean and std
2023-06-16 11:07:31,423:INFO:Creating metrics dataframe
2023-06-16 11:07:31,830:INFO:Uploading results into container
2023-06-16 11:07:31,831:INFO:Uploading model into container now
2023-06-16 11:07:31,831:INFO:_master_model_container: 11
2023-06-16 11:07:31,832:INFO:_display_container: 2
2023-06-16 11:07:31,832:INFO:KNeighborsRegressor(n_jobs=-1)
2023-06-16 11:07:31,832:INFO:create_model() successfully completed......................................
2023-06-16 11:07:31,989:INFO:SubProcess create_model() end ==================================
2023-06-16 11:07:31,989:INFO:Creating metrics dataframe
2023-06-16 11:07:32,003:INFO:Initializing Decision Tree Regressor
2023-06-16 11:07:32,003:INFO:Total runtime is 0.4577263275782266 minutes
2023-06-16 11:07:32,007:INFO:SubProcess create_model() called ==================================
2023-06-16 11:07:32,007:INFO:Initializing create_model()
2023-06-16 11:07:32,007:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023066344AF0>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:07:32,007:INFO:Checking exceptions
2023-06-16 11:07:32,007:INFO:Importing libraries
2023-06-16 11:07:32,007:INFO:Copying training dataset
2023-06-16 11:07:32,023:INFO:Defining folds
2023-06-16 11:07:32,023:INFO:Declaring metric variables
2023-06-16 11:07:32,030:INFO:Importing untrained model
2023-06-16 11:07:32,035:INFO:Decision Tree Regressor Imported successfully
2023-06-16 11:07:32,053:INFO:Starting cross validation
2023-06-16 11:07:32,054:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:07:33,367:INFO:Calculating mean and std
2023-06-16 11:07:33,369:INFO:Creating metrics dataframe
2023-06-16 11:07:33,919:INFO:Uploading results into container
2023-06-16 11:07:33,920:INFO:Uploading model into container now
2023-06-16 11:07:33,920:INFO:_master_model_container: 12
2023-06-16 11:07:33,920:INFO:_display_container: 2
2023-06-16 11:07:33,921:INFO:DecisionTreeRegressor(random_state=42)
2023-06-16 11:07:33,921:INFO:create_model() successfully completed......................................
2023-06-16 11:07:34,048:INFO:SubProcess create_model() end ==================================
2023-06-16 11:07:34,049:INFO:Creating metrics dataframe
2023-06-16 11:07:34,080:INFO:Initializing Random Forest Regressor
2023-06-16 11:07:34,080:INFO:Total runtime is 0.4923428058624266 minutes
2023-06-16 11:07:34,085:INFO:SubProcess create_model() called ==================================
2023-06-16 11:07:34,085:INFO:Initializing create_model()
2023-06-16 11:07:34,085:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023066344AF0>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:07:34,086:INFO:Checking exceptions
2023-06-16 11:07:34,086:INFO:Importing libraries
2023-06-16 11:07:34,086:INFO:Copying training dataset
2023-06-16 11:07:34,102:INFO:Defining folds
2023-06-16 11:07:34,103:INFO:Declaring metric variables
2023-06-16 11:07:34,107:INFO:Importing untrained model
2023-06-16 11:07:34,113:INFO:Random Forest Regressor Imported successfully
2023-06-16 11:07:34,120:INFO:Starting cross validation
2023-06-16 11:07:34,121:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:07:35,558:INFO:Calculating mean and std
2023-06-16 11:07:35,559:INFO:Creating metrics dataframe
2023-06-16 11:07:36,083:INFO:Uploading results into container
2023-06-16 11:07:36,084:INFO:Uploading model into container now
2023-06-16 11:07:36,085:INFO:_master_model_container: 13
2023-06-16 11:07:36,085:INFO:_display_container: 2
2023-06-16 11:07:36,086:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 11:07:36,086:INFO:create_model() successfully completed......................................
2023-06-16 11:07:36,204:INFO:SubProcess create_model() end ==================================
2023-06-16 11:07:36,205:INFO:Creating metrics dataframe
2023-06-16 11:07:36,218:INFO:Initializing Extra Trees Regressor
2023-06-16 11:07:36,218:INFO:Total runtime is 0.5279729207356769 minutes
2023-06-16 11:07:36,225:INFO:SubProcess create_model() called ==================================
2023-06-16 11:07:36,225:INFO:Initializing create_model()
2023-06-16 11:07:36,226:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023066344AF0>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:07:36,226:INFO:Checking exceptions
2023-06-16 11:07:36,226:INFO:Importing libraries
2023-06-16 11:07:36,226:INFO:Copying training dataset
2023-06-16 11:07:36,239:INFO:Defining folds
2023-06-16 11:07:36,239:INFO:Declaring metric variables
2023-06-16 11:07:36,245:INFO:Importing untrained model
2023-06-16 11:07:36,251:INFO:Extra Trees Regressor Imported successfully
2023-06-16 11:07:36,258:INFO:Starting cross validation
2023-06-16 11:07:36,260:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:07:37,759:INFO:Calculating mean and std
2023-06-16 11:07:37,760:INFO:Creating metrics dataframe
2023-06-16 11:07:38,262:INFO:Uploading results into container
2023-06-16 11:07:38,263:INFO:Uploading model into container now
2023-06-16 11:07:38,263:INFO:_master_model_container: 14
2023-06-16 11:07:38,264:INFO:_display_container: 2
2023-06-16 11:07:38,264:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2023-06-16 11:07:38,264:INFO:create_model() successfully completed......................................
2023-06-16 11:07:38,392:INFO:SubProcess create_model() end ==================================
2023-06-16 11:07:38,392:INFO:Creating metrics dataframe
2023-06-16 11:07:38,404:INFO:Initializing AdaBoost Regressor
2023-06-16 11:07:38,404:INFO:Total runtime is 0.56440851688385 minutes
2023-06-16 11:07:38,408:INFO:SubProcess create_model() called ==================================
2023-06-16 11:07:38,408:INFO:Initializing create_model()
2023-06-16 11:07:38,408:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023066344AF0>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:07:38,408:INFO:Checking exceptions
2023-06-16 11:07:38,408:INFO:Importing libraries
2023-06-16 11:07:38,408:INFO:Copying training dataset
2023-06-16 11:07:38,415:INFO:Defining folds
2023-06-16 11:07:38,415:INFO:Declaring metric variables
2023-06-16 11:07:38,419:INFO:Importing untrained model
2023-06-16 11:07:38,423:INFO:AdaBoost Regressor Imported successfully
2023-06-16 11:07:38,437:INFO:Starting cross validation
2023-06-16 11:07:38,438:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:07:39,680:INFO:Calculating mean and std
2023-06-16 11:07:39,681:INFO:Creating metrics dataframe
2023-06-16 11:07:40,112:INFO:Uploading results into container
2023-06-16 11:07:40,113:INFO:Uploading model into container now
2023-06-16 11:07:40,113:INFO:_master_model_container: 15
2023-06-16 11:07:40,113:INFO:_display_container: 2
2023-06-16 11:07:40,114:INFO:AdaBoostRegressor(random_state=42)
2023-06-16 11:07:40,114:INFO:create_model() successfully completed......................................
2023-06-16 11:07:40,243:INFO:SubProcess create_model() end ==================================
2023-06-16 11:07:40,243:INFO:Creating metrics dataframe
2023-06-16 11:07:40,264:INFO:Initializing Gradient Boosting Regressor
2023-06-16 11:07:40,264:INFO:Total runtime is 0.5954086343447366 minutes
2023-06-16 11:07:40,275:INFO:SubProcess create_model() called ==================================
2023-06-16 11:07:40,276:INFO:Initializing create_model()
2023-06-16 11:07:40,276:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023066344AF0>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:07:40,276:INFO:Checking exceptions
2023-06-16 11:07:40,276:INFO:Importing libraries
2023-06-16 11:07:40,277:INFO:Copying training dataset
2023-06-16 11:07:40,289:INFO:Defining folds
2023-06-16 11:07:40,289:INFO:Declaring metric variables
2023-06-16 11:07:40,294:INFO:Importing untrained model
2023-06-16 11:07:40,299:INFO:Gradient Boosting Regressor Imported successfully
2023-06-16 11:07:40,309:INFO:Starting cross validation
2023-06-16 11:07:40,311:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:07:41,553:INFO:Calculating mean and std
2023-06-16 11:07:41,554:INFO:Creating metrics dataframe
2023-06-16 11:07:41,909:INFO:Uploading results into container
2023-06-16 11:07:41,909:INFO:Uploading model into container now
2023-06-16 11:07:41,910:INFO:_master_model_container: 16
2023-06-16 11:07:41,910:INFO:_display_container: 2
2023-06-16 11:07:41,910:INFO:GradientBoostingRegressor(random_state=42)
2023-06-16 11:07:41,910:INFO:create_model() successfully completed......................................
2023-06-16 11:07:42,057:INFO:SubProcess create_model() end ==================================
2023-06-16 11:07:42,058:INFO:Creating metrics dataframe
2023-06-16 11:07:42,081:INFO:Initializing Extreme Gradient Boosting
2023-06-16 11:07:42,081:INFO:Total runtime is 0.62568724155426 minutes
2023-06-16 11:07:42,088:INFO:SubProcess create_model() called ==================================
2023-06-16 11:07:42,088:INFO:Initializing create_model()
2023-06-16 11:07:42,089:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023066344AF0>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:07:42,089:INFO:Checking exceptions
2023-06-16 11:07:42,089:INFO:Importing libraries
2023-06-16 11:07:42,089:INFO:Copying training dataset
2023-06-16 11:07:42,100:INFO:Defining folds
2023-06-16 11:07:42,100:INFO:Declaring metric variables
2023-06-16 11:07:42,113:INFO:Importing untrained model
2023-06-16 11:07:42,118:INFO:Extreme Gradient Boosting Imported successfully
2023-06-16 11:07:42,128:INFO:Starting cross validation
2023-06-16 11:07:42,129:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:07:43,622:INFO:Calculating mean and std
2023-06-16 11:07:43,624:INFO:Creating metrics dataframe
2023-06-16 11:07:44,032:INFO:Uploading results into container
2023-06-16 11:07:44,033:INFO:Uploading model into container now
2023-06-16 11:07:44,033:INFO:_master_model_container: 17
2023-06-16 11:07:44,033:INFO:_display_container: 2
2023-06-16 11:07:44,034:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=42, ...)
2023-06-16 11:07:44,034:INFO:create_model() successfully completed......................................
2023-06-16 11:07:44,154:INFO:SubProcess create_model() end ==================================
2023-06-16 11:07:44,155:INFO:Creating metrics dataframe
2023-06-16 11:07:44,174:INFO:Initializing Light Gradient Boosting Machine
2023-06-16 11:07:44,174:INFO:Total runtime is 0.6605757196744281 minutes
2023-06-16 11:07:44,178:INFO:SubProcess create_model() called ==================================
2023-06-16 11:07:44,179:INFO:Initializing create_model()
2023-06-16 11:07:44,179:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023066344AF0>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:07:44,179:INFO:Checking exceptions
2023-06-16 11:07:44,179:INFO:Importing libraries
2023-06-16 11:07:44,179:INFO:Copying training dataset
2023-06-16 11:07:44,185:INFO:Defining folds
2023-06-16 11:07:44,185:INFO:Declaring metric variables
2023-06-16 11:07:44,189:INFO:Importing untrained model
2023-06-16 11:07:44,194:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-16 11:07:44,203:INFO:Starting cross validation
2023-06-16 11:07:44,204:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:07:46,545:INFO:Calculating mean and std
2023-06-16 11:07:46,547:INFO:Creating metrics dataframe
2023-06-16 11:07:46,990:INFO:Uploading results into container
2023-06-16 11:07:46,991:INFO:Uploading model into container now
2023-06-16 11:07:46,992:INFO:_master_model_container: 18
2023-06-16 11:07:46,992:INFO:_display_container: 2
2023-06-16 11:07:46,993:INFO:LGBMRegressor(random_state=42)
2023-06-16 11:07:46,993:INFO:create_model() successfully completed......................................
2023-06-16 11:07:47,130:INFO:SubProcess create_model() end ==================================
2023-06-16 11:07:47,130:INFO:Creating metrics dataframe
2023-06-16 11:07:47,144:INFO:Initializing Dummy Regressor
2023-06-16 11:07:47,144:INFO:Total runtime is 0.710069676240285 minutes
2023-06-16 11:07:47,148:INFO:SubProcess create_model() called ==================================
2023-06-16 11:07:47,149:INFO:Initializing create_model()
2023-06-16 11:07:47,149:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023066344AF0>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:07:47,150:INFO:Checking exceptions
2023-06-16 11:07:47,150:INFO:Importing libraries
2023-06-16 11:07:47,150:INFO:Copying training dataset
2023-06-16 11:07:47,165:INFO:Defining folds
2023-06-16 11:07:47,165:INFO:Declaring metric variables
2023-06-16 11:07:47,170:INFO:Importing untrained model
2023-06-16 11:07:47,174:INFO:Dummy Regressor Imported successfully
2023-06-16 11:07:47,180:INFO:Starting cross validation
2023-06-16 11:07:47,181:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:07:48,447:INFO:Calculating mean and std
2023-06-16 11:07:48,448:INFO:Creating metrics dataframe
2023-06-16 11:07:48,973:INFO:Uploading results into container
2023-06-16 11:07:48,974:INFO:Uploading model into container now
2023-06-16 11:07:48,975:INFO:_master_model_container: 19
2023-06-16 11:07:48,975:INFO:_display_container: 2
2023-06-16 11:07:48,976:INFO:DummyRegressor()
2023-06-16 11:07:48,976:INFO:create_model() successfully completed......................................
2023-06-16 11:07:49,101:INFO:SubProcess create_model() end ==================================
2023-06-16 11:07:49,102:INFO:Creating metrics dataframe
2023-06-16 11:07:49,157:INFO:Initializing create_model()
2023-06-16 11:07:49,157:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, estimator=HuberRegressor(), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:07:49,158:INFO:Checking exceptions
2023-06-16 11:07:49,161:INFO:Importing libraries
2023-06-16 11:07:49,161:INFO:Copying training dataset
2023-06-16 11:07:49,169:INFO:Defining folds
2023-06-16 11:07:49,170:INFO:Declaring metric variables
2023-06-16 11:07:49,170:INFO:Importing untrained model
2023-06-16 11:07:49,170:INFO:Declaring custom model
2023-06-16 11:07:49,170:INFO:Huber Regressor Imported successfully
2023-06-16 11:07:49,171:INFO:Cross validation set to False
2023-06-16 11:07:49,171:INFO:Fitting Model
2023-06-16 11:07:49,255:WARNING:lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html

2023-06-16 11:07:49,500:INFO:HuberRegressor()
2023-06-16 11:07:49,500:INFO:create_model() successfully completed......................................
2023-06-16 11:07:49,643:INFO:_master_model_container: 19
2023-06-16 11:07:49,643:INFO:_display_container: 2
2023-06-16 11:07:49,644:INFO:HuberRegressor()
2023-06-16 11:07:49,644:INFO:compare_models() successfully completed......................................
2023-06-16 11:07:59,334:INFO:Initializing create_model()
2023-06-16 11:07:59,334:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, estimator=huber, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:07:59,334:INFO:Checking exceptions
2023-06-16 11:07:59,362:INFO:Importing libraries
2023-06-16 11:07:59,362:INFO:Copying training dataset
2023-06-16 11:07:59,367:INFO:Defining folds
2023-06-16 11:07:59,367:INFO:Declaring metric variables
2023-06-16 11:07:59,370:INFO:Importing untrained model
2023-06-16 11:07:59,374:INFO:Huber Regressor Imported successfully
2023-06-16 11:07:59,380:INFO:Starting cross validation
2023-06-16 11:07:59,381:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:07:59,502:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:07:59,527:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:07:59,533:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:07:59,536:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:00,765:INFO:Calculating mean and std
2023-06-16 11:08:00,766:INFO:Creating metrics dataframe
2023-06-16 11:08:00,773:INFO:Finalizing model
2023-06-16 11:08:00,899:WARNING:lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html

2023-06-16 11:08:01,455:INFO:Uploading results into container
2023-06-16 11:08:01,456:INFO:Uploading model into container now
2023-06-16 11:08:01,471:INFO:_master_model_container: 20
2023-06-16 11:08:01,471:INFO:_display_container: 3
2023-06-16 11:08:01,471:INFO:HuberRegressor()
2023-06-16 11:08:01,471:INFO:create_model() successfully completed......................................
2023-06-16 11:08:06,503:INFO:Initializing plot_model()
2023-06-16 11:08:06,503:INFO:plot_model(plot=learning, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, system=True)
2023-06-16 11:08:06,503:INFO:Checking exceptions
2023-06-16 11:08:06,510:INFO:Preloading libraries
2023-06-16 11:08:06,510:INFO:Copying training dataset
2023-06-16 11:08:06,510:INFO:Plot type: learning
2023-06-16 11:08:06,608:INFO:Fitting Model
2023-06-16 11:08:06,721:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:06,734:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:06,737:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:06,745:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:06,750:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:06,786:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:06,802:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:06,811:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:06,826:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:06,830:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:06,861:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:06,862:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:06,906:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:06,910:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:06,917:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:06,918:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:06,926:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:06,938:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:06,939:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:06,964:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:06,999:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,003:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,013:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,016:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,022:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,027:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,033:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,053:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,081:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,094:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,112:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,125:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,135:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,138:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,161:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,165:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,181:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,196:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,202:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,217:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,223:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,223:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,250:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,263:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,275:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,279:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,285:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,314:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,317:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,345:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,373:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,374:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,375:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,378:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,379:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,399:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,437:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,468:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,468:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,473:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,483:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,483:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,484:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,493:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,518:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,564:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,566:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,581:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,595:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,595:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,615:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,625:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,639:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,658:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,686:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,689:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,719:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,720:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,738:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,752:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,759:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,761:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,766:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,807:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,816:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,839:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,844:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,845:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,851:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:07,853:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:08,043:INFO:Visual Rendered Successfully
2023-06-16 11:08:08,155:INFO:plot_model() successfully completed......................................
2023-06-16 11:08:16,192:INFO:Initializing plot_model()
2023-06-16 11:08:16,192:INFO:plot_model(plot=vc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, system=True)
2023-06-16 11:08:16,193:INFO:Checking exceptions
2023-06-16 11:08:16,198:INFO:Preloading libraries
2023-06-16 11:08:16,199:INFO:Copying training dataset
2023-06-16 11:08:16,199:INFO:Plot type: vc
2023-06-16 11:08:16,200:INFO:Determining param_name
2023-06-16 11:08:16,200:INFO:param_name: alpha
2023-06-16 11:08:16,285:INFO:Fitting Model
2023-06-16 11:08:16,400:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,414:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,415:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,416:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,430:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,438:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,439:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,443:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,500:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,514:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,521:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,550:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,551:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,555:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,560:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,574:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,626:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,626:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,646:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,648:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,657:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,662:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,669:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,679:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,732:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,738:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,743:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,753:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,770:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,782:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,783:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,791:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,842:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,851:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,853:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,871:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,886:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,894:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,894:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,901:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,948:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,956:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,969:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,984:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:16,990:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,009:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,010:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,013:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,049:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,051:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,079:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,085:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,089:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,110:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,119:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,127:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,167:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,181:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,186:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,190:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,195:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,207:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,232:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,234:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,284:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,293:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,296:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,299:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,300:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,332:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,332:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,348:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,389:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,393:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,405:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,410:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,410:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,438:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,456:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,466:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,498:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,500:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,513:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,527:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,532:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,545:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,559:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,579:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,602:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,615:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,622:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,648:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,650:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,668:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,669:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,687:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,708:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,712:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,719:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,724:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:17,902:INFO:Visual Rendered Successfully
2023-06-16 11:08:18,019:INFO:plot_model() successfully completed......................................
2023-06-16 11:08:21,279:INFO:Initializing plot_model()
2023-06-16 11:08:21,280:INFO:plot_model(plot=learning, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, system=True)
2023-06-16 11:08:21,280:INFO:Checking exceptions
2023-06-16 11:08:21,287:INFO:Preloading libraries
2023-06-16 11:08:21,287:INFO:Copying training dataset
2023-06-16 11:08:21,287:INFO:Plot type: learning
2023-06-16 11:08:21,376:INFO:Fitting Model
2023-06-16 11:08:21,479:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:21,487:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:21,494:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:21,498:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:21,514:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:21,563:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:21,567:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:21,569:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:21,571:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:21,584:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:21,607:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:21,628:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:21,662:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:21,666:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:21,668:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:21,677:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:21,681:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:21,688:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:21,695:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:21,726:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:21,749:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:21,752:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:21,764:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:21,778:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:21,791:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:21,796:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:21,798:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:21,821:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:21,841:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:21,849:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:21,868:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:21,895:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:21,899:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:21,900:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:21,935:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:21,937:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:21,939:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:21,963:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:21,968:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:21,981:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:21,989:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:21,994:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,037:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,038:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,044:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,048:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,052:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,082:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,087:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,136:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,141:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,142:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,145:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,148:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,154:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,162:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,222:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,230:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,243:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,247:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,250:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,250:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,252:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,258:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,296:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,331:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,339:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,349:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,350:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,366:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,391:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,396:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,401:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,413:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,437:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,443:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,474:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,487:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,497:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,508:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,510:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,517:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,576:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,580:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,595:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,600:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,600:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,605:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,613:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:08:22,813:INFO:Visual Rendered Successfully
2023-06-16 11:08:22,928:INFO:plot_model() successfully completed......................................
2023-06-16 11:08:44,126:INFO:Initializing plot_model()
2023-06-16 11:08:44,126:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, system=True)
2023-06-16 11:08:44,127:INFO:Checking exceptions
2023-06-16 11:08:44,131:INFO:Preloading libraries
2023-06-16 11:08:44,131:INFO:Copying training dataset
2023-06-16 11:08:44,132:INFO:Plot type: error
2023-06-16 11:08:44,239:INFO:Fitting Model
2023-06-16 11:08:44,239:WARNING:X does not have valid feature names, but HuberRegressor was fitted with feature names

2023-06-16 11:08:44,240:INFO:Scoring test/hold-out set
2023-06-16 11:08:44,627:INFO:Visual Rendered Successfully
2023-06-16 11:08:44,735:INFO:plot_model() successfully completed......................................
2023-06-16 11:08:51,800:INFO:Initializing plot_model()
2023-06-16 11:08:51,800:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, system=True)
2023-06-16 11:08:51,800:INFO:Checking exceptions
2023-06-16 11:08:51,806:INFO:Preloading libraries
2023-06-16 11:08:51,806:INFO:Copying training dataset
2023-06-16 11:08:51,806:INFO:Plot type: feature
2023-06-16 11:08:52,029:INFO:Visual Rendered Successfully
2023-06-16 11:08:52,136:INFO:plot_model() successfully completed......................................
2023-06-16 11:08:56,888:INFO:Initializing plot_model()
2023-06-16 11:08:56,888:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=3, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, system=True)
2023-06-16 11:08:56,888:INFO:Checking exceptions
2023-06-16 11:08:56,892:INFO:Preloading libraries
2023-06-16 11:08:56,892:INFO:Copying training dataset
2023-06-16 11:08:56,893:INFO:Plot type: residuals
2023-06-16 11:08:57,039:INFO:Fitting Model
2023-06-16 11:08:57,039:WARNING:X does not have valid feature names, but HuberRegressor was fitted with feature names

2023-06-16 11:08:57,082:INFO:Scoring test/hold-out set
2023-06-16 11:08:57,717:INFO:Visual Rendered Successfully
2023-06-16 11:08:57,846:INFO:plot_model() successfully completed......................................
2023-06-16 11:09:35,030:INFO:Initializing tune_model()
2023-06-16 11:09:35,031:INFO:tune_model(estimator=HuberRegressor(), fold=5, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>)
2023-06-16 11:09:35,031:INFO:Checking exceptions
2023-06-16 11:09:35,056:INFO:Copying training dataset
2023-06-16 11:09:35,062:INFO:Checking base model
2023-06-16 11:09:35,063:INFO:Base model : Huber Regressor
2023-06-16 11:09:35,069:INFO:Declaring metric variables
2023-06-16 11:09:35,074:INFO:Defining Hyperparameters
2023-06-16 11:09:35,199:INFO:Tuning with n_jobs=-1
2023-06-16 11:09:35,200:INFO:Initializing RandomizedSearchCV
2023-06-16 11:09:35,361:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:35,387:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:35,388:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:35,395:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:35,396:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:35,408:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:35,427:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:35,440:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:35,963:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:36,010:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:36,018:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:36,077:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:36,079:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:36,084:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:36,085:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:36,207:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:36,584:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:36,590:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:36,723:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:36,732:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:36,891:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:36,994:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:37,240:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:37,372:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:37,628:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:37,754:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:37,964:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:38,101:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:38,321:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:38,453:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:38,715:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:38,857:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:39,089:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:39,216:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:39,375:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:39,517:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:39,783:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:39,937:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:40,301:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:40,520:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:40,741:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:40,869:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:41,119:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:41,247:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:41,524:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:41,656:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:41,947:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:42,057:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:42,625:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:43,284:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:50,775:INFO:best_params: {'actual_estimator__fit_intercept': True, 'actual_estimator__epsilon': 1.5, 'actual_estimator__alpha': 0.7}
2023-06-16 11:09:50,776:INFO:Hyperparameter search completed
2023-06-16 11:09:50,776:INFO:SubProcess create_model() called ==================================
2023-06-16 11:09:50,777:INFO:Initializing create_model()
2023-06-16 11:09:50,777:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, estimator=HuberRegressor(), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023062112200>, model_only=True, return_train_score=False, kwargs={'fit_intercept': True, 'epsilon': 1.5, 'alpha': 0.7})
2023-06-16 11:09:50,777:INFO:Checking exceptions
2023-06-16 11:09:50,777:INFO:Importing libraries
2023-06-16 11:09:50,777:INFO:Copying training dataset
2023-06-16 11:09:50,785:INFO:Defining folds
2023-06-16 11:09:50,785:INFO:Declaring metric variables
2023-06-16 11:09:50,791:INFO:Importing untrained model
2023-06-16 11:09:50,791:INFO:Declaring custom model
2023-06-16 11:09:50,797:INFO:Huber Regressor Imported successfully
2023-06-16 11:09:50,809:INFO:Starting cross validation
2023-06-16 11:09:50,810:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:09:50,940:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:50,961:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:50,981:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:50,984:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:51,009:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:52,140:INFO:Calculating mean and std
2023-06-16 11:09:52,141:INFO:Creating metrics dataframe
2023-06-16 11:09:52,148:INFO:Finalizing model
2023-06-16 11:09:52,288:WARNING:lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html

2023-06-16 11:09:52,654:INFO:Uploading results into container
2023-06-16 11:09:52,654:INFO:Uploading model into container now
2023-06-16 11:09:52,655:INFO:_master_model_container: 21
2023-06-16 11:09:52,655:INFO:_display_container: 4
2023-06-16 11:09:52,655:INFO:HuberRegressor(alpha=0.7, epsilon=1.5)
2023-06-16 11:09:52,656:INFO:create_model() successfully completed......................................
2023-06-16 11:09:52,792:INFO:SubProcess create_model() end ==================================
2023-06-16 11:09:52,793:INFO:choose_better activated
2023-06-16 11:09:52,798:INFO:SubProcess create_model() called ==================================
2023-06-16 11:09:52,798:INFO:Initializing create_model()
2023-06-16 11:09:52,799:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, estimator=HuberRegressor(), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:09:52,799:INFO:Checking exceptions
2023-06-16 11:09:52,802:INFO:Importing libraries
2023-06-16 11:09:52,802:INFO:Copying training dataset
2023-06-16 11:09:52,814:INFO:Defining folds
2023-06-16 11:09:52,814:INFO:Declaring metric variables
2023-06-16 11:09:52,814:INFO:Importing untrained model
2023-06-16 11:09:52,814:INFO:Declaring custom model
2023-06-16 11:09:52,816:INFO:Huber Regressor Imported successfully
2023-06-16 11:09:52,816:INFO:Starting cross validation
2023-06-16 11:09:52,818:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:09:52,973:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:52,983:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:53,000:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:53,010:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:09:54,060:INFO:Calculating mean and std
2023-06-16 11:09:54,062:INFO:Creating metrics dataframe
2023-06-16 11:09:54,065:INFO:Finalizing model
2023-06-16 11:09:54,210:WARNING:lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html

2023-06-16 11:09:54,671:INFO:Uploading results into container
2023-06-16 11:09:54,671:INFO:Uploading model into container now
2023-06-16 11:09:54,672:INFO:_master_model_container: 22
2023-06-16 11:09:54,672:INFO:_display_container: 5
2023-06-16 11:09:54,672:INFO:HuberRegressor()
2023-06-16 11:09:54,672:INFO:create_model() successfully completed......................................
2023-06-16 11:09:54,781:INFO:SubProcess create_model() end ==================================
2023-06-16 11:09:54,781:INFO:HuberRegressor() result for R2 is 0.9445
2023-06-16 11:09:54,782:INFO:HuberRegressor(alpha=0.7, epsilon=1.5) result for R2 is 0.9466
2023-06-16 11:09:54,782:INFO:HuberRegressor(alpha=0.7, epsilon=1.5) is best model
2023-06-16 11:09:54,782:INFO:choose_better completed
2023-06-16 11:09:54,793:INFO:_master_model_container: 22
2023-06-16 11:09:54,793:INFO:_display_container: 4
2023-06-16 11:09:54,793:INFO:HuberRegressor(alpha=0.7, epsilon=1.5)
2023-06-16 11:09:54,793:INFO:tune_model() successfully completed......................................
2023-06-16 11:10:05,903:INFO:Initializing plot_model()
2023-06-16 11:10:05,904:INFO:plot_model(plot=learning, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=HuberRegressor(alpha=0.7, epsilon=1.5), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, system=True)
2023-06-16 11:10:05,904:INFO:Checking exceptions
2023-06-16 11:10:05,910:INFO:Preloading libraries
2023-06-16 11:10:05,910:INFO:Copying training dataset
2023-06-16 11:10:05,910:INFO:Plot type: learning
2023-06-16 11:10:06,004:INFO:Fitting Model
2023-06-16 11:10:06,114:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,135:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,142:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,143:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,154:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,156:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,156:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,177:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,204:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,214:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,221:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,236:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,243:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,252:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,260:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,290:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,302:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,302:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,311:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,314:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,320:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,325:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,331:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,373:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,398:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,402:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,403:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,421:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,422:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,423:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,434:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,453:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,471:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,485:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,494:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,510:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,521:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,525:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,537:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,549:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,560:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,570:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,571:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,593:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,608:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,639:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,642:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,656:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,658:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,659:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,667:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,667:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,702:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,741:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,767:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,769:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,770:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,777:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,778:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,816:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,850:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,875:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,878:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,897:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,910:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,912:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,923:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,925:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,932:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,984:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:06,999:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:07,011:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:07,019:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:07,020:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:07,027:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:07,039:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:07,050:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:07,056:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:07,108:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:07,112:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:07,114:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:07,128:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:07,139:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:07,141:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:07,158:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:07,182:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:07,186:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:07,200:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:07,218:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:07,223:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:07,224:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:07,234:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:07,254:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:07,429:INFO:Visual Rendered Successfully
2023-06-16 11:10:07,546:INFO:plot_model() successfully completed......................................
2023-06-16 11:10:10,342:INFO:Initializing plot_model()
2023-06-16 11:10:10,342:INFO:plot_model(plot=vc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=HuberRegressor(alpha=0.7, epsilon=1.5), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, system=True)
2023-06-16 11:10:10,342:INFO:Checking exceptions
2023-06-16 11:10:10,348:INFO:Preloading libraries
2023-06-16 11:10:10,348:INFO:Copying training dataset
2023-06-16 11:10:10,348:INFO:Plot type: vc
2023-06-16 11:10:10,349:INFO:Determining param_name
2023-06-16 11:10:10,349:INFO:param_name: alpha
2023-06-16 11:10:10,442:INFO:Fitting Model
2023-06-16 11:10:10,623:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:10,624:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:10,628:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:10,628:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:10,631:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:10,636:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:10,645:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:10,650:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:10,729:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:10,730:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:10,737:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:10,738:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:10,747:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:10,765:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:10,771:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:10,772:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:10,832:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:10,841:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:10,844:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:10,848:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:10,861:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:10,864:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:10,871:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:10,874:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:10,945:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:10,950:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:10,966:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:10,971:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:10,972:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:10,980:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:10,994:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:10,996:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,058:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,067:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,077:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,104:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,110:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,122:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,124:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,125:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,178:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,197:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,208:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,216:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,226:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,228:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,229:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,244:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,316:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,326:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,328:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,343:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,344:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,348:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,349:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,377:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,431:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,439:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,445:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,453:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,455:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,457:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,458:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,496:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,543:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,545:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,558:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,561:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,571:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,580:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,584:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,644:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,664:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,674:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,682:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,682:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,697:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,727:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,758:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,760:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,787:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,787:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,790:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,803:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,813:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,833:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,858:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,874:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,885:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,895:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,908:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,910:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,921:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,933:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,948:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,963:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,972:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:11,974:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:10:12,240:INFO:Visual Rendered Successfully
2023-06-16 11:10:12,405:INFO:plot_model() successfully completed......................................
2023-06-16 11:10:25,528:INFO:Initializing plot_model()
2023-06-16 11:10:25,528:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=HuberRegressor(alpha=0.7, epsilon=1.5), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, system=True)
2023-06-16 11:10:25,529:INFO:Checking exceptions
2023-06-16 11:10:25,535:INFO:Preloading libraries
2023-06-16 11:10:25,535:INFO:Copying training dataset
2023-06-16 11:10:25,536:INFO:Plot type: error
2023-06-16 11:10:25,624:INFO:Fitting Model
2023-06-16 11:10:25,624:WARNING:X does not have valid feature names, but HuberRegressor was fitted with feature names

2023-06-16 11:10:25,624:INFO:Scoring test/hold-out set
2023-06-16 11:10:25,900:INFO:Visual Rendered Successfully
2023-06-16 11:10:26,036:INFO:plot_model() successfully completed......................................
2023-06-16 11:10:30,480:INFO:Initializing plot_model()
2023-06-16 11:10:30,480:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=HuberRegressor(alpha=0.7, epsilon=1.5), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, system=True)
2023-06-16 11:10:30,480:INFO:Checking exceptions
2023-06-16 11:10:30,484:INFO:Preloading libraries
2023-06-16 11:10:30,484:INFO:Copying training dataset
2023-06-16 11:10:30,484:INFO:Plot type: feature
2023-06-16 11:10:30,745:INFO:Visual Rendered Successfully
2023-06-16 11:10:30,858:INFO:plot_model() successfully completed......................................
2023-06-16 11:10:37,439:INFO:Initializing plot_model()
2023-06-16 11:10:37,440:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=HuberRegressor(alpha=0.7, epsilon=1.5), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=3, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, system=True)
2023-06-16 11:10:37,440:INFO:Checking exceptions
2023-06-16 11:10:37,447:INFO:Preloading libraries
2023-06-16 11:10:37,447:INFO:Copying training dataset
2023-06-16 11:10:37,447:INFO:Plot type: residuals
2023-06-16 11:10:37,579:INFO:Fitting Model
2023-06-16 11:10:37,579:WARNING:X does not have valid feature names, but HuberRegressor was fitted with feature names

2023-06-16 11:10:37,640:INFO:Scoring test/hold-out set
2023-06-16 11:10:38,245:INFO:Visual Rendered Successfully
2023-06-16 11:10:38,360:INFO:plot_model() successfully completed......................................
2023-06-16 11:13:44,823:INFO:Initializing tune_model()
2023-06-16 11:13:44,824:INFO:tune_model(estimator=HuberRegressor(), fold=5, round=4, n_iter=10, custom_grid={' alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'epsilon': [1.0, 1.5, 2.0, 2.5]}, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>)
2023-06-16 11:13:44,824:INFO:Checking exceptions
2023-06-16 11:13:44,851:INFO:Copying training dataset
2023-06-16 11:13:44,854:INFO:Checking base model
2023-06-16 11:13:44,855:INFO:Base model : Huber Regressor
2023-06-16 11:13:44,857:INFO:Declaring metric variables
2023-06-16 11:13:44,860:INFO:Defining Hyperparameters
2023-06-16 11:13:44,979:INFO:custom_grid: {'actual_estimator__ alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'actual_estimator__epsilon': [1.0, 1.5, 2.0, 2.5]}
2023-06-16 11:13:44,979:INFO:Tuning with n_jobs=-1
2023-06-16 11:13:44,979:INFO:Initializing RandomizedSearchCV
2023-06-16 11:15:00,763:INFO:Initializing tune_model()
2023-06-16 11:15:00,763:INFO:tune_model(estimator=HuberRegressor(), fold=5, round=4, n_iter=10, custom_grid={' alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'epsilon': [1.3, 1.5, 1.7]}, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>)
2023-06-16 11:15:00,764:INFO:Checking exceptions
2023-06-16 11:15:00,790:INFO:Copying training dataset
2023-06-16 11:15:00,795:INFO:Checking base model
2023-06-16 11:15:00,795:INFO:Base model : Huber Regressor
2023-06-16 11:15:00,799:INFO:Declaring metric variables
2023-06-16 11:15:00,802:INFO:Defining Hyperparameters
2023-06-16 11:15:00,963:INFO:custom_grid: {'actual_estimator__ alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'actual_estimator__epsilon': [1.3, 1.5, 1.7]}
2023-06-16 11:15:00,963:INFO:Tuning with n_jobs=-1
2023-06-16 11:15:00,963:INFO:Initializing RandomizedSearchCV
2023-06-16 11:15:36,001:INFO:Initializing tune_model()
2023-06-16 11:15:36,002:INFO:tune_model(estimator=HuberRegressor(), fold=5, round=4, n_iter=10, custom_grid={' alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>)
2023-06-16 11:15:36,002:INFO:Checking exceptions
2023-06-16 11:15:36,026:INFO:Copying training dataset
2023-06-16 11:15:36,034:INFO:Checking base model
2023-06-16 11:15:36,034:INFO:Base model : Huber Regressor
2023-06-16 11:15:36,039:INFO:Declaring metric variables
2023-06-16 11:15:36,042:INFO:Defining Hyperparameters
2023-06-16 11:15:37,132:INFO:custom_grid: {'actual_estimator__ alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}
2023-06-16 11:15:37,132:INFO:Tuning with n_jobs=-1
2023-06-16 11:15:37,132:INFO:Initializing RandomizedSearchCV
2023-06-16 11:15:37,144:WARNING:The total space of parameters 9 is smaller than n_iter=10. Running 9 iterations. For exhaustive searches, use GridSearchCV.

2023-06-16 11:31:48,297:INFO:Initializing tune_model()
2023-06-16 11:31:48,297:INFO:tune_model(estimator=HuberRegressor(), fold=5, round=4, n_iter=10, custom_grid={'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>)
2023-06-16 11:31:48,297:INFO:Checking exceptions
2023-06-16 11:31:48,322:INFO:Copying training dataset
2023-06-16 11:31:48,328:INFO:Checking base model
2023-06-16 11:31:48,328:INFO:Base model : Huber Regressor
2023-06-16 11:31:48,331:INFO:Declaring metric variables
2023-06-16 11:31:48,334:INFO:Defining Hyperparameters
2023-06-16 11:31:48,766:INFO:custom_grid: {'actual_estimator__alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}
2023-06-16 11:31:48,767:INFO:Tuning with n_jobs=-1
2023-06-16 11:31:48,767:INFO:Initializing RandomizedSearchCV
2023-06-16 11:31:48,771:WARNING:The total space of parameters 9 is smaller than n_iter=10. Running 9 iterations. For exhaustive searches, use GridSearchCV.

2023-06-16 11:31:54,768:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:31:54,775:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:31:54,801:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:31:54,807:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:31:54,832:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:31:54,834:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:31:54,841:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:31:55,560:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:31:55,601:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:31:55,603:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:31:55,629:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:31:55,632:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:31:55,635:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:31:55,678:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:31:55,684:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:31:56,316:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:31:56,339:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:31:56,386:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:31:56,681:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:31:57,062:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:31:57,395:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:31:57,783:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:31:58,197:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:31:58,516:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:31:58,853:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:31:59,216:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:31:59,618:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:31:59,963:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:32:00,319:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:32:00,545:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:32:00,826:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:32:01,185:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:32:01,505:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:32:01,829:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:32:02,199:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:32:02,537:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:32:02,929:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:32:03,216:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:32:03,556:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:32:03,930:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:32:04,278:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:32:04,614:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:32:04,994:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:32:05,329:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:32:09,109:WARNING:
1 fits failed out of a total of 45.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\lapei\anaconda3\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py", line 338, in fit
    raise ValueError(
ValueError: HuberRegressor convergence failed: l-BFGS-b solver terminated with ABNORMAL_TERMINATION_IN_LNSRCH


2023-06-16 11:32:09,110:WARNING:One or more of the test scores are non-finite: [       nan 0.9454665  0.94436889 0.94373877 0.94734328 0.94573156
 0.94370825 0.94513295 0.94505704]

2023-06-16 11:32:09,740:INFO:best_params: {'actual_estimator__alpha': 0.5}
2023-06-16 11:32:09,742:INFO:Hyperparameter search completed
2023-06-16 11:32:09,743:INFO:SubProcess create_model() called ==================================
2023-06-16 11:32:09,744:INFO:Initializing create_model()
2023-06-16 11:32:09,744:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, estimator=HuberRegressor(), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002306B4EF9D0>, model_only=True, return_train_score=False, kwargs={'alpha': 0.5})
2023-06-16 11:32:09,744:INFO:Checking exceptions
2023-06-16 11:32:09,744:INFO:Importing libraries
2023-06-16 11:32:09,745:INFO:Copying training dataset
2023-06-16 11:32:09,755:INFO:Defining folds
2023-06-16 11:32:09,755:INFO:Declaring metric variables
2023-06-16 11:32:09,762:INFO:Importing untrained model
2023-06-16 11:32:09,763:INFO:Declaring custom model
2023-06-16 11:32:09,769:INFO:Huber Regressor Imported successfully
2023-06-16 11:32:09,781:INFO:Starting cross validation
2023-06-16 11:32:09,782:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:32:09,916:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:32:09,928:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:32:09,946:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:32:09,948:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:32:09,967:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:32:11,082:INFO:Calculating mean and std
2023-06-16 11:32:11,084:INFO:Creating metrics dataframe
2023-06-16 11:32:11,091:INFO:Finalizing model
2023-06-16 11:32:11,257:WARNING:lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html

2023-06-16 11:32:11,785:INFO:Uploading results into container
2023-06-16 11:32:11,786:INFO:Uploading model into container now
2023-06-16 11:32:11,786:INFO:_master_model_container: 23
2023-06-16 11:32:11,786:INFO:_display_container: 5
2023-06-16 11:32:11,787:INFO:HuberRegressor(alpha=0.5)
2023-06-16 11:32:11,787:INFO:create_model() successfully completed......................................
2023-06-16 11:32:11,935:INFO:SubProcess create_model() end ==================================
2023-06-16 11:32:11,935:INFO:choose_better activated
2023-06-16 11:32:11,938:INFO:SubProcess create_model() called ==================================
2023-06-16 11:32:11,939:INFO:Initializing create_model()
2023-06-16 11:32:11,939:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, estimator=HuberRegressor(), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:32:11,939:INFO:Checking exceptions
2023-06-16 11:32:11,941:INFO:Importing libraries
2023-06-16 11:32:11,941:INFO:Copying training dataset
2023-06-16 11:32:11,946:INFO:Defining folds
2023-06-16 11:32:11,946:INFO:Declaring metric variables
2023-06-16 11:32:11,947:INFO:Importing untrained model
2023-06-16 11:32:11,947:INFO:Declaring custom model
2023-06-16 11:32:11,947:INFO:Huber Regressor Imported successfully
2023-06-16 11:32:11,947:INFO:Starting cross validation
2023-06-16 11:32:11,948:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:32:12,092:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:32:12,122:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:32:12,127:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:32:12,147:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:32:13,303:INFO:Calculating mean and std
2023-06-16 11:32:13,303:INFO:Creating metrics dataframe
2023-06-16 11:32:13,305:INFO:Finalizing model
2023-06-16 11:32:13,427:WARNING:lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html

2023-06-16 11:32:13,812:INFO:Uploading results into container
2023-06-16 11:32:13,813:INFO:Uploading model into container now
2023-06-16 11:32:13,813:INFO:_master_model_container: 24
2023-06-16 11:32:13,813:INFO:_display_container: 6
2023-06-16 11:32:13,814:INFO:HuberRegressor()
2023-06-16 11:32:13,814:INFO:create_model() successfully completed......................................
2023-06-16 11:32:13,993:INFO:SubProcess create_model() end ==================================
2023-06-16 11:32:13,994:INFO:HuberRegressor() result for R2 is 0.9445
2023-06-16 11:32:13,995:INFO:HuberRegressor(alpha=0.5) result for R2 is 0.9473
2023-06-16 11:32:13,995:INFO:HuberRegressor(alpha=0.5) is best model
2023-06-16 11:32:13,996:INFO:choose_better completed
2023-06-16 11:32:14,016:INFO:_master_model_container: 24
2023-06-16 11:32:14,017:INFO:_display_container: 5
2023-06-16 11:32:14,017:INFO:HuberRegressor(alpha=0.5)
2023-06-16 11:32:14,018:INFO:tune_model() successfully completed......................................
2023-06-16 11:34:04,733:INFO:Initializing tune_model()
2023-06-16 11:34:04,734:INFO:tune_model(estimator=HuberRegressor(), fold=5, round=4, n_iter=10, custom_grid={'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'epsilon': [1.3, 1.5, 1.8, 2.0]}, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>)
2023-06-16 11:34:04,734:INFO:Checking exceptions
2023-06-16 11:34:04,762:INFO:Copying training dataset
2023-06-16 11:34:04,769:INFO:Checking base model
2023-06-16 11:34:04,770:INFO:Base model : Huber Regressor
2023-06-16 11:34:04,773:INFO:Declaring metric variables
2023-06-16 11:34:04,777:INFO:Defining Hyperparameters
2023-06-16 11:34:04,962:INFO:custom_grid: {'actual_estimator__alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'actual_estimator__epsilon': [1.3, 1.5, 1.8, 2.0]}
2023-06-16 11:34:04,962:INFO:Tuning with n_jobs=-1
2023-06-16 11:34:04,962:INFO:Initializing RandomizedSearchCV
2023-06-16 11:34:05,117:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:05,118:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:05,137:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:05,157:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:05,159:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:05,160:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:05,183:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:05,191:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:05,722:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:05,739:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:05,741:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:05,805:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:05,808:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:05,837:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:05,845:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:05,882:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:06,319:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:06,333:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:06,421:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:06,455:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:06,504:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:06,626:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:06,870:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:06,989:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:07,229:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:07,333:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:07,525:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:07,663:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:07,939:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:08,136:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:08,255:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:08,376:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:08,638:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:08,783:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:08,969:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:09,109:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:09,293:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:09,429:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:09,685:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:09,826:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:10,077:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:10,194:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:10,402:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:10,552:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:10,752:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:10,936:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:11,217:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:11,345:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:11,895:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:12,485:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:20,172:INFO:best_params: {'actual_estimator__epsilon': 1.8, 'actual_estimator__alpha': 0.4}
2023-06-16 11:34:20,173:INFO:Hyperparameter search completed
2023-06-16 11:34:20,173:INFO:SubProcess create_model() called ==================================
2023-06-16 11:34:20,174:INFO:Initializing create_model()
2023-06-16 11:34:20,174:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, estimator=HuberRegressor(), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002306B0690F0>, model_only=True, return_train_score=False, kwargs={'epsilon': 1.8, 'alpha': 0.4})
2023-06-16 11:34:20,174:INFO:Checking exceptions
2023-06-16 11:34:20,174:INFO:Importing libraries
2023-06-16 11:34:20,174:INFO:Copying training dataset
2023-06-16 11:34:20,183:INFO:Defining folds
2023-06-16 11:34:20,184:INFO:Declaring metric variables
2023-06-16 11:34:20,188:INFO:Importing untrained model
2023-06-16 11:34:20,188:INFO:Declaring custom model
2023-06-16 11:34:20,193:INFO:Huber Regressor Imported successfully
2023-06-16 11:34:20,201:INFO:Starting cross validation
2023-06-16 11:34:20,204:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:34:20,343:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:20,349:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:20,367:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:20,373:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:20,384:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:21,510:INFO:Calculating mean and std
2023-06-16 11:34:21,512:INFO:Creating metrics dataframe
2023-06-16 11:34:21,518:INFO:Finalizing model
2023-06-16 11:34:21,660:WARNING:lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html

2023-06-16 11:34:22,205:INFO:Uploading results into container
2023-06-16 11:34:22,206:INFO:Uploading model into container now
2023-06-16 11:34:22,206:INFO:_master_model_container: 25
2023-06-16 11:34:22,206:INFO:_display_container: 6
2023-06-16 11:34:22,206:INFO:HuberRegressor(alpha=0.4, epsilon=1.8)
2023-06-16 11:34:22,207:INFO:create_model() successfully completed......................................
2023-06-16 11:34:22,359:INFO:SubProcess create_model() end ==================================
2023-06-16 11:34:22,359:INFO:choose_better activated
2023-06-16 11:34:22,362:INFO:SubProcess create_model() called ==================================
2023-06-16 11:34:22,363:INFO:Initializing create_model()
2023-06-16 11:34:22,363:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, estimator=HuberRegressor(), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:34:22,363:INFO:Checking exceptions
2023-06-16 11:34:22,366:INFO:Importing libraries
2023-06-16 11:34:22,366:INFO:Copying training dataset
2023-06-16 11:34:22,373:INFO:Defining folds
2023-06-16 11:34:22,373:INFO:Declaring metric variables
2023-06-16 11:34:22,373:INFO:Importing untrained model
2023-06-16 11:34:22,373:INFO:Declaring custom model
2023-06-16 11:34:22,374:INFO:Huber Regressor Imported successfully
2023-06-16 11:34:22,374:INFO:Starting cross validation
2023-06-16 11:34:22,375:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:34:22,514:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:22,521:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:22,523:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:22,548:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:34:23,591:INFO:Calculating mean and std
2023-06-16 11:34:23,592:INFO:Creating metrics dataframe
2023-06-16 11:34:23,594:INFO:Finalizing model
2023-06-16 11:34:23,725:WARNING:lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html

2023-06-16 11:34:24,192:INFO:Uploading results into container
2023-06-16 11:34:24,193:INFO:Uploading model into container now
2023-06-16 11:34:24,193:INFO:_master_model_container: 26
2023-06-16 11:34:24,193:INFO:_display_container: 7
2023-06-16 11:34:24,193:INFO:HuberRegressor()
2023-06-16 11:34:24,194:INFO:create_model() successfully completed......................................
2023-06-16 11:34:24,339:INFO:SubProcess create_model() end ==================================
2023-06-16 11:34:24,340:INFO:HuberRegressor() result for R2 is 0.9445
2023-06-16 11:34:24,340:INFO:HuberRegressor(alpha=0.4, epsilon=1.8) result for R2 is 0.9472
2023-06-16 11:34:24,341:INFO:HuberRegressor(alpha=0.4, epsilon=1.8) is best model
2023-06-16 11:34:24,341:INFO:choose_better completed
2023-06-16 11:34:24,354:INFO:_master_model_container: 26
2023-06-16 11:34:24,355:INFO:_display_container: 6
2023-06-16 11:34:24,355:INFO:HuberRegressor(alpha=0.4, epsilon=1.8)
2023-06-16 11:34:24,355:INFO:tune_model() successfully completed......................................
2023-06-16 11:35:06,915:INFO:Initializing plot_model()
2023-06-16 11:35:06,915:INFO:plot_model(plot=learning, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=HuberRegressor(alpha=0.4, epsilon=1.8), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, system=True)
2023-06-16 11:35:06,915:INFO:Checking exceptions
2023-06-16 11:35:06,922:INFO:Preloading libraries
2023-06-16 11:35:06,922:INFO:Copying training dataset
2023-06-16 11:35:06,922:INFO:Plot type: learning
2023-06-16 11:35:07,069:INFO:Fitting Model
2023-06-16 11:35:07,168:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,174:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,177:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,188:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,191:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,210:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,221:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,250:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,256:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,263:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,266:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,268:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,285:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,314:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,332:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,333:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,339:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,356:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,366:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,372:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,382:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,401:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,418:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,424:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,452:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,456:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,457:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,473:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,481:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,485:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,516:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,526:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,555:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,574:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,575:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,592:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,606:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,607:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,611:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,621:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,655:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,688:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,700:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,701:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,707:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,710:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,714:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,725:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,733:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,770:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,783:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,800:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,800:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,808:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,819:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,825:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,830:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,844:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,852:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,886:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,900:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,913:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,932:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,937:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,938:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,940:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,941:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,960:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:07,983:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:08,022:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:08,027:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:08,029:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:08,034:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:08,040:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:08,040:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:08,055:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:08,056:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:08,101:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:08,119:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:08,124:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:08,129:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:08,129:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:08,136:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:08,150:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:08,167:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:08,170:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:08,206:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:08,214:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:08,215:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:08,227:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:08,228:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:08,249:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:08,502:INFO:Visual Rendered Successfully
2023-06-16 11:35:08,727:INFO:plot_model() successfully completed......................................
2023-06-16 11:35:12,835:INFO:Initializing plot_model()
2023-06-16 11:35:12,835:INFO:plot_model(plot=vc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=HuberRegressor(alpha=0.4, epsilon=1.8), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, system=True)
2023-06-16 11:35:12,835:INFO:Checking exceptions
2023-06-16 11:35:12,844:INFO:Preloading libraries
2023-06-16 11:35:12,845:INFO:Copying training dataset
2023-06-16 11:35:12,845:INFO:Plot type: vc
2023-06-16 11:35:12,845:INFO:Determining param_name
2023-06-16 11:35:12,845:INFO:param_name: alpha
2023-06-16 11:35:12,934:INFO:Fitting Model
2023-06-16 11:35:13,103:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,103:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,110:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,110:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,117:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,123:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,133:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,213:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,222:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,223:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,229:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,230:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,234:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,240:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,252:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,319:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,325:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,336:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,338:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,340:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,346:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,346:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,351:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,418:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,429:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,434:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,439:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,442:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,454:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,458:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,464:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,516:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,523:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,530:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,543:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,551:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,557:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,562:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,585:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,622:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,628:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,636:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,641:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,646:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,654:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,657:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,694:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,723:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,728:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,764:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,766:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,766:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,768:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,772:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,805:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,827:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,850:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,876:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,879:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,879:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,885:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,893:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,905:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,926:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,944:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,977:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,979:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,985:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:13,986:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:14,016:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:14,018:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:14,021:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:14,040:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:14,076:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:14,080:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:14,100:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:14,104:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:14,108:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:14,116:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:14,121:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:14,136:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:14,186:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:14,189:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:14,204:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:14,212:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:14,223:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:14,226:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:14,228:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:14,241:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:14,282:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:14,302:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:14,311:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:14,324:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:14,333:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:14,336:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:14,342:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:14,346:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:14,363:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:14,379:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:35:14,557:INFO:Visual Rendered Successfully
2023-06-16 11:35:14,737:INFO:plot_model() successfully completed......................................
2023-06-16 11:35:19,402:INFO:Initializing plot_model()
2023-06-16 11:35:19,402:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=HuberRegressor(alpha=0.4, epsilon=1.8), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, system=True)
2023-06-16 11:35:19,403:INFO:Checking exceptions
2023-06-16 11:35:19,409:INFO:Preloading libraries
2023-06-16 11:35:19,410:INFO:Copying training dataset
2023-06-16 11:35:19,410:INFO:Plot type: error
2023-06-16 11:35:19,527:INFO:Fitting Model
2023-06-16 11:35:19,527:WARNING:X does not have valid feature names, but HuberRegressor was fitted with feature names

2023-06-16 11:35:19,527:INFO:Scoring test/hold-out set
2023-06-16 11:35:19,796:INFO:Visual Rendered Successfully
2023-06-16 11:35:19,941:INFO:plot_model() successfully completed......................................
2023-06-16 11:37:02,265:INFO:Initializing plot_model()
2023-06-16 11:37:02,265:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=HuberRegressor(alpha=0.4, epsilon=1.8), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, system=True)
2023-06-16 11:37:02,266:INFO:Checking exceptions
2023-06-16 11:37:02,273:INFO:Preloading libraries
2023-06-16 11:37:02,273:INFO:Copying training dataset
2023-06-16 11:37:02,273:INFO:Plot type: feature
2023-06-16 11:37:02,493:INFO:Visual Rendered Successfully
2023-06-16 11:37:02,647:INFO:plot_model() successfully completed......................................
2023-06-16 11:37:10,474:INFO:Initializing plot_model()
2023-06-16 11:37:10,474:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=HuberRegressor(alpha=0.4, epsilon=1.8), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=3, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, system=True)
2023-06-16 11:37:10,474:INFO:Checking exceptions
2023-06-16 11:37:10,479:INFO:Preloading libraries
2023-06-16 11:37:10,479:INFO:Copying training dataset
2023-06-16 11:37:10,479:INFO:Plot type: residuals
2023-06-16 11:37:10,602:INFO:Fitting Model
2023-06-16 11:37:10,602:WARNING:X does not have valid feature names, but HuberRegressor was fitted with feature names

2023-06-16 11:37:10,647:INFO:Scoring test/hold-out set
2023-06-16 11:37:11,349:INFO:Visual Rendered Successfully
2023-06-16 11:37:11,503:INFO:plot_model() successfully completed......................................
2023-06-16 11:37:28,411:INFO:Initializing predict_model()
2023-06-16 11:37:28,412:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000230668AF1F0>, estimator=HuberRegressor(alpha=0.4, epsilon=1.8), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000023067214670>)
2023-06-16 11:37:28,412:INFO:Checking exceptions
2023-06-16 11:37:28,412:INFO:Preloading libraries
2023-06-16 11:37:28,414:INFO:Set up data.
2023-06-16 11:37:28,424:INFO:Set up index.
2023-06-16 11:37:59,554:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-16 11:37:59,554:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-16 11:37:59,554:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-16 11:37:59,554:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-16 11:38:00,546:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-16 11:38:33,865:INFO:PyCaret RegressionExperiment
2023-06-16 11:38:33,865:INFO:Logging name: reg-default-name
2023-06-16 11:38:33,865:INFO:ML Usecase: MLUsecase.REGRESSION
2023-06-16 11:38:33,865:INFO:version 3.0.2
2023-06-16 11:38:33,865:INFO:Initializing setup()
2023-06-16 11:38:33,865:INFO:self.USI: 4dfd
2023-06-16 11:38:33,865:INFO:self._variable_keys: {'X_train', 'n_jobs_param', 'X', 'pipeline', 'gpu_param', '_available_plots', 'transform_target_param', 'memory', 'fold_generator', 'log_plots_param', 'exp_name_log', 'seed', 'X_test', '_ml_usecase', 'idx', 'y_test', 'exp_id', 'fold_shuffle_param', 'USI', 'data', 'y_train', 'target_param', 'gpu_n_jobs_param', 'fold_groups_param', 'y', 'logging_param', 'html_param'}
2023-06-16 11:38:33,866:INFO:Checking environment
2023-06-16 11:38:33,866:INFO:python_version: 3.10.9
2023-06-16 11:38:33,866:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-06-16 11:38:33,866:INFO:machine: AMD64
2023-06-16 11:38:33,866:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-16 11:38:33,866:INFO:Memory: svmem(total=16901767168, available=5493096448, percent=67.5, used=11408670720, free=5493096448)
2023-06-16 11:38:33,866:INFO:Physical Core: 4
2023-06-16 11:38:33,866:INFO:Logical Core: 8
2023-06-16 11:38:33,866:INFO:Checking libraries
2023-06-16 11:38:33,866:INFO:System:
2023-06-16 11:38:33,866:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-06-16 11:38:33,866:INFO:executable: C:\Users\lapei\anaconda3\python.exe
2023-06-16 11:38:33,866:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-16 11:38:33,866:INFO:PyCaret required dependencies:
2023-06-16 11:38:33,866:INFO:                 pip: 22.3.1
2023-06-16 11:38:33,866:INFO:          setuptools: 65.6.3
2023-06-16 11:38:33,866:INFO:             pycaret: 3.0.2
2023-06-16 11:38:33,866:INFO:             IPython: 8.10.0
2023-06-16 11:38:33,866:INFO:          ipywidgets: 7.6.5
2023-06-16 11:38:33,866:INFO:                tqdm: 4.64.1
2023-06-16 11:38:33,866:INFO:               numpy: 1.23.5
2023-06-16 11:38:33,867:INFO:              pandas: 1.5.3
2023-06-16 11:38:33,867:INFO:              jinja2: 3.1.2
2023-06-16 11:38:33,867:INFO:               scipy: 1.10.0
2023-06-16 11:38:33,867:INFO:              joblib: 1.2.0
2023-06-16 11:38:33,867:INFO:             sklearn: 1.2.1
2023-06-16 11:38:33,867:INFO:                pyod: 1.0.9
2023-06-16 11:38:33,867:INFO:            imblearn: 0.10.1
2023-06-16 11:38:33,867:INFO:   category_encoders: 2.6.1
2023-06-16 11:38:33,867:INFO:            lightgbm: 3.3.5
2023-06-16 11:38:33,867:INFO:               numba: 0.56.4
2023-06-16 11:38:33,867:INFO:            requests: 2.28.1
2023-06-16 11:38:33,867:INFO:          matplotlib: 3.7.0
2023-06-16 11:38:33,867:INFO:          scikitplot: 0.3.7
2023-06-16 11:38:33,867:INFO:         yellowbrick: 1.5
2023-06-16 11:38:33,867:INFO:              plotly: 5.9.0
2023-06-16 11:38:33,867:INFO:             kaleido: 0.2.1
2023-06-16 11:38:33,867:INFO:         statsmodels: 0.13.5
2023-06-16 11:38:33,867:INFO:              sktime: 0.17.0
2023-06-16 11:38:33,867:INFO:               tbats: 1.1.3
2023-06-16 11:38:33,867:INFO:            pmdarima: 2.0.3
2023-06-16 11:38:33,867:INFO:              psutil: 5.9.0
2023-06-16 11:38:33,867:INFO:PyCaret optional dependencies:
2023-06-16 11:38:33,905:INFO:                shap: 0.41.0
2023-06-16 11:38:33,905:INFO:           interpret: Not installed
2023-06-16 11:38:33,905:INFO:                umap: Not installed
2023-06-16 11:38:33,905:INFO:    pandas_profiling: Not installed
2023-06-16 11:38:33,905:INFO:  explainerdashboard: Not installed
2023-06-16 11:38:33,905:INFO:             autoviz: Not installed
2023-06-16 11:38:33,905:INFO:           fairlearn: Not installed
2023-06-16 11:38:33,905:INFO:             xgboost: 1.7.3
2023-06-16 11:38:33,905:INFO:            catboost: Not installed
2023-06-16 11:38:33,905:INFO:              kmodes: Not installed
2023-06-16 11:38:33,905:INFO:             mlxtend: Not installed
2023-06-16 11:38:33,905:INFO:       statsforecast: Not installed
2023-06-16 11:38:33,905:INFO:        tune_sklearn: Not installed
2023-06-16 11:38:33,905:INFO:                 ray: Not installed
2023-06-16 11:38:33,905:INFO:            hyperopt: Not installed
2023-06-16 11:38:33,905:INFO:              optuna: Not installed
2023-06-16 11:38:33,905:INFO:               skopt: 0.9.0
2023-06-16 11:38:33,905:INFO:              mlflow: Not installed
2023-06-16 11:38:33,905:INFO:              gradio: Not installed
2023-06-16 11:38:33,905:INFO:             fastapi: Not installed
2023-06-16 11:38:33,905:INFO:             uvicorn: Not installed
2023-06-16 11:38:33,906:INFO:              m2cgen: Not installed
2023-06-16 11:38:33,906:INFO:           evidently: Not installed
2023-06-16 11:38:33,906:INFO:               fugue: Not installed
2023-06-16 11:38:33,906:INFO:           streamlit: Not installed
2023-06-16 11:38:33,906:INFO:             prophet: Not installed
2023-06-16 11:38:33,906:INFO:None
2023-06-16 11:38:33,906:INFO:Set up data.
2023-06-16 11:38:33,916:INFO:Set up train/test split.
2023-06-16 11:38:33,920:INFO:Set up index.
2023-06-16 11:38:33,921:INFO:Set up folding strategy.
2023-06-16 11:38:33,921:INFO:Assigning column types.
2023-06-16 11:38:33,924:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-16 11:38:33,924:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-16 11:38:33,928:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-16 11:38:33,932:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-16 11:38:33,987:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-16 11:38:34,043:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-16 11:38:34,044:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 11:38:34,234:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 11:38:34,234:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-16 11:38:34,241:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-16 11:38:34,246:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-16 11:38:34,327:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-16 11:38:34,398:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-16 11:38:34,399:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 11:38:34,401:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 11:38:34,401:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-06-16 11:38:34,406:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-16 11:38:34,410:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-16 11:38:34,497:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-16 11:38:34,539:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-16 11:38:34,539:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 11:38:34,542:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 11:38:34,546:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-16 11:38:34,551:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-16 11:38:34,605:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-16 11:38:34,675:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-16 11:38:34,676:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 11:38:34,678:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 11:38:34,679:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-06-16 11:38:34,688:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-16 11:38:34,761:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-16 11:38:34,836:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-16 11:38:34,837:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 11:38:34,839:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 11:38:34,848:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-16 11:38:34,903:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-16 11:38:34,973:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-16 11:38:34,973:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 11:38:34,976:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 11:38:34,976:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-06-16 11:38:35,037:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-16 11:38:35,086:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-16 11:38:35,089:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 11:38:35,092:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 11:38:35,155:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-16 11:38:35,201:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-16 11:38:35,202:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 11:38:35,208:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 11:38:35,209:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-16 11:38:35,286:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-16 11:38:35,329:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 11:38:35,331:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 11:38:35,398:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-16 11:38:35,442:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 11:38:35,445:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 11:38:35,445:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-06-16 11:38:35,592:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 11:38:35,596:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 11:38:35,705:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 11:38:35,708:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 11:38:35,710:INFO:Preparing preprocessing pipeline...
2023-06-16 11:38:35,710:INFO:Set up simple imputation.
2023-06-16 11:38:35,711:INFO:Set up column name cleaning.
2023-06-16 11:38:35,759:INFO:Finished creating preprocessing pipeline.
2023-06-16 11:38:35,767:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\lapei\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['taxa_homicidio', 'RH_adm_dir',
                                             'densidade_banda_larga',
                                             'densidade_telefonia_movel',
                                             'qtd_cursos_engenharias',
                                             'qtd_cursos_negocios_direito',
                                             'media_notas_CN', 'media_notas_CH',
                                             'media_NU_NOTA_LC',
                                             'media_NU_NOTA_MT',
                                             'media_...
                                             'Isencao_ISSQN_Sim',
                                             'Isencao_Tx_Sim',
                                             'Cessao_terrenos_Sim',
                                             'Doacao_terrenos_Sim',
                                             'Outros_mecanismos_Sim',
                                             'ISH_Baixa', 'ISH_Máxima',
                                             'ISH_Média', 'ISH_Mínima'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-06-16 11:38:35,767:INFO:Creating final display dataframe.
2023-06-16 11:38:35,860:INFO:Setup _display_container:                     Description                              Value
0                    Session id                                 42
1                        Target  qtd_abertas_Empresario_Individual
2                   Target type                         Regression
3           Original data shape                         (4456, 30)
4        Transformed data shape                         (4456, 30)
5   Transformed train set shape                         (3119, 30)
6    Transformed test set shape                         (1337, 30)
7              Numeric features                                 29
8                    Preprocess                               True
9               Imputation type                             simple
10           Numeric imputation                               mean
11       Categorical imputation                               mode
12               Fold Generator                              KFold
13                  Fold Number                                 10
14                     CPU Jobs                                 -1
15                      Use GPU                              False
16               Log Experiment                              False
17              Experiment Name                   reg-default-name
18                          USI                               4dfd
2023-06-16 11:38:35,973:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 11:38:35,976:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 11:38:36,090:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 11:38:36,093:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 11:38:36,097:INFO:setup() successfully completed in 2.57s...............
2023-06-16 11:38:45,756:INFO:Initializing compare_models()
2023-06-16 11:38:45,756:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, include=None, fold=5, round=4, cross_validation=True, sort=MAPE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, 'include': None, 'exclude': None, 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'MAPE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-06-16 11:38:45,756:INFO:Checking exceptions
2023-06-16 11:38:45,760:INFO:Preparing display monitor
2023-06-16 11:38:45,793:INFO:Initializing Linear Regression
2023-06-16 11:38:45,794:INFO:Total runtime is 1.6669432322184246e-05 minutes
2023-06-16 11:38:45,797:INFO:SubProcess create_model() called ==================================
2023-06-16 11:38:45,797:INFO:Initializing create_model()
2023-06-16 11:38:45,797:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000261E1F39E10>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:38:45,797:INFO:Checking exceptions
2023-06-16 11:38:45,798:INFO:Importing libraries
2023-06-16 11:38:45,798:INFO:Copying training dataset
2023-06-16 11:38:45,803:INFO:Defining folds
2023-06-16 11:38:45,803:INFO:Declaring metric variables
2023-06-16 11:38:45,806:INFO:Importing untrained model
2023-06-16 11:38:45,809:INFO:Linear Regression Imported successfully
2023-06-16 11:38:45,817:INFO:Starting cross validation
2023-06-16 11:38:45,823:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:38:51,347:INFO:Calculating mean and std
2023-06-16 11:38:51,349:INFO:Creating metrics dataframe
2023-06-16 11:38:51,931:INFO:Uploading results into container
2023-06-16 11:38:51,933:INFO:Uploading model into container now
2023-06-16 11:38:51,934:INFO:_master_model_container: 1
2023-06-16 11:38:51,934:INFO:_display_container: 2
2023-06-16 11:38:51,934:INFO:LinearRegression(n_jobs=-1)
2023-06-16 11:38:51,935:INFO:create_model() successfully completed......................................
2023-06-16 11:38:52,064:INFO:SubProcess create_model() end ==================================
2023-06-16 11:38:52,065:INFO:Creating metrics dataframe
2023-06-16 11:38:52,073:INFO:Initializing Lasso Regression
2023-06-16 11:38:52,073:INFO:Total runtime is 0.10467112064361572 minutes
2023-06-16 11:38:52,077:INFO:SubProcess create_model() called ==================================
2023-06-16 11:38:52,077:INFO:Initializing create_model()
2023-06-16 11:38:52,077:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000261E1F39E10>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:38:52,077:INFO:Checking exceptions
2023-06-16 11:38:52,077:INFO:Importing libraries
2023-06-16 11:38:52,077:INFO:Copying training dataset
2023-06-16 11:38:52,088:INFO:Defining folds
2023-06-16 11:38:52,089:INFO:Declaring metric variables
2023-06-16 11:38:52,094:INFO:Importing untrained model
2023-06-16 11:38:52,098:INFO:Lasso Regression Imported successfully
2023-06-16 11:38:52,107:INFO:Starting cross validation
2023-06-16 11:38:52,108:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:38:55,010:INFO:Calculating mean and std
2023-06-16 11:38:55,011:INFO:Creating metrics dataframe
2023-06-16 11:38:55,788:INFO:Uploading results into container
2023-06-16 11:38:55,790:INFO:Uploading model into container now
2023-06-16 11:38:55,791:INFO:_master_model_container: 2
2023-06-16 11:38:55,791:INFO:_display_container: 2
2023-06-16 11:38:55,792:INFO:Lasso(random_state=42)
2023-06-16 11:38:55,792:INFO:create_model() successfully completed......................................
2023-06-16 11:38:55,937:INFO:SubProcess create_model() end ==================================
2023-06-16 11:38:55,937:INFO:Creating metrics dataframe
2023-06-16 11:38:55,946:INFO:Initializing Ridge Regression
2023-06-16 11:38:55,947:INFO:Total runtime is 0.1692365845044454 minutes
2023-06-16 11:38:55,950:INFO:SubProcess create_model() called ==================================
2023-06-16 11:38:55,950:INFO:Initializing create_model()
2023-06-16 11:38:55,950:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000261E1F39E10>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:38:55,950:INFO:Checking exceptions
2023-06-16 11:38:55,950:INFO:Importing libraries
2023-06-16 11:38:55,950:INFO:Copying training dataset
2023-06-16 11:38:55,959:INFO:Defining folds
2023-06-16 11:38:55,959:INFO:Declaring metric variables
2023-06-16 11:38:55,963:INFO:Importing untrained model
2023-06-16 11:38:55,968:INFO:Ridge Regression Imported successfully
2023-06-16 11:38:55,974:INFO:Starting cross validation
2023-06-16 11:38:55,975:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:38:57,286:INFO:Calculating mean and std
2023-06-16 11:38:57,288:INFO:Creating metrics dataframe
2023-06-16 11:38:57,832:INFO:Uploading results into container
2023-06-16 11:38:57,833:INFO:Uploading model into container now
2023-06-16 11:38:57,833:INFO:_master_model_container: 3
2023-06-16 11:38:57,833:INFO:_display_container: 2
2023-06-16 11:38:57,834:INFO:Ridge(random_state=42)
2023-06-16 11:38:57,834:INFO:create_model() successfully completed......................................
2023-06-16 11:38:57,950:INFO:SubProcess create_model() end ==================================
2023-06-16 11:38:57,950:INFO:Creating metrics dataframe
2023-06-16 11:38:57,960:INFO:Initializing Elastic Net
2023-06-16 11:38:57,960:INFO:Total runtime is 0.20278605620066326 minutes
2023-06-16 11:38:57,964:INFO:SubProcess create_model() called ==================================
2023-06-16 11:38:57,965:INFO:Initializing create_model()
2023-06-16 11:38:57,965:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000261E1F39E10>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:38:57,965:INFO:Checking exceptions
2023-06-16 11:38:57,965:INFO:Importing libraries
2023-06-16 11:38:57,965:INFO:Copying training dataset
2023-06-16 11:38:57,973:INFO:Defining folds
2023-06-16 11:38:57,973:INFO:Declaring metric variables
2023-06-16 11:38:57,978:INFO:Importing untrained model
2023-06-16 11:38:57,982:INFO:Elastic Net Imported successfully
2023-06-16 11:38:57,996:INFO:Starting cross validation
2023-06-16 11:38:57,998:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:38:59,213:INFO:Calculating mean and std
2023-06-16 11:38:59,214:INFO:Creating metrics dataframe
2023-06-16 11:38:59,715:INFO:Uploading results into container
2023-06-16 11:38:59,716:INFO:Uploading model into container now
2023-06-16 11:38:59,717:INFO:_master_model_container: 4
2023-06-16 11:38:59,717:INFO:_display_container: 2
2023-06-16 11:38:59,718:INFO:ElasticNet(random_state=42)
2023-06-16 11:38:59,718:INFO:create_model() successfully completed......................................
2023-06-16 11:38:59,846:INFO:SubProcess create_model() end ==================================
2023-06-16 11:38:59,846:INFO:Creating metrics dataframe
2023-06-16 11:38:59,861:INFO:Initializing Least Angle Regression
2023-06-16 11:38:59,861:INFO:Total runtime is 0.23446648518244426 minutes
2023-06-16 11:38:59,870:INFO:SubProcess create_model() called ==================================
2023-06-16 11:38:59,871:INFO:Initializing create_model()
2023-06-16 11:38:59,871:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000261E1F39E10>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:38:59,872:INFO:Checking exceptions
2023-06-16 11:38:59,872:INFO:Importing libraries
2023-06-16 11:38:59,872:INFO:Copying training dataset
2023-06-16 11:38:59,877:INFO:Defining folds
2023-06-16 11:38:59,877:INFO:Declaring metric variables
2023-06-16 11:38:59,882:INFO:Importing untrained model
2023-06-16 11:38:59,887:INFO:Least Angle Regression Imported successfully
2023-06-16 11:38:59,896:INFO:Starting cross validation
2023-06-16 11:38:59,897:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:39:01,139:INFO:Calculating mean and std
2023-06-16 11:39:01,141:INFO:Creating metrics dataframe
2023-06-16 11:39:01,758:INFO:Uploading results into container
2023-06-16 11:39:01,759:INFO:Uploading model into container now
2023-06-16 11:39:01,760:INFO:_master_model_container: 5
2023-06-16 11:39:01,760:INFO:_display_container: 2
2023-06-16 11:39:01,761:INFO:Lars(random_state=42)
2023-06-16 11:39:01,761:INFO:create_model() successfully completed......................................
2023-06-16 11:39:01,875:INFO:SubProcess create_model() end ==================================
2023-06-16 11:39:01,875:INFO:Creating metrics dataframe
2023-06-16 11:39:01,898:INFO:Initializing Lasso Least Angle Regression
2023-06-16 11:39:01,898:INFO:Total runtime is 0.2684170603752136 minutes
2023-06-16 11:39:01,903:INFO:SubProcess create_model() called ==================================
2023-06-16 11:39:01,904:INFO:Initializing create_model()
2023-06-16 11:39:01,904:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000261E1F39E10>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:39:01,904:INFO:Checking exceptions
2023-06-16 11:39:01,904:INFO:Importing libraries
2023-06-16 11:39:01,904:INFO:Copying training dataset
2023-06-16 11:39:01,913:INFO:Defining folds
2023-06-16 11:39:01,913:INFO:Declaring metric variables
2023-06-16 11:39:01,918:INFO:Importing untrained model
2023-06-16 11:39:01,928:INFO:Lasso Least Angle Regression Imported successfully
2023-06-16 11:39:01,936:INFO:Starting cross validation
2023-06-16 11:39:01,939:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:39:03,258:INFO:Calculating mean and std
2023-06-16 11:39:03,260:INFO:Creating metrics dataframe
2023-06-16 11:39:03,995:INFO:Uploading results into container
2023-06-16 11:39:03,996:INFO:Uploading model into container now
2023-06-16 11:39:03,996:INFO:_master_model_container: 6
2023-06-16 11:39:03,996:INFO:_display_container: 2
2023-06-16 11:39:03,997:INFO:LassoLars(random_state=42)
2023-06-16 11:39:03,997:INFO:create_model() successfully completed......................................
2023-06-16 11:39:04,134:INFO:SubProcess create_model() end ==================================
2023-06-16 11:39:04,134:INFO:Creating metrics dataframe
2023-06-16 11:39:04,148:INFO:Initializing Orthogonal Matching Pursuit
2023-06-16 11:39:04,148:INFO:Total runtime is 0.30591141382853193 minutes
2023-06-16 11:39:04,155:INFO:SubProcess create_model() called ==================================
2023-06-16 11:39:04,156:INFO:Initializing create_model()
2023-06-16 11:39:04,156:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000261E1F39E10>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:39:04,156:INFO:Checking exceptions
2023-06-16 11:39:04,156:INFO:Importing libraries
2023-06-16 11:39:04,156:INFO:Copying training dataset
2023-06-16 11:39:04,162:INFO:Defining folds
2023-06-16 11:39:04,162:INFO:Declaring metric variables
2023-06-16 11:39:04,167:INFO:Importing untrained model
2023-06-16 11:39:04,170:INFO:Orthogonal Matching Pursuit Imported successfully
2023-06-16 11:39:04,189:INFO:Starting cross validation
2023-06-16 11:39:04,191:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:39:05,482:INFO:Calculating mean and std
2023-06-16 11:39:05,483:INFO:Creating metrics dataframe
2023-06-16 11:39:05,842:INFO:Uploading results into container
2023-06-16 11:39:05,843:INFO:Uploading model into container now
2023-06-16 11:39:05,844:INFO:_master_model_container: 7
2023-06-16 11:39:05,844:INFO:_display_container: 2
2023-06-16 11:39:05,845:INFO:OrthogonalMatchingPursuit()
2023-06-16 11:39:05,845:INFO:create_model() successfully completed......................................
2023-06-16 11:39:05,970:INFO:SubProcess create_model() end ==================================
2023-06-16 11:39:05,970:INFO:Creating metrics dataframe
2023-06-16 11:39:05,988:INFO:Initializing Bayesian Ridge
2023-06-16 11:39:05,988:INFO:Total runtime is 0.3365860581398011 minutes
2023-06-16 11:39:05,997:INFO:SubProcess create_model() called ==================================
2023-06-16 11:39:05,997:INFO:Initializing create_model()
2023-06-16 11:39:05,997:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000261E1F39E10>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:39:05,998:INFO:Checking exceptions
2023-06-16 11:39:05,998:INFO:Importing libraries
2023-06-16 11:39:05,998:INFO:Copying training dataset
2023-06-16 11:39:06,008:INFO:Defining folds
2023-06-16 11:39:06,008:INFO:Declaring metric variables
2023-06-16 11:39:06,014:INFO:Importing untrained model
2023-06-16 11:39:06,019:INFO:Bayesian Ridge Imported successfully
2023-06-16 11:39:06,025:INFO:Starting cross validation
2023-06-16 11:39:06,026:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:39:07,456:INFO:Calculating mean and std
2023-06-16 11:39:07,457:INFO:Creating metrics dataframe
2023-06-16 11:39:08,047:INFO:Uploading results into container
2023-06-16 11:39:08,048:INFO:Uploading model into container now
2023-06-16 11:39:08,049:INFO:_master_model_container: 8
2023-06-16 11:39:08,049:INFO:_display_container: 2
2023-06-16 11:39:08,050:INFO:BayesianRidge()
2023-06-16 11:39:08,050:INFO:create_model() successfully completed......................................
2023-06-16 11:39:08,189:INFO:SubProcess create_model() end ==================================
2023-06-16 11:39:08,189:INFO:Creating metrics dataframe
2023-06-16 11:39:08,202:INFO:Initializing Passive Aggressive Regressor
2023-06-16 11:39:08,203:INFO:Total runtime is 0.37350148359934493 minutes
2023-06-16 11:39:08,206:INFO:SubProcess create_model() called ==================================
2023-06-16 11:39:08,207:INFO:Initializing create_model()
2023-06-16 11:39:08,207:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000261E1F39E10>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:39:08,207:INFO:Checking exceptions
2023-06-16 11:39:08,207:INFO:Importing libraries
2023-06-16 11:39:08,207:INFO:Copying training dataset
2023-06-16 11:39:08,224:INFO:Defining folds
2023-06-16 11:39:08,225:INFO:Declaring metric variables
2023-06-16 11:39:08,237:INFO:Importing untrained model
2023-06-16 11:39:08,245:INFO:Passive Aggressive Regressor Imported successfully
2023-06-16 11:39:08,256:INFO:Starting cross validation
2023-06-16 11:39:08,258:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:39:09,533:INFO:Calculating mean and std
2023-06-16 11:39:09,535:INFO:Creating metrics dataframe
2023-06-16 11:39:10,079:INFO:Uploading results into container
2023-06-16 11:39:10,080:INFO:Uploading model into container now
2023-06-16 11:39:10,081:INFO:_master_model_container: 9
2023-06-16 11:39:10,082:INFO:_display_container: 2
2023-06-16 11:39:10,082:INFO:PassiveAggressiveRegressor(random_state=42)
2023-06-16 11:39:10,083:INFO:create_model() successfully completed......................................
2023-06-16 11:39:10,197:INFO:SubProcess create_model() end ==================================
2023-06-16 11:39:10,197:INFO:Creating metrics dataframe
2023-06-16 11:39:10,212:INFO:Initializing Huber Regressor
2023-06-16 11:39:10,212:INFO:Total runtime is 0.40699172814687096 minutes
2023-06-16 11:39:10,217:INFO:SubProcess create_model() called ==================================
2023-06-16 11:39:10,218:INFO:Initializing create_model()
2023-06-16 11:39:10,218:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000261E1F39E10>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:39:10,218:INFO:Checking exceptions
2023-06-16 11:39:10,219:INFO:Importing libraries
2023-06-16 11:39:10,219:INFO:Copying training dataset
2023-06-16 11:39:10,230:INFO:Defining folds
2023-06-16 11:39:10,231:INFO:Declaring metric variables
2023-06-16 11:39:10,237:INFO:Importing untrained model
2023-06-16 11:39:10,241:INFO:Huber Regressor Imported successfully
2023-06-16 11:39:10,256:INFO:Starting cross validation
2023-06-16 11:39:10,257:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:39:10,424:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:39:10,454:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:39:10,466:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:39:10,499:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 11:39:11,635:INFO:Calculating mean and std
2023-06-16 11:39:11,637:INFO:Creating metrics dataframe
2023-06-16 11:39:12,052:INFO:Uploading results into container
2023-06-16 11:39:12,052:INFO:Uploading model into container now
2023-06-16 11:39:12,053:INFO:_master_model_container: 10
2023-06-16 11:39:12,053:INFO:_display_container: 2
2023-06-16 11:39:12,053:INFO:HuberRegressor()
2023-06-16 11:39:12,053:INFO:create_model() successfully completed......................................
2023-06-16 11:39:12,176:INFO:SubProcess create_model() end ==================================
2023-06-16 11:39:12,177:INFO:Creating metrics dataframe
2023-06-16 11:39:12,197:INFO:Initializing K Neighbors Regressor
2023-06-16 11:39:12,198:INFO:Total runtime is 0.44008353948593143 minutes
2023-06-16 11:39:12,202:INFO:SubProcess create_model() called ==================================
2023-06-16 11:39:12,203:INFO:Initializing create_model()
2023-06-16 11:39:12,203:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000261E1F39E10>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:39:12,203:INFO:Checking exceptions
2023-06-16 11:39:12,203:INFO:Importing libraries
2023-06-16 11:39:12,203:INFO:Copying training dataset
2023-06-16 11:39:12,210:INFO:Defining folds
2023-06-16 11:39:12,210:INFO:Declaring metric variables
2023-06-16 11:39:12,215:INFO:Importing untrained model
2023-06-16 11:39:12,218:INFO:K Neighbors Regressor Imported successfully
2023-06-16 11:39:12,225:INFO:Starting cross validation
2023-06-16 11:39:12,226:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:39:13,719:INFO:Calculating mean and std
2023-06-16 11:39:13,720:INFO:Creating metrics dataframe
2023-06-16 11:39:14,264:INFO:Uploading results into container
2023-06-16 11:39:14,265:INFO:Uploading model into container now
2023-06-16 11:39:14,265:INFO:_master_model_container: 11
2023-06-16 11:39:14,265:INFO:_display_container: 2
2023-06-16 11:39:14,266:INFO:KNeighborsRegressor(n_jobs=-1)
2023-06-16 11:39:14,266:INFO:create_model() successfully completed......................................
2023-06-16 11:39:14,431:INFO:SubProcess create_model() end ==================================
2023-06-16 11:39:14,431:INFO:Creating metrics dataframe
2023-06-16 11:39:14,445:INFO:Initializing Decision Tree Regressor
2023-06-16 11:39:14,445:INFO:Total runtime is 0.47753399610519415 minutes
2023-06-16 11:39:14,451:INFO:SubProcess create_model() called ==================================
2023-06-16 11:39:14,452:INFO:Initializing create_model()
2023-06-16 11:39:14,452:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000261E1F39E10>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:39:14,453:INFO:Checking exceptions
2023-06-16 11:39:14,453:INFO:Importing libraries
2023-06-16 11:39:14,453:INFO:Copying training dataset
2023-06-16 11:39:14,462:INFO:Defining folds
2023-06-16 11:39:14,463:INFO:Declaring metric variables
2023-06-16 11:39:14,467:INFO:Importing untrained model
2023-06-16 11:39:14,472:INFO:Decision Tree Regressor Imported successfully
2023-06-16 11:39:14,480:INFO:Starting cross validation
2023-06-16 11:39:14,482:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:39:15,889:INFO:Calculating mean and std
2023-06-16 11:39:15,891:INFO:Creating metrics dataframe
2023-06-16 11:39:16,620:INFO:Uploading results into container
2023-06-16 11:39:16,622:INFO:Uploading model into container now
2023-06-16 11:39:16,623:INFO:_master_model_container: 12
2023-06-16 11:39:16,623:INFO:_display_container: 2
2023-06-16 11:39:16,624:INFO:DecisionTreeRegressor(random_state=42)
2023-06-16 11:39:16,624:INFO:create_model() successfully completed......................................
2023-06-16 11:39:16,751:INFO:SubProcess create_model() end ==================================
2023-06-16 11:39:16,751:INFO:Creating metrics dataframe
2023-06-16 11:39:16,776:INFO:Initializing Random Forest Regressor
2023-06-16 11:39:16,776:INFO:Total runtime is 0.5163856824239096 minutes
2023-06-16 11:39:16,787:INFO:SubProcess create_model() called ==================================
2023-06-16 11:39:16,788:INFO:Initializing create_model()
2023-06-16 11:39:16,788:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000261E1F39E10>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:39:16,788:INFO:Checking exceptions
2023-06-16 11:39:16,789:INFO:Importing libraries
2023-06-16 11:39:16,789:INFO:Copying training dataset
2023-06-16 11:39:16,802:INFO:Defining folds
2023-06-16 11:39:16,802:INFO:Declaring metric variables
2023-06-16 11:39:16,808:INFO:Importing untrained model
2023-06-16 11:39:16,813:INFO:Random Forest Regressor Imported successfully
2023-06-16 11:39:16,821:INFO:Starting cross validation
2023-06-16 11:39:16,822:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:39:18,277:INFO:Calculating mean and std
2023-06-16 11:39:18,278:INFO:Creating metrics dataframe
2023-06-16 11:39:18,727:INFO:Uploading results into container
2023-06-16 11:39:18,728:INFO:Uploading model into container now
2023-06-16 11:39:18,728:INFO:_master_model_container: 13
2023-06-16 11:39:18,728:INFO:_display_container: 2
2023-06-16 11:39:18,729:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 11:39:18,729:INFO:create_model() successfully completed......................................
2023-06-16 11:39:18,859:INFO:SubProcess create_model() end ==================================
2023-06-16 11:39:18,859:INFO:Creating metrics dataframe
2023-06-16 11:39:18,877:INFO:Initializing Extra Trees Regressor
2023-06-16 11:39:18,877:INFO:Total runtime is 0.5513951142628989 minutes
2023-06-16 11:39:18,881:INFO:SubProcess create_model() called ==================================
2023-06-16 11:39:18,881:INFO:Initializing create_model()
2023-06-16 11:39:18,882:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000261E1F39E10>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:39:18,882:INFO:Checking exceptions
2023-06-16 11:39:18,882:INFO:Importing libraries
2023-06-16 11:39:18,882:INFO:Copying training dataset
2023-06-16 11:39:18,890:INFO:Defining folds
2023-06-16 11:39:18,891:INFO:Declaring metric variables
2023-06-16 11:39:18,895:INFO:Importing untrained model
2023-06-16 11:39:18,900:INFO:Extra Trees Regressor Imported successfully
2023-06-16 11:39:18,911:INFO:Starting cross validation
2023-06-16 11:39:18,913:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:39:20,351:INFO:Calculating mean and std
2023-06-16 11:39:20,352:INFO:Creating metrics dataframe
2023-06-16 11:39:20,976:INFO:Uploading results into container
2023-06-16 11:39:20,977:INFO:Uploading model into container now
2023-06-16 11:39:20,978:INFO:_master_model_container: 14
2023-06-16 11:39:20,978:INFO:_display_container: 2
2023-06-16 11:39:20,979:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2023-06-16 11:39:20,979:INFO:create_model() successfully completed......................................
2023-06-16 11:39:21,087:INFO:SubProcess create_model() end ==================================
2023-06-16 11:39:21,088:INFO:Creating metrics dataframe
2023-06-16 11:39:21,121:INFO:Initializing AdaBoost Regressor
2023-06-16 11:39:21,121:INFO:Total runtime is 0.5888081749280295 minutes
2023-06-16 11:39:21,131:INFO:SubProcess create_model() called ==================================
2023-06-16 11:39:21,131:INFO:Initializing create_model()
2023-06-16 11:39:21,132:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000261E1F39E10>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:39:21,132:INFO:Checking exceptions
2023-06-16 11:39:21,132:INFO:Importing libraries
2023-06-16 11:39:21,132:INFO:Copying training dataset
2023-06-16 11:39:21,145:INFO:Defining folds
2023-06-16 11:39:21,145:INFO:Declaring metric variables
2023-06-16 11:39:21,149:INFO:Importing untrained model
2023-06-16 11:39:21,160:INFO:AdaBoost Regressor Imported successfully
2023-06-16 11:39:21,174:INFO:Starting cross validation
2023-06-16 11:39:21,176:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:39:22,400:INFO:Calculating mean and std
2023-06-16 11:39:22,401:INFO:Creating metrics dataframe
2023-06-16 11:39:23,177:INFO:Uploading results into container
2023-06-16 11:39:23,179:INFO:Uploading model into container now
2023-06-16 11:39:23,180:INFO:_master_model_container: 15
2023-06-16 11:39:23,180:INFO:_display_container: 2
2023-06-16 11:39:23,181:INFO:AdaBoostRegressor(random_state=42)
2023-06-16 11:39:23,181:INFO:create_model() successfully completed......................................
2023-06-16 11:39:23,300:INFO:SubProcess create_model() end ==================================
2023-06-16 11:39:23,301:INFO:Creating metrics dataframe
2023-06-16 11:39:23,313:INFO:Initializing Gradient Boosting Regressor
2023-06-16 11:39:23,314:INFO:Total runtime is 0.6253561337788901 minutes
2023-06-16 11:39:23,317:INFO:SubProcess create_model() called ==================================
2023-06-16 11:39:23,318:INFO:Initializing create_model()
2023-06-16 11:39:23,318:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000261E1F39E10>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:39:23,318:INFO:Checking exceptions
2023-06-16 11:39:23,318:INFO:Importing libraries
2023-06-16 11:39:23,319:INFO:Copying training dataset
2023-06-16 11:39:23,332:INFO:Defining folds
2023-06-16 11:39:23,332:INFO:Declaring metric variables
2023-06-16 11:39:23,340:INFO:Importing untrained model
2023-06-16 11:39:23,350:INFO:Gradient Boosting Regressor Imported successfully
2023-06-16 11:39:23,365:INFO:Starting cross validation
2023-06-16 11:39:23,368:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:39:24,760:INFO:Calculating mean and std
2023-06-16 11:39:24,761:INFO:Creating metrics dataframe
2023-06-16 11:39:25,408:INFO:Uploading results into container
2023-06-16 11:39:25,410:INFO:Uploading model into container now
2023-06-16 11:39:25,411:INFO:_master_model_container: 16
2023-06-16 11:39:25,412:INFO:_display_container: 2
2023-06-16 11:39:25,413:INFO:GradientBoostingRegressor(random_state=42)
2023-06-16 11:39:25,413:INFO:create_model() successfully completed......................................
2023-06-16 11:39:25,545:INFO:SubProcess create_model() end ==================================
2023-06-16 11:39:25,546:INFO:Creating metrics dataframe
2023-06-16 11:39:25,564:INFO:Initializing Extreme Gradient Boosting
2023-06-16 11:39:25,564:INFO:Total runtime is 0.6628530104955038 minutes
2023-06-16 11:39:25,568:INFO:SubProcess create_model() called ==================================
2023-06-16 11:39:25,568:INFO:Initializing create_model()
2023-06-16 11:39:25,568:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000261E1F39E10>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:39:25,568:INFO:Checking exceptions
2023-06-16 11:39:25,568:INFO:Importing libraries
2023-06-16 11:39:25,568:INFO:Copying training dataset
2023-06-16 11:39:25,577:INFO:Defining folds
2023-06-16 11:39:25,577:INFO:Declaring metric variables
2023-06-16 11:39:25,582:INFO:Importing untrained model
2023-06-16 11:39:25,591:INFO:Extreme Gradient Boosting Imported successfully
2023-06-16 11:39:25,602:INFO:Starting cross validation
2023-06-16 11:39:25,604:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:39:26,993:INFO:Calculating mean and std
2023-06-16 11:39:26,994:INFO:Creating metrics dataframe
2023-06-16 11:39:27,601:INFO:Uploading results into container
2023-06-16 11:39:27,603:INFO:Uploading model into container now
2023-06-16 11:39:27,605:INFO:_master_model_container: 17
2023-06-16 11:39:27,605:INFO:_display_container: 2
2023-06-16 11:39:27,607:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=42, ...)
2023-06-16 11:39:27,607:INFO:create_model() successfully completed......................................
2023-06-16 11:39:27,728:INFO:SubProcess create_model() end ==================================
2023-06-16 11:39:27,729:INFO:Creating metrics dataframe
2023-06-16 11:39:27,742:INFO:Initializing Light Gradient Boosting Machine
2023-06-16 11:39:27,742:INFO:Total runtime is 0.6991591334342957 minutes
2023-06-16 11:39:27,747:INFO:SubProcess create_model() called ==================================
2023-06-16 11:39:27,747:INFO:Initializing create_model()
2023-06-16 11:39:27,747:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000261E1F39E10>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:39:27,747:INFO:Checking exceptions
2023-06-16 11:39:27,747:INFO:Importing libraries
2023-06-16 11:39:27,747:INFO:Copying training dataset
2023-06-16 11:39:27,754:INFO:Defining folds
2023-06-16 11:39:27,754:INFO:Declaring metric variables
2023-06-16 11:39:27,764:INFO:Importing untrained model
2023-06-16 11:39:27,769:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-16 11:39:27,781:INFO:Starting cross validation
2023-06-16 11:39:27,783:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:39:30,084:INFO:Calculating mean and std
2023-06-16 11:39:30,085:INFO:Creating metrics dataframe
2023-06-16 11:39:30,525:INFO:Uploading results into container
2023-06-16 11:39:30,526:INFO:Uploading model into container now
2023-06-16 11:39:30,527:INFO:_master_model_container: 18
2023-06-16 11:39:30,527:INFO:_display_container: 2
2023-06-16 11:39:30,528:INFO:LGBMRegressor(random_state=42)
2023-06-16 11:39:30,528:INFO:create_model() successfully completed......................................
2023-06-16 11:39:30,675:INFO:SubProcess create_model() end ==================================
2023-06-16 11:39:30,675:INFO:Creating metrics dataframe
2023-06-16 11:39:30,688:INFO:Initializing Dummy Regressor
2023-06-16 11:39:30,688:INFO:Total runtime is 0.7482461214065552 minutes
2023-06-16 11:39:30,692:INFO:SubProcess create_model() called ==================================
2023-06-16 11:39:30,692:INFO:Initializing create_model()
2023-06-16 11:39:30,693:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000261E1F39E10>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:39:30,693:INFO:Checking exceptions
2023-06-16 11:39:30,693:INFO:Importing libraries
2023-06-16 11:39:30,693:INFO:Copying training dataset
2023-06-16 11:39:30,699:INFO:Defining folds
2023-06-16 11:39:30,699:INFO:Declaring metric variables
2023-06-16 11:39:30,703:INFO:Importing untrained model
2023-06-16 11:39:30,706:INFO:Dummy Regressor Imported successfully
2023-06-16 11:39:30,712:INFO:Starting cross validation
2023-06-16 11:39:30,713:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:39:31,961:INFO:Calculating mean and std
2023-06-16 11:39:31,963:INFO:Creating metrics dataframe
2023-06-16 11:39:32,405:INFO:Uploading results into container
2023-06-16 11:39:32,406:INFO:Uploading model into container now
2023-06-16 11:39:32,407:INFO:_master_model_container: 19
2023-06-16 11:39:32,407:INFO:_display_container: 2
2023-06-16 11:39:32,407:INFO:DummyRegressor()
2023-06-16 11:39:32,407:INFO:create_model() successfully completed......................................
2023-06-16 11:39:32,534:INFO:SubProcess create_model() end ==================================
2023-06-16 11:39:32,534:INFO:Creating metrics dataframe
2023-06-16 11:39:32,558:INFO:Initializing create_model()
2023-06-16 11:39:32,558:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:39:32,558:INFO:Checking exceptions
2023-06-16 11:39:32,560:INFO:Importing libraries
2023-06-16 11:39:32,560:INFO:Copying training dataset
2023-06-16 11:39:32,564:INFO:Defining folds
2023-06-16 11:39:32,564:INFO:Declaring metric variables
2023-06-16 11:39:32,564:INFO:Importing untrained model
2023-06-16 11:39:32,564:INFO:Declaring custom model
2023-06-16 11:39:32,564:INFO:Random Forest Regressor Imported successfully
2023-06-16 11:39:32,566:INFO:Cross validation set to False
2023-06-16 11:39:32,566:INFO:Fitting Model
2023-06-16 11:39:32,888:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 11:39:32,888:INFO:create_model() successfully completed......................................
2023-06-16 11:39:33,040:INFO:_master_model_container: 19
2023-06-16 11:39:33,040:INFO:_display_container: 2
2023-06-16 11:39:33,040:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 11:39:33,040:INFO:compare_models() successfully completed......................................
2023-06-16 11:39:49,153:INFO:Initializing create_model()
2023-06-16 11:39:49,153:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, estimator=rf, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-16 11:39:49,153:INFO:Checking exceptions
2023-06-16 11:39:49,176:INFO:Importing libraries
2023-06-16 11:39:49,176:INFO:Copying training dataset
2023-06-16 11:39:49,188:INFO:Defining folds
2023-06-16 11:39:49,189:INFO:Declaring metric variables
2023-06-16 11:39:49,196:INFO:Importing untrained model
2023-06-16 11:39:49,202:INFO:Random Forest Regressor Imported successfully
2023-06-16 11:39:49,207:INFO:Starting cross validation
2023-06-16 11:39:49,208:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 11:39:50,665:INFO:Calculating mean and std
2023-06-16 11:39:50,667:INFO:Creating metrics dataframe
2023-06-16 11:39:50,677:INFO:Finalizing model
2023-06-16 11:39:51,278:INFO:Uploading results into container
2023-06-16 11:39:51,279:INFO:Uploading model into container now
2023-06-16 11:39:51,290:INFO:_master_model_container: 20
2023-06-16 11:39:51,290:INFO:_display_container: 3
2023-06-16 11:39:51,292:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 11:39:51,292:INFO:create_model() successfully completed......................................
2023-06-16 11:39:54,577:INFO:Initializing plot_model()
2023-06-16 11:39:54,577:INFO:plot_model(plot=learning, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, system=True)
2023-06-16 11:39:54,578:INFO:Checking exceptions
2023-06-16 11:39:54,607:INFO:Preloading libraries
2023-06-16 11:39:54,653:INFO:Copying training dataset
2023-06-16 11:39:54,653:INFO:Plot type: learning
2023-06-16 11:39:54,744:INFO:Fitting Model
2023-06-16 11:41:15,499:INFO:Visual Rendered Successfully
2023-06-16 11:41:15,635:INFO:plot_model() successfully completed......................................
2023-06-16 11:41:15,651:INFO:Initializing plot_model()
2023-06-16 11:41:15,652:INFO:plot_model(plot=vc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, system=True)
2023-06-16 11:41:15,653:INFO:Checking exceptions
2023-06-16 11:41:15,696:INFO:Preloading libraries
2023-06-16 11:41:15,745:INFO:Copying training dataset
2023-06-16 11:41:15,745:INFO:Plot type: vc
2023-06-16 11:41:15,745:INFO:Determining param_name
2023-06-16 11:41:15,745:INFO:param_name: max_depth
2023-06-16 11:41:15,831:INFO:Fitting Model
2023-06-16 11:42:05,750:INFO:Visual Rendered Successfully
2023-06-16 11:42:05,893:INFO:plot_model() successfully completed......................................
2023-06-16 11:42:05,913:INFO:Initializing plot_model()
2023-06-16 11:42:05,913:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, system=True)
2023-06-16 11:42:05,913:INFO:Checking exceptions
2023-06-16 11:42:05,936:INFO:Preloading libraries
2023-06-16 11:42:05,983:INFO:Copying training dataset
2023-06-16 11:42:05,983:INFO:Plot type: error
2023-06-16 11:42:06,122:INFO:Fitting Model
2023-06-16 11:42:06,122:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2023-06-16 11:42:06,122:INFO:Scoring test/hold-out set
2023-06-16 11:42:06,558:INFO:Visual Rendered Successfully
2023-06-16 11:42:06,686:INFO:plot_model() successfully completed......................................
2023-06-16 11:42:06,704:INFO:Initializing plot_model()
2023-06-16 11:42:06,705:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, system=True)
2023-06-16 11:42:06,705:INFO:Checking exceptions
2023-06-16 11:42:06,738:INFO:Preloading libraries
2023-06-16 11:42:06,784:INFO:Copying training dataset
2023-06-16 11:42:06,784:INFO:Plot type: feature
2023-06-16 11:42:06,785:WARNING:No coef_ found. Trying feature_importances_
2023-06-16 11:42:07,037:INFO:Visual Rendered Successfully
2023-06-16 11:42:07,150:INFO:plot_model() successfully completed......................................
2023-06-16 11:42:07,171:INFO:Initializing plot_model()
2023-06-16 11:42:07,171:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=3, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, system=True)
2023-06-16 11:42:07,171:INFO:Checking exceptions
2023-06-16 11:42:07,192:INFO:Preloading libraries
2023-06-16 11:42:07,225:INFO:Copying training dataset
2023-06-16 11:42:07,225:INFO:Plot type: residuals
2023-06-16 11:42:07,331:INFO:Fitting Model
2023-06-16 11:42:07,331:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2023-06-16 11:42:07,413:INFO:Scoring test/hold-out set
2023-06-16 11:42:08,175:INFO:Visual Rendered Successfully
2023-06-16 11:42:08,298:INFO:plot_model() successfully completed......................................
2023-06-16 11:42:08,315:INFO:Initializing interpret_model()
2023-06-16 11:42:08,315:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>)
2023-06-16 11:42:08,315:INFO:Checking exceptions
2023-06-16 11:42:08,315:INFO:Soft dependency imported: shap: 0.41.0
2023-06-16 11:42:08,347:INFO:plot type: summary
2023-06-16 11:42:08,347:INFO:Creating TreeExplainer
2023-06-16 11:42:08,379:INFO:Compiling shap values
2023-06-16 11:44:00,720:WARNING:No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored

2023-06-16 11:44:01,518:INFO:Visual Rendered Successfully
2023-06-16 11:44:01,518:INFO:interpret_model() successfully completed......................................
2023-06-16 11:44:01,660:INFO:Initializing interpret_model()
2023-06-16 11:44:01,660:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=correlation, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>)
2023-06-16 11:44:01,660:INFO:Checking exceptions
2023-06-16 11:44:01,660:INFO:Soft dependency imported: shap: 0.41.0
2023-06-16 11:44:01,700:INFO:plot type: correlation
2023-06-16 11:44:01,700:WARNING:No feature passed. Default value of feature used for correlation plot: taxa_homicidio
2023-06-16 11:44:01,700:INFO:Creating TreeExplainer
2023-06-16 11:44:01,736:INFO:Compiling shap values
2023-06-16 11:46:01,506:INFO:model type detected: type 2
2023-06-16 11:46:01,861:INFO:Visual Rendered Successfully
2023-06-16 11:46:01,861:INFO:interpret_model() successfully completed......................................
2023-06-16 11:46:02,042:INFO:Initializing interpret_model()
2023-06-16 11:46:02,042:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=1, plot=reason, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>)
2023-06-16 11:46:02,042:INFO:Checking exceptions
2023-06-16 11:46:02,042:INFO:Soft dependency imported: shap: 0.41.0
2023-06-16 11:46:02,084:INFO:plot type: reason
2023-06-16 11:46:02,085:INFO:model type detected: type 2
2023-06-16 11:46:02,085:INFO:Creating TreeExplainer
2023-06-16 11:46:02,103:INFO:Compiling shap values
2023-06-16 11:48:03,472:INFO:Visual Rendered Successfully
2023-06-16 11:48:03,472:INFO:interpret_model() successfully completed......................................
2023-06-16 11:48:03,627:INFO:Initializing interpret_model()
2023-06-16 11:48:03,627:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=3, plot=reason, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>)
2023-06-16 11:48:03,627:INFO:Checking exceptions
2023-06-16 11:48:03,627:INFO:Soft dependency imported: shap: 0.41.0
2023-06-16 11:48:03,669:INFO:plot type: reason
2023-06-16 11:48:03,669:INFO:model type detected: type 2
2023-06-16 11:48:03,669:INFO:Creating TreeExplainer
2023-06-16 11:48:03,687:INFO:Compiling shap values
2023-06-16 11:50:00,580:INFO:Visual Rendered Successfully
2023-06-16 11:50:00,581:INFO:interpret_model() successfully completed......................................
2023-06-16 12:48:26,993:INFO:Initializing tune_model()
2023-06-16 12:48:26,994:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=5, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>)
2023-06-16 12:48:26,994:INFO:Checking exceptions
2023-06-16 12:48:27,025:INFO:Copying training dataset
2023-06-16 12:48:27,031:INFO:Checking base model
2023-06-16 12:48:27,032:INFO:Base model : Random Forest Regressor
2023-06-16 12:48:27,038:INFO:Declaring metric variables
2023-06-16 12:48:27,043:INFO:Defining Hyperparameters
2023-06-16 12:48:27,185:INFO:Tuning with n_jobs=-1
2023-06-16 12:48:27,185:INFO:Initializing RandomizedSearchCV
2023-06-16 12:48:50,765:INFO:best_params: {'actual_estimator__n_estimators': 190, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 4, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': True}
2023-06-16 12:48:50,766:INFO:Hyperparameter search completed
2023-06-16 12:48:50,766:INFO:SubProcess create_model() called ==================================
2023-06-16 12:48:50,767:INFO:Initializing create_model()
2023-06-16 12:48:50,767:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000261E1878070>, model_only=True, return_train_score=False, kwargs={'n_estimators': 190, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.3, 'max_features': 1.0, 'max_depth': 4, 'criterion': 'squared_error', 'bootstrap': True})
2023-06-16 12:48:50,767:INFO:Checking exceptions
2023-06-16 12:48:50,767:INFO:Importing libraries
2023-06-16 12:48:50,767:INFO:Copying training dataset
2023-06-16 12:48:50,775:INFO:Defining folds
2023-06-16 12:48:50,775:INFO:Declaring metric variables
2023-06-16 12:48:50,778:INFO:Importing untrained model
2023-06-16 12:48:50,778:INFO:Declaring custom model
2023-06-16 12:48:50,781:INFO:Random Forest Regressor Imported successfully
2023-06-16 12:48:50,788:INFO:Starting cross validation
2023-06-16 12:48:50,790:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 12:48:52,329:INFO:Calculating mean and std
2023-06-16 12:48:52,331:INFO:Creating metrics dataframe
2023-06-16 12:48:52,337:INFO:Finalizing model
2023-06-16 12:48:52,892:INFO:Uploading results into container
2023-06-16 12:48:52,893:INFO:Uploading model into container now
2023-06-16 12:48:52,894:INFO:_master_model_container: 21
2023-06-16 12:48:52,894:INFO:_display_container: 4
2023-06-16 12:48:52,894:INFO:RandomForestRegressor(max_depth=4, min_impurity_decrease=0.3,
                      min_samples_leaf=2, n_estimators=190, n_jobs=-1,
                      random_state=42)
2023-06-16 12:48:52,894:INFO:create_model() successfully completed......................................
2023-06-16 12:48:53,027:INFO:SubProcess create_model() end ==================================
2023-06-16 12:48:53,027:INFO:choose_better activated
2023-06-16 12:48:53,034:INFO:SubProcess create_model() called ==================================
2023-06-16 12:48:53,036:INFO:Initializing create_model()
2023-06-16 12:48:53,036:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-16 12:48:53,036:INFO:Checking exceptions
2023-06-16 12:48:53,041:INFO:Importing libraries
2023-06-16 12:48:53,041:INFO:Copying training dataset
2023-06-16 12:48:53,051:INFO:Defining folds
2023-06-16 12:48:53,051:INFO:Declaring metric variables
2023-06-16 12:48:53,051:INFO:Importing untrained model
2023-06-16 12:48:53,051:INFO:Declaring custom model
2023-06-16 12:48:53,053:INFO:Random Forest Regressor Imported successfully
2023-06-16 12:48:53,053:INFO:Starting cross validation
2023-06-16 12:48:53,055:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 12:48:54,567:INFO:Calculating mean and std
2023-06-16 12:48:54,568:INFO:Creating metrics dataframe
2023-06-16 12:48:54,570:INFO:Finalizing model
2023-06-16 12:48:55,093:INFO:Uploading results into container
2023-06-16 12:48:55,094:INFO:Uploading model into container now
2023-06-16 12:48:55,095:INFO:_master_model_container: 22
2023-06-16 12:48:55,095:INFO:_display_container: 5
2023-06-16 12:48:55,095:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 12:48:55,095:INFO:create_model() successfully completed......................................
2023-06-16 12:48:55,208:INFO:SubProcess create_model() end ==================================
2023-06-16 12:48:55,209:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) result for R2 is 0.9102
2023-06-16 12:48:55,209:INFO:RandomForestRegressor(max_depth=4, min_impurity_decrease=0.3,
                      min_samples_leaf=2, n_estimators=190, n_jobs=-1,
                      random_state=42) result for R2 is 0.8871
2023-06-16 12:48:55,210:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) is best model
2023-06-16 12:48:55,210:INFO:choose_better completed
2023-06-16 12:48:55,210:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-06-16 12:48:55,218:INFO:_master_model_container: 22
2023-06-16 12:48:55,218:INFO:_display_container: 4
2023-06-16 12:48:55,220:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 12:48:55,220:INFO:tune_model() successfully completed......................................
2023-06-16 12:49:06,823:INFO:Initializing plot_model()
2023-06-16 12:49:06,824:INFO:plot_model(plot=learning, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, system=True)
2023-06-16 12:49:06,824:INFO:Checking exceptions
2023-06-16 12:49:06,852:INFO:Preloading libraries
2023-06-16 12:49:06,885:INFO:Copying training dataset
2023-06-16 12:49:06,885:INFO:Plot type: learning
2023-06-16 12:49:06,992:INFO:Fitting Model
2023-06-16 12:50:26,744:INFO:Visual Rendered Successfully
2023-06-16 12:50:26,895:INFO:plot_model() successfully completed......................................
2023-06-16 12:50:26,911:INFO:Initializing plot_model()
2023-06-16 12:50:26,911:INFO:plot_model(plot=vc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, system=True)
2023-06-16 12:50:26,912:INFO:Checking exceptions
2023-06-16 12:50:26,941:INFO:Preloading libraries
2023-06-16 12:50:27,005:INFO:Copying training dataset
2023-06-16 12:50:27,005:INFO:Plot type: vc
2023-06-16 12:50:27,006:INFO:Determining param_name
2023-06-16 12:50:27,006:INFO:param_name: max_depth
2023-06-16 12:50:27,140:INFO:Fitting Model
2023-06-16 12:51:20,173:INFO:Visual Rendered Successfully
2023-06-16 12:51:20,297:INFO:plot_model() successfully completed......................................
2023-06-16 12:51:20,308:INFO:Initializing plot_model()
2023-06-16 12:51:20,308:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, system=True)
2023-06-16 12:51:20,309:INFO:Checking exceptions
2023-06-16 12:51:20,334:INFO:Preloading libraries
2023-06-16 12:51:20,388:INFO:Copying training dataset
2023-06-16 12:51:20,389:INFO:Plot type: error
2023-06-16 12:51:20,521:INFO:Fitting Model
2023-06-16 12:51:20,521:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2023-06-16 12:51:20,521:INFO:Scoring test/hold-out set
2023-06-16 12:51:20,830:INFO:Visual Rendered Successfully
2023-06-16 12:51:20,964:INFO:plot_model() successfully completed......................................
2023-06-16 12:51:20,989:INFO:Initializing plot_model()
2023-06-16 12:51:20,989:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, system=True)
2023-06-16 12:51:20,990:INFO:Checking exceptions
2023-06-16 12:51:21,019:INFO:Preloading libraries
2023-06-16 12:51:21,059:INFO:Copying training dataset
2023-06-16 12:51:21,059:INFO:Plot type: feature
2023-06-16 12:51:21,059:WARNING:No coef_ found. Trying feature_importances_
2023-06-16 12:51:21,321:INFO:Visual Rendered Successfully
2023-06-16 12:51:21,463:INFO:plot_model() successfully completed......................................
2023-06-16 12:51:21,478:INFO:Initializing plot_model()
2023-06-16 12:51:21,478:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=3, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, system=True)
2023-06-16 12:51:21,478:INFO:Checking exceptions
2023-06-16 12:51:21,501:INFO:Preloading libraries
2023-06-16 12:51:21,570:INFO:Copying training dataset
2023-06-16 12:51:21,570:INFO:Plot type: residuals
2023-06-16 12:51:21,713:INFO:Fitting Model
2023-06-16 12:51:21,713:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2023-06-16 12:51:21,842:INFO:Scoring test/hold-out set
2023-06-16 12:51:22,584:INFO:Visual Rendered Successfully
2023-06-16 12:51:22,705:INFO:plot_model() successfully completed......................................
2023-06-16 12:51:22,759:INFO:Initializing interpret_model()
2023-06-16 12:51:22,759:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>)
2023-06-16 12:51:22,760:INFO:Checking exceptions
2023-06-16 12:51:22,760:INFO:Soft dependency imported: shap: 0.41.0
2023-06-16 12:51:22,808:INFO:plot type: summary
2023-06-16 12:51:22,809:INFO:Creating TreeExplainer
2023-06-16 12:51:22,834:INFO:Compiling shap values
2023-06-16 12:53:11,405:WARNING:No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored

2023-06-16 12:53:12,101:INFO:Visual Rendered Successfully
2023-06-16 12:53:12,102:INFO:interpret_model() successfully completed......................................
2023-06-16 12:53:12,264:INFO:Initializing interpret_model()
2023-06-16 12:53:12,265:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=correlation, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>)
2023-06-16 12:53:12,266:INFO:Checking exceptions
2023-06-16 12:53:12,266:INFO:Soft dependency imported: shap: 0.41.0
2023-06-16 12:53:12,295:INFO:plot type: correlation
2023-06-16 12:53:12,296:WARNING:No feature passed. Default value of feature used for correlation plot: taxa_homicidio
2023-06-16 12:53:12,296:INFO:Creating TreeExplainer
2023-06-16 12:53:12,325:INFO:Compiling shap values
2023-06-16 12:55:05,863:INFO:model type detected: type 2
2023-06-16 12:55:06,222:INFO:Visual Rendered Successfully
2023-06-16 12:55:06,222:INFO:interpret_model() successfully completed......................................
2023-06-16 12:55:06,368:INFO:Initializing interpret_model()
2023-06-16 12:55:06,368:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=1, plot=reason, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>)
2023-06-16 12:55:06,368:INFO:Checking exceptions
2023-06-16 12:55:06,368:INFO:Soft dependency imported: shap: 0.41.0
2023-06-16 12:55:06,397:INFO:plot type: reason
2023-06-16 12:55:06,397:INFO:model type detected: type 2
2023-06-16 12:55:06,397:INFO:Creating TreeExplainer
2023-06-16 12:55:06,419:INFO:Compiling shap values
2023-06-16 12:57:00,720:INFO:Visual Rendered Successfully
2023-06-16 12:57:00,720:INFO:interpret_model() successfully completed......................................
2023-06-16 12:57:00,894:INFO:Initializing interpret_model()
2023-06-16 12:57:00,894:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=3, plot=reason, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>)
2023-06-16 12:57:00,895:INFO:Checking exceptions
2023-06-16 12:57:00,895:INFO:Soft dependency imported: shap: 0.41.0
2023-06-16 12:57:00,932:INFO:plot type: reason
2023-06-16 12:57:00,932:INFO:model type detected: type 2
2023-06-16 12:57:00,932:INFO:Creating TreeExplainer
2023-06-16 12:57:00,964:INFO:Compiling shap values
2023-06-16 12:58:52,979:INFO:Visual Rendered Successfully
2023-06-16 12:58:52,980:INFO:interpret_model() successfully completed......................................
2023-06-16 12:58:53,147:INFO:Initializing tune_model()
2023-06-16 12:58:53,148:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=5, round=4, n_iter=10, custom_grid={'max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>)
2023-06-16 12:58:53,148:INFO:Checking exceptions
2023-06-16 12:58:53,169:INFO:Copying training dataset
2023-06-16 12:58:53,176:INFO:Checking base model
2023-06-16 12:58:53,176:INFO:Base model : Random Forest Regressor
2023-06-16 12:58:53,184:INFO:Declaring metric variables
2023-06-16 12:58:53,188:INFO:Defining Hyperparameters
2023-06-16 12:58:53,326:INFO:custom_grid: {'actual_estimator__max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}
2023-06-16 12:58:53,326:INFO:Tuning with n_jobs=-1
2023-06-16 12:58:53,326:INFO:Initializing RandomizedSearchCV
2023-06-16 12:59:17,243:WARNING:
5 fits failed out of a total of 50.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\lapei\anaconda3\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py", line 340, in fit
    self._validate_params()
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\base.py", line 581, in _validate_params
    validate_parameter_constraints(
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 97, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestRegressor must be an int in the range [1, inf) or None. Got 0 instead.


2023-06-16 12:59:17,244:WARNING:One or more of the test scores are non-finite: [       nan 0.48652662 0.84008985 0.88700297 0.89957066 0.90836024
 0.90866937 0.90843499 0.90995616 0.91114377]

2023-06-16 12:59:17,716:INFO:best_params: {'actual_estimator__max_depth': 10}
2023-06-16 12:59:17,718:INFO:Hyperparameter search completed
2023-06-16 12:59:17,718:INFO:SubProcess create_model() called ==================================
2023-06-16 12:59:17,720:INFO:Initializing create_model()
2023-06-16 12:59:17,721:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000261E1878070>, model_only=True, return_train_score=False, kwargs={'max_depth': 10})
2023-06-16 12:59:17,721:INFO:Checking exceptions
2023-06-16 12:59:17,722:INFO:Importing libraries
2023-06-16 12:59:17,722:INFO:Copying training dataset
2023-06-16 12:59:17,732:INFO:Defining folds
2023-06-16 12:59:17,733:INFO:Declaring metric variables
2023-06-16 12:59:17,740:INFO:Importing untrained model
2023-06-16 12:59:17,740:INFO:Declaring custom model
2023-06-16 12:59:17,744:INFO:Random Forest Regressor Imported successfully
2023-06-16 12:59:17,755:INFO:Starting cross validation
2023-06-16 12:59:17,757:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 12:59:19,220:INFO:Calculating mean and std
2023-06-16 12:59:19,221:INFO:Creating metrics dataframe
2023-06-16 12:59:19,231:INFO:Finalizing model
2023-06-16 12:59:19,714:INFO:Uploading results into container
2023-06-16 12:59:19,715:INFO:Uploading model into container now
2023-06-16 12:59:19,715:INFO:_master_model_container: 23
2023-06-16 12:59:19,715:INFO:_display_container: 5
2023-06-16 12:59:19,717:INFO:RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42)
2023-06-16 12:59:19,717:INFO:create_model() successfully completed......................................
2023-06-16 12:59:19,870:INFO:SubProcess create_model() end ==================================
2023-06-16 12:59:19,870:INFO:choose_better activated
2023-06-16 12:59:19,874:INFO:SubProcess create_model() called ==================================
2023-06-16 12:59:19,874:INFO:Initializing create_model()
2023-06-16 12:59:19,874:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-16 12:59:19,875:INFO:Checking exceptions
2023-06-16 12:59:19,876:INFO:Importing libraries
2023-06-16 12:59:19,876:INFO:Copying training dataset
2023-06-16 12:59:19,886:INFO:Defining folds
2023-06-16 12:59:19,886:INFO:Declaring metric variables
2023-06-16 12:59:19,886:INFO:Importing untrained model
2023-06-16 12:59:19,886:INFO:Declaring custom model
2023-06-16 12:59:19,888:INFO:Random Forest Regressor Imported successfully
2023-06-16 12:59:19,889:INFO:Starting cross validation
2023-06-16 12:59:19,891:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 12:59:21,406:INFO:Calculating mean and std
2023-06-16 12:59:21,406:INFO:Creating metrics dataframe
2023-06-16 12:59:21,410:INFO:Finalizing model
2023-06-16 12:59:22,014:INFO:Uploading results into container
2023-06-16 12:59:22,014:INFO:Uploading model into container now
2023-06-16 12:59:22,015:INFO:_master_model_container: 24
2023-06-16 12:59:22,015:INFO:_display_container: 6
2023-06-16 12:59:22,015:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 12:59:22,015:INFO:create_model() successfully completed......................................
2023-06-16 12:59:22,151:INFO:SubProcess create_model() end ==================================
2023-06-16 12:59:22,153:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) result for R2 is 0.9102
2023-06-16 12:59:22,154:INFO:RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42) result for R2 is 0.9111
2023-06-16 12:59:22,155:INFO:RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42) is best model
2023-06-16 12:59:22,155:INFO:choose_better completed
2023-06-16 12:59:22,170:INFO:_master_model_container: 24
2023-06-16 12:59:22,170:INFO:_display_container: 5
2023-06-16 12:59:22,171:INFO:RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42)
2023-06-16 12:59:22,171:INFO:tune_model() successfully completed......................................
2023-06-16 12:59:22,665:INFO:Initializing tune_model()
2023-06-16 12:59:22,665:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=5, round=4, n_iter=10, custom_grid={'max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'min_samples_split': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'min_samples_leaf': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'ccp_alpha': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.9]}, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>)
2023-06-16 12:59:22,665:INFO:Checking exceptions
2023-06-16 12:59:22,693:INFO:Copying training dataset
2023-06-16 12:59:22,697:INFO:Checking base model
2023-06-16 12:59:22,697:INFO:Base model : Random Forest Regressor
2023-06-16 12:59:22,700:INFO:Declaring metric variables
2023-06-16 12:59:22,705:INFO:Defining Hyperparameters
2023-06-16 12:59:22,850:INFO:custom_grid: {'actual_estimator__max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'actual_estimator__min_samples_split': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'actual_estimator__min_samples_leaf': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'actual_estimator__ccp_alpha': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.9]}
2023-06-16 12:59:22,851:INFO:Tuning with n_jobs=-1
2023-06-16 12:59:22,852:INFO:Initializing RandomizedSearchCV
2023-06-16 12:59:39,695:WARNING:
10 fits failed out of a total of 50.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\lapei\anaconda3\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py", line 340, in fit
    self._validate_params()
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\base.py", line 581, in _validate_params
    validate_parameter_constraints(
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 97, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_leaf' parameter of RandomForestRegressor must be an int in the range [1, inf) or a float in the range (0.0, 1.0). Got 0 instead.

--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\lapei\anaconda3\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py", line 340, in fit
    self._validate_params()
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\base.py", line 581, in _validate_params
    validate_parameter_constraints(
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 97, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestRegressor must be an int in the range [1, inf) or None. Got 0 instead.


2023-06-16 12:59:39,696:WARNING:One or more of the test scores are non-finite: [0.71688307 0.8282534  0.7137073         nan 0.78077576 0.84008985
        nan 0.70168477 0.74884873 0.90843499]

2023-06-16 12:59:40,307:INFO:best_params: {'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 1, 'actual_estimator__max_depth': 7, 'actual_estimator__ccp_alpha': 0.0}
2023-06-16 12:59:40,309:INFO:Hyperparameter search completed
2023-06-16 12:59:40,309:INFO:SubProcess create_model() called ==================================
2023-06-16 12:59:40,310:INFO:Initializing create_model()
2023-06-16 12:59:40,311:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000261DFD4AE00>, model_only=True, return_train_score=False, kwargs={'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'ccp_alpha': 0.0})
2023-06-16 12:59:40,311:INFO:Checking exceptions
2023-06-16 12:59:40,311:INFO:Importing libraries
2023-06-16 12:59:40,311:INFO:Copying training dataset
2023-06-16 12:59:40,325:INFO:Defining folds
2023-06-16 12:59:40,325:INFO:Declaring metric variables
2023-06-16 12:59:40,331:INFO:Importing untrained model
2023-06-16 12:59:40,332:INFO:Declaring custom model
2023-06-16 12:59:40,338:INFO:Random Forest Regressor Imported successfully
2023-06-16 12:59:40,350:INFO:Starting cross validation
2023-06-16 12:59:40,352:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 12:59:41,914:INFO:Calculating mean and std
2023-06-16 12:59:41,916:INFO:Creating metrics dataframe
2023-06-16 12:59:41,923:INFO:Finalizing model
2023-06-16 12:59:42,491:INFO:Uploading results into container
2023-06-16 12:59:42,492:INFO:Uploading model into container now
2023-06-16 12:59:42,492:INFO:_master_model_container: 25
2023-06-16 12:59:42,492:INFO:_display_container: 6
2023-06-16 12:59:42,492:INFO:RandomForestRegressor(max_depth=7, n_jobs=-1, random_state=42)
2023-06-16 12:59:42,492:INFO:create_model() successfully completed......................................
2023-06-16 12:59:42,633:INFO:SubProcess create_model() end ==================================
2023-06-16 12:59:42,634:INFO:choose_better activated
2023-06-16 12:59:42,644:INFO:SubProcess create_model() called ==================================
2023-06-16 12:59:42,646:INFO:Initializing create_model()
2023-06-16 12:59:42,646:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-16 12:59:42,646:INFO:Checking exceptions
2023-06-16 12:59:42,650:INFO:Importing libraries
2023-06-16 12:59:42,650:INFO:Copying training dataset
2023-06-16 12:59:42,659:INFO:Defining folds
2023-06-16 12:59:42,659:INFO:Declaring metric variables
2023-06-16 12:59:42,659:INFO:Importing untrained model
2023-06-16 12:59:42,660:INFO:Declaring custom model
2023-06-16 12:59:42,660:INFO:Random Forest Regressor Imported successfully
2023-06-16 12:59:42,661:INFO:Starting cross validation
2023-06-16 12:59:42,662:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 12:59:44,171:INFO:Calculating mean and std
2023-06-16 12:59:44,171:INFO:Creating metrics dataframe
2023-06-16 12:59:44,174:INFO:Finalizing model
2023-06-16 12:59:44,667:INFO:Uploading results into container
2023-06-16 12:59:44,668:INFO:Uploading model into container now
2023-06-16 12:59:44,669:INFO:_master_model_container: 26
2023-06-16 12:59:44,669:INFO:_display_container: 7
2023-06-16 12:59:44,669:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 12:59:44,669:INFO:create_model() successfully completed......................................
2023-06-16 12:59:44,820:INFO:SubProcess create_model() end ==================================
2023-06-16 12:59:44,821:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) result for R2 is 0.9102
2023-06-16 12:59:44,822:INFO:RandomForestRegressor(max_depth=7, n_jobs=-1, random_state=42) result for R2 is 0.9084
2023-06-16 12:59:44,822:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) is best model
2023-06-16 12:59:44,822:INFO:choose_better completed
2023-06-16 12:59:44,822:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-06-16 12:59:44,832:INFO:_master_model_container: 26
2023-06-16 12:59:44,832:INFO:_display_container: 6
2023-06-16 12:59:44,833:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 12:59:44,833:INFO:tune_model() successfully completed......................................
2023-06-16 12:59:45,258:INFO:Initializing plot_model()
2023-06-16 12:59:45,258:INFO:plot_model(plot=learning, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, system=True)
2023-06-16 12:59:45,258:INFO:Checking exceptions
2023-06-16 12:59:45,277:INFO:Preloading libraries
2023-06-16 12:59:45,291:INFO:Copying training dataset
2023-06-16 12:59:45,291:INFO:Plot type: learning
2023-06-16 12:59:45,397:INFO:Fitting Model
2023-06-16 13:00:37,083:INFO:Visual Rendered Successfully
2023-06-16 13:00:37,240:INFO:plot_model() successfully completed......................................
2023-06-16 13:00:37,258:INFO:Initializing plot_model()
2023-06-16 13:00:37,258:INFO:plot_model(plot=vc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, system=True)
2023-06-16 13:00:37,258:INFO:Checking exceptions
2023-06-16 13:00:37,280:INFO:Preloading libraries
2023-06-16 13:00:37,290:INFO:Copying training dataset
2023-06-16 13:00:37,290:INFO:Plot type: vc
2023-06-16 13:00:37,290:INFO:Determining param_name
2023-06-16 13:00:37,290:INFO:param_name: max_depth
2023-06-16 13:00:37,405:INFO:Fitting Model
2023-06-16 13:01:24,443:INFO:Visual Rendered Successfully
2023-06-16 13:01:24,583:INFO:plot_model() successfully completed......................................
2023-06-16 13:01:24,593:INFO:Initializing plot_model()
2023-06-16 13:01:24,594:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, system=True)
2023-06-16 13:01:24,594:INFO:Checking exceptions
2023-06-16 13:01:24,612:INFO:Preloading libraries
2023-06-16 13:01:24,623:INFO:Copying training dataset
2023-06-16 13:01:24,624:INFO:Plot type: error
2023-06-16 13:01:24,718:INFO:Fitting Model
2023-06-16 13:01:24,718:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2023-06-16 13:01:24,718:INFO:Scoring test/hold-out set
2023-06-16 13:01:25,027:INFO:Visual Rendered Successfully
2023-06-16 13:01:25,182:INFO:plot_model() successfully completed......................................
2023-06-16 13:01:25,195:INFO:Initializing plot_model()
2023-06-16 13:01:25,196:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, system=True)
2023-06-16 13:01:25,196:INFO:Checking exceptions
2023-06-16 13:01:25,213:INFO:Preloading libraries
2023-06-16 13:01:25,220:INFO:Copying training dataset
2023-06-16 13:01:25,220:INFO:Plot type: feature
2023-06-16 13:01:25,221:WARNING:No coef_ found. Trying feature_importances_
2023-06-16 13:01:25,419:INFO:Visual Rendered Successfully
2023-06-16 13:01:25,557:INFO:plot_model() successfully completed......................................
2023-06-16 13:01:25,571:INFO:Initializing plot_model()
2023-06-16 13:01:25,572:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=3, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>, system=True)
2023-06-16 13:01:25,572:INFO:Checking exceptions
2023-06-16 13:01:25,592:INFO:Preloading libraries
2023-06-16 13:01:25,603:INFO:Copying training dataset
2023-06-16 13:01:25,604:INFO:Plot type: residuals
2023-06-16 13:01:25,719:INFO:Fitting Model
2023-06-16 13:01:25,719:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2023-06-16 13:01:25,804:INFO:Scoring test/hold-out set
2023-06-16 13:01:26,526:INFO:Visual Rendered Successfully
2023-06-16 13:01:26,668:INFO:plot_model() successfully completed......................................
2023-06-16 13:01:26,690:INFO:Initializing interpret_model()
2023-06-16 13:01:26,690:INFO:interpret_model(estimator=RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>)
2023-06-16 13:01:26,690:INFO:Checking exceptions
2023-06-16 13:01:26,690:INFO:Soft dependency imported: shap: 0.41.0
2023-06-16 13:01:26,726:INFO:plot type: summary
2023-06-16 13:01:26,726:INFO:Creating TreeExplainer
2023-06-16 13:01:26,733:INFO:Compiling shap values
2023-06-16 13:01:32,456:WARNING:No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored

2023-06-16 13:01:33,056:INFO:Visual Rendered Successfully
2023-06-16 13:01:33,056:INFO:interpret_model() successfully completed......................................
2023-06-16 13:01:33,213:INFO:Initializing interpret_model()
2023-06-16 13:01:33,214:INFO:interpret_model(estimator=RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=correlation, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>)
2023-06-16 13:01:33,214:INFO:Checking exceptions
2023-06-16 13:01:33,214:INFO:Soft dependency imported: shap: 0.41.0
2023-06-16 13:01:33,244:INFO:plot type: correlation
2023-06-16 13:01:33,244:WARNING:No feature passed. Default value of feature used for correlation plot: taxa_homicidio
2023-06-16 13:01:33,244:INFO:Creating TreeExplainer
2023-06-16 13:01:33,249:INFO:Compiling shap values
2023-06-16 13:01:38,655:INFO:model type detected: type 2
2023-06-16 13:01:38,923:INFO:Visual Rendered Successfully
2023-06-16 13:01:38,923:INFO:interpret_model() successfully completed......................................
2023-06-16 13:01:39,066:INFO:Initializing interpret_model()
2023-06-16 13:01:39,067:INFO:interpret_model(estimator=RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=1, plot=reason, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>)
2023-06-16 13:01:39,067:INFO:Checking exceptions
2023-06-16 13:01:39,067:INFO:Soft dependency imported: shap: 0.41.0
2023-06-16 13:01:39,106:INFO:plot type: reason
2023-06-16 13:01:39,106:INFO:model type detected: type 2
2023-06-16 13:01:39,106:INFO:Creating TreeExplainer
2023-06-16 13:01:39,110:INFO:Compiling shap values
2023-06-16 13:01:44,779:INFO:Visual Rendered Successfully
2023-06-16 13:01:44,779:INFO:interpret_model() successfully completed......................................
2023-06-16 13:01:44,922:INFO:Initializing interpret_model()
2023-06-16 13:01:44,923:INFO:interpret_model(estimator=RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=3, plot=reason, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000261E1662A70>)
2023-06-16 13:01:44,923:INFO:Checking exceptions
2023-06-16 13:01:44,923:INFO:Soft dependency imported: shap: 0.41.0
2023-06-16 13:01:44,954:INFO:plot type: reason
2023-06-16 13:01:44,954:INFO:model type detected: type 2
2023-06-16 13:01:44,954:INFO:Creating TreeExplainer
2023-06-16 13:01:44,958:INFO:Compiling shap values
2023-06-16 13:01:50,818:INFO:Visual Rendered Successfully
2023-06-16 13:01:50,819:INFO:interpret_model() successfully completed......................................
2023-06-16 13:09:09,161:INFO:Initializing compare_models()
2023-06-16 13:09:09,165:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, include=None, fold=5, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, 'include': None, 'exclude': None, 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-06-16 13:09:09,166:INFO:Checking exceptions
2023-06-16 13:09:09,236:INFO:Preparing display monitor
2023-06-16 13:09:09,321:INFO:Initializing Linear Regression
2023-06-16 13:09:09,321:INFO:Total runtime is 1.6657511393229165e-05 minutes
2023-06-16 13:09:09,325:INFO:SubProcess create_model() called ==================================
2023-06-16 13:09:09,328:INFO:Initializing create_model()
2023-06-16 13:09:09,329:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196DB2E5450>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 13:09:09,329:INFO:Checking exceptions
2023-06-16 13:09:09,329:INFO:Importing libraries
2023-06-16 13:09:09,330:INFO:Copying training dataset
2023-06-16 13:09:09,335:INFO:Defining folds
2023-06-16 13:09:09,336:INFO:Declaring metric variables
2023-06-16 13:09:09,340:INFO:Importing untrained model
2023-06-16 13:09:09,345:INFO:Linear Regression Imported successfully
2023-06-16 13:09:09,354:INFO:Starting cross validation
2023-06-16 13:09:09,358:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 13:09:14,934:INFO:Calculating mean and std
2023-06-16 13:09:14,936:INFO:Creating metrics dataframe
2023-06-16 13:09:15,461:INFO:Uploading results into container
2023-06-16 13:09:15,462:INFO:Uploading model into container now
2023-06-16 13:09:15,463:INFO:_master_model_container: 87
2023-06-16 13:09:15,463:INFO:_display_container: 13
2023-06-16 13:09:15,464:INFO:LinearRegression(n_jobs=-1)
2023-06-16 13:09:15,464:INFO:create_model() successfully completed......................................
2023-06-16 13:09:15,933:INFO:SubProcess create_model() end ==================================
2023-06-16 13:09:15,934:INFO:Creating metrics dataframe
2023-06-16 13:09:15,944:INFO:Initializing Lasso Regression
2023-06-16 13:09:15,944:INFO:Total runtime is 0.11039340098698933 minutes
2023-06-16 13:09:15,947:INFO:SubProcess create_model() called ==================================
2023-06-16 13:09:15,947:INFO:Initializing create_model()
2023-06-16 13:09:15,947:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196DB2E5450>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 13:09:15,948:INFO:Checking exceptions
2023-06-16 13:09:15,948:INFO:Importing libraries
2023-06-16 13:09:15,948:INFO:Copying training dataset
2023-06-16 13:09:15,958:INFO:Defining folds
2023-06-16 13:09:15,959:INFO:Declaring metric variables
2023-06-16 13:09:15,963:INFO:Importing untrained model
2023-06-16 13:09:15,967:INFO:Lasso Regression Imported successfully
2023-06-16 13:09:15,976:INFO:Starting cross validation
2023-06-16 13:09:15,977:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 13:09:19,228:INFO:Calculating mean and std
2023-06-16 13:09:19,228:INFO:Creating metrics dataframe
2023-06-16 13:09:19,703:INFO:Uploading results into container
2023-06-16 13:09:19,705:INFO:Uploading model into container now
2023-06-16 13:09:19,706:INFO:_master_model_container: 88
2023-06-16 13:09:19,706:INFO:_display_container: 13
2023-06-16 13:09:19,706:INFO:Lasso(random_state=42)
2023-06-16 13:09:19,707:INFO:create_model() successfully completed......................................
2023-06-16 13:09:19,912:INFO:SubProcess create_model() end ==================================
2023-06-16 13:09:19,913:INFO:Creating metrics dataframe
2023-06-16 13:09:19,933:INFO:Initializing Ridge Regression
2023-06-16 13:09:19,933:INFO:Total runtime is 0.17688964207967123 minutes
2023-06-16 13:09:19,942:INFO:SubProcess create_model() called ==================================
2023-06-16 13:09:19,943:INFO:Initializing create_model()
2023-06-16 13:09:19,944:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196DB2E5450>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 13:09:19,944:INFO:Checking exceptions
2023-06-16 13:09:19,944:INFO:Importing libraries
2023-06-16 13:09:19,944:INFO:Copying training dataset
2023-06-16 13:09:19,952:INFO:Defining folds
2023-06-16 13:09:19,953:INFO:Declaring metric variables
2023-06-16 13:09:19,958:INFO:Importing untrained model
2023-06-16 13:09:19,961:INFO:Ridge Regression Imported successfully
2023-06-16 13:09:19,969:INFO:Starting cross validation
2023-06-16 13:09:19,972:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 13:09:21,308:INFO:Calculating mean and std
2023-06-16 13:09:21,310:INFO:Creating metrics dataframe
2023-06-16 13:09:21,914:INFO:Uploading results into container
2023-06-16 13:09:21,915:INFO:Uploading model into container now
2023-06-16 13:09:21,915:INFO:_master_model_container: 89
2023-06-16 13:09:21,915:INFO:_display_container: 13
2023-06-16 13:09:21,916:INFO:Ridge(random_state=42)
2023-06-16 13:09:21,916:INFO:create_model() successfully completed......................................
2023-06-16 13:09:22,104:INFO:SubProcess create_model() end ==================================
2023-06-16 13:09:22,104:INFO:Creating metrics dataframe
2023-06-16 13:09:22,114:INFO:Initializing Elastic Net
2023-06-16 13:09:22,114:INFO:Total runtime is 0.2132312297821045 minutes
2023-06-16 13:09:22,119:INFO:SubProcess create_model() called ==================================
2023-06-16 13:09:22,119:INFO:Initializing create_model()
2023-06-16 13:09:22,119:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196DB2E5450>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 13:09:22,120:INFO:Checking exceptions
2023-06-16 13:09:22,120:INFO:Importing libraries
2023-06-16 13:09:22,120:INFO:Copying training dataset
2023-06-16 13:09:22,125:INFO:Defining folds
2023-06-16 13:09:22,125:INFO:Declaring metric variables
2023-06-16 13:09:22,129:INFO:Importing untrained model
2023-06-16 13:09:22,132:INFO:Elastic Net Imported successfully
2023-06-16 13:09:22,143:INFO:Starting cross validation
2023-06-16 13:09:22,144:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 13:09:23,414:INFO:Calculating mean and std
2023-06-16 13:09:23,415:INFO:Creating metrics dataframe
2023-06-16 13:09:23,771:INFO:Uploading results into container
2023-06-16 13:09:23,771:INFO:Uploading model into container now
2023-06-16 13:09:23,772:INFO:_master_model_container: 90
2023-06-16 13:09:23,772:INFO:_display_container: 13
2023-06-16 13:09:23,773:INFO:ElasticNet(random_state=42)
2023-06-16 13:09:23,773:INFO:create_model() successfully completed......................................
2023-06-16 13:09:23,967:INFO:SubProcess create_model() end ==================================
2023-06-16 13:09:23,968:INFO:Creating metrics dataframe
2023-06-16 13:09:23,977:INFO:Initializing Least Angle Regression
2023-06-16 13:09:23,977:INFO:Total runtime is 0.2442776401837667 minutes
2023-06-16 13:09:23,982:INFO:SubProcess create_model() called ==================================
2023-06-16 13:09:23,982:INFO:Initializing create_model()
2023-06-16 13:09:23,982:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196DB2E5450>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 13:09:23,982:INFO:Checking exceptions
2023-06-16 13:09:23,982:INFO:Importing libraries
2023-06-16 13:09:23,982:INFO:Copying training dataset
2023-06-16 13:09:23,988:INFO:Defining folds
2023-06-16 13:09:23,988:INFO:Declaring metric variables
2023-06-16 13:09:23,993:INFO:Importing untrained model
2023-06-16 13:09:23,997:INFO:Least Angle Regression Imported successfully
2023-06-16 13:09:24,009:INFO:Starting cross validation
2023-06-16 13:09:24,010:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 13:09:25,224:INFO:Calculating mean and std
2023-06-16 13:09:25,225:INFO:Creating metrics dataframe
2023-06-16 13:09:25,629:INFO:Uploading results into container
2023-06-16 13:09:25,629:INFO:Uploading model into container now
2023-06-16 13:09:25,630:INFO:_master_model_container: 91
2023-06-16 13:09:25,630:INFO:_display_container: 13
2023-06-16 13:09:25,631:INFO:Lars(random_state=42)
2023-06-16 13:09:25,631:INFO:create_model() successfully completed......................................
2023-06-16 13:09:25,833:INFO:SubProcess create_model() end ==================================
2023-06-16 13:09:25,833:INFO:Creating metrics dataframe
2023-06-16 13:09:25,852:INFO:Initializing Lasso Least Angle Regression
2023-06-16 13:09:25,852:INFO:Total runtime is 0.2755399227142334 minutes
2023-06-16 13:09:25,857:INFO:SubProcess create_model() called ==================================
2023-06-16 13:09:25,857:INFO:Initializing create_model()
2023-06-16 13:09:25,857:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196DB2E5450>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 13:09:25,858:INFO:Checking exceptions
2023-06-16 13:09:25,858:INFO:Importing libraries
2023-06-16 13:09:25,858:INFO:Copying training dataset
2023-06-16 13:09:25,867:INFO:Defining folds
2023-06-16 13:09:25,867:INFO:Declaring metric variables
2023-06-16 13:09:25,872:INFO:Importing untrained model
2023-06-16 13:09:25,876:INFO:Lasso Least Angle Regression Imported successfully
2023-06-16 13:09:25,893:INFO:Starting cross validation
2023-06-16 13:09:25,894:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 13:09:27,207:INFO:Calculating mean and std
2023-06-16 13:09:27,208:INFO:Creating metrics dataframe
2023-06-16 13:09:27,784:INFO:Uploading results into container
2023-06-16 13:09:27,785:INFO:Uploading model into container now
2023-06-16 13:09:27,786:INFO:_master_model_container: 92
2023-06-16 13:09:27,786:INFO:_display_container: 13
2023-06-16 13:09:27,787:INFO:LassoLars(random_state=42)
2023-06-16 13:09:27,787:INFO:create_model() successfully completed......................................
2023-06-16 13:09:28,016:INFO:SubProcess create_model() end ==================================
2023-06-16 13:09:28,017:INFO:Creating metrics dataframe
2023-06-16 13:09:28,031:INFO:Initializing Orthogonal Matching Pursuit
2023-06-16 13:09:28,031:INFO:Total runtime is 0.31184873580932615 minutes
2023-06-16 13:09:28,037:INFO:SubProcess create_model() called ==================================
2023-06-16 13:09:28,037:INFO:Initializing create_model()
2023-06-16 13:09:28,038:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196DB2E5450>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 13:09:28,038:INFO:Checking exceptions
2023-06-16 13:09:28,038:INFO:Importing libraries
2023-06-16 13:09:28,038:INFO:Copying training dataset
2023-06-16 13:09:28,044:INFO:Defining folds
2023-06-16 13:09:28,045:INFO:Declaring metric variables
2023-06-16 13:09:28,048:INFO:Importing untrained model
2023-06-16 13:09:28,052:INFO:Orthogonal Matching Pursuit Imported successfully
2023-06-16 13:09:28,059:INFO:Starting cross validation
2023-06-16 13:09:28,060:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 13:09:29,435:INFO:Calculating mean and std
2023-06-16 13:09:29,437:INFO:Creating metrics dataframe
2023-06-16 13:09:30,126:INFO:Uploading results into container
2023-06-16 13:09:30,127:INFO:Uploading model into container now
2023-06-16 13:09:30,127:INFO:_master_model_container: 93
2023-06-16 13:09:30,128:INFO:_display_container: 13
2023-06-16 13:09:30,128:INFO:OrthogonalMatchingPursuit()
2023-06-16 13:09:30,129:INFO:create_model() successfully completed......................................
2023-06-16 13:09:30,322:INFO:SubProcess create_model() end ==================================
2023-06-16 13:09:30,322:INFO:Creating metrics dataframe
2023-06-16 13:09:30,333:INFO:Initializing Bayesian Ridge
2023-06-16 13:09:30,333:INFO:Total runtime is 0.3502192338307698 minutes
2023-06-16 13:09:30,340:INFO:SubProcess create_model() called ==================================
2023-06-16 13:09:30,340:INFO:Initializing create_model()
2023-06-16 13:09:30,340:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196DB2E5450>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 13:09:30,340:INFO:Checking exceptions
2023-06-16 13:09:30,341:INFO:Importing libraries
2023-06-16 13:09:30,341:INFO:Copying training dataset
2023-06-16 13:09:30,346:INFO:Defining folds
2023-06-16 13:09:30,347:INFO:Declaring metric variables
2023-06-16 13:09:30,351:INFO:Importing untrained model
2023-06-16 13:09:30,355:INFO:Bayesian Ridge Imported successfully
2023-06-16 13:09:30,362:INFO:Starting cross validation
2023-06-16 13:09:30,363:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 13:09:31,627:INFO:Calculating mean and std
2023-06-16 13:09:31,629:INFO:Creating metrics dataframe
2023-06-16 13:09:32,045:INFO:Uploading results into container
2023-06-16 13:09:32,047:INFO:Uploading model into container now
2023-06-16 13:09:32,047:INFO:_master_model_container: 94
2023-06-16 13:09:32,048:INFO:_display_container: 13
2023-06-16 13:09:32,048:INFO:BayesianRidge()
2023-06-16 13:09:32,049:INFO:create_model() successfully completed......................................
2023-06-16 13:09:32,258:INFO:SubProcess create_model() end ==================================
2023-06-16 13:09:32,258:INFO:Creating metrics dataframe
2023-06-16 13:09:32,272:INFO:Initializing Passive Aggressive Regressor
2023-06-16 13:09:32,272:INFO:Total runtime is 0.3825297911961873 minutes
2023-06-16 13:09:32,275:INFO:SubProcess create_model() called ==================================
2023-06-16 13:09:32,276:INFO:Initializing create_model()
2023-06-16 13:09:32,276:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196DB2E5450>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 13:09:32,276:INFO:Checking exceptions
2023-06-16 13:09:32,276:INFO:Importing libraries
2023-06-16 13:09:32,276:INFO:Copying training dataset
2023-06-16 13:09:32,281:INFO:Defining folds
2023-06-16 13:09:32,281:INFO:Declaring metric variables
2023-06-16 13:09:32,285:INFO:Importing untrained model
2023-06-16 13:09:32,288:INFO:Passive Aggressive Regressor Imported successfully
2023-06-16 13:09:32,296:INFO:Starting cross validation
2023-06-16 13:09:32,297:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 13:09:33,522:INFO:Calculating mean and std
2023-06-16 13:09:33,523:INFO:Creating metrics dataframe
2023-06-16 13:09:33,979:INFO:Uploading results into container
2023-06-16 13:09:33,980:INFO:Uploading model into container now
2023-06-16 13:09:33,981:INFO:_master_model_container: 95
2023-06-16 13:09:33,981:INFO:_display_container: 13
2023-06-16 13:09:33,982:INFO:PassiveAggressiveRegressor(random_state=42)
2023-06-16 13:09:33,982:INFO:create_model() successfully completed......................................
2023-06-16 13:09:34,179:INFO:SubProcess create_model() end ==================================
2023-06-16 13:09:34,180:INFO:Creating metrics dataframe
2023-06-16 13:09:34,190:INFO:Initializing Huber Regressor
2023-06-16 13:09:34,190:INFO:Total runtime is 0.4144961794217427 minutes
2023-06-16 13:09:34,193:INFO:SubProcess create_model() called ==================================
2023-06-16 13:09:34,193:INFO:Initializing create_model()
2023-06-16 13:09:34,193:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196DB2E5450>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 13:09:34,193:INFO:Checking exceptions
2023-06-16 13:09:34,193:INFO:Importing libraries
2023-06-16 13:09:34,193:INFO:Copying training dataset
2023-06-16 13:09:34,200:INFO:Defining folds
2023-06-16 13:09:34,200:INFO:Declaring metric variables
2023-06-16 13:09:34,207:INFO:Importing untrained model
2023-06-16 13:09:34,211:INFO:Huber Regressor Imported successfully
2023-06-16 13:09:34,218:INFO:Starting cross validation
2023-06-16 13:09:34,220:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 13:09:34,357:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 13:09:34,357:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 13:09:34,399:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 13:09:34,415:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 13:09:34,416:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 13:09:35,530:INFO:Calculating mean and std
2023-06-16 13:09:35,532:INFO:Creating metrics dataframe
2023-06-16 13:09:36,104:INFO:Uploading results into container
2023-06-16 13:09:36,106:INFO:Uploading model into container now
2023-06-16 13:09:36,106:INFO:_master_model_container: 96
2023-06-16 13:09:36,106:INFO:_display_container: 13
2023-06-16 13:09:36,106:INFO:HuberRegressor()
2023-06-16 13:09:36,106:INFO:create_model() successfully completed......................................
2023-06-16 13:09:36,288:INFO:SubProcess create_model() end ==================================
2023-06-16 13:09:36,288:INFO:Creating metrics dataframe
2023-06-16 13:09:36,299:INFO:Initializing K Neighbors Regressor
2023-06-16 13:09:36,299:INFO:Total runtime is 0.44964751005172726 minutes
2023-06-16 13:09:36,304:INFO:SubProcess create_model() called ==================================
2023-06-16 13:09:36,304:INFO:Initializing create_model()
2023-06-16 13:09:36,304:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196DB2E5450>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 13:09:36,304:INFO:Checking exceptions
2023-06-16 13:09:36,304:INFO:Importing libraries
2023-06-16 13:09:36,304:INFO:Copying training dataset
2023-06-16 13:09:36,310:INFO:Defining folds
2023-06-16 13:09:36,310:INFO:Declaring metric variables
2023-06-16 13:09:36,314:INFO:Importing untrained model
2023-06-16 13:09:36,320:INFO:K Neighbors Regressor Imported successfully
2023-06-16 13:09:36,334:INFO:Starting cross validation
2023-06-16 13:09:36,340:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 13:09:37,881:INFO:Calculating mean and std
2023-06-16 13:09:37,881:INFO:Creating metrics dataframe
2023-06-16 13:09:38,268:INFO:Uploading results into container
2023-06-16 13:09:38,269:INFO:Uploading model into container now
2023-06-16 13:09:38,269:INFO:_master_model_container: 97
2023-06-16 13:09:38,270:INFO:_display_container: 13
2023-06-16 13:09:38,270:INFO:KNeighborsRegressor(n_jobs=-1)
2023-06-16 13:09:38,270:INFO:create_model() successfully completed......................................
2023-06-16 13:09:38,463:INFO:SubProcess create_model() end ==================================
2023-06-16 13:09:38,464:INFO:Creating metrics dataframe
2023-06-16 13:09:38,474:INFO:Initializing Decision Tree Regressor
2023-06-16 13:09:38,474:INFO:Total runtime is 0.4859076062838236 minutes
2023-06-16 13:09:38,479:INFO:SubProcess create_model() called ==================================
2023-06-16 13:09:38,480:INFO:Initializing create_model()
2023-06-16 13:09:38,480:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196DB2E5450>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 13:09:38,480:INFO:Checking exceptions
2023-06-16 13:09:38,480:INFO:Importing libraries
2023-06-16 13:09:38,480:INFO:Copying training dataset
2023-06-16 13:09:38,490:INFO:Defining folds
2023-06-16 13:09:38,491:INFO:Declaring metric variables
2023-06-16 13:09:38,495:INFO:Importing untrained model
2023-06-16 13:09:38,501:INFO:Decision Tree Regressor Imported successfully
2023-06-16 13:09:38,509:INFO:Starting cross validation
2023-06-16 13:09:38,511:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 13:09:39,743:INFO:Calculating mean and std
2023-06-16 13:09:39,745:INFO:Creating metrics dataframe
2023-06-16 13:09:40,104:INFO:Uploading results into container
2023-06-16 13:09:40,105:INFO:Uploading model into container now
2023-06-16 13:09:40,106:INFO:_master_model_container: 98
2023-06-16 13:09:40,106:INFO:_display_container: 13
2023-06-16 13:09:40,106:INFO:DecisionTreeRegressor(random_state=42)
2023-06-16 13:09:40,106:INFO:create_model() successfully completed......................................
2023-06-16 13:09:40,336:INFO:SubProcess create_model() end ==================================
2023-06-16 13:09:40,337:INFO:Creating metrics dataframe
2023-06-16 13:09:40,362:INFO:Initializing Random Forest Regressor
2023-06-16 13:09:40,362:INFO:Total runtime is 0.5173666318257649 minutes
2023-06-16 13:09:40,366:INFO:SubProcess create_model() called ==================================
2023-06-16 13:09:40,366:INFO:Initializing create_model()
2023-06-16 13:09:40,366:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196DB2E5450>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 13:09:40,366:INFO:Checking exceptions
2023-06-16 13:09:40,366:INFO:Importing libraries
2023-06-16 13:09:40,366:INFO:Copying training dataset
2023-06-16 13:09:40,372:INFO:Defining folds
2023-06-16 13:09:40,372:INFO:Declaring metric variables
2023-06-16 13:09:40,376:INFO:Importing untrained model
2023-06-16 13:09:40,385:INFO:Random Forest Regressor Imported successfully
2023-06-16 13:09:40,400:INFO:Starting cross validation
2023-06-16 13:09:40,402:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 13:09:41,792:INFO:Calculating mean and std
2023-06-16 13:09:41,793:INFO:Creating metrics dataframe
2023-06-16 13:09:42,188:INFO:Uploading results into container
2023-06-16 13:09:42,189:INFO:Uploading model into container now
2023-06-16 13:09:42,189:INFO:_master_model_container: 99
2023-06-16 13:09:42,189:INFO:_display_container: 13
2023-06-16 13:09:42,189:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 13:09:42,189:INFO:create_model() successfully completed......................................
2023-06-16 13:09:42,354:INFO:SubProcess create_model() end ==================================
2023-06-16 13:09:42,354:INFO:Creating metrics dataframe
2023-06-16 13:09:42,378:INFO:Initializing Extra Trees Regressor
2023-06-16 13:09:42,378:INFO:Total runtime is 0.5509608546892801 minutes
2023-06-16 13:09:42,381:INFO:SubProcess create_model() called ==================================
2023-06-16 13:09:42,381:INFO:Initializing create_model()
2023-06-16 13:09:42,382:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196DB2E5450>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 13:09:42,382:INFO:Checking exceptions
2023-06-16 13:09:42,382:INFO:Importing libraries
2023-06-16 13:09:42,382:INFO:Copying training dataset
2023-06-16 13:09:42,389:INFO:Defining folds
2023-06-16 13:09:42,390:INFO:Declaring metric variables
2023-06-16 13:09:42,393:INFO:Importing untrained model
2023-06-16 13:09:42,398:INFO:Extra Trees Regressor Imported successfully
2023-06-16 13:09:42,404:INFO:Starting cross validation
2023-06-16 13:09:42,405:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 13:09:43,867:INFO:Calculating mean and std
2023-06-16 13:09:43,870:INFO:Creating metrics dataframe
2023-06-16 13:09:44,506:INFO:Uploading results into container
2023-06-16 13:09:44,507:INFO:Uploading model into container now
2023-06-16 13:09:44,508:INFO:_master_model_container: 100
2023-06-16 13:09:44,508:INFO:_display_container: 13
2023-06-16 13:09:44,508:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2023-06-16 13:09:44,509:INFO:create_model() successfully completed......................................
2023-06-16 13:09:44,719:INFO:SubProcess create_model() end ==================================
2023-06-16 13:09:44,719:INFO:Creating metrics dataframe
2023-06-16 13:09:44,732:INFO:Initializing AdaBoost Regressor
2023-06-16 13:09:44,732:INFO:Total runtime is 0.590208093325297 minutes
2023-06-16 13:09:44,736:INFO:SubProcess create_model() called ==================================
2023-06-16 13:09:44,737:INFO:Initializing create_model()
2023-06-16 13:09:44,737:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196DB2E5450>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 13:09:44,737:INFO:Checking exceptions
2023-06-16 13:09:44,737:INFO:Importing libraries
2023-06-16 13:09:44,737:INFO:Copying training dataset
2023-06-16 13:09:44,743:INFO:Defining folds
2023-06-16 13:09:44,743:INFO:Declaring metric variables
2023-06-16 13:09:44,749:INFO:Importing untrained model
2023-06-16 13:09:44,752:INFO:AdaBoost Regressor Imported successfully
2023-06-16 13:09:44,763:INFO:Starting cross validation
2023-06-16 13:09:44,764:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 13:09:46,134:INFO:Calculating mean and std
2023-06-16 13:09:46,136:INFO:Creating metrics dataframe
2023-06-16 13:09:46,554:INFO:Uploading results into container
2023-06-16 13:09:46,556:INFO:Uploading model into container now
2023-06-16 13:09:46,556:INFO:_master_model_container: 101
2023-06-16 13:09:46,556:INFO:_display_container: 13
2023-06-16 13:09:46,557:INFO:AdaBoostRegressor(random_state=42)
2023-06-16 13:09:46,557:INFO:create_model() successfully completed......................................
2023-06-16 13:09:46,774:INFO:SubProcess create_model() end ==================================
2023-06-16 13:09:46,775:INFO:Creating metrics dataframe
2023-06-16 13:09:46,790:INFO:Initializing Gradient Boosting Regressor
2023-06-16 13:09:46,791:INFO:Total runtime is 0.6245152950286865 minutes
2023-06-16 13:09:46,795:INFO:SubProcess create_model() called ==================================
2023-06-16 13:09:46,796:INFO:Initializing create_model()
2023-06-16 13:09:46,797:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196DB2E5450>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 13:09:46,797:INFO:Checking exceptions
2023-06-16 13:09:46,797:INFO:Importing libraries
2023-06-16 13:09:46,797:INFO:Copying training dataset
2023-06-16 13:09:46,805:INFO:Defining folds
2023-06-16 13:09:46,805:INFO:Declaring metric variables
2023-06-16 13:09:46,810:INFO:Importing untrained model
2023-06-16 13:09:46,814:INFO:Gradient Boosting Regressor Imported successfully
2023-06-16 13:09:46,822:INFO:Starting cross validation
2023-06-16 13:09:46,823:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 13:09:48,090:INFO:Calculating mean and std
2023-06-16 13:09:48,092:INFO:Creating metrics dataframe
2023-06-16 13:09:48,525:INFO:Uploading results into container
2023-06-16 13:09:48,526:INFO:Uploading model into container now
2023-06-16 13:09:48,527:INFO:_master_model_container: 102
2023-06-16 13:09:48,527:INFO:_display_container: 13
2023-06-16 13:09:48,528:INFO:GradientBoostingRegressor(random_state=42)
2023-06-16 13:09:48,528:INFO:create_model() successfully completed......................................
2023-06-16 13:09:48,724:INFO:SubProcess create_model() end ==================================
2023-06-16 13:09:48,724:INFO:Creating metrics dataframe
2023-06-16 13:09:48,739:INFO:Initializing Extreme Gradient Boosting
2023-06-16 13:09:48,739:INFO:Total runtime is 0.6569875876108805 minutes
2023-06-16 13:09:48,745:INFO:SubProcess create_model() called ==================================
2023-06-16 13:09:48,746:INFO:Initializing create_model()
2023-06-16 13:09:48,746:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196DB2E5450>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 13:09:48,746:INFO:Checking exceptions
2023-06-16 13:09:48,746:INFO:Importing libraries
2023-06-16 13:09:48,746:INFO:Copying training dataset
2023-06-16 13:09:48,757:INFO:Defining folds
2023-06-16 13:09:48,757:INFO:Declaring metric variables
2023-06-16 13:09:48,761:INFO:Importing untrained model
2023-06-16 13:09:48,767:INFO:Extreme Gradient Boosting Imported successfully
2023-06-16 13:09:48,774:INFO:Starting cross validation
2023-06-16 13:09:48,776:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 13:09:50,109:INFO:Calculating mean and std
2023-06-16 13:09:50,110:INFO:Creating metrics dataframe
2023-06-16 13:09:50,522:INFO:Uploading results into container
2023-06-16 13:09:50,523:INFO:Uploading model into container now
2023-06-16 13:09:50,523:INFO:_master_model_container: 103
2023-06-16 13:09:50,523:INFO:_display_container: 13
2023-06-16 13:09:50,524:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=42, ...)
2023-06-16 13:09:50,525:INFO:create_model() successfully completed......................................
2023-06-16 13:09:50,702:INFO:SubProcess create_model() end ==================================
2023-06-16 13:09:50,702:INFO:Creating metrics dataframe
2023-06-16 13:09:50,725:INFO:Initializing Light Gradient Boosting Machine
2023-06-16 13:09:50,725:INFO:Total runtime is 0.6900829553604125 minutes
2023-06-16 13:09:50,730:INFO:SubProcess create_model() called ==================================
2023-06-16 13:09:50,730:INFO:Initializing create_model()
2023-06-16 13:09:50,730:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196DB2E5450>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 13:09:50,730:INFO:Checking exceptions
2023-06-16 13:09:50,730:INFO:Importing libraries
2023-06-16 13:09:50,730:INFO:Copying training dataset
2023-06-16 13:09:50,741:INFO:Defining folds
2023-06-16 13:09:50,741:INFO:Declaring metric variables
2023-06-16 13:09:50,747:INFO:Importing untrained model
2023-06-16 13:09:50,775:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-16 13:09:50,783:INFO:Starting cross validation
2023-06-16 13:09:50,784:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 13:09:53,162:INFO:Calculating mean and std
2023-06-16 13:09:53,164:INFO:Creating metrics dataframe
2023-06-16 13:09:53,585:INFO:Uploading results into container
2023-06-16 13:09:53,586:INFO:Uploading model into container now
2023-06-16 13:09:53,587:INFO:_master_model_container: 104
2023-06-16 13:09:53,587:INFO:_display_container: 13
2023-06-16 13:09:53,588:INFO:LGBMRegressor(random_state=42)
2023-06-16 13:09:53,588:INFO:create_model() successfully completed......................................
2023-06-16 13:09:53,775:INFO:SubProcess create_model() end ==================================
2023-06-16 13:09:53,775:INFO:Creating metrics dataframe
2023-06-16 13:09:53,789:INFO:Initializing Dummy Regressor
2023-06-16 13:09:53,789:INFO:Total runtime is 0.741142960389455 minutes
2023-06-16 13:09:53,794:INFO:SubProcess create_model() called ==================================
2023-06-16 13:09:53,794:INFO:Initializing create_model()
2023-06-16 13:09:53,795:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196DB2E5450>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 13:09:53,795:INFO:Checking exceptions
2023-06-16 13:09:53,795:INFO:Importing libraries
2023-06-16 13:09:53,795:INFO:Copying training dataset
2023-06-16 13:09:53,807:INFO:Defining folds
2023-06-16 13:09:53,807:INFO:Declaring metric variables
2023-06-16 13:09:53,817:INFO:Importing untrained model
2023-06-16 13:09:53,827:INFO:Dummy Regressor Imported successfully
2023-06-16 13:09:53,847:INFO:Starting cross validation
2023-06-16 13:09:53,849:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 13:09:55,130:INFO:Calculating mean and std
2023-06-16 13:09:55,132:INFO:Creating metrics dataframe
2023-06-16 13:09:55,565:INFO:Uploading results into container
2023-06-16 13:09:55,566:INFO:Uploading model into container now
2023-06-16 13:09:55,567:INFO:_master_model_container: 105
2023-06-16 13:09:55,567:INFO:_display_container: 13
2023-06-16 13:09:55,567:INFO:DummyRegressor()
2023-06-16 13:09:55,567:INFO:create_model() successfully completed......................................
2023-06-16 13:09:55,796:INFO:SubProcess create_model() end ==================================
2023-06-16 13:09:55,797:INFO:Creating metrics dataframe
2023-06-16 13:09:55,819:INFO:Initializing create_model()
2023-06-16 13:09:55,820:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-16 13:09:55,820:INFO:Checking exceptions
2023-06-16 13:09:55,822:INFO:Importing libraries
2023-06-16 13:09:55,822:INFO:Copying training dataset
2023-06-16 13:09:55,832:INFO:Defining folds
2023-06-16 13:09:55,832:INFO:Declaring metric variables
2023-06-16 13:09:55,832:INFO:Importing untrained model
2023-06-16 13:09:55,832:INFO:Declaring custom model
2023-06-16 13:09:55,833:INFO:Random Forest Regressor Imported successfully
2023-06-16 13:09:55,834:INFO:Cross validation set to False
2023-06-16 13:09:55,834:INFO:Fitting Model
2023-06-16 13:09:56,238:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 13:09:56,238:INFO:create_model() successfully completed......................................
2023-06-16 13:09:56,515:INFO:_master_model_container: 105
2023-06-16 13:09:56,516:INFO:_display_container: 13
2023-06-16 13:09:56,516:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 13:09:56,516:INFO:compare_models() successfully completed......................................
2023-06-16 13:09:56,550:INFO:Initializing create_model()
2023-06-16 13:09:56,551:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=rf, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-16 13:09:56,551:INFO:Checking exceptions
2023-06-16 13:09:56,574:INFO:Importing libraries
2023-06-16 13:09:56,574:INFO:Copying training dataset
2023-06-16 13:09:56,584:INFO:Defining folds
2023-06-16 13:09:56,584:INFO:Declaring metric variables
2023-06-16 13:09:56,590:INFO:Importing untrained model
2023-06-16 13:09:56,593:INFO:Random Forest Regressor Imported successfully
2023-06-16 13:09:56,601:INFO:Starting cross validation
2023-06-16 13:09:56,602:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 13:09:58,034:INFO:Calculating mean and std
2023-06-16 13:09:58,036:INFO:Creating metrics dataframe
2023-06-16 13:09:58,046:INFO:Finalizing model
2023-06-16 13:09:58,773:INFO:Uploading results into container
2023-06-16 13:09:58,774:INFO:Uploading model into container now
2023-06-16 13:09:58,786:INFO:_master_model_container: 106
2023-06-16 13:09:58,786:INFO:_display_container: 14
2023-06-16 13:09:58,786:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 13:09:58,787:INFO:create_model() successfully completed......................................
2023-06-16 13:09:59,011:INFO:Initializing plot_model()
2023-06-16 13:09:59,012:INFO:plot_model(plot=learning, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, system=True)
2023-06-16 13:09:59,012:INFO:Checking exceptions
2023-06-16 13:09:59,040:INFO:Preloading libraries
2023-06-16 13:09:59,072:INFO:Copying training dataset
2023-06-16 13:09:59,072:INFO:Plot type: learning
2023-06-16 13:09:59,179:INFO:Fitting Model
2023-06-16 13:11:17,456:INFO:Visual Rendered Successfully
2023-06-16 13:11:17,640:INFO:plot_model() successfully completed......................................
2023-06-16 13:11:17,657:INFO:Initializing plot_model()
2023-06-16 13:11:17,658:INFO:plot_model(plot=vc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, system=True)
2023-06-16 13:11:17,658:INFO:Checking exceptions
2023-06-16 13:11:17,686:INFO:Preloading libraries
2023-06-16 13:11:17,726:INFO:Copying training dataset
2023-06-16 13:11:17,727:INFO:Plot type: vc
2023-06-16 13:11:17,727:INFO:Determining param_name
2023-06-16 13:11:17,727:INFO:param_name: max_depth
2023-06-16 13:11:17,849:INFO:Fitting Model
2023-06-16 13:12:02,895:INFO:Visual Rendered Successfully
2023-06-16 13:12:03,073:INFO:plot_model() successfully completed......................................
2023-06-16 13:12:03,088:INFO:Initializing plot_model()
2023-06-16 13:12:03,088:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, system=True)
2023-06-16 13:12:03,089:INFO:Checking exceptions
2023-06-16 13:12:03,108:INFO:Preloading libraries
2023-06-16 13:12:03,144:INFO:Copying training dataset
2023-06-16 13:12:03,144:INFO:Plot type: error
2023-06-16 13:12:03,282:INFO:Fitting Model
2023-06-16 13:12:03,283:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2023-06-16 13:12:03,283:INFO:Scoring test/hold-out set
2023-06-16 13:12:03,612:INFO:Visual Rendered Successfully
2023-06-16 13:12:03,811:INFO:plot_model() successfully completed......................................
2023-06-16 13:12:03,829:INFO:Initializing plot_model()
2023-06-16 13:12:03,830:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, system=True)
2023-06-16 13:12:03,830:INFO:Checking exceptions
2023-06-16 13:12:03,853:INFO:Preloading libraries
2023-06-16 13:12:03,886:INFO:Copying training dataset
2023-06-16 13:12:03,886:INFO:Plot type: feature
2023-06-16 13:12:03,886:WARNING:No coef_ found. Trying feature_importances_
2023-06-16 13:12:04,092:INFO:Visual Rendered Successfully
2023-06-16 13:12:04,284:INFO:plot_model() successfully completed......................................
2023-06-16 13:12:04,320:INFO:Initializing plot_model()
2023-06-16 13:12:04,320:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=3, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, system=True)
2023-06-16 13:12:04,320:INFO:Checking exceptions
2023-06-16 13:12:04,356:INFO:Preloading libraries
2023-06-16 13:12:04,409:INFO:Copying training dataset
2023-06-16 13:12:04,409:INFO:Plot type: residuals
2023-06-16 13:12:04,548:INFO:Fitting Model
2023-06-16 13:12:04,548:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2023-06-16 13:12:04,677:INFO:Scoring test/hold-out set
2023-06-16 13:12:05,425:INFO:Visual Rendered Successfully
2023-06-16 13:12:05,640:INFO:plot_model() successfully completed......................................
2023-06-16 13:12:05,664:INFO:Initializing interpret_model()
2023-06-16 13:12:05,666:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>)
2023-06-16 13:12:05,666:INFO:Checking exceptions
2023-06-16 13:12:05,666:INFO:Soft dependency imported: shap: 0.41.0
2023-06-16 13:12:05,710:INFO:plot type: summary
2023-06-16 13:12:05,710:INFO:Creating TreeExplainer
2023-06-16 13:12:05,731:INFO:Compiling shap values
2023-06-16 13:13:57,591:WARNING:No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored

2023-06-16 13:13:58,221:INFO:Visual Rendered Successfully
2023-06-16 13:13:58,222:INFO:interpret_model() successfully completed......................................
2023-06-16 13:13:58,423:INFO:Initializing interpret_model()
2023-06-16 13:13:58,424:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=correlation, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>)
2023-06-16 13:13:58,424:INFO:Checking exceptions
2023-06-16 13:13:58,424:INFO:Soft dependency imported: shap: 0.41.0
2023-06-16 13:13:58,466:INFO:plot type: correlation
2023-06-16 13:13:58,466:WARNING:No feature passed. Default value of feature used for correlation plot: taxa_homicidio
2023-06-16 13:13:58,466:INFO:Creating TreeExplainer
2023-06-16 13:13:58,483:INFO:Compiling shap values
2023-06-16 13:15:46,694:INFO:model type detected: type 2
2023-06-16 13:15:47,029:INFO:Visual Rendered Successfully
2023-06-16 13:15:47,029:INFO:interpret_model() successfully completed......................................
2023-06-16 13:15:47,227:INFO:Initializing interpret_model()
2023-06-16 13:15:47,228:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=1, plot=reason, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>)
2023-06-16 13:15:47,228:INFO:Checking exceptions
2023-06-16 13:15:47,228:INFO:Soft dependency imported: shap: 0.41.0
2023-06-16 13:15:47,258:INFO:plot type: reason
2023-06-16 13:15:47,259:INFO:model type detected: type 2
2023-06-16 13:15:47,259:INFO:Creating TreeExplainer
2023-06-16 13:15:47,277:INFO:Compiling shap values
2023-06-16 13:17:36,942:INFO:Visual Rendered Successfully
2023-06-16 13:17:36,942:INFO:interpret_model() successfully completed......................................
2023-06-16 13:17:37,156:INFO:Initializing interpret_model()
2023-06-16 13:17:37,157:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=3, plot=reason, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>)
2023-06-16 13:17:37,157:INFO:Checking exceptions
2023-06-16 13:17:37,157:INFO:Soft dependency imported: shap: 0.41.0
2023-06-16 13:17:37,188:INFO:plot type: reason
2023-06-16 13:17:37,188:INFO:model type detected: type 2
2023-06-16 13:17:37,188:INFO:Creating TreeExplainer
2023-06-16 13:17:37,204:INFO:Compiling shap values
2023-06-16 13:19:28,097:INFO:Visual Rendered Successfully
2023-06-16 13:19:28,098:INFO:interpret_model() successfully completed......................................
2023-06-16 13:19:28,338:INFO:Initializing tune_model()
2023-06-16 13:19:28,338:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=5, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>)
2023-06-16 13:19:28,338:INFO:Checking exceptions
2023-06-16 13:19:28,387:INFO:Copying training dataset
2023-06-16 13:19:28,399:INFO:Checking base model
2023-06-16 13:19:28,399:INFO:Base model : Random Forest Regressor
2023-06-16 13:19:28,404:INFO:Declaring metric variables
2023-06-16 13:19:28,409:INFO:Defining Hyperparameters
2023-06-16 13:19:28,630:INFO:Tuning with n_jobs=-1
2023-06-16 13:19:28,630:INFO:Initializing RandomizedSearchCV
2023-06-16 13:19:52,250:INFO:best_params: {'actual_estimator__n_estimators': 190, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 4, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': True}
2023-06-16 13:19:52,251:INFO:Hyperparameter search completed
2023-06-16 13:19:52,252:INFO:SubProcess create_model() called ==================================
2023-06-16 13:19:52,253:INFO:Initializing create_model()
2023-06-16 13:19:52,254:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196E409AC20>, model_only=True, return_train_score=False, kwargs={'n_estimators': 190, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.3, 'max_features': 1.0, 'max_depth': 4, 'criterion': 'squared_error', 'bootstrap': True})
2023-06-16 13:19:52,254:INFO:Checking exceptions
2023-06-16 13:19:52,254:INFO:Importing libraries
2023-06-16 13:19:52,254:INFO:Copying training dataset
2023-06-16 13:19:52,265:INFO:Defining folds
2023-06-16 13:19:52,265:INFO:Declaring metric variables
2023-06-16 13:19:52,268:INFO:Importing untrained model
2023-06-16 13:19:52,268:INFO:Declaring custom model
2023-06-16 13:19:52,273:INFO:Random Forest Regressor Imported successfully
2023-06-16 13:19:52,283:INFO:Starting cross validation
2023-06-16 13:19:52,285:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 13:19:53,743:INFO:Calculating mean and std
2023-06-16 13:19:53,745:INFO:Creating metrics dataframe
2023-06-16 13:19:53,751:INFO:Finalizing model
2023-06-16 13:19:54,449:INFO:Uploading results into container
2023-06-16 13:19:54,450:INFO:Uploading model into container now
2023-06-16 13:19:54,450:INFO:_master_model_container: 107
2023-06-16 13:19:54,450:INFO:_display_container: 15
2023-06-16 13:19:54,451:INFO:RandomForestRegressor(max_depth=4, min_impurity_decrease=0.3,
                      min_samples_leaf=2, n_estimators=190, n_jobs=-1,
                      random_state=42)
2023-06-16 13:19:54,451:INFO:create_model() successfully completed......................................
2023-06-16 13:19:54,645:INFO:SubProcess create_model() end ==================================
2023-06-16 13:19:54,645:INFO:choose_better activated
2023-06-16 13:19:54,655:INFO:SubProcess create_model() called ==================================
2023-06-16 13:19:54,656:INFO:Initializing create_model()
2023-06-16 13:19:54,657:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-16 13:19:54,657:INFO:Checking exceptions
2023-06-16 13:19:54,658:INFO:Importing libraries
2023-06-16 13:19:54,658:INFO:Copying training dataset
2023-06-16 13:19:54,664:INFO:Defining folds
2023-06-16 13:19:54,664:INFO:Declaring metric variables
2023-06-16 13:19:54,664:INFO:Importing untrained model
2023-06-16 13:19:54,664:INFO:Declaring custom model
2023-06-16 13:19:54,665:INFO:Random Forest Regressor Imported successfully
2023-06-16 13:19:54,665:INFO:Starting cross validation
2023-06-16 13:19:54,666:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 13:19:56,188:INFO:Calculating mean and std
2023-06-16 13:19:56,189:INFO:Creating metrics dataframe
2023-06-16 13:19:56,192:INFO:Finalizing model
2023-06-16 13:19:56,769:INFO:Uploading results into container
2023-06-16 13:19:56,769:INFO:Uploading model into container now
2023-06-16 13:19:56,770:INFO:_master_model_container: 108
2023-06-16 13:19:56,770:INFO:_display_container: 16
2023-06-16 13:19:56,770:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 13:19:56,770:INFO:create_model() successfully completed......................................
2023-06-16 13:19:56,974:INFO:SubProcess create_model() end ==================================
2023-06-16 13:19:56,975:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) result for R2 is 0.9092
2023-06-16 13:19:56,976:INFO:RandomForestRegressor(max_depth=4, min_impurity_decrease=0.3,
                      min_samples_leaf=2, n_estimators=190, n_jobs=-1,
                      random_state=42) result for R2 is 0.8853
2023-06-16 13:19:56,976:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) is best model
2023-06-16 13:19:56,976:INFO:choose_better completed
2023-06-16 13:19:56,976:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-06-16 13:19:56,986:INFO:_master_model_container: 108
2023-06-16 13:19:56,986:INFO:_display_container: 15
2023-06-16 13:19:56,986:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 13:19:56,987:INFO:tune_model() successfully completed......................................
2023-06-16 13:19:57,444:INFO:Initializing plot_model()
2023-06-16 13:19:57,445:INFO:plot_model(plot=learning, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, system=True)
2023-06-16 13:19:57,445:INFO:Checking exceptions
2023-06-16 13:19:57,466:INFO:Preloading libraries
2023-06-16 13:19:57,490:INFO:Copying training dataset
2023-06-16 13:19:57,490:INFO:Plot type: learning
2023-06-16 13:19:57,577:INFO:Fitting Model
2023-06-16 13:21:14,745:INFO:Visual Rendered Successfully
2023-06-16 13:21:14,974:INFO:plot_model() successfully completed......................................
2023-06-16 13:21:14,986:INFO:Initializing plot_model()
2023-06-16 13:21:14,986:INFO:plot_model(plot=vc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, system=True)
2023-06-16 13:21:14,986:INFO:Checking exceptions
2023-06-16 13:21:15,009:INFO:Preloading libraries
2023-06-16 13:21:15,074:INFO:Copying training dataset
2023-06-16 13:21:15,074:INFO:Plot type: vc
2023-06-16 13:21:15,074:INFO:Determining param_name
2023-06-16 13:21:15,074:INFO:param_name: max_depth
2023-06-16 13:21:15,161:INFO:Fitting Model
2023-06-16 13:21:58,711:INFO:Visual Rendered Successfully
2023-06-16 13:21:58,913:INFO:plot_model() successfully completed......................................
2023-06-16 13:21:58,932:INFO:Initializing plot_model()
2023-06-16 13:21:58,933:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, system=True)
2023-06-16 13:21:58,933:INFO:Checking exceptions
2023-06-16 13:21:58,962:INFO:Preloading libraries
2023-06-16 13:21:58,994:INFO:Copying training dataset
2023-06-16 13:21:58,994:INFO:Plot type: error
2023-06-16 13:21:59,079:INFO:Fitting Model
2023-06-16 13:21:59,079:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2023-06-16 13:21:59,079:INFO:Scoring test/hold-out set
2023-06-16 13:21:59,371:INFO:Visual Rendered Successfully
2023-06-16 13:21:59,544:INFO:plot_model() successfully completed......................................
2023-06-16 13:21:59,564:INFO:Initializing plot_model()
2023-06-16 13:21:59,564:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, system=True)
2023-06-16 13:21:59,564:INFO:Checking exceptions
2023-06-16 13:21:59,599:INFO:Preloading libraries
2023-06-16 13:21:59,652:INFO:Copying training dataset
2023-06-16 13:21:59,652:INFO:Plot type: feature
2023-06-16 13:21:59,653:WARNING:No coef_ found. Trying feature_importances_
2023-06-16 13:21:59,866:INFO:Visual Rendered Successfully
2023-06-16 13:22:00,046:INFO:plot_model() successfully completed......................................
2023-06-16 13:22:00,055:INFO:Initializing plot_model()
2023-06-16 13:22:00,055:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=3, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, system=True)
2023-06-16 13:22:00,056:INFO:Checking exceptions
2023-06-16 13:22:00,075:INFO:Preloading libraries
2023-06-16 13:22:00,102:INFO:Copying training dataset
2023-06-16 13:22:00,102:INFO:Plot type: residuals
2023-06-16 13:22:00,213:INFO:Fitting Model
2023-06-16 13:22:00,214:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2023-06-16 13:22:00,313:INFO:Scoring test/hold-out set
2023-06-16 13:22:00,968:INFO:Visual Rendered Successfully
2023-06-16 13:22:01,171:INFO:plot_model() successfully completed......................................
2023-06-16 13:22:01,230:INFO:Initializing interpret_model()
2023-06-16 13:22:01,230:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>)
2023-06-16 13:22:01,231:INFO:Checking exceptions
2023-06-16 13:22:01,231:INFO:Soft dependency imported: shap: 0.41.0
2023-06-16 13:22:01,274:INFO:plot type: summary
2023-06-16 13:22:01,274:INFO:Creating TreeExplainer
2023-06-16 13:22:01,291:INFO:Compiling shap values
2023-06-16 13:23:43,539:WARNING:No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored

2023-06-16 13:23:44,136:INFO:Visual Rendered Successfully
2023-06-16 13:23:44,136:INFO:interpret_model() successfully completed......................................
2023-06-16 13:23:44,338:INFO:Initializing interpret_model()
2023-06-16 13:23:44,339:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=correlation, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>)
2023-06-16 13:23:44,339:INFO:Checking exceptions
2023-06-16 13:23:44,339:INFO:Soft dependency imported: shap: 0.41.0
2023-06-16 13:23:44,392:INFO:plot type: correlation
2023-06-16 13:23:44,393:WARNING:No feature passed. Default value of feature used for correlation plot: taxa_homicidio
2023-06-16 13:23:44,393:INFO:Creating TreeExplainer
2023-06-16 13:23:44,421:INFO:Compiling shap values
2023-06-16 13:25:26,869:INFO:model type detected: type 2
2023-06-16 13:25:27,159:INFO:Visual Rendered Successfully
2023-06-16 13:25:27,160:INFO:interpret_model() successfully completed......................................
2023-06-16 13:25:27,376:INFO:Initializing interpret_model()
2023-06-16 13:25:27,376:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=1, plot=reason, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>)
2023-06-16 13:25:27,376:INFO:Checking exceptions
2023-06-16 13:25:27,376:INFO:Soft dependency imported: shap: 0.41.0
2023-06-16 13:25:27,409:INFO:plot type: reason
2023-06-16 13:25:27,409:INFO:model type detected: type 2
2023-06-16 13:25:27,409:INFO:Creating TreeExplainer
2023-06-16 13:25:27,424:INFO:Compiling shap values
2023-06-16 13:27:20,873:INFO:Visual Rendered Successfully
2023-06-16 13:27:20,873:INFO:interpret_model() successfully completed......................................
2023-06-16 13:27:21,164:INFO:Initializing interpret_model()
2023-06-16 13:27:21,164:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=3, plot=reason, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>)
2023-06-16 13:27:21,164:INFO:Checking exceptions
2023-06-16 13:27:21,164:INFO:Soft dependency imported: shap: 0.41.0
2023-06-16 13:27:21,196:INFO:plot type: reason
2023-06-16 13:27:21,196:INFO:model type detected: type 2
2023-06-16 13:27:21,196:INFO:Creating TreeExplainer
2023-06-16 13:27:21,220:INFO:Compiling shap values
2023-06-16 13:29:05,470:INFO:Visual Rendered Successfully
2023-06-16 13:29:05,470:INFO:interpret_model() successfully completed......................................
2023-06-16 13:29:05,671:INFO:Initializing tune_model()
2023-06-16 13:29:05,671:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=5, round=4, n_iter=10, custom_grid={'max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>)
2023-06-16 13:29:05,672:INFO:Checking exceptions
2023-06-16 13:29:05,709:INFO:Copying training dataset
2023-06-16 13:29:05,714:INFO:Checking base model
2023-06-16 13:29:05,714:INFO:Base model : Random Forest Regressor
2023-06-16 13:29:05,718:INFO:Declaring metric variables
2023-06-16 13:29:05,721:INFO:Defining Hyperparameters
2023-06-16 13:29:05,929:INFO:custom_grid: {'actual_estimator__max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}
2023-06-16 13:29:05,930:INFO:Tuning with n_jobs=-1
2023-06-16 13:29:05,930:INFO:Initializing RandomizedSearchCV
2023-06-16 13:29:26,209:WARNING:
5 fits failed out of a total of 50.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\lapei\anaconda3\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py", line 340, in fit
    self._validate_params()
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\base.py", line 581, in _validate_params
    validate_parameter_constraints(
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 97, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestRegressor must be an int in the range [1, inf) or None. Got 0 instead.


2023-06-16 13:29:26,210:WARNING:One or more of the test scores are non-finite: [       nan 0.49419939 0.84058494 0.88612187 0.89725281 0.90282624
 0.90641901 0.90529087 0.90911226 0.90600098]

2023-06-16 13:29:26,954:INFO:best_params: {'actual_estimator__max_depth': 9}
2023-06-16 13:29:26,955:INFO:Hyperparameter search completed
2023-06-16 13:29:26,956:INFO:SubProcess create_model() called ==================================
2023-06-16 13:29:26,957:INFO:Initializing create_model()
2023-06-16 13:29:26,957:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196E4093E50>, model_only=True, return_train_score=False, kwargs={'max_depth': 9})
2023-06-16 13:29:26,958:INFO:Checking exceptions
2023-06-16 13:29:26,958:INFO:Importing libraries
2023-06-16 13:29:26,958:INFO:Copying training dataset
2023-06-16 13:29:26,969:INFO:Defining folds
2023-06-16 13:29:26,970:INFO:Declaring metric variables
2023-06-16 13:29:26,976:INFO:Importing untrained model
2023-06-16 13:29:26,976:INFO:Declaring custom model
2023-06-16 13:29:26,982:INFO:Random Forest Regressor Imported successfully
2023-06-16 13:29:26,995:INFO:Starting cross validation
2023-06-16 13:29:26,997:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 13:29:28,261:INFO:Calculating mean and std
2023-06-16 13:29:28,263:INFO:Creating metrics dataframe
2023-06-16 13:29:28,268:INFO:Finalizing model
2023-06-16 13:29:29,006:INFO:Uploading results into container
2023-06-16 13:29:29,007:INFO:Uploading model into container now
2023-06-16 13:29:29,007:INFO:_master_model_container: 109
2023-06-16 13:29:29,007:INFO:_display_container: 16
2023-06-16 13:29:29,007:INFO:RandomForestRegressor(max_depth=9, n_jobs=-1, random_state=42)
2023-06-16 13:29:29,008:INFO:create_model() successfully completed......................................
2023-06-16 13:29:29,203:INFO:SubProcess create_model() end ==================================
2023-06-16 13:29:29,203:INFO:choose_better activated
2023-06-16 13:29:29,208:INFO:SubProcess create_model() called ==================================
2023-06-16 13:29:29,208:INFO:Initializing create_model()
2023-06-16 13:29:29,208:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-16 13:29:29,208:INFO:Checking exceptions
2023-06-16 13:29:29,210:INFO:Importing libraries
2023-06-16 13:29:29,210:INFO:Copying training dataset
2023-06-16 13:29:29,223:INFO:Defining folds
2023-06-16 13:29:29,223:INFO:Declaring metric variables
2023-06-16 13:29:29,224:INFO:Importing untrained model
2023-06-16 13:29:29,224:INFO:Declaring custom model
2023-06-16 13:29:29,226:INFO:Random Forest Regressor Imported successfully
2023-06-16 13:29:29,226:INFO:Starting cross validation
2023-06-16 13:29:29,228:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 13:29:30,657:INFO:Calculating mean and std
2023-06-16 13:29:30,657:INFO:Creating metrics dataframe
2023-06-16 13:29:30,662:INFO:Finalizing model
2023-06-16 13:29:31,600:INFO:Uploading results into container
2023-06-16 13:29:31,600:INFO:Uploading model into container now
2023-06-16 13:29:31,601:INFO:_master_model_container: 110
2023-06-16 13:29:31,601:INFO:_display_container: 17
2023-06-16 13:29:31,601:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 13:29:31,601:INFO:create_model() successfully completed......................................
2023-06-16 13:29:31,772:INFO:SubProcess create_model() end ==================================
2023-06-16 13:29:31,773:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) result for R2 is 0.9092
2023-06-16 13:29:31,773:INFO:RandomForestRegressor(max_depth=9, n_jobs=-1, random_state=42) result for R2 is 0.9091
2023-06-16 13:29:31,774:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) is best model
2023-06-16 13:29:31,774:INFO:choose_better completed
2023-06-16 13:29:31,774:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-06-16 13:29:31,789:INFO:_master_model_container: 110
2023-06-16 13:29:31,789:INFO:_display_container: 16
2023-06-16 13:29:31,789:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 13:29:31,789:INFO:tune_model() successfully completed......................................
2023-06-16 13:29:32,294:INFO:Initializing tune_model()
2023-06-16 13:29:32,294:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=5, round=4, n_iter=10, custom_grid={'max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'min_samples_split': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'min_samples_leaf': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'ccp_alpha': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.9]}, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>)
2023-06-16 13:29:32,294:INFO:Checking exceptions
2023-06-16 13:29:32,335:INFO:Copying training dataset
2023-06-16 13:29:32,340:INFO:Checking base model
2023-06-16 13:29:32,340:INFO:Base model : Random Forest Regressor
2023-06-16 13:29:32,345:INFO:Declaring metric variables
2023-06-16 13:29:32,348:INFO:Defining Hyperparameters
2023-06-16 13:29:32,524:INFO:custom_grid: {'actual_estimator__max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'actual_estimator__min_samples_split': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'actual_estimator__min_samples_leaf': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'actual_estimator__ccp_alpha': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.9]}
2023-06-16 13:29:32,525:INFO:Tuning with n_jobs=-1
2023-06-16 13:29:32,525:INFO:Initializing RandomizedSearchCV
2023-06-16 13:29:36,594:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-16 13:29:36,917:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 13:29:36,928:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 13:29:37,469:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 13:29:37,820:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 13:29:37,898:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-16 13:29:55,768:WARNING:
10 fits failed out of a total of 50.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\lapei\anaconda3\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py", line 340, in fit
    self._validate_params()
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\base.py", line 581, in _validate_params
    validate_parameter_constraints(
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 97, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_leaf' parameter of RandomForestRegressor must be an int in the range [1, inf) or a float in the range (0.0, 1.0). Got 0 instead.

--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\lapei\anaconda3\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py", line 340, in fit
    self._validate_params()
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\base.py", line 581, in _validate_params
    validate_parameter_constraints(
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 97, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestRegressor must be an int in the range [1, inf) or None. Got 0 instead.


2023-06-16 13:29:55,769:WARNING:One or more of the test scores are non-finite: [0.712624   0.82378602 0.71147917        nan 0.78365739 0.84058494
        nan 0.6994668  0.74455273 0.90529087]

2023-06-16 13:29:56,267:INFO:best_params: {'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 1, 'actual_estimator__max_depth': 7, 'actual_estimator__ccp_alpha': 0.0}
2023-06-16 13:29:56,268:INFO:Hyperparameter search completed
2023-06-16 13:29:56,268:INFO:SubProcess create_model() called ==================================
2023-06-16 13:29:56,269:INFO:Initializing create_model()
2023-06-16 13:29:56,269:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196E502A8F0>, model_only=True, return_train_score=False, kwargs={'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'ccp_alpha': 0.0})
2023-06-16 13:29:56,269:INFO:Checking exceptions
2023-06-16 13:29:56,269:INFO:Importing libraries
2023-06-16 13:29:56,269:INFO:Copying training dataset
2023-06-16 13:29:56,276:INFO:Defining folds
2023-06-16 13:29:56,276:INFO:Declaring metric variables
2023-06-16 13:29:56,279:INFO:Importing untrained model
2023-06-16 13:29:56,279:INFO:Declaring custom model
2023-06-16 13:29:56,284:INFO:Random Forest Regressor Imported successfully
2023-06-16 13:29:56,291:INFO:Starting cross validation
2023-06-16 13:29:56,292:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 13:29:57,614:INFO:Calculating mean and std
2023-06-16 13:29:57,615:INFO:Creating metrics dataframe
2023-06-16 13:29:57,621:INFO:Finalizing model
2023-06-16 13:29:58,687:INFO:Uploading results into container
2023-06-16 13:29:58,688:INFO:Uploading model into container now
2023-06-16 13:29:58,689:INFO:_master_model_container: 111
2023-06-16 13:29:58,691:INFO:_display_container: 17
2023-06-16 13:29:58,692:INFO:RandomForestRegressor(max_depth=7, n_jobs=-1, random_state=42)
2023-06-16 13:29:58,692:INFO:create_model() successfully completed......................................
2023-06-16 13:29:58,885:INFO:SubProcess create_model() end ==================================
2023-06-16 13:29:58,885:INFO:choose_better activated
2023-06-16 13:29:58,889:INFO:SubProcess create_model() called ==================================
2023-06-16 13:29:58,889:INFO:Initializing create_model()
2023-06-16 13:29:58,889:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-16 13:29:58,889:INFO:Checking exceptions
2023-06-16 13:29:58,892:INFO:Importing libraries
2023-06-16 13:29:58,892:INFO:Copying training dataset
2023-06-16 13:29:58,897:INFO:Defining folds
2023-06-16 13:29:58,897:INFO:Declaring metric variables
2023-06-16 13:29:58,897:INFO:Importing untrained model
2023-06-16 13:29:58,897:INFO:Declaring custom model
2023-06-16 13:29:58,898:INFO:Random Forest Regressor Imported successfully
2023-06-16 13:29:58,898:INFO:Starting cross validation
2023-06-16 13:29:58,899:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 13:30:00,295:INFO:Calculating mean and std
2023-06-16 13:30:00,295:INFO:Creating metrics dataframe
2023-06-16 13:30:00,297:INFO:Finalizing model
2023-06-16 13:30:00,905:INFO:Uploading results into container
2023-06-16 13:30:00,906:INFO:Uploading model into container now
2023-06-16 13:30:00,906:INFO:_master_model_container: 112
2023-06-16 13:30:00,906:INFO:_display_container: 18
2023-06-16 13:30:00,906:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 13:30:00,906:INFO:create_model() successfully completed......................................
2023-06-16 13:30:01,095:INFO:SubProcess create_model() end ==================================
2023-06-16 13:30:01,096:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) result for R2 is 0.9092
2023-06-16 13:30:01,096:INFO:RandomForestRegressor(max_depth=7, n_jobs=-1, random_state=42) result for R2 is 0.9053
2023-06-16 13:30:01,097:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) is best model
2023-06-16 13:30:01,097:INFO:choose_better completed
2023-06-16 13:30:01,097:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-06-16 13:30:01,108:INFO:_master_model_container: 112
2023-06-16 13:30:01,108:INFO:_display_container: 17
2023-06-16 13:30:01,108:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 13:30:01,108:INFO:tune_model() successfully completed......................................
2023-06-16 13:30:01,593:INFO:Initializing plot_model()
2023-06-16 13:30:01,593:INFO:plot_model(plot=learning, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, system=True)
2023-06-16 13:30:01,593:INFO:Checking exceptions
2023-06-16 13:30:01,623:INFO:Preloading libraries
2023-06-16 13:30:01,666:INFO:Copying training dataset
2023-06-16 13:30:01,666:INFO:Plot type: learning
2023-06-16 13:30:01,755:INFO:Fitting Model
2023-06-16 13:31:15,229:INFO:Visual Rendered Successfully
2023-06-16 13:31:15,484:INFO:plot_model() successfully completed......................................
2023-06-16 13:31:15,517:INFO:Initializing plot_model()
2023-06-16 13:31:15,517:INFO:plot_model(plot=vc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, system=True)
2023-06-16 13:31:15,518:INFO:Checking exceptions
2023-06-16 13:31:15,560:INFO:Preloading libraries
2023-06-16 13:31:15,601:INFO:Copying training dataset
2023-06-16 13:31:15,602:INFO:Plot type: vc
2023-06-16 13:31:15,602:INFO:Determining param_name
2023-06-16 13:31:15,602:INFO:param_name: max_depth
2023-06-16 13:31:15,684:INFO:Fitting Model
2023-06-16 13:51:17,286:INFO:Visual Rendered Successfully
2023-06-16 13:51:17,541:INFO:plot_model() successfully completed......................................
2023-06-16 13:51:17,562:INFO:Initializing plot_model()
2023-06-16 13:51:17,563:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, system=True)
2023-06-16 13:51:17,563:INFO:Checking exceptions
2023-06-16 13:51:17,621:INFO:Preloading libraries
2023-06-16 13:51:17,667:INFO:Copying training dataset
2023-06-16 13:51:17,667:INFO:Plot type: error
2023-06-16 13:51:17,778:INFO:Fitting Model
2023-06-16 13:51:17,778:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2023-06-16 13:51:17,778:INFO:Scoring test/hold-out set
2023-06-16 13:51:18,135:INFO:Visual Rendered Successfully
2023-06-16 13:51:18,367:INFO:plot_model() successfully completed......................................
2023-06-16 13:51:18,380:INFO:Initializing plot_model()
2023-06-16 13:51:18,380:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, system=True)
2023-06-16 13:51:18,380:INFO:Checking exceptions
2023-06-16 13:51:18,428:INFO:Preloading libraries
2023-06-16 13:51:18,468:INFO:Copying training dataset
2023-06-16 13:51:18,469:INFO:Plot type: feature
2023-06-16 13:51:18,469:WARNING:No coef_ found. Trying feature_importances_
2023-06-16 13:51:18,697:INFO:Visual Rendered Successfully
2023-06-16 13:51:18,900:INFO:plot_model() successfully completed......................................
2023-06-16 13:51:18,917:INFO:Initializing plot_model()
2023-06-16 13:51:18,918:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=3, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, system=True)
2023-06-16 13:51:18,918:INFO:Checking exceptions
2023-06-16 13:51:18,960:INFO:Preloading libraries
2023-06-16 13:51:18,989:INFO:Copying training dataset
2023-06-16 13:51:18,989:INFO:Plot type: residuals
2023-06-16 13:51:19,097:INFO:Fitting Model
2023-06-16 13:51:19,097:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2023-06-16 13:51:19,188:INFO:Scoring test/hold-out set
2023-06-16 13:51:19,879:INFO:Visual Rendered Successfully
2023-06-16 13:51:20,070:INFO:plot_model() successfully completed......................................
2023-06-16 13:51:20,079:INFO:Initializing interpret_model()
2023-06-16 13:51:20,080:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>)
2023-06-16 13:51:20,080:INFO:Checking exceptions
2023-06-16 13:51:20,080:INFO:Soft dependency imported: shap: 0.41.0
2023-06-16 13:51:20,101:INFO:plot type: summary
2023-06-16 13:51:20,101:INFO:Creating TreeExplainer
2023-06-16 13:51:20,117:INFO:Compiling shap values
2023-06-16 13:53:04,354:WARNING:No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored

2023-06-16 13:53:04,947:INFO:Visual Rendered Successfully
2023-06-16 13:53:04,947:INFO:interpret_model() successfully completed......................................
2023-06-16 13:53:05,157:INFO:Initializing interpret_model()
2023-06-16 13:53:05,157:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=correlation, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>)
2023-06-16 13:53:05,157:INFO:Checking exceptions
2023-06-16 13:53:05,158:INFO:Soft dependency imported: shap: 0.41.0
2023-06-16 13:53:05,214:INFO:plot type: correlation
2023-06-16 13:53:05,215:WARNING:No feature passed. Default value of feature used for correlation plot: taxa_homicidio
2023-06-16 13:53:05,215:INFO:Creating TreeExplainer
2023-06-16 13:53:05,237:INFO:Compiling shap values
2023-06-16 13:54:50,491:INFO:model type detected: type 2
2023-06-16 13:54:50,773:INFO:Visual Rendered Successfully
2023-06-16 13:54:50,773:INFO:interpret_model() successfully completed......................................
2023-06-16 13:54:50,965:INFO:Initializing interpret_model()
2023-06-16 13:54:50,965:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=1, plot=reason, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>)
2023-06-16 13:54:50,966:INFO:Checking exceptions
2023-06-16 13:54:50,966:INFO:Soft dependency imported: shap: 0.41.0
2023-06-16 13:54:50,997:INFO:plot type: reason
2023-06-16 13:54:50,997:INFO:model type detected: type 2
2023-06-16 13:54:50,997:INFO:Creating TreeExplainer
2023-06-16 13:54:51,019:INFO:Compiling shap values
2023-06-16 13:56:37,632:INFO:Visual Rendered Successfully
2023-06-16 13:56:37,632:INFO:interpret_model() successfully completed......................................
2023-06-16 13:56:37,854:INFO:Initializing interpret_model()
2023-06-16 13:56:37,855:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=3, plot=reason, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>)
2023-06-16 13:56:37,855:INFO:Checking exceptions
2023-06-16 13:56:37,855:INFO:Soft dependency imported: shap: 0.41.0
2023-06-16 13:56:37,895:INFO:plot type: reason
2023-06-16 13:56:37,895:INFO:model type detected: type 2
2023-06-16 13:56:37,895:INFO:Creating TreeExplainer
2023-06-16 13:56:37,914:INFO:Compiling shap values
2023-06-16 13:58:25,099:INFO:Visual Rendered Successfully
2023-06-16 13:58:25,099:INFO:interpret_model() successfully completed......................................
2023-06-16 13:58:25,296:INFO:Initializing predict_model()
2023-06-16 13:58:25,296:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196DA8B1000>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000196E527A560>)
2023-06-16 13:58:25,296:INFO:Checking exceptions
2023-06-16 13:58:25,297:INFO:Preloading libraries
2023-06-16 13:58:25,300:INFO:Set up data.
2023-06-16 13:58:25,308:INFO:Set up index.
2023-06-16 14:18:46,733:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-16 14:18:46,733:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-16 14:18:46,733:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-16 14:18:46,733:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-16 14:18:47,305:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-16 14:19:04,333:INFO:PyCaret RegressionExperiment
2023-06-16 14:19:04,333:INFO:Logging name: reg-default-name
2023-06-16 14:19:04,333:INFO:ML Usecase: MLUsecase.REGRESSION
2023-06-16 14:19:04,333:INFO:version 3.0.2
2023-06-16 14:19:04,333:INFO:Initializing setup()
2023-06-16 14:19:04,333:INFO:self.USI: 1ff7
2023-06-16 14:19:04,333:INFO:self._variable_keys: {'y_test', 'X_test', 'n_jobs_param', 'logging_param', 'fold_generator', 'transform_target_param', 'pipeline', 'X_train', '_ml_usecase', 'exp_name_log', 'idx', 'fold_shuffle_param', 'y', 'seed', 'y_train', 'html_param', 'USI', 'gpu_param', 'data', '_available_plots', 'X', 'log_plots_param', 'memory', 'gpu_n_jobs_param', 'target_param', 'exp_id', 'fold_groups_param'}
2023-06-16 14:19:04,333:INFO:Checking environment
2023-06-16 14:19:04,333:INFO:python_version: 3.10.9
2023-06-16 14:19:04,334:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-06-16 14:19:04,334:INFO:machine: AMD64
2023-06-16 14:19:04,334:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-16 14:19:04,334:INFO:Memory: svmem(total=16901767168, available=8254500864, percent=51.2, used=8647266304, free=8254500864)
2023-06-16 14:19:04,334:INFO:Physical Core: 4
2023-06-16 14:19:04,334:INFO:Logical Core: 8
2023-06-16 14:19:04,334:INFO:Checking libraries
2023-06-16 14:19:04,334:INFO:System:
2023-06-16 14:19:04,334:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-06-16 14:19:04,334:INFO:executable: C:\Users\lapei\anaconda3\python.exe
2023-06-16 14:19:04,334:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-16 14:19:04,334:INFO:PyCaret required dependencies:
2023-06-16 14:19:04,334:INFO:                 pip: 22.3.1
2023-06-16 14:19:04,334:INFO:          setuptools: 65.6.3
2023-06-16 14:19:04,334:INFO:             pycaret: 3.0.2
2023-06-16 14:19:04,334:INFO:             IPython: 8.10.0
2023-06-16 14:19:04,334:INFO:          ipywidgets: 7.6.5
2023-06-16 14:19:04,334:INFO:                tqdm: 4.64.1
2023-06-16 14:19:04,334:INFO:               numpy: 1.23.5
2023-06-16 14:19:04,334:INFO:              pandas: 1.5.3
2023-06-16 14:19:04,334:INFO:              jinja2: 3.1.2
2023-06-16 14:19:04,334:INFO:               scipy: 1.10.0
2023-06-16 14:19:04,334:INFO:              joblib: 1.2.0
2023-06-16 14:19:04,334:INFO:             sklearn: 1.2.1
2023-06-16 14:19:04,334:INFO:                pyod: 1.0.9
2023-06-16 14:19:04,334:INFO:            imblearn: 0.10.1
2023-06-16 14:19:04,334:INFO:   category_encoders: 2.6.1
2023-06-16 14:19:04,335:INFO:            lightgbm: 3.3.5
2023-06-16 14:19:04,335:INFO:               numba: 0.56.4
2023-06-16 14:19:04,335:INFO:            requests: 2.28.1
2023-06-16 14:19:04,335:INFO:          matplotlib: 3.7.0
2023-06-16 14:19:04,335:INFO:          scikitplot: 0.3.7
2023-06-16 14:19:04,335:INFO:         yellowbrick: 1.5
2023-06-16 14:19:04,335:INFO:              plotly: 5.9.0
2023-06-16 14:19:04,335:INFO:             kaleido: 0.2.1
2023-06-16 14:19:04,335:INFO:         statsmodels: 0.13.5
2023-06-16 14:19:04,335:INFO:              sktime: 0.17.0
2023-06-16 14:19:04,335:INFO:               tbats: 1.1.3
2023-06-16 14:19:04,335:INFO:            pmdarima: 2.0.3
2023-06-16 14:19:04,335:INFO:              psutil: 5.9.0
2023-06-16 14:19:04,335:INFO:PyCaret optional dependencies:
2023-06-16 14:19:04,363:INFO:                shap: 0.41.0
2023-06-16 14:19:04,363:INFO:           interpret: Not installed
2023-06-16 14:19:04,363:INFO:                umap: Not installed
2023-06-16 14:19:04,363:INFO:    pandas_profiling: Not installed
2023-06-16 14:19:04,364:INFO:  explainerdashboard: Not installed
2023-06-16 14:19:04,364:INFO:             autoviz: Not installed
2023-06-16 14:19:04,364:INFO:           fairlearn: Not installed
2023-06-16 14:19:04,364:INFO:             xgboost: 1.7.3
2023-06-16 14:19:04,364:INFO:            catboost: Not installed
2023-06-16 14:19:04,364:INFO:              kmodes: Not installed
2023-06-16 14:19:04,364:INFO:             mlxtend: Not installed
2023-06-16 14:19:04,364:INFO:       statsforecast: Not installed
2023-06-16 14:19:04,364:INFO:        tune_sklearn: Not installed
2023-06-16 14:19:04,364:INFO:                 ray: Not installed
2023-06-16 14:19:04,364:INFO:            hyperopt: Not installed
2023-06-16 14:19:04,364:INFO:              optuna: Not installed
2023-06-16 14:19:04,364:INFO:               skopt: 0.9.0
2023-06-16 14:19:04,364:INFO:              mlflow: Not installed
2023-06-16 14:19:04,364:INFO:              gradio: Not installed
2023-06-16 14:19:04,364:INFO:             fastapi: Not installed
2023-06-16 14:19:04,364:INFO:             uvicorn: Not installed
2023-06-16 14:19:04,364:INFO:              m2cgen: Not installed
2023-06-16 14:19:04,364:INFO:           evidently: Not installed
2023-06-16 14:19:04,364:INFO:               fugue: Not installed
2023-06-16 14:19:04,364:INFO:           streamlit: Not installed
2023-06-16 14:19:04,364:INFO:             prophet: Not installed
2023-06-16 14:19:04,364:INFO:None
2023-06-16 14:19:04,364:INFO:Set up data.
2023-06-16 14:19:04,372:INFO:Set up train/test split.
2023-06-16 14:19:04,376:INFO:Set up index.
2023-06-16 14:19:04,376:INFO:Set up folding strategy.
2023-06-16 14:19:04,376:INFO:Assigning column types.
2023-06-16 14:19:04,379:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-16 14:19:04,379:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-16 14:19:04,383:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-16 14:19:04,386:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-16 14:19:04,433:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-16 14:19:04,468:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-16 14:19:04,469:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 14:19:04,625:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 14:19:04,625:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-16 14:19:04,629:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-16 14:19:04,632:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-16 14:19:04,679:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-16 14:19:04,715:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-16 14:19:04,715:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 14:19:04,717:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 14:19:04,718:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-06-16 14:19:04,721:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-16 14:19:04,725:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-16 14:19:04,772:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-16 14:19:04,808:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-16 14:19:04,808:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 14:19:04,810:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 14:19:04,814:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-16 14:19:04,818:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-16 14:19:04,865:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-16 14:19:04,901:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-16 14:19:04,902:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 14:19:04,904:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 14:19:04,904:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-06-16 14:19:04,911:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-16 14:19:04,958:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-16 14:19:04,994:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-16 14:19:04,994:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 14:19:04,996:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 14:19:05,003:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-16 14:19:05,051:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-16 14:19:05,087:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-16 14:19:05,087:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 14:19:05,089:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 14:19:05,090:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-06-16 14:19:05,143:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-16 14:19:05,180:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-16 14:19:05,180:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 14:19:05,182:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 14:19:05,236:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-16 14:19:05,276:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-16 14:19:05,277:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 14:19:05,279:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 14:19:05,279:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-16 14:19:05,333:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-16 14:19:05,369:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 14:19:05,371:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 14:19:05,426:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-16 14:19:05,463:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 14:19:05,465:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 14:19:05,466:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-06-16 14:19:05,559:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 14:19:05,561:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 14:19:05,656:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 14:19:05,658:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 14:19:05,661:INFO:Preparing preprocessing pipeline...
2023-06-16 14:19:05,661:INFO:Set up simple imputation.
2023-06-16 14:19:05,662:INFO:Set up column name cleaning.
2023-06-16 14:19:05,684:INFO:Finished creating preprocessing pipeline.
2023-06-16 14:19:05,689:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\lapei\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['taxa_homicidio', 'RH_adm_dir',
                                             'densidade_banda_larga',
                                             'densidade_telefonia_movel',
                                             'qtd_cursos_engenharias',
                                             'qtd_cursos_negocios_direito',
                                             'media_notas_CN', 'media_notas_CH',
                                             'media_NU_NOTA_LC',
                                             'media_NU_NOTA_MT',
                                             'media_...
                                             'Isencao_ISSQN_Sim',
                                             'Isencao_Tx_Sim',
                                             'Cessao_terrenos_Sim',
                                             'Doacao_terrenos_Sim',
                                             'Outros_mecanismos_Sim',
                                             'ISH_Baixa', 'ISH_Máxima',
                                             'ISH_Média', 'ISH_Mínima'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-06-16 14:19:05,689:INFO:Creating final display dataframe.
2023-06-16 14:19:05,754:INFO:Setup _display_container:                     Description                              Value
0                    Session id                                 42
1                        Target  qtd_abertas_Empresario_Individual
2                   Target type                         Regression
3           Original data shape                         (4456, 30)
4        Transformed data shape                         (4456, 30)
5   Transformed train set shape                         (3119, 30)
6    Transformed test set shape                         (1337, 30)
7              Numeric features                                 29
8                    Preprocess                               True
9               Imputation type                             simple
10           Numeric imputation                               mean
11       Categorical imputation                               mode
12               Fold Generator                              KFold
13                  Fold Number                                 10
14                     CPU Jobs                                 -1
15                      Use GPU                              False
16               Log Experiment                              False
17              Experiment Name                   reg-default-name
18                          USI                               1ff7
2023-06-16 14:19:05,850:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 14:19:05,853:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 14:19:05,949:INFO:Soft dependency imported: xgboost: 1.7.3
2023-06-16 14:19:05,951:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-16 14:19:05,952:INFO:setup() successfully completed in 1.83s...............
2023-06-16 14:19:14,534:INFO:Initializing compare_models()
2023-06-16 14:19:14,535:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, include=None, fold=5, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, 'include': None, 'exclude': None, 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-06-16 14:19:14,535:INFO:Checking exceptions
2023-06-16 14:19:14,538:INFO:Preparing display monitor
2023-06-16 14:19:14,561:INFO:Initializing Linear Regression
2023-06-16 14:19:14,562:INFO:Total runtime is 1.6538302103678384e-05 minutes
2023-06-16 14:19:14,565:INFO:SubProcess create_model() called ==================================
2023-06-16 14:19:14,566:INFO:Initializing create_model()
2023-06-16 14:19:14,566:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014D31A17190>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 14:19:14,566:INFO:Checking exceptions
2023-06-16 14:19:14,566:INFO:Importing libraries
2023-06-16 14:19:14,566:INFO:Copying training dataset
2023-06-16 14:19:14,571:INFO:Defining folds
2023-06-16 14:19:14,572:INFO:Declaring metric variables
2023-06-16 14:19:14,574:INFO:Importing untrained model
2023-06-16 14:19:14,578:INFO:Linear Regression Imported successfully
2023-06-16 14:19:14,583:INFO:Starting cross validation
2023-06-16 14:19:14,592:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 14:19:20,216:INFO:Calculating mean and std
2023-06-16 14:19:20,217:INFO:Creating metrics dataframe
2023-06-16 14:19:20,516:INFO:Uploading results into container
2023-06-16 14:19:20,516:INFO:Uploading model into container now
2023-06-16 14:19:20,517:INFO:_master_model_container: 1
2023-06-16 14:19:20,517:INFO:_display_container: 2
2023-06-16 14:19:20,517:INFO:LinearRegression(n_jobs=-1)
2023-06-16 14:19:20,517:INFO:create_model() successfully completed......................................
2023-06-16 14:19:20,605:INFO:SubProcess create_model() end ==================================
2023-06-16 14:19:20,606:INFO:Creating metrics dataframe
2023-06-16 14:19:20,612:INFO:Initializing Lasso Regression
2023-06-16 14:19:20,612:INFO:Total runtime is 0.10084025065104166 minutes
2023-06-16 14:19:20,615:INFO:SubProcess create_model() called ==================================
2023-06-16 14:19:20,616:INFO:Initializing create_model()
2023-06-16 14:19:20,616:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014D31A17190>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 14:19:20,616:INFO:Checking exceptions
2023-06-16 14:19:20,616:INFO:Importing libraries
2023-06-16 14:19:20,616:INFO:Copying training dataset
2023-06-16 14:19:20,622:INFO:Defining folds
2023-06-16 14:19:20,622:INFO:Declaring metric variables
2023-06-16 14:19:20,625:INFO:Importing untrained model
2023-06-16 14:19:20,628:INFO:Lasso Regression Imported successfully
2023-06-16 14:19:20,635:INFO:Starting cross validation
2023-06-16 14:19:20,636:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 14:19:23,397:INFO:Calculating mean and std
2023-06-16 14:19:23,397:INFO:Creating metrics dataframe
2023-06-16 14:19:23,686:INFO:Uploading results into container
2023-06-16 14:19:23,687:INFO:Uploading model into container now
2023-06-16 14:19:23,687:INFO:_master_model_container: 2
2023-06-16 14:19:23,688:INFO:_display_container: 2
2023-06-16 14:19:23,688:INFO:Lasso(random_state=42)
2023-06-16 14:19:23,688:INFO:create_model() successfully completed......................................
2023-06-16 14:19:23,779:INFO:SubProcess create_model() end ==================================
2023-06-16 14:19:23,779:INFO:Creating metrics dataframe
2023-06-16 14:19:23,786:INFO:Initializing Ridge Regression
2023-06-16 14:19:23,787:INFO:Total runtime is 0.1537472407023112 minutes
2023-06-16 14:19:23,789:INFO:SubProcess create_model() called ==================================
2023-06-16 14:19:23,789:INFO:Initializing create_model()
2023-06-16 14:19:23,789:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014D31A17190>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 14:19:23,789:INFO:Checking exceptions
2023-06-16 14:19:23,789:INFO:Importing libraries
2023-06-16 14:19:23,789:INFO:Copying training dataset
2023-06-16 14:19:23,795:INFO:Defining folds
2023-06-16 14:19:23,795:INFO:Declaring metric variables
2023-06-16 14:19:23,798:INFO:Importing untrained model
2023-06-16 14:19:23,802:INFO:Ridge Regression Imported successfully
2023-06-16 14:19:23,810:INFO:Starting cross validation
2023-06-16 14:19:23,811:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 14:19:24,840:INFO:Calculating mean and std
2023-06-16 14:19:24,841:INFO:Creating metrics dataframe
2023-06-16 14:19:25,139:INFO:Uploading results into container
2023-06-16 14:19:25,140:INFO:Uploading model into container now
2023-06-16 14:19:25,140:INFO:_master_model_container: 3
2023-06-16 14:19:25,141:INFO:_display_container: 2
2023-06-16 14:19:25,141:INFO:Ridge(random_state=42)
2023-06-16 14:19:25,141:INFO:create_model() successfully completed......................................
2023-06-16 14:19:25,231:INFO:SubProcess create_model() end ==================================
2023-06-16 14:19:25,231:INFO:Creating metrics dataframe
2023-06-16 14:19:25,238:INFO:Initializing Elastic Net
2023-06-16 14:19:25,238:INFO:Total runtime is 0.1779488960901896 minutes
2023-06-16 14:19:25,241:INFO:SubProcess create_model() called ==================================
2023-06-16 14:19:25,242:INFO:Initializing create_model()
2023-06-16 14:19:25,242:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014D31A17190>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 14:19:25,242:INFO:Checking exceptions
2023-06-16 14:19:25,242:INFO:Importing libraries
2023-06-16 14:19:25,242:INFO:Copying training dataset
2023-06-16 14:19:25,248:INFO:Defining folds
2023-06-16 14:19:25,249:INFO:Declaring metric variables
2023-06-16 14:19:25,253:INFO:Importing untrained model
2023-06-16 14:19:25,259:INFO:Elastic Net Imported successfully
2023-06-16 14:19:25,264:INFO:Starting cross validation
2023-06-16 14:19:25,265:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 14:19:26,315:INFO:Calculating mean and std
2023-06-16 14:19:26,316:INFO:Creating metrics dataframe
2023-06-16 14:19:26,608:INFO:Uploading results into container
2023-06-16 14:19:26,609:INFO:Uploading model into container now
2023-06-16 14:19:26,609:INFO:_master_model_container: 4
2023-06-16 14:19:26,609:INFO:_display_container: 2
2023-06-16 14:19:26,610:INFO:ElasticNet(random_state=42)
2023-06-16 14:19:26,610:INFO:create_model() successfully completed......................................
2023-06-16 14:19:26,700:INFO:SubProcess create_model() end ==================================
2023-06-16 14:19:26,700:INFO:Creating metrics dataframe
2023-06-16 14:19:26,709:INFO:Initializing Least Angle Regression
2023-06-16 14:19:26,709:INFO:Total runtime is 0.2024625460306803 minutes
2023-06-16 14:19:26,712:INFO:SubProcess create_model() called ==================================
2023-06-16 14:19:26,712:INFO:Initializing create_model()
2023-06-16 14:19:26,712:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014D31A17190>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 14:19:26,712:INFO:Checking exceptions
2023-06-16 14:19:26,713:INFO:Importing libraries
2023-06-16 14:19:26,713:INFO:Copying training dataset
2023-06-16 14:19:26,718:INFO:Defining folds
2023-06-16 14:19:26,718:INFO:Declaring metric variables
2023-06-16 14:19:26,722:INFO:Importing untrained model
2023-06-16 14:19:26,725:INFO:Least Angle Regression Imported successfully
2023-06-16 14:19:26,732:INFO:Starting cross validation
2023-06-16 14:19:26,733:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 14:19:27,771:INFO:Calculating mean and std
2023-06-16 14:19:27,772:INFO:Creating metrics dataframe
2023-06-16 14:19:28,079:INFO:Uploading results into container
2023-06-16 14:19:28,079:INFO:Uploading model into container now
2023-06-16 14:19:28,079:INFO:_master_model_container: 5
2023-06-16 14:19:28,079:INFO:_display_container: 2
2023-06-16 14:19:28,079:INFO:Lars(random_state=42)
2023-06-16 14:19:28,079:INFO:create_model() successfully completed......................................
2023-06-16 14:19:28,167:INFO:SubProcess create_model() end ==================================
2023-06-16 14:19:28,168:INFO:Creating metrics dataframe
2023-06-16 14:19:28,177:INFO:Initializing Lasso Least Angle Regression
2023-06-16 14:19:28,177:INFO:Total runtime is 0.22693243821461992 minutes
2023-06-16 14:19:28,180:INFO:SubProcess create_model() called ==================================
2023-06-16 14:19:28,180:INFO:Initializing create_model()
2023-06-16 14:19:28,180:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014D31A17190>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 14:19:28,180:INFO:Checking exceptions
2023-06-16 14:19:28,180:INFO:Importing libraries
2023-06-16 14:19:28,181:INFO:Copying training dataset
2023-06-16 14:19:28,185:INFO:Defining folds
2023-06-16 14:19:28,185:INFO:Declaring metric variables
2023-06-16 14:19:28,188:INFO:Importing untrained model
2023-06-16 14:19:28,191:INFO:Lasso Least Angle Regression Imported successfully
2023-06-16 14:19:28,198:INFO:Starting cross validation
2023-06-16 14:19:28,199:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 14:19:29,227:INFO:Calculating mean and std
2023-06-16 14:19:29,228:INFO:Creating metrics dataframe
2023-06-16 14:19:29,535:INFO:Uploading results into container
2023-06-16 14:19:29,536:INFO:Uploading model into container now
2023-06-16 14:19:29,536:INFO:_master_model_container: 6
2023-06-16 14:19:29,536:INFO:_display_container: 2
2023-06-16 14:19:29,537:INFO:LassoLars(random_state=42)
2023-06-16 14:19:29,537:INFO:create_model() successfully completed......................................
2023-06-16 14:19:29,628:INFO:SubProcess create_model() end ==================================
2023-06-16 14:19:29,628:INFO:Creating metrics dataframe
2023-06-16 14:19:29,636:INFO:Initializing Orthogonal Matching Pursuit
2023-06-16 14:19:29,637:INFO:Total runtime is 0.25126345554987584 minutes
2023-06-16 14:19:29,639:INFO:SubProcess create_model() called ==================================
2023-06-16 14:19:29,639:INFO:Initializing create_model()
2023-06-16 14:19:29,639:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014D31A17190>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 14:19:29,640:INFO:Checking exceptions
2023-06-16 14:19:29,640:INFO:Importing libraries
2023-06-16 14:19:29,640:INFO:Copying training dataset
2023-06-16 14:19:29,644:INFO:Defining folds
2023-06-16 14:19:29,644:INFO:Declaring metric variables
2023-06-16 14:19:29,647:INFO:Importing untrained model
2023-06-16 14:19:29,653:INFO:Orthogonal Matching Pursuit Imported successfully
2023-06-16 14:19:29,660:INFO:Starting cross validation
2023-06-16 14:19:29,661:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 14:19:30,724:INFO:Calculating mean and std
2023-06-16 14:19:30,725:INFO:Creating metrics dataframe
2023-06-16 14:19:31,027:INFO:Uploading results into container
2023-06-16 14:19:31,028:INFO:Uploading model into container now
2023-06-16 14:19:31,028:INFO:_master_model_container: 7
2023-06-16 14:19:31,028:INFO:_display_container: 2
2023-06-16 14:19:31,029:INFO:OrthogonalMatchingPursuit()
2023-06-16 14:19:31,029:INFO:create_model() successfully completed......................................
2023-06-16 14:19:31,118:INFO:SubProcess create_model() end ==================================
2023-06-16 14:19:31,118:INFO:Creating metrics dataframe
2023-06-16 14:19:31,127:INFO:Initializing Bayesian Ridge
2023-06-16 14:19:31,127:INFO:Total runtime is 0.27608809471130363 minutes
2023-06-16 14:19:31,129:INFO:SubProcess create_model() called ==================================
2023-06-16 14:19:31,129:INFO:Initializing create_model()
2023-06-16 14:19:31,129:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014D31A17190>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 14:19:31,129:INFO:Checking exceptions
2023-06-16 14:19:31,129:INFO:Importing libraries
2023-06-16 14:19:31,130:INFO:Copying training dataset
2023-06-16 14:19:31,134:INFO:Defining folds
2023-06-16 14:19:31,135:INFO:Declaring metric variables
2023-06-16 14:19:31,138:INFO:Importing untrained model
2023-06-16 14:19:31,142:INFO:Bayesian Ridge Imported successfully
2023-06-16 14:19:31,148:INFO:Starting cross validation
2023-06-16 14:19:31,149:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 14:19:32,202:INFO:Calculating mean and std
2023-06-16 14:19:32,203:INFO:Creating metrics dataframe
2023-06-16 14:19:32,511:INFO:Uploading results into container
2023-06-16 14:19:32,512:INFO:Uploading model into container now
2023-06-16 14:19:32,512:INFO:_master_model_container: 8
2023-06-16 14:19:32,512:INFO:_display_container: 2
2023-06-16 14:19:32,512:INFO:BayesianRidge()
2023-06-16 14:19:32,512:INFO:create_model() successfully completed......................................
2023-06-16 14:19:32,600:INFO:SubProcess create_model() end ==================================
2023-06-16 14:19:32,600:INFO:Creating metrics dataframe
2023-06-16 14:19:32,608:INFO:Initializing Passive Aggressive Regressor
2023-06-16 14:19:32,608:INFO:Total runtime is 0.300783610343933 minutes
2023-06-16 14:19:32,612:INFO:SubProcess create_model() called ==================================
2023-06-16 14:19:32,612:INFO:Initializing create_model()
2023-06-16 14:19:32,612:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014D31A17190>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 14:19:32,613:INFO:Checking exceptions
2023-06-16 14:19:32,613:INFO:Importing libraries
2023-06-16 14:19:32,613:INFO:Copying training dataset
2023-06-16 14:19:32,618:INFO:Defining folds
2023-06-16 14:19:32,618:INFO:Declaring metric variables
2023-06-16 14:19:32,620:INFO:Importing untrained model
2023-06-16 14:19:32,623:INFO:Passive Aggressive Regressor Imported successfully
2023-06-16 14:19:32,636:INFO:Starting cross validation
2023-06-16 14:19:32,637:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 14:19:33,692:INFO:Calculating mean and std
2023-06-16 14:19:33,693:INFO:Creating metrics dataframe
2023-06-16 14:19:33,993:INFO:Uploading results into container
2023-06-16 14:19:33,993:INFO:Uploading model into container now
2023-06-16 14:19:33,993:INFO:_master_model_container: 9
2023-06-16 14:19:33,993:INFO:_display_container: 2
2023-06-16 14:19:33,993:INFO:PassiveAggressiveRegressor(random_state=42)
2023-06-16 14:19:33,993:INFO:create_model() successfully completed......................................
2023-06-16 14:19:34,082:INFO:SubProcess create_model() end ==================================
2023-06-16 14:19:34,082:INFO:Creating metrics dataframe
2023-06-16 14:19:34,089:INFO:Initializing Huber Regressor
2023-06-16 14:19:34,089:INFO:Total runtime is 0.32546653747558585 minutes
2023-06-16 14:19:34,093:INFO:SubProcess create_model() called ==================================
2023-06-16 14:19:34,094:INFO:Initializing create_model()
2023-06-16 14:19:34,094:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014D31A17190>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 14:19:34,094:INFO:Checking exceptions
2023-06-16 14:19:34,094:INFO:Importing libraries
2023-06-16 14:19:34,094:INFO:Copying training dataset
2023-06-16 14:19:34,099:INFO:Defining folds
2023-06-16 14:19:34,099:INFO:Declaring metric variables
2023-06-16 14:19:34,101:INFO:Importing untrained model
2023-06-16 14:19:34,105:INFO:Huber Regressor Imported successfully
2023-06-16 14:19:34,110:INFO:Starting cross validation
2023-06-16 14:19:34,110:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 14:19:34,202:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 14:19:34,206:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 14:19:34,231:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 14:19:34,245:WARNING:C:\Users\lapei\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-16 14:19:35,230:INFO:Calculating mean and std
2023-06-16 14:19:35,231:INFO:Creating metrics dataframe
2023-06-16 14:19:35,544:INFO:Uploading results into container
2023-06-16 14:19:35,545:INFO:Uploading model into container now
2023-06-16 14:19:35,545:INFO:_master_model_container: 10
2023-06-16 14:19:35,546:INFO:_display_container: 2
2023-06-16 14:19:35,546:INFO:HuberRegressor()
2023-06-16 14:19:35,546:INFO:create_model() successfully completed......................................
2023-06-16 14:19:35,634:INFO:SubProcess create_model() end ==================================
2023-06-16 14:19:35,634:INFO:Creating metrics dataframe
2023-06-16 14:19:35,643:INFO:Initializing K Neighbors Regressor
2023-06-16 14:19:35,643:INFO:Total runtime is 0.35135804017384836 minutes
2023-06-16 14:19:35,646:INFO:SubProcess create_model() called ==================================
2023-06-16 14:19:35,646:INFO:Initializing create_model()
2023-06-16 14:19:35,646:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014D31A17190>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 14:19:35,646:INFO:Checking exceptions
2023-06-16 14:19:35,646:INFO:Importing libraries
2023-06-16 14:19:35,646:INFO:Copying training dataset
2023-06-16 14:19:35,651:INFO:Defining folds
2023-06-16 14:19:35,652:INFO:Declaring metric variables
2023-06-16 14:19:35,656:INFO:Importing untrained model
2023-06-16 14:19:35,660:INFO:K Neighbors Regressor Imported successfully
2023-06-16 14:19:35,666:INFO:Starting cross validation
2023-06-16 14:19:35,667:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 14:19:36,806:INFO:Calculating mean and std
2023-06-16 14:19:36,810:INFO:Creating metrics dataframe
2023-06-16 14:19:37,117:INFO:Uploading results into container
2023-06-16 14:19:37,118:INFO:Uploading model into container now
2023-06-16 14:19:37,118:INFO:_master_model_container: 11
2023-06-16 14:19:37,118:INFO:_display_container: 2
2023-06-16 14:19:37,118:INFO:KNeighborsRegressor(n_jobs=-1)
2023-06-16 14:19:37,119:INFO:create_model() successfully completed......................................
2023-06-16 14:19:37,207:INFO:SubProcess create_model() end ==================================
2023-06-16 14:19:37,207:INFO:Creating metrics dataframe
2023-06-16 14:19:37,218:INFO:Initializing Decision Tree Regressor
2023-06-16 14:19:37,218:INFO:Total runtime is 0.37760450442632026 minutes
2023-06-16 14:19:37,221:INFO:SubProcess create_model() called ==================================
2023-06-16 14:19:37,222:INFO:Initializing create_model()
2023-06-16 14:19:37,222:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014D31A17190>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 14:19:37,222:INFO:Checking exceptions
2023-06-16 14:19:37,222:INFO:Importing libraries
2023-06-16 14:19:37,222:INFO:Copying training dataset
2023-06-16 14:19:37,226:INFO:Defining folds
2023-06-16 14:19:37,227:INFO:Declaring metric variables
2023-06-16 14:19:37,229:INFO:Importing untrained model
2023-06-16 14:19:37,232:INFO:Decision Tree Regressor Imported successfully
2023-06-16 14:19:37,238:INFO:Starting cross validation
2023-06-16 14:19:37,239:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 14:19:38,351:INFO:Calculating mean and std
2023-06-16 14:19:38,352:INFO:Creating metrics dataframe
2023-06-16 14:19:38,659:INFO:Uploading results into container
2023-06-16 14:19:38,660:INFO:Uploading model into container now
2023-06-16 14:19:38,660:INFO:_master_model_container: 12
2023-06-16 14:19:38,660:INFO:_display_container: 2
2023-06-16 14:19:38,661:INFO:DecisionTreeRegressor(random_state=42)
2023-06-16 14:19:38,661:INFO:create_model() successfully completed......................................
2023-06-16 14:19:38,750:INFO:SubProcess create_model() end ==================================
2023-06-16 14:19:38,750:INFO:Creating metrics dataframe
2023-06-16 14:19:38,761:INFO:Initializing Random Forest Regressor
2023-06-16 14:19:38,761:INFO:Total runtime is 0.4033269842465717 minutes
2023-06-16 14:19:38,764:INFO:SubProcess create_model() called ==================================
2023-06-16 14:19:38,764:INFO:Initializing create_model()
2023-06-16 14:19:38,764:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014D31A17190>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 14:19:38,764:INFO:Checking exceptions
2023-06-16 14:19:38,764:INFO:Importing libraries
2023-06-16 14:19:38,764:INFO:Copying training dataset
2023-06-16 14:19:38,769:INFO:Defining folds
2023-06-16 14:19:38,769:INFO:Declaring metric variables
2023-06-16 14:19:38,773:INFO:Importing untrained model
2023-06-16 14:19:38,776:INFO:Random Forest Regressor Imported successfully
2023-06-16 14:19:38,782:INFO:Starting cross validation
2023-06-16 14:19:38,783:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 14:19:39,986:INFO:Calculating mean and std
2023-06-16 14:19:39,987:INFO:Creating metrics dataframe
2023-06-16 14:19:40,292:INFO:Uploading results into container
2023-06-16 14:19:40,293:INFO:Uploading model into container now
2023-06-16 14:19:40,293:INFO:_master_model_container: 13
2023-06-16 14:19:40,293:INFO:_display_container: 2
2023-06-16 14:19:40,293:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 14:19:40,293:INFO:create_model() successfully completed......................................
2023-06-16 14:19:40,380:INFO:SubProcess create_model() end ==================================
2023-06-16 14:19:40,381:INFO:Creating metrics dataframe
2023-06-16 14:19:40,390:INFO:Initializing Extra Trees Regressor
2023-06-16 14:19:40,390:INFO:Total runtime is 0.43047782182693467 minutes
2023-06-16 14:19:40,393:INFO:SubProcess create_model() called ==================================
2023-06-16 14:19:40,394:INFO:Initializing create_model()
2023-06-16 14:19:40,394:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014D31A17190>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 14:19:40,395:INFO:Checking exceptions
2023-06-16 14:19:40,395:INFO:Importing libraries
2023-06-16 14:19:40,395:INFO:Copying training dataset
2023-06-16 14:19:40,399:INFO:Defining folds
2023-06-16 14:19:40,399:INFO:Declaring metric variables
2023-06-16 14:19:40,402:INFO:Importing untrained model
2023-06-16 14:19:40,406:INFO:Extra Trees Regressor Imported successfully
2023-06-16 14:19:40,413:INFO:Starting cross validation
2023-06-16 14:19:40,414:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 14:19:41,673:INFO:Calculating mean and std
2023-06-16 14:19:41,674:INFO:Creating metrics dataframe
2023-06-16 14:19:41,984:INFO:Uploading results into container
2023-06-16 14:19:41,984:INFO:Uploading model into container now
2023-06-16 14:19:41,985:INFO:_master_model_container: 14
2023-06-16 14:19:41,985:INFO:_display_container: 2
2023-06-16 14:19:41,985:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2023-06-16 14:19:41,985:INFO:create_model() successfully completed......................................
2023-06-16 14:19:42,072:INFO:SubProcess create_model() end ==================================
2023-06-16 14:19:42,072:INFO:Creating metrics dataframe
2023-06-16 14:19:42,082:INFO:Initializing AdaBoost Regressor
2023-06-16 14:19:42,082:INFO:Total runtime is 0.4586827476819355 minutes
2023-06-16 14:19:42,087:INFO:SubProcess create_model() called ==================================
2023-06-16 14:19:42,088:INFO:Initializing create_model()
2023-06-16 14:19:42,088:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014D31A17190>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 14:19:42,088:INFO:Checking exceptions
2023-06-16 14:19:42,088:INFO:Importing libraries
2023-06-16 14:19:42,088:INFO:Copying training dataset
2023-06-16 14:19:42,096:INFO:Defining folds
2023-06-16 14:19:42,096:INFO:Declaring metric variables
2023-06-16 14:19:42,099:INFO:Importing untrained model
2023-06-16 14:19:42,102:INFO:AdaBoost Regressor Imported successfully
2023-06-16 14:19:42,109:INFO:Starting cross validation
2023-06-16 14:19:42,110:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 14:19:43,200:INFO:Calculating mean and std
2023-06-16 14:19:43,201:INFO:Creating metrics dataframe
2023-06-16 14:19:43,513:INFO:Uploading results into container
2023-06-16 14:19:43,513:INFO:Uploading model into container now
2023-06-16 14:19:43,514:INFO:_master_model_container: 15
2023-06-16 14:19:43,514:INFO:_display_container: 2
2023-06-16 14:19:43,514:INFO:AdaBoostRegressor(random_state=42)
2023-06-16 14:19:43,514:INFO:create_model() successfully completed......................................
2023-06-16 14:19:43,604:INFO:SubProcess create_model() end ==================================
2023-06-16 14:19:43,604:INFO:Creating metrics dataframe
2023-06-16 14:19:43,614:INFO:Initializing Gradient Boosting Regressor
2023-06-16 14:19:43,616:INFO:Total runtime is 0.4842490235964456 minutes
2023-06-16 14:19:43,618:INFO:SubProcess create_model() called ==================================
2023-06-16 14:19:43,619:INFO:Initializing create_model()
2023-06-16 14:19:43,619:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014D31A17190>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 14:19:43,619:INFO:Checking exceptions
2023-06-16 14:19:43,619:INFO:Importing libraries
2023-06-16 14:19:43,619:INFO:Copying training dataset
2023-06-16 14:19:43,624:INFO:Defining folds
2023-06-16 14:19:43,624:INFO:Declaring metric variables
2023-06-16 14:19:43,627:INFO:Importing untrained model
2023-06-16 14:19:43,631:INFO:Gradient Boosting Regressor Imported successfully
2023-06-16 14:19:43,636:INFO:Starting cross validation
2023-06-16 14:19:43,638:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 14:19:44,781:INFO:Calculating mean and std
2023-06-16 14:19:44,782:INFO:Creating metrics dataframe
2023-06-16 14:19:45,093:INFO:Uploading results into container
2023-06-16 14:19:45,094:INFO:Uploading model into container now
2023-06-16 14:19:45,095:INFO:_master_model_container: 16
2023-06-16 14:19:45,095:INFO:_display_container: 2
2023-06-16 14:19:45,095:INFO:GradientBoostingRegressor(random_state=42)
2023-06-16 14:19:45,095:INFO:create_model() successfully completed......................................
2023-06-16 14:19:45,182:INFO:SubProcess create_model() end ==================================
2023-06-16 14:19:45,182:INFO:Creating metrics dataframe
2023-06-16 14:19:45,192:INFO:Initializing Extreme Gradient Boosting
2023-06-16 14:19:45,192:INFO:Total runtime is 0.5105121533075967 minutes
2023-06-16 14:19:45,196:INFO:SubProcess create_model() called ==================================
2023-06-16 14:19:45,196:INFO:Initializing create_model()
2023-06-16 14:19:45,196:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014D31A17190>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 14:19:45,197:INFO:Checking exceptions
2023-06-16 14:19:45,197:INFO:Importing libraries
2023-06-16 14:19:45,197:INFO:Copying training dataset
2023-06-16 14:19:45,202:INFO:Defining folds
2023-06-16 14:19:45,202:INFO:Declaring metric variables
2023-06-16 14:19:45,205:INFO:Importing untrained model
2023-06-16 14:19:45,208:INFO:Extreme Gradient Boosting Imported successfully
2023-06-16 14:19:45,213:INFO:Starting cross validation
2023-06-16 14:19:45,214:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 14:19:46,356:INFO:Calculating mean and std
2023-06-16 14:19:46,357:INFO:Creating metrics dataframe
2023-06-16 14:19:46,672:INFO:Uploading results into container
2023-06-16 14:19:46,673:INFO:Uploading model into container now
2023-06-16 14:19:46,673:INFO:_master_model_container: 17
2023-06-16 14:19:46,673:INFO:_display_container: 2
2023-06-16 14:19:46,674:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=42, ...)
2023-06-16 14:19:46,674:INFO:create_model() successfully completed......................................
2023-06-16 14:19:46,762:INFO:SubProcess create_model() end ==================================
2023-06-16 14:19:46,762:INFO:Creating metrics dataframe
2023-06-16 14:19:46,772:INFO:Initializing Light Gradient Boosting Machine
2023-06-16 14:19:46,772:INFO:Total runtime is 0.5368467171986896 minutes
2023-06-16 14:19:46,777:INFO:SubProcess create_model() called ==================================
2023-06-16 14:19:46,777:INFO:Initializing create_model()
2023-06-16 14:19:46,777:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014D31A17190>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 14:19:46,777:INFO:Checking exceptions
2023-06-16 14:19:46,777:INFO:Importing libraries
2023-06-16 14:19:46,778:INFO:Copying training dataset
2023-06-16 14:19:46,783:INFO:Defining folds
2023-06-16 14:19:46,783:INFO:Declaring metric variables
2023-06-16 14:19:46,787:INFO:Importing untrained model
2023-06-16 14:19:46,796:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-16 14:19:46,806:INFO:Starting cross validation
2023-06-16 14:19:46,807:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 14:19:48,870:INFO:Calculating mean and std
2023-06-16 14:19:48,871:INFO:Creating metrics dataframe
2023-06-16 14:19:49,178:INFO:Uploading results into container
2023-06-16 14:19:49,179:INFO:Uploading model into container now
2023-06-16 14:19:49,179:INFO:_master_model_container: 18
2023-06-16 14:19:49,179:INFO:_display_container: 2
2023-06-16 14:19:49,180:INFO:LGBMRegressor(random_state=42)
2023-06-16 14:19:49,180:INFO:create_model() successfully completed......................................
2023-06-16 14:19:49,270:INFO:SubProcess create_model() end ==================================
2023-06-16 14:19:49,270:INFO:Creating metrics dataframe
2023-06-16 14:19:49,280:INFO:Initializing Dummy Regressor
2023-06-16 14:19:49,280:INFO:Total runtime is 0.5786429683367409 minutes
2023-06-16 14:19:49,283:INFO:SubProcess create_model() called ==================================
2023-06-16 14:19:49,283:INFO:Initializing create_model()
2023-06-16 14:19:49,283:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014D31A17190>, model_only=True, return_train_score=False, kwargs={})
2023-06-16 14:19:49,284:INFO:Checking exceptions
2023-06-16 14:19:49,284:INFO:Importing libraries
2023-06-16 14:19:49,284:INFO:Copying training dataset
2023-06-16 14:19:49,289:INFO:Defining folds
2023-06-16 14:19:49,290:INFO:Declaring metric variables
2023-06-16 14:19:49,293:INFO:Importing untrained model
2023-06-16 14:19:49,296:INFO:Dummy Regressor Imported successfully
2023-06-16 14:19:49,302:INFO:Starting cross validation
2023-06-16 14:19:49,303:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 14:19:50,420:INFO:Calculating mean and std
2023-06-16 14:19:50,421:INFO:Creating metrics dataframe
2023-06-16 14:19:50,740:INFO:Uploading results into container
2023-06-16 14:19:50,741:INFO:Uploading model into container now
2023-06-16 14:19:50,741:INFO:_master_model_container: 19
2023-06-16 14:19:50,741:INFO:_display_container: 2
2023-06-16 14:19:50,742:INFO:DummyRegressor()
2023-06-16 14:19:50,742:INFO:create_model() successfully completed......................................
2023-06-16 14:19:50,829:INFO:SubProcess create_model() end ==================================
2023-06-16 14:19:50,829:INFO:Creating metrics dataframe
2023-06-16 14:19:50,851:INFO:Initializing create_model()
2023-06-16 14:19:50,851:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-16 14:19:50,852:INFO:Checking exceptions
2023-06-16 14:19:50,853:INFO:Importing libraries
2023-06-16 14:19:50,853:INFO:Copying training dataset
2023-06-16 14:19:50,857:INFO:Defining folds
2023-06-16 14:19:50,857:INFO:Declaring metric variables
2023-06-16 14:19:50,857:INFO:Importing untrained model
2023-06-16 14:19:50,857:INFO:Declaring custom model
2023-06-16 14:19:50,858:INFO:Random Forest Regressor Imported successfully
2023-06-16 14:19:50,858:INFO:Cross validation set to False
2023-06-16 14:19:50,858:INFO:Fitting Model
2023-06-16 14:19:51,140:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 14:19:51,140:INFO:create_model() successfully completed......................................
2023-06-16 14:19:51,254:INFO:_master_model_container: 19
2023-06-16 14:19:51,254:INFO:_display_container: 2
2023-06-16 14:19:51,255:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 14:19:51,255:INFO:compare_models() successfully completed......................................
2023-06-16 14:19:55,293:INFO:Initializing create_model()
2023-06-16 14:19:55,293:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, estimator=rf, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-16 14:19:55,293:INFO:Checking exceptions
2023-06-16 14:19:55,309:INFO:Importing libraries
2023-06-16 14:19:55,309:INFO:Copying training dataset
2023-06-16 14:19:55,317:INFO:Defining folds
2023-06-16 14:19:55,317:INFO:Declaring metric variables
2023-06-16 14:19:55,321:INFO:Importing untrained model
2023-06-16 14:19:55,326:INFO:Random Forest Regressor Imported successfully
2023-06-16 14:19:55,331:INFO:Starting cross validation
2023-06-16 14:19:55,332:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 14:19:56,520:INFO:Calculating mean and std
2023-06-16 14:19:56,521:INFO:Creating metrics dataframe
2023-06-16 14:19:56,527:INFO:Finalizing model
2023-06-16 14:19:56,890:INFO:Uploading results into container
2023-06-16 14:19:56,892:INFO:Uploading model into container now
2023-06-16 14:19:56,900:INFO:_master_model_container: 20
2023-06-16 14:19:56,900:INFO:_display_container: 3
2023-06-16 14:19:56,900:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 14:19:56,900:INFO:create_model() successfully completed......................................
2023-06-16 14:19:59,181:INFO:Initializing plot_model()
2023-06-16 14:19:59,181:INFO:plot_model(plot=learning, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, system=True)
2023-06-16 14:19:59,181:INFO:Checking exceptions
2023-06-16 14:19:59,203:INFO:Preloading libraries
2023-06-16 14:19:59,234:INFO:Copying training dataset
2023-06-16 14:19:59,234:INFO:Plot type: learning
2023-06-16 14:19:59,306:INFO:Fitting Model
2023-06-16 14:21:17,138:INFO:Visual Rendered Successfully
2023-06-16 14:21:17,246:INFO:plot_model() successfully completed......................................
2023-06-16 14:21:17,267:INFO:Initializing plot_model()
2023-06-16 14:21:17,268:INFO:plot_model(plot=vc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, system=True)
2023-06-16 14:21:17,268:INFO:Checking exceptions
2023-06-16 14:21:17,289:INFO:Preloading libraries
2023-06-16 14:21:17,321:INFO:Copying training dataset
2023-06-16 14:21:17,321:INFO:Plot type: vc
2023-06-16 14:21:17,321:INFO:Determining param_name
2023-06-16 14:21:17,321:INFO:param_name: max_depth
2023-06-16 14:21:17,397:INFO:Fitting Model
2023-06-16 14:22:05,903:INFO:Visual Rendered Successfully
2023-06-16 14:22:06,007:INFO:plot_model() successfully completed......................................
2023-06-16 14:22:06,028:INFO:Initializing plot_model()
2023-06-16 14:22:06,029:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, system=True)
2023-06-16 14:22:06,029:INFO:Checking exceptions
2023-06-16 14:22:06,051:INFO:Preloading libraries
2023-06-16 14:22:06,084:INFO:Copying training dataset
2023-06-16 14:22:06,084:INFO:Plot type: error
2023-06-16 14:22:06,181:INFO:Fitting Model
2023-06-16 14:22:06,181:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2023-06-16 14:22:06,182:INFO:Scoring test/hold-out set
2023-06-16 14:22:06,531:INFO:Visual Rendered Successfully
2023-06-16 14:22:06,629:INFO:plot_model() successfully completed......................................
2023-06-16 14:22:06,639:INFO:Initializing plot_model()
2023-06-16 14:22:06,640:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, system=True)
2023-06-16 14:22:06,640:INFO:Checking exceptions
2023-06-16 14:22:06,661:INFO:Preloading libraries
2023-06-16 14:22:06,691:INFO:Copying training dataset
2023-06-16 14:22:06,692:INFO:Plot type: feature
2023-06-16 14:22:06,692:WARNING:No coef_ found. Trying feature_importances_
2023-06-16 14:22:06,854:INFO:Visual Rendered Successfully
2023-06-16 14:22:06,947:INFO:plot_model() successfully completed......................................
2023-06-16 14:22:06,973:INFO:Initializing plot_model()
2023-06-16 14:22:06,974:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=3, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, system=True)
2023-06-16 14:22:06,974:INFO:Checking exceptions
2023-06-16 14:22:06,994:INFO:Preloading libraries
2023-06-16 14:22:07,023:INFO:Copying training dataset
2023-06-16 14:22:07,023:INFO:Plot type: residuals
2023-06-16 14:22:07,112:INFO:Fitting Model
2023-06-16 14:22:07,112:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2023-06-16 14:22:07,182:INFO:Scoring test/hold-out set
2023-06-16 14:22:07,696:INFO:Visual Rendered Successfully
2023-06-16 14:22:07,789:INFO:plot_model() successfully completed......................................
2023-06-16 14:23:21,948:INFO:Initializing interpret_model()
2023-06-16 14:23:21,948:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>)
2023-06-16 14:23:21,948:INFO:Checking exceptions
2023-06-16 14:23:21,948:INFO:Soft dependency imported: shap: 0.41.0
2023-06-16 14:23:21,971:INFO:plot type: summary
2023-06-16 14:23:21,971:INFO:Creating TreeExplainer
2023-06-16 14:23:21,985:INFO:Compiling shap values
2023-06-16 14:24:34,791:WARNING:No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored

2023-06-16 14:24:35,284:INFO:Visual Rendered Successfully
2023-06-16 14:24:35,284:INFO:interpret_model() successfully completed......................................
2023-06-16 14:24:35,388:INFO:Initializing interpret_model()
2023-06-16 14:24:35,389:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=correlation, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>)
2023-06-16 14:24:35,389:INFO:Checking exceptions
2023-06-16 14:24:35,389:INFO:Soft dependency imported: shap: 0.41.0
2023-06-16 14:24:35,413:INFO:plot type: correlation
2023-06-16 14:24:35,413:WARNING:No feature passed. Default value of feature used for correlation plot: taxa_homicidio
2023-06-16 14:24:35,413:INFO:Creating TreeExplainer
2023-06-16 14:24:35,429:INFO:Compiling shap values
2023-06-16 14:25:49,663:INFO:model type detected: type 2
2023-06-16 14:25:49,864:INFO:Visual Rendered Successfully
2023-06-16 14:25:49,865:INFO:interpret_model() successfully completed......................................
2023-06-16 14:25:49,966:INFO:Initializing interpret_model()
2023-06-16 14:25:49,966:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=1, plot=reason, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>)
2023-06-16 14:25:49,966:INFO:Checking exceptions
2023-06-16 14:25:49,966:INFO:Soft dependency imported: shap: 0.41.0
2023-06-16 14:25:49,986:INFO:plot type: reason
2023-06-16 14:25:49,986:INFO:model type detected: type 2
2023-06-16 14:25:49,986:INFO:Creating TreeExplainer
2023-06-16 14:25:50,001:INFO:Compiling shap values
2023-06-16 14:27:05,135:INFO:Visual Rendered Successfully
2023-06-16 14:27:05,136:INFO:interpret_model() successfully completed......................................
2023-06-16 14:27:05,299:INFO:Initializing interpret_model()
2023-06-16 14:27:05,299:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=3, plot=reason, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>)
2023-06-16 14:27:05,300:INFO:Checking exceptions
2023-06-16 14:27:05,300:INFO:Soft dependency imported: shap: 0.41.0
2023-06-16 14:27:05,325:INFO:plot type: reason
2023-06-16 14:27:05,325:INFO:model type detected: type 2
2023-06-16 14:27:05,325:INFO:Creating TreeExplainer
2023-06-16 14:27:05,340:INFO:Compiling shap values
2023-06-16 14:28:20,737:INFO:Visual Rendered Successfully
2023-06-16 14:28:20,737:INFO:interpret_model() successfully completed......................................
2023-06-16 14:39:24,958:INFO:Initializing tune_model()
2023-06-16 14:39:24,958:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=5, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>)
2023-06-16 14:39:24,958:INFO:Checking exceptions
2023-06-16 14:39:24,976:INFO:Copying training dataset
2023-06-16 14:39:24,982:INFO:Checking base model
2023-06-16 14:39:24,982:INFO:Base model : Random Forest Regressor
2023-06-16 14:39:24,986:INFO:Declaring metric variables
2023-06-16 14:39:24,990:INFO:Defining Hyperparameters
2023-06-16 14:39:25,098:INFO:Tuning with n_jobs=-1
2023-06-16 14:39:25,098:INFO:Initializing RandomizedSearchCV
2023-06-16 14:39:43,284:INFO:best_params: {'actual_estimator__n_estimators': 190, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 4, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': True}
2023-06-16 14:39:43,285:INFO:Hyperparameter search completed
2023-06-16 14:39:43,285:INFO:SubProcess create_model() called ==================================
2023-06-16 14:39:43,285:INFO:Initializing create_model()
2023-06-16 14:39:43,285:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014D21088820>, model_only=True, return_train_score=False, kwargs={'n_estimators': 190, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.3, 'max_features': 1.0, 'max_depth': 4, 'criterion': 'squared_error', 'bootstrap': True})
2023-06-16 14:39:43,286:INFO:Checking exceptions
2023-06-16 14:39:43,286:INFO:Importing libraries
2023-06-16 14:39:43,286:INFO:Copying training dataset
2023-06-16 14:39:43,291:INFO:Defining folds
2023-06-16 14:39:43,291:INFO:Declaring metric variables
2023-06-16 14:39:43,294:INFO:Importing untrained model
2023-06-16 14:39:43,294:INFO:Declaring custom model
2023-06-16 14:39:43,297:INFO:Random Forest Regressor Imported successfully
2023-06-16 14:39:43,302:INFO:Starting cross validation
2023-06-16 14:39:43,303:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 14:39:44,572:INFO:Calculating mean and std
2023-06-16 14:39:44,573:INFO:Creating metrics dataframe
2023-06-16 14:39:44,577:INFO:Finalizing model
2023-06-16 14:39:44,946:INFO:Uploading results into container
2023-06-16 14:39:44,946:INFO:Uploading model into container now
2023-06-16 14:39:44,947:INFO:_master_model_container: 21
2023-06-16 14:39:44,947:INFO:_display_container: 4
2023-06-16 14:39:44,947:INFO:RandomForestRegressor(max_depth=4, min_impurity_decrease=0.3,
                      min_samples_leaf=2, n_estimators=190, n_jobs=-1,
                      random_state=42)
2023-06-16 14:39:44,948:INFO:create_model() successfully completed......................................
2023-06-16 14:39:45,043:INFO:SubProcess create_model() end ==================================
2023-06-16 14:39:45,043:INFO:choose_better activated
2023-06-16 14:39:45,045:INFO:SubProcess create_model() called ==================================
2023-06-16 14:39:45,045:INFO:Initializing create_model()
2023-06-16 14:39:45,045:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-16 14:39:45,045:INFO:Checking exceptions
2023-06-16 14:39:45,046:INFO:Importing libraries
2023-06-16 14:39:45,046:INFO:Copying training dataset
2023-06-16 14:39:45,051:INFO:Defining folds
2023-06-16 14:39:45,051:INFO:Declaring metric variables
2023-06-16 14:39:45,051:INFO:Importing untrained model
2023-06-16 14:39:45,051:INFO:Declaring custom model
2023-06-16 14:39:45,052:INFO:Random Forest Regressor Imported successfully
2023-06-16 14:39:45,052:INFO:Starting cross validation
2023-06-16 14:39:45,053:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 14:39:46,254:INFO:Calculating mean and std
2023-06-16 14:39:46,254:INFO:Creating metrics dataframe
2023-06-16 14:39:46,256:INFO:Finalizing model
2023-06-16 14:39:46,618:INFO:Uploading results into container
2023-06-16 14:39:46,619:INFO:Uploading model into container now
2023-06-16 14:39:46,619:INFO:_master_model_container: 22
2023-06-16 14:39:46,619:INFO:_display_container: 5
2023-06-16 14:39:46,619:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 14:39:46,619:INFO:create_model() successfully completed......................................
2023-06-16 14:39:46,707:INFO:SubProcess create_model() end ==================================
2023-06-16 14:39:46,708:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) result for R2 is 0.9102
2023-06-16 14:39:46,708:INFO:RandomForestRegressor(max_depth=4, min_impurity_decrease=0.3,
                      min_samples_leaf=2, n_estimators=190, n_jobs=-1,
                      random_state=42) result for R2 is 0.8871
2023-06-16 14:39:46,708:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) is best model
2023-06-16 14:39:46,709:INFO:choose_better completed
2023-06-16 14:39:46,709:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-06-16 14:39:46,716:INFO:_master_model_container: 22
2023-06-16 14:39:46,716:INFO:_display_container: 4
2023-06-16 14:39:46,717:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 14:39:46,717:INFO:tune_model() successfully completed......................................
2023-06-16 14:39:47,026:INFO:Initializing plot_model()
2023-06-16 14:39:47,026:INFO:plot_model(plot=learning, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, system=True)
2023-06-16 14:39:47,026:INFO:Checking exceptions
2023-06-16 14:39:47,044:INFO:Preloading libraries
2023-06-16 14:39:47,072:INFO:Copying training dataset
2023-06-16 14:39:47,072:INFO:Plot type: learning
2023-06-16 14:39:47,147:INFO:Fitting Model
2023-06-16 14:41:02,960:INFO:Visual Rendered Successfully
2023-06-16 14:41:03,058:INFO:plot_model() successfully completed......................................
2023-06-16 14:41:03,074:INFO:Initializing plot_model()
2023-06-16 14:41:03,075:INFO:plot_model(plot=vc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, system=True)
2023-06-16 14:41:03,075:INFO:Checking exceptions
2023-06-16 14:41:03,097:INFO:Preloading libraries
2023-06-16 14:41:03,125:INFO:Copying training dataset
2023-06-16 14:41:03,125:INFO:Plot type: vc
2023-06-16 14:41:03,125:INFO:Determining param_name
2023-06-16 14:41:03,125:INFO:param_name: max_depth
2023-06-16 14:41:03,204:INFO:Fitting Model
2023-06-16 14:41:48,321:INFO:Visual Rendered Successfully
2023-06-16 14:41:48,420:INFO:plot_model() successfully completed......................................
2023-06-16 14:41:48,434:INFO:Initializing plot_model()
2023-06-16 14:41:48,434:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, system=True)
2023-06-16 14:41:48,434:INFO:Checking exceptions
2023-06-16 14:41:48,453:INFO:Preloading libraries
2023-06-16 14:41:48,482:INFO:Copying training dataset
2023-06-16 14:41:48,482:INFO:Plot type: error
2023-06-16 14:41:48,555:INFO:Fitting Model
2023-06-16 14:41:48,555:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2023-06-16 14:41:48,555:INFO:Scoring test/hold-out set
2023-06-16 14:41:48,804:INFO:Visual Rendered Successfully
2023-06-16 14:41:48,900:INFO:plot_model() successfully completed......................................
2023-06-16 14:41:48,922:INFO:Initializing plot_model()
2023-06-16 14:41:48,922:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, system=True)
2023-06-16 14:41:48,922:INFO:Checking exceptions
2023-06-16 14:41:48,943:INFO:Preloading libraries
2023-06-16 14:41:48,971:INFO:Copying training dataset
2023-06-16 14:41:48,971:INFO:Plot type: feature
2023-06-16 14:41:48,971:WARNING:No coef_ found. Trying feature_importances_
2023-06-16 14:41:49,140:INFO:Visual Rendered Successfully
2023-06-16 14:41:49,230:INFO:plot_model() successfully completed......................................
2023-06-16 14:41:49,243:INFO:Initializing plot_model()
2023-06-16 14:41:49,244:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=3, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, system=True)
2023-06-16 14:41:49,244:INFO:Checking exceptions
2023-06-16 14:41:49,263:INFO:Preloading libraries
2023-06-16 14:41:49,289:INFO:Copying training dataset
2023-06-16 14:41:49,289:INFO:Plot type: residuals
2023-06-16 14:41:49,377:INFO:Fitting Model
2023-06-16 14:41:49,378:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2023-06-16 14:41:49,445:INFO:Scoring test/hold-out set
2023-06-16 14:41:49,968:INFO:Visual Rendered Successfully
2023-06-16 14:41:50,064:INFO:plot_model() successfully completed......................................
2023-06-16 14:41:50,120:INFO:Initializing interpret_model()
2023-06-16 14:41:50,120:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>)
2023-06-16 14:41:50,120:INFO:Checking exceptions
2023-06-16 14:41:50,120:INFO:Soft dependency imported: shap: 0.41.0
2023-06-16 14:41:50,140:INFO:plot type: summary
2023-06-16 14:41:50,140:INFO:Creating TreeExplainer
2023-06-16 14:41:50,155:INFO:Compiling shap values
2023-06-16 14:43:06,380:WARNING:No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored

2023-06-16 14:43:06,853:INFO:Visual Rendered Successfully
2023-06-16 14:43:06,853:INFO:interpret_model() successfully completed......................................
2023-06-16 14:43:06,969:INFO:Initializing interpret_model()
2023-06-16 14:43:06,969:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=correlation, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>)
2023-06-16 14:43:06,969:INFO:Checking exceptions
2023-06-16 14:43:06,969:INFO:Soft dependency imported: shap: 0.41.0
2023-06-16 14:43:06,990:INFO:plot type: correlation
2023-06-16 14:43:06,990:WARNING:No feature passed. Default value of feature used for correlation plot: taxa_homicidio
2023-06-16 14:43:06,990:INFO:Creating TreeExplainer
2023-06-16 14:43:07,004:INFO:Compiling shap values
2023-06-16 14:44:22,682:INFO:model type detected: type 2
2023-06-16 14:44:22,893:INFO:Visual Rendered Successfully
2023-06-16 14:44:22,893:INFO:interpret_model() successfully completed......................................
2023-06-16 14:44:23,000:INFO:Initializing interpret_model()
2023-06-16 14:44:23,000:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=1, plot=reason, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>)
2023-06-16 14:44:23,000:INFO:Checking exceptions
2023-06-16 14:44:23,000:INFO:Soft dependency imported: shap: 0.41.0
2023-06-16 14:44:23,020:INFO:plot type: reason
2023-06-16 14:44:23,020:INFO:model type detected: type 2
2023-06-16 14:44:23,020:INFO:Creating TreeExplainer
2023-06-16 14:44:23,035:INFO:Compiling shap values
2023-06-16 14:45:41,621:INFO:Visual Rendered Successfully
2023-06-16 14:45:41,621:INFO:interpret_model() successfully completed......................................
2023-06-16 14:45:41,736:INFO:Initializing interpret_model()
2023-06-16 14:45:41,736:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=3, plot=reason, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>)
2023-06-16 14:45:41,736:INFO:Checking exceptions
2023-06-16 14:45:41,736:INFO:Soft dependency imported: shap: 0.41.0
2023-06-16 14:45:41,756:INFO:plot type: reason
2023-06-16 14:45:41,757:INFO:model type detected: type 2
2023-06-16 14:45:41,757:INFO:Creating TreeExplainer
2023-06-16 14:45:41,771:INFO:Compiling shap values
2023-06-16 14:46:59,326:INFO:Visual Rendered Successfully
2023-06-16 14:46:59,326:INFO:interpret_model() successfully completed......................................
2023-06-16 14:46:59,459:INFO:Initializing tune_model()
2023-06-16 14:46:59,459:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=5, round=4, n_iter=10, custom_grid={'max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>)
2023-06-16 14:46:59,460:INFO:Checking exceptions
2023-06-16 14:46:59,476:INFO:Copying training dataset
2023-06-16 14:46:59,483:INFO:Checking base model
2023-06-16 14:46:59,484:INFO:Base model : Random Forest Regressor
2023-06-16 14:46:59,487:INFO:Declaring metric variables
2023-06-16 14:46:59,491:INFO:Defining Hyperparameters
2023-06-16 14:46:59,602:INFO:custom_grid: {'actual_estimator__max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}
2023-06-16 14:46:59,602:INFO:Tuning with n_jobs=-1
2023-06-16 14:46:59,603:INFO:Initializing RandomizedSearchCV
2023-06-16 14:47:00,124:WARNING:A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.

2023-06-16 14:47:22,977:WARNING:
5 fits failed out of a total of 50.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\lapei\anaconda3\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py", line 340, in fit
    self._validate_params()
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\base.py", line 581, in _validate_params
    validate_parameter_constraints(
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 97, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestRegressor must be an int in the range [1, inf) or None. Got 0 instead.


2023-06-16 14:47:22,978:WARNING:One or more of the test scores are non-finite: [       nan 0.48652662 0.84008985 0.88700297 0.89957066 0.90836024
 0.90866937 0.90843499 0.90995616 0.91114377]

2023-06-16 14:47:23,294:INFO:best_params: {'actual_estimator__max_depth': 10}
2023-06-16 14:47:23,295:INFO:Hyperparameter search completed
2023-06-16 14:47:23,295:INFO:SubProcess create_model() called ==================================
2023-06-16 14:47:23,295:INFO:Initializing create_model()
2023-06-16 14:47:23,295:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014D319977F0>, model_only=True, return_train_score=False, kwargs={'max_depth': 10})
2023-06-16 14:47:23,295:INFO:Checking exceptions
2023-06-16 14:47:23,295:INFO:Importing libraries
2023-06-16 14:47:23,295:INFO:Copying training dataset
2023-06-16 14:47:23,301:INFO:Defining folds
2023-06-16 14:47:23,301:INFO:Declaring metric variables
2023-06-16 14:47:23,304:INFO:Importing untrained model
2023-06-16 14:47:23,304:INFO:Declaring custom model
2023-06-16 14:47:23,307:INFO:Random Forest Regressor Imported successfully
2023-06-16 14:47:23,314:INFO:Starting cross validation
2023-06-16 14:47:23,315:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 14:47:24,802:INFO:Calculating mean and std
2023-06-16 14:47:24,804:INFO:Creating metrics dataframe
2023-06-16 14:47:24,809:INFO:Finalizing model
2023-06-16 14:47:25,200:INFO:Uploading results into container
2023-06-16 14:47:25,201:INFO:Uploading model into container now
2023-06-16 14:47:25,201:INFO:_master_model_container: 23
2023-06-16 14:47:25,201:INFO:_display_container: 5
2023-06-16 14:47:25,202:INFO:RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42)
2023-06-16 14:47:25,202:INFO:create_model() successfully completed......................................
2023-06-16 14:47:25,304:INFO:SubProcess create_model() end ==================================
2023-06-16 14:47:25,304:INFO:choose_better activated
2023-06-16 14:47:25,308:INFO:SubProcess create_model() called ==================================
2023-06-16 14:47:25,308:INFO:Initializing create_model()
2023-06-16 14:47:25,308:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-16 14:47:25,308:INFO:Checking exceptions
2023-06-16 14:47:25,310:INFO:Importing libraries
2023-06-16 14:47:25,310:INFO:Copying training dataset
2023-06-16 14:47:25,314:INFO:Defining folds
2023-06-16 14:47:25,314:INFO:Declaring metric variables
2023-06-16 14:47:25,314:INFO:Importing untrained model
2023-06-16 14:47:25,314:INFO:Declaring custom model
2023-06-16 14:47:25,315:INFO:Random Forest Regressor Imported successfully
2023-06-16 14:47:25,315:INFO:Starting cross validation
2023-06-16 14:47:25,316:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 14:47:26,805:INFO:Calculating mean and std
2023-06-16 14:47:26,806:INFO:Creating metrics dataframe
2023-06-16 14:47:26,807:INFO:Finalizing model
2023-06-16 14:47:27,214:INFO:Uploading results into container
2023-06-16 14:47:27,215:INFO:Uploading model into container now
2023-06-16 14:47:27,215:INFO:_master_model_container: 24
2023-06-16 14:47:27,215:INFO:_display_container: 6
2023-06-16 14:47:27,216:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 14:47:27,216:INFO:create_model() successfully completed......................................
2023-06-16 14:47:27,312:INFO:SubProcess create_model() end ==================================
2023-06-16 14:47:27,312:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) result for R2 is 0.9102
2023-06-16 14:47:27,314:INFO:RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42) result for R2 is 0.9111
2023-06-16 14:47:27,314:INFO:RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42) is best model
2023-06-16 14:47:27,314:INFO:choose_better completed
2023-06-16 14:47:27,322:INFO:_master_model_container: 24
2023-06-16 14:47:27,322:INFO:_display_container: 5
2023-06-16 14:47:27,322:INFO:RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42)
2023-06-16 14:47:27,323:INFO:tune_model() successfully completed......................................
2023-06-16 14:47:27,647:INFO:Initializing tune_model()
2023-06-16 14:47:27,647:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=5, round=4, n_iter=10, custom_grid={'max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'min_samples_split': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'min_samples_leaf': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'ccp_alpha': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.9]}, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>)
2023-06-16 14:47:27,648:INFO:Checking exceptions
2023-06-16 14:47:27,667:INFO:Copying training dataset
2023-06-16 14:47:27,671:INFO:Checking base model
2023-06-16 14:47:27,671:INFO:Base model : Random Forest Regressor
2023-06-16 14:47:27,674:INFO:Declaring metric variables
2023-06-16 14:47:27,678:INFO:Defining Hyperparameters
2023-06-16 14:47:27,775:INFO:custom_grid: {'actual_estimator__max_depth': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'actual_estimator__min_samples_split': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'actual_estimator__min_samples_leaf': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'actual_estimator__ccp_alpha': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.9]}
2023-06-16 14:47:27,775:INFO:Tuning with n_jobs=-1
2023-06-16 14:47:27,775:INFO:Initializing RandomizedSearchCV
2023-06-16 14:47:42,731:WARNING:
10 fits failed out of a total of 50.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\lapei\anaconda3\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py", line 340, in fit
    self._validate_params()
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\base.py", line 581, in _validate_params
    validate_parameter_constraints(
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 97, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_leaf' parameter of RandomForestRegressor must be an int in the range [1, inf) or a float in the range (0.0, 1.0). Got 0 instead.

--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\lapei\anaconda3\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\lapei\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py", line 340, in fit
    self._validate_params()
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\base.py", line 581, in _validate_params
    validate_parameter_constraints(
  File "C:\Users\lapei\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 97, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestRegressor must be an int in the range [1, inf) or None. Got 0 instead.


2023-06-16 14:47:42,732:WARNING:One or more of the test scores are non-finite: [0.71688307 0.8282534  0.7137073         nan 0.78077576 0.84008985
        nan 0.70168477 0.74884873 0.90843499]

2023-06-16 14:47:43,040:INFO:best_params: {'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 1, 'actual_estimator__max_depth': 7, 'actual_estimator__ccp_alpha': 0.0}
2023-06-16 14:47:43,041:INFO:Hyperparameter search completed
2023-06-16 14:47:43,041:INFO:SubProcess create_model() called ==================================
2023-06-16 14:47:43,041:INFO:Initializing create_model()
2023-06-16 14:47:43,041:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014D33223910>, model_only=True, return_train_score=False, kwargs={'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7, 'ccp_alpha': 0.0})
2023-06-16 14:47:43,041:INFO:Checking exceptions
2023-06-16 14:47:43,041:INFO:Importing libraries
2023-06-16 14:47:43,042:INFO:Copying training dataset
2023-06-16 14:47:43,048:INFO:Defining folds
2023-06-16 14:47:43,048:INFO:Declaring metric variables
2023-06-16 14:47:43,051:INFO:Importing untrained model
2023-06-16 14:47:43,051:INFO:Declaring custom model
2023-06-16 14:47:43,055:INFO:Random Forest Regressor Imported successfully
2023-06-16 14:47:43,059:INFO:Starting cross validation
2023-06-16 14:47:43,060:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 14:47:44,422:INFO:Calculating mean and std
2023-06-16 14:47:44,424:INFO:Creating metrics dataframe
2023-06-16 14:47:44,429:INFO:Finalizing model
2023-06-16 14:47:44,797:INFO:Uploading results into container
2023-06-16 14:47:44,798:INFO:Uploading model into container now
2023-06-16 14:47:44,798:INFO:_master_model_container: 25
2023-06-16 14:47:44,798:INFO:_display_container: 6
2023-06-16 14:47:44,799:INFO:RandomForestRegressor(max_depth=7, n_jobs=-1, random_state=42)
2023-06-16 14:47:44,799:INFO:create_model() successfully completed......................................
2023-06-16 14:47:44,898:INFO:SubProcess create_model() end ==================================
2023-06-16 14:47:44,898:INFO:choose_better activated
2023-06-16 14:47:44,902:INFO:SubProcess create_model() called ==================================
2023-06-16 14:47:44,902:INFO:Initializing create_model()
2023-06-16 14:47:44,902:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-16 14:47:44,902:INFO:Checking exceptions
2023-06-16 14:47:44,903:INFO:Importing libraries
2023-06-16 14:47:44,904:INFO:Copying training dataset
2023-06-16 14:47:44,908:INFO:Defining folds
2023-06-16 14:47:44,908:INFO:Declaring metric variables
2023-06-16 14:47:44,908:INFO:Importing untrained model
2023-06-16 14:47:44,908:INFO:Declaring custom model
2023-06-16 14:47:44,909:INFO:Random Forest Regressor Imported successfully
2023-06-16 14:47:44,909:INFO:Starting cross validation
2023-06-16 14:47:44,910:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-16 14:47:46,394:INFO:Calculating mean and std
2023-06-16 14:47:46,396:INFO:Creating metrics dataframe
2023-06-16 14:47:46,397:INFO:Finalizing model
2023-06-16 14:47:46,788:INFO:Uploading results into container
2023-06-16 14:47:46,789:INFO:Uploading model into container now
2023-06-16 14:47:46,789:INFO:_master_model_container: 26
2023-06-16 14:47:46,789:INFO:_display_container: 7
2023-06-16 14:47:46,790:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 14:47:46,790:INFO:create_model() successfully completed......................................
2023-06-16 14:47:46,887:INFO:SubProcess create_model() end ==================================
2023-06-16 14:47:46,888:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) result for R2 is 0.9102
2023-06-16 14:47:46,888:INFO:RandomForestRegressor(max_depth=7, n_jobs=-1, random_state=42) result for R2 is 0.9084
2023-06-16 14:47:46,888:INFO:RandomForestRegressor(n_jobs=-1, random_state=42) is best model
2023-06-16 14:47:46,888:INFO:choose_better completed
2023-06-16 14:47:46,888:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-06-16 14:47:46,896:INFO:_master_model_container: 26
2023-06-16 14:47:46,896:INFO:_display_container: 6
2023-06-16 14:47:46,896:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-06-16 14:47:46,897:INFO:tune_model() successfully completed......................................
2023-06-16 14:47:47,218:INFO:Initializing plot_model()
2023-06-16 14:47:47,218:INFO:plot_model(plot=learning, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, system=True)
2023-06-16 14:47:47,218:INFO:Checking exceptions
2023-06-16 14:47:47,236:INFO:Preloading libraries
2023-06-16 14:47:47,244:INFO:Copying training dataset
2023-06-16 14:47:47,244:INFO:Plot type: learning
2023-06-16 14:47:47,317:INFO:Fitting Model
2023-06-16 14:48:48,277:INFO:Visual Rendered Successfully
2023-06-16 14:48:48,382:INFO:plot_model() successfully completed......................................
2023-06-16 14:48:48,394:INFO:Initializing plot_model()
2023-06-16 14:48:48,395:INFO:plot_model(plot=vc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, system=True)
2023-06-16 14:48:48,395:INFO:Checking exceptions
2023-06-16 14:48:48,414:INFO:Preloading libraries
2023-06-16 14:48:48,423:INFO:Copying training dataset
2023-06-16 14:48:48,423:INFO:Plot type: vc
2023-06-16 14:48:48,425:INFO:Determining param_name
2023-06-16 14:48:48,425:INFO:param_name: max_depth
2023-06-16 14:48:48,505:INFO:Fitting Model
2023-06-16 14:49:42,682:INFO:Visual Rendered Successfully
2023-06-16 14:49:42,801:INFO:plot_model() successfully completed......................................
2023-06-16 14:49:42,811:INFO:Initializing plot_model()
2023-06-16 14:49:42,811:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, system=True)
2023-06-16 14:49:42,811:INFO:Checking exceptions
2023-06-16 14:49:42,835:INFO:Preloading libraries
2023-06-16 14:49:42,843:INFO:Copying training dataset
2023-06-16 14:49:42,844:INFO:Plot type: error
2023-06-16 14:49:42,930:INFO:Fitting Model
2023-06-16 14:49:42,931:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2023-06-16 14:49:42,931:INFO:Scoring test/hold-out set
2023-06-16 14:49:43,202:INFO:Visual Rendered Successfully
2023-06-16 14:49:43,304:INFO:plot_model() successfully completed......................................
2023-06-16 14:49:43,322:INFO:Initializing plot_model()
2023-06-16 14:49:43,322:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, system=True)
2023-06-16 14:49:43,323:INFO:Checking exceptions
2023-06-16 14:49:43,341:INFO:Preloading libraries
2023-06-16 14:49:43,348:INFO:Copying training dataset
2023-06-16 14:49:43,348:INFO:Plot type: feature
2023-06-16 14:49:43,348:WARNING:No coef_ found. Trying feature_importances_
2023-06-16 14:49:43,519:INFO:Visual Rendered Successfully
2023-06-16 14:49:43,617:INFO:plot_model() successfully completed......................................
2023-06-16 14:49:43,634:INFO:Initializing plot_model()
2023-06-16 14:49:43,634:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=3, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, system=True)
2023-06-16 14:49:43,634:INFO:Checking exceptions
2023-06-16 14:49:43,652:INFO:Preloading libraries
2023-06-16 14:49:43,658:INFO:Copying training dataset
2023-06-16 14:49:43,658:INFO:Plot type: residuals
2023-06-16 14:49:43,752:INFO:Fitting Model
2023-06-16 14:49:43,752:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2023-06-16 14:49:43,820:INFO:Scoring test/hold-out set
2023-06-16 14:49:44,361:INFO:Visual Rendered Successfully
2023-06-16 14:49:44,465:INFO:plot_model() successfully completed......................................
2023-06-16 14:49:44,476:INFO:Initializing interpret_model()
2023-06-16 14:49:44,477:INFO:interpret_model(estimator=RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>)
2023-06-16 14:49:44,477:INFO:Checking exceptions
2023-06-16 14:49:44,477:INFO:Soft dependency imported: shap: 0.41.0
2023-06-16 14:49:44,496:INFO:plot type: summary
2023-06-16 14:49:44,496:INFO:Creating TreeExplainer
2023-06-16 14:49:44,499:INFO:Compiling shap values
2023-06-16 14:49:48,629:WARNING:No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored

2023-06-16 14:49:49,118:INFO:Visual Rendered Successfully
2023-06-16 14:49:49,119:INFO:interpret_model() successfully completed......................................
2023-06-16 14:49:49,225:INFO:Initializing interpret_model()
2023-06-16 14:49:49,225:INFO:interpret_model(estimator=RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=correlation, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>)
2023-06-16 14:49:49,225:INFO:Checking exceptions
2023-06-16 14:49:49,226:INFO:Soft dependency imported: shap: 0.41.0
2023-06-16 14:49:49,245:INFO:plot type: correlation
2023-06-16 14:49:49,245:WARNING:No feature passed. Default value of feature used for correlation plot: taxa_homicidio
2023-06-16 14:49:49,245:INFO:Creating TreeExplainer
2023-06-16 14:49:49,248:INFO:Compiling shap values
2023-06-16 14:49:53,401:INFO:model type detected: type 2
2023-06-16 14:49:53,605:INFO:Visual Rendered Successfully
2023-06-16 14:49:53,605:INFO:interpret_model() successfully completed......................................
2023-06-16 14:49:53,707:INFO:Initializing interpret_model()
2023-06-16 14:49:53,708:INFO:interpret_model(estimator=RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=1, plot=reason, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>)
2023-06-16 14:49:53,708:INFO:Checking exceptions
2023-06-16 14:49:53,708:INFO:Soft dependency imported: shap: 0.41.0
2023-06-16 14:49:53,727:INFO:plot type: reason
2023-06-16 14:49:53,727:INFO:model type detected: type 2
2023-06-16 14:49:53,727:INFO:Creating TreeExplainer
2023-06-16 14:49:53,731:INFO:Compiling shap values
2023-06-16 14:49:57,851:INFO:Visual Rendered Successfully
2023-06-16 14:49:57,851:INFO:interpret_model() successfully completed......................................
2023-06-16 14:49:57,952:INFO:Initializing interpret_model()
2023-06-16 14:49:57,952:INFO:interpret_model(estimator=RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=3, plot=reason, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>)
2023-06-16 14:49:57,952:INFO:Checking exceptions
2023-06-16 14:49:57,952:INFO:Soft dependency imported: shap: 0.41.0
2023-06-16 14:49:57,972:INFO:plot type: reason
2023-06-16 14:49:57,973:INFO:model type detected: type 2
2023-06-16 14:49:57,973:INFO:Creating TreeExplainer
2023-06-16 14:49:57,976:INFO:Compiling shap values
2023-06-16 14:50:02,181:INFO:Visual Rendered Successfully
2023-06-16 14:50:02,181:INFO:interpret_model() successfully completed......................................
2023-06-16 14:50:02,281:INFO:Initializing predict_model()
2023-06-16 14:50:02,281:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, estimator=RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000014D316A1240>)
2023-06-16 14:50:02,281:INFO:Checking exceptions
2023-06-16 14:50:02,281:INFO:Preloading libraries
2023-06-16 14:50:02,282:INFO:Set up data.
2023-06-16 14:50:02,290:INFO:Set up index.
2023-06-16 14:50:02,452:INFO:Initializing evaluate_model()
2023-06-16 14:50:02,452:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-06-16 14:50:02,467:INFO:Initializing plot_model()
2023-06-16 14:50:02,467:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014D3103F370>, system=True)
2023-06-16 14:50:02,468:INFO:Checking exceptions
2023-06-16 14:50:02,482:INFO:Preloading libraries
2023-06-16 14:50:02,509:INFO:Copying training dataset
2023-06-16 14:50:02,509:INFO:Plot type: pipeline
2023-06-16 14:50:02,622:INFO:Visual Rendered Successfully
2023-06-16 14:50:02,713:INFO:plot_model() successfully completed......................................
